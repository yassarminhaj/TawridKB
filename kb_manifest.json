{
  "tree": [
    ".env.example",
    "app.py",
    "config.py",
    "manifest.py",
    "README.txt",
    "requirements.txt",
    ".idea\\.gitignore",
    ".idea\\KB.iml",
    ".idea\\misc.xml",
    ".idea\\modules.xml",
    ".idea\\workspace.xml",
    ".idea\\inspectionProfiles\\profiles_settings.xml",
    ".venv\\.gitignore",
    ".venv\\CACHEDIR.TAG",
    ".venv\\pyvenv.cfg",
    ".venv\\Lib\\site-packages\\pip-25.1.1.virtualenv",
    ".venv\\Lib\\site-packages\\_virtualenv.pth",
    ".venv\\Lib\\site-packages\\_virtualenv.py",
    ".venv\\Lib\\site-packages\\blinker\\base.py",
    ".venv\\Lib\\site-packages\\blinker\\py.typed",
    ".venv\\Lib\\site-packages\\blinker\\_utilities.py",
    ".venv\\Lib\\site-packages\\blinker\\__init__.py",
    ".venv\\Lib\\site-packages\\blinker-1.9.0.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\blinker-1.9.0.dist-info\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\blinker-1.9.0.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\blinker-1.9.0.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\blinker-1.9.0.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\click\\core.py",
    ".venv\\Lib\\site-packages\\click\\decorators.py",
    ".venv\\Lib\\site-packages\\click\\exceptions.py",
    ".venv\\Lib\\site-packages\\click\\formatting.py",
    ".venv\\Lib\\site-packages\\click\\globals.py",
    ".venv\\Lib\\site-packages\\click\\parser.py",
    ".venv\\Lib\\site-packages\\click\\py.typed",
    ".venv\\Lib\\site-packages\\click\\shell_completion.py",
    ".venv\\Lib\\site-packages\\click\\termui.py",
    ".venv\\Lib\\site-packages\\click\\testing.py",
    ".venv\\Lib\\site-packages\\click\\types.py",
    ".venv\\Lib\\site-packages\\click\\utils.py",
    ".venv\\Lib\\site-packages\\click\\_compat.py",
    ".venv\\Lib\\site-packages\\click\\_termui_impl.py",
    ".venv\\Lib\\site-packages\\click\\_textwrap.py",
    ".venv\\Lib\\site-packages\\click\\_winconsole.py",
    ".venv\\Lib\\site-packages\\click\\__init__.py",
    ".venv\\Lib\\site-packages\\click-8.2.1.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\click-8.2.1.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\click-8.2.1.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\click-8.2.1.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\click-8.2.1.dist-info\\licenses\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\colorama\\ansi.py",
    ".venv\\Lib\\site-packages\\colorama\\ansitowin32.py",
    ".venv\\Lib\\site-packages\\colorama\\initialise.py",
    ".venv\\Lib\\site-packages\\colorama\\win32.py",
    ".venv\\Lib\\site-packages\\colorama\\winterm.py",
    ".venv\\Lib\\site-packages\\colorama\\__init__.py",
    ".venv\\Lib\\site-packages\\colorama\\tests\\ansitowin32_test.py",
    ".venv\\Lib\\site-packages\\colorama\\tests\\ansi_test.py",
    ".venv\\Lib\\site-packages\\colorama\\tests\\initialise_test.py",
    ".venv\\Lib\\site-packages\\colorama\\tests\\isatty_test.py",
    ".venv\\Lib\\site-packages\\colorama\\tests\\utils.py",
    ".venv\\Lib\\site-packages\\colorama\\tests\\winterm_test.py",
    ".venv\\Lib\\site-packages\\colorama\\tests\\__init__.py",
    ".venv\\Lib\\site-packages\\colorama-0.4.6.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\colorama-0.4.6.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\colorama-0.4.6.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\colorama-0.4.6.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\colorama-0.4.6.dist-info\\licenses\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\dotenv\\cli.py",
    ".venv\\Lib\\site-packages\\dotenv\\ipython.py",
    ".venv\\Lib\\site-packages\\dotenv\\main.py",
    ".venv\\Lib\\site-packages\\dotenv\\parser.py",
    ".venv\\Lib\\site-packages\\dotenv\\py.typed",
    ".venv\\Lib\\site-packages\\dotenv\\variables.py",
    ".venv\\Lib\\site-packages\\dotenv\\version.py",
    ".venv\\Lib\\site-packages\\dotenv\\__init__.py",
    ".venv\\Lib\\site-packages\\dotenv\\__main__.py",
    ".venv\\Lib\\site-packages\\flask\\app.py",
    ".venv\\Lib\\site-packages\\flask\\blueprints.py",
    ".venv\\Lib\\site-packages\\flask\\cli.py",
    ".venv\\Lib\\site-packages\\flask\\config.py",
    ".venv\\Lib\\site-packages\\flask\\ctx.py",
    ".venv\\Lib\\site-packages\\flask\\debughelpers.py",
    ".venv\\Lib\\site-packages\\flask\\globals.py",
    ".venv\\Lib\\site-packages\\flask\\helpers.py",
    ".venv\\Lib\\site-packages\\flask\\logging.py",
    ".venv\\Lib\\site-packages\\flask\\py.typed",
    ".venv\\Lib\\site-packages\\flask\\sessions.py",
    ".venv\\Lib\\site-packages\\flask\\signals.py",
    ".venv\\Lib\\site-packages\\flask\\templating.py",
    ".venv\\Lib\\site-packages\\flask\\testing.py",
    ".venv\\Lib\\site-packages\\flask\\typing.py",
    ".venv\\Lib\\site-packages\\flask\\views.py",
    ".venv\\Lib\\site-packages\\flask\\wrappers.py",
    ".venv\\Lib\\site-packages\\flask\\__init__.py",
    ".venv\\Lib\\site-packages\\flask\\__main__.py",
    ".venv\\Lib\\site-packages\\flask\\json\\provider.py",
    ".venv\\Lib\\site-packages\\flask\\json\\tag.py",
    ".venv\\Lib\\site-packages\\flask\\json\\__init__.py",
    ".venv\\Lib\\site-packages\\flask\\sansio\\app.py",
    ".venv\\Lib\\site-packages\\flask\\sansio\\blueprints.py",
    ".venv\\Lib\\site-packages\\flask\\sansio\\README.md",
    ".venv\\Lib\\site-packages\\flask\\sansio\\scaffold.py",
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\entry_points.txt",
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\REQUESTED",
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\licenses\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\itsdangerous\\encoding.py",
    ".venv\\Lib\\site-packages\\itsdangerous\\exc.py",
    ".venv\\Lib\\site-packages\\itsdangerous\\py.typed",
    ".venv\\Lib\\site-packages\\itsdangerous\\serializer.py",
    ".venv\\Lib\\site-packages\\itsdangerous\\signer.py",
    ".venv\\Lib\\site-packages\\itsdangerous\\timed.py",
    ".venv\\Lib\\site-packages\\itsdangerous\\url_safe.py",
    ".venv\\Lib\\site-packages\\itsdangerous\\_json.py",
    ".venv\\Lib\\site-packages\\itsdangerous\\__init__.py",
    ".venv\\Lib\\site-packages\\itsdangerous-2.2.0.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\itsdangerous-2.2.0.dist-info\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\itsdangerous-2.2.0.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\itsdangerous-2.2.0.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\itsdangerous-2.2.0.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\jinja2\\async_utils.py",
    ".venv\\Lib\\site-packages\\jinja2\\bccache.py",
    ".venv\\Lib\\site-packages\\jinja2\\compiler.py",
    ".venv\\Lib\\site-packages\\jinja2\\constants.py",
    ".venv\\Lib\\site-packages\\jinja2\\debug.py",
    ".venv\\Lib\\site-packages\\jinja2\\defaults.py",
    ".venv\\Lib\\site-packages\\jinja2\\environment.py",
    ".venv\\Lib\\site-packages\\jinja2\\exceptions.py",
    ".venv\\Lib\\site-packages\\jinja2\\ext.py",
    ".venv\\Lib\\site-packages\\jinja2\\filters.py",
    ".venv\\Lib\\site-packages\\jinja2\\idtracking.py",
    ".venv\\Lib\\site-packages\\jinja2\\lexer.py",
    ".venv\\Lib\\site-packages\\jinja2\\loaders.py",
    ".venv\\Lib\\site-packages\\jinja2\\meta.py",
    ".venv\\Lib\\site-packages\\jinja2\\nativetypes.py",
    ".venv\\Lib\\site-packages\\jinja2\\nodes.py",
    ".venv\\Lib\\site-packages\\jinja2\\optimizer.py",
    ".venv\\Lib\\site-packages\\jinja2\\parser.py",
    ".venv\\Lib\\site-packages\\jinja2\\py.typed",
    ".venv\\Lib\\site-packages\\jinja2\\runtime.py",
    ".venv\\Lib\\site-packages\\jinja2\\sandbox.py",
    ".venv\\Lib\\site-packages\\jinja2\\tests.py",
    ".venv\\Lib\\site-packages\\jinja2\\utils.py",
    ".venv\\Lib\\site-packages\\jinja2\\visitor.py",
    ".venv\\Lib\\site-packages\\jinja2\\_identifier.py",
    ".venv\\Lib\\site-packages\\jinja2\\__init__.py",
    ".venv\\Lib\\site-packages\\jinja2-3.1.6.dist-info\\entry_points.txt",
    ".venv\\Lib\\site-packages\\jinja2-3.1.6.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\jinja2-3.1.6.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\jinja2-3.1.6.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\jinja2-3.1.6.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\jinja2-3.1.6.dist-info\\licenses\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\markupsafe\\py.typed",
    ".venv\\Lib\\site-packages\\markupsafe\\_native.py",
    ".venv\\Lib\\site-packages\\markupsafe\\_speedups.c",
    ".venv\\Lib\\site-packages\\markupsafe\\_speedups.cp312-win_amd64.pyd",
    ".venv\\Lib\\site-packages\\markupsafe\\_speedups.pyi",
    ".venv\\Lib\\site-packages\\markupsafe\\__init__.py",
    ".venv\\Lib\\site-packages\\MarkupSafe-3.0.2.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\MarkupSafe-3.0.2.dist-info\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\MarkupSafe-3.0.2.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\MarkupSafe-3.0.2.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\MarkupSafe-3.0.2.dist-info\\top_level.txt",
    ".venv\\Lib\\site-packages\\MarkupSafe-3.0.2.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\pip\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\__main__.py",
    ".venv\\Lib\\site-packages\\pip\\__pip-runner__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\build_env.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cache.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\configuration.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\exceptions.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\main.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\pyproject.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\self_outdated_check.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\wheel_builder.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\autocompletion.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\cmdoptions.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\command_context.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\index_command.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\main.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\main_parser.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\parser.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\spinners.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\status_codes.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\cache.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\check.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\completion.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\configuration.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\debug.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\download.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\freeze.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\hash.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\help.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\index.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\inspect.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\install.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\list.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\lock.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\search.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\show.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\uninstall.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\wheel.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\base.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\installed.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\wheel.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\index\\collector.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\index\\package_finder.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\index\\sources.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\index\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\locations\\base.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\locations\\_distutils.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\locations\\_sysconfig.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\locations\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\base.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\_json.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_compat.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_dists.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_envs.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\candidate.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\direct_url.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\format_control.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\index.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\installation_report.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\link.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\pylock.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\scheme.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\search_scope.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\selection_prefs.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\target_python.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\wheel.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\auth.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\cache.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\download.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\lazy_wheel.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\session.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\utils.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\xmlrpc.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\check.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\freeze.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\build_tracker.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata_editable.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata_legacy.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel_editable.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel_legacy.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\install\\editable_legacy.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\install\\wheel.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\install\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\constructors.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_dependency_group.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_file.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_install.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_set.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\base.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\legacy\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\base.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\provider.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\reporter.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\requirements.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\appdirs.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\compat.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\compatibility_tags.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\datetime.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\deprecation.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\direct_url_helpers.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\egg_link.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\entrypoints.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\filesystem.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\filetypes.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\glibc.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\hashes.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\logging.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\misc.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\packaging.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\retry.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\setuptools_build.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\subprocess.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\unpacking.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\urls.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\virtualenv.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\wheel.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\_jaraco_text.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\_log.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\bazaar.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\git.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\mercurial.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\subversion.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\versioncontrol.py",
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\typing_extensions.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\vendor.txt",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\adapter.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\cache.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\controller.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\heuristics.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\serialize.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\wrapper.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\_cmd.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\caches\\file_cache.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\caches\\redis_cache.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\caches\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\certifi\\cacert.pem",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\certifi\\core.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\certifi\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\certifi\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\certifi\\__main__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\_implementation.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\_lint_dependency_groups.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\_pip_wrapper.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\_toml_compat.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\__main__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\compat.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\database.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\index.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\locators.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\manifest.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\markers.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\metadata.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\resources.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\scripts.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\t32.exe",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\t64-arm.exe",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\t64.exe",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\util.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\version.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\w32.exe",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\w64-arm.exe",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\w64.exe",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\wheel.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distro\\distro.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distro\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distro\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distro\\__main__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\codec.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\compat.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\core.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\idnadata.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\intranges.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\package_data.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\uts46data.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\msgpack\\exceptions.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\msgpack\\ext.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\msgpack\\fallback.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\msgpack\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\markers.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\metadata.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\specifiers.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\tags.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\utils.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\version.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_elffile.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_manylinux.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_musllinux.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_parser.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_structures.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_tokenizer.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\licenses\\_spdx.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\licenses\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\android.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\api.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\macos.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\unix.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\version.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\windows.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\__main__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\console.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\filter.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\formatter.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\lexer.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\modeline.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\plugin.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\regexopt.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\scanner.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\sphinxext.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\style.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\token.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\unistring.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\util.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\__main__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\filters\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\formatters\\_mapping.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\formatters\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\lexers\\python.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\lexers\\_mapping.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\lexers\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\styles\\_mapping.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\styles\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\adapters.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\api.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\auth.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\certs.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\compat.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\cookies.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\exceptions.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\help.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\hooks.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\models.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\packages.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\sessions.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\status_codes.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\structures.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\utils.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\_internal_utils.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\__version__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\providers.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\reporters.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\abstract.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\criterion.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\exceptions.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\abc.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\align.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\ansi.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\bar.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\box.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\cells.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\color.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\color_triplet.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\columns.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\console.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\constrain.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\containers.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\control.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\default_styles.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\diagnose.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\emoji.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\errors.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\filesize.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\file_proxy.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\highlighter.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\json.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\jupyter.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\layout.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\live.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\live_render.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\logging.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\markup.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\measure.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\padding.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\pager.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\palette.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\panel.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\pretty.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\progress.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\progress_bar.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\prompt.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\protocol.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\region.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\repr.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\rule.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\scope.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\screen.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\segment.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\spinner.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\status.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\style.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\styled.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\syntax.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\table.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\terminal_theme.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\text.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\theme.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\themes.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\traceback.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\tree.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_cell_widths.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_emoji_codes.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_emoji_replace.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_export_format.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_extension.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_fileno.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_inspect.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_log_render.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_loop.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_null_file.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_palettes.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_pick.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_ratio.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_spinners.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_stack.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_timer.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_windows.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_wrap.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\__main__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\_parser.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\_re.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\_types.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli_w\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli_w\\_writer.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli_w\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\py.typed",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_api.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_macos.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_openssl.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_ssl_constants.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_windows.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\connection.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\connectionpool.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\exceptions.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\fields.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\filepost.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\poolmanager.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\request.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\_collections.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\_version.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\appengine.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\ntlmpool.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\pyopenssl.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\securetransport.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\socks.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\_appengine_environ.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\_securetransport\\bindings.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\_securetransport\\low_level.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\_securetransport\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\six.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\backports\\makefile.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\backports\\weakref_finalize.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\backports\\__init__.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\connection.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\proxy.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\queue.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\request.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\response.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\retry.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\ssltransport.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\ssl_.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\ssl_match_hostname.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\timeout.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\url.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\wait.py",
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\__init__.py",
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\entry_points.txt",
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\top_level.txt",
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\licenses\\AUTHORS.txt",
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\licenses\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\entry_points.txt",
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\REQUESTED",
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\top_level.txt",
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\WHEEL",
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\licenses\\LICENSE",
    ".venv\\Lib\\site-packages\\werkzeug\\exceptions.py",
    ".venv\\Lib\\site-packages\\werkzeug\\formparser.py",
    ".venv\\Lib\\site-packages\\werkzeug\\http.py",
    ".venv\\Lib\\site-packages\\werkzeug\\local.py",
    ".venv\\Lib\\site-packages\\werkzeug\\py.typed",
    ".venv\\Lib\\site-packages\\werkzeug\\security.py",
    ".venv\\Lib\\site-packages\\werkzeug\\serving.py",
    ".venv\\Lib\\site-packages\\werkzeug\\test.py",
    ".venv\\Lib\\site-packages\\werkzeug\\testapp.py",
    ".venv\\Lib\\site-packages\\werkzeug\\urls.py",
    ".venv\\Lib\\site-packages\\werkzeug\\user_agent.py",
    ".venv\\Lib\\site-packages\\werkzeug\\utils.py",
    ".venv\\Lib\\site-packages\\werkzeug\\wsgi.py",
    ".venv\\Lib\\site-packages\\werkzeug\\_internal.py",
    ".venv\\Lib\\site-packages\\werkzeug\\_reloader.py",
    ".venv\\Lib\\site-packages\\werkzeug\\__init__.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\accept.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\auth.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\cache_control.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\csp.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\etag.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\file_storage.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\headers.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\mixins.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\range.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\structures.py",
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\__init__.py",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\console.py",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\repr.py",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\tbtools.py",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\__init__.py",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\console.png",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\debugger.js",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\ICON_LICENSE.md",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\less.png",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\more.png",
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\style.css",
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\dispatcher.py",
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\http_proxy.py",
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\lint.py",
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\profiler.py",
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\proxy_fix.py",
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\shared_data.py",
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\__init__.py",
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\converters.py",
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\exceptions.py",
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\map.py",
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\matcher.py",
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\rules.py",
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\__init__.py",
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\http.py",
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\multipart.py",
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\request.py",
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\response.py",
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\utils.py",
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\__init__.py",
    ".venv\\Lib\\site-packages\\werkzeug\\wrappers\\request.py",
    ".venv\\Lib\\site-packages\\werkzeug\\wrappers\\response.py",
    ".venv\\Lib\\site-packages\\werkzeug\\wrappers\\__init__.py",
    ".venv\\Lib\\site-packages\\werkzeug-3.1.3.dist-info\\INSTALLER",
    ".venv\\Lib\\site-packages\\werkzeug-3.1.3.dist-info\\LICENSE.txt",
    ".venv\\Lib\\site-packages\\werkzeug-3.1.3.dist-info\\METADATA",
    ".venv\\Lib\\site-packages\\werkzeug-3.1.3.dist-info\\RECORD",
    ".venv\\Lib\\site-packages\\werkzeug-3.1.3.dist-info\\WHEEL",
    ".venv\\Scripts\\activate",
    ".venv\\Scripts\\activate.bat",
    ".venv\\Scripts\\activate.fish",
    ".venv\\Scripts\\activate.nu",
    ".venv\\Scripts\\activate.ps1",
    ".venv\\Scripts\\activate_this.py",
    ".venv\\Scripts\\deactivate.bat",
    ".venv\\Scripts\\dotenv.exe",
    ".venv\\Scripts\\flask.exe",
    ".venv\\Scripts\\pip-3.12.exe",
    ".venv\\Scripts\\pip.exe",
    ".venv\\Scripts\\pip3.12.exe",
    ".venv\\Scripts\\pip3.exe",
    ".venv\\Scripts\\pydoc.bat",
    ".venv\\Scripts\\python.exe",
    ".venv\\Scripts\\pythonw.exe",
    "static\\css\\custom.css",
    "static\\css\\normalize.css",
    "static\\css\\skeleton.css",
    "static\\images\\default-logo.png",
    "static\\js\\jquery.min.js",
    "static\\js\\site.js",
    "templates\\base.html",
    "templates\\index.html",
    "templates\\view.html",
    "uploads\\pdf\\01_supplier\\ReportGeneration_Cortex.html",
    "uploads\\pdf\\01_supplier\\ReportGeneration_Cortex.pdf",
    "uploads\\pdf\\01_supplier\\Restart_CORTEX_CC_services.html",
    "uploads\\pdf\\01_supplier\\Restart_CORTEX_CC_services.pdf",
    "uploads\\pdf\\02_buyer\\Issuance_Fawri_Card_manual.html",
    "uploads\\pdf\\02_buyer\\Issuance_Fawri_Card_manual.pdf",
    "uploads\\pdf\\02_buyer\\New Text Document.txt",
    "uploads\\pdf\\02_buyer\\SymexUserManual.html",
    "uploads\\pdf\\02_buyer\\SymexUserManual.pdf",
    "uploads\\pdf\\03_funder\\Cashier_System_Guide.html",
    "uploads\\pdf\\03_funder\\Cashier_System_Guide.pdf",
    "uploads\\videos\\01_supplier\\01_SupplierOboarding.mp4",
    "uploads\\videos\\01_supplier\\02_CAEnablingKYCCompletion.mp4",
    "uploads\\videos\\01_supplier\\03_CA Creating New User.mp4",
    "uploads\\videos\\01_supplier\\04_Delegator Actions.mp4",
    "uploads\\videos\\01_supplier\\05_SayenRegistrationProcess.mp4",
    "uploads\\videos\\01_supplier\\06_Signatory Actions.mp4",
    "uploads\\videos\\01_supplier\\07_Program Acceptance & Notification.mp4",
    "uploads\\videos\\01_supplier\\08_Program Notification.mp4",
    "uploads\\videos\\01_supplier\\09_SupplierIBAN Update.mp4",
    "uploads\\videos\\01_supplier\\10_Business Rule.mp4",
    "uploads\\videos\\01_supplier\\11_Additional User.mp4",
    "uploads\\videos\\01_supplier\\final_with_chapters.mp4",
    "uploads\\videos\\02_buyer\\01_BuyerOnboarding.mp4",
    "uploads\\videos\\02_buyer\\02_CA User Creations.mp4",
    "uploads\\videos\\02_buyer\\03_Delegator Actions.mp4",
    "uploads\\videos\\02_buyer\\04_SayenRegistration.mp4",
    "uploads\\videos\\02_buyer\\05_SignatoryActions.mp4",
    "uploads\\videos\\02_buyer\\06_SupplierOboardingBy Buyer- For buyer video.mp4",
    "uploads\\videos\\02_buyer\\07_Program Acceptance.mp4",
    "uploads\\videos\\02_buyer\\08_Invoice Submission.mp4",
    "uploads\\videos\\02_buyer\\09_Notifications.mp4"
  ],
  "files": {
    "app.py": {
      "sha": "a84457dba501",
      "lines": 76,
      "head": "\nfrom __future__ import annotations\nimport pathlib, mimetypes, os\nfrom flask import Flask, render_template, send_from_directory, abort, url_for, jsonify\nfrom dotenv import load_dotenv\n\nload_dotenv()\napp = Flask(__name__)\napp.config.from_object(\"config.Config\")\n\nROOT = pathlib.Path(__file__).resolve().parent\nUPLOAD_ROOT = ROOT / app.config[\"UPLOAD_ROOT\"]\nUPLOAD_ROOT.mkdir(parents=True, exist_ok=True)\n\nVIDEO_EXTS = {e.strip().lower().lstrip(\".\") for e in app.config[\"ALLOWED_VIDEO_EXT\"]}\n\ndef safe_rel(p: pathlib.Path) -> str:\n    return str(p.relative_to(UPLOAD_ROOT).as_posix())\n\ndef scan_videos():\n    out = {}\n    base = UPLOAD_ROOT / \"videos\"\n    for code, label in app.config[\"CATEGORIES\"]:\n        folder = base / code\n        items = []\n        if folder.exists():\n            for p in sorted(folder.glob(\"*\")):\n                if p.is_file() and p.suffix.lower().lstrip(\".\") in VIDEO_EXTS:\n                    items.append({\"name\": p.name, \"url\": url_for(\"uploaded_file\", filename=safe_rel(p))})\n        out[code] = items\n    return out\n\ndef scan_pdfs():\n    out = {}\n    base = UPLOAD_ROOT / \"pdf\"\n    if base.exists():\n        for folder in sorted([d for d in base.iterdir() if d.is_dir()]):\n            items = []\n            for p in sorted(folder.glob(\"*.pdf\")):\n                items.append({\n                    \"name\": p.name,\n                    \"viewer\": url_for(\"view\", rel=safe_rel(p)),\n                })\n            out[folder.name] = items  # key is the folder name (e.g., 01_supplier)\n    return out\n\n@app.route(\"/\")\ndef home():\n    return render_template(\"index.html\", categories=app.config[\"CATEGORIES\"], title=app.config[\"SITE_TITLE\"])\n\n@app.route(\"/api/videos\")\ndef api_videos():\n    return jsonify(scan_videos())\n\n@app.route(\"/api/pdfs\")\ndef api_pdfs():\n    return jsonify(scan_pdfs())\n\n@app.route(\"/view/<path:rel>\")\ndef view(rel: str):\n    p = (UPLOAD_ROOT / rel).resolve()\n    if not str(p).startswith(str(UPLOAD_ROOT)) or not p.exists():\n        abort(404)\n    mime, _ = mimetypes.guess_type(p.name)\n    return render_template(\"view.html\", file_name=p.name, file_url=url_for(\"uploaded_file\", filename=rel), mime=mime or \"application/octet-stream\")\n\n@app.route(\"/uploads/<path:filename>\")\ndef uploaded_file(filename: str):\n    return send_from_directory(UPLOAD_ROOT, filename, as_attachment=False)\n\n@app.route(\"/healthz\")\ndef healthz():\n    return {\"status\": \"ok\"}\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n"
    },
    "config.py": {
      "sha": "316e2a4109c6",
      "lines": 14,
      "head": "\nimport os\n\nclass Config:\n    SECRET_KEY = os.getenv(\"SECRET_KEY\", \"dev\")\n    UPLOAD_ROOT = os.getenv(\"UPLOAD_ROOT\", \"uploads\")\n    ALLOWED_VIDEO_EXT = set(os.getenv(\"ALLOWED_VIDEO_EXT\", \"mp4,webm,mov,m4v,avi\").lower().split(\",\"))\n    SITE_TITLE = os.getenv(\"SITE_TITLE\", \"Knowledge Base - Tawrid\")\n    BRAND = os.getenv(\"BRAND\", \"Tawrid\")\n    CATEGORIES = [\n        (\"01_supplier\", \"Supplier\"),\n        (\"02_buyer\", \"Buyer\"),\n        (\"03_funder\", \"Funder\"),\n    ]\n"
    },
    "manifest.py": {
      "sha": "6f3fe617620d",
      "lines": 34,
      "head": "import os, json, hashlib, textwrap\nroot = \".\"  # set to your project root if needed\ndef sha1(p, n=1024*64):\n    h = hashlib.sha1()\n    with open(p,'rb') as f:\n        while True:\n            b=f.read(n)\n            if not b: break\n            h.update(b)\n    return h.hexdigest()[:12]\n\nreport = {\"tree\":[], \"files\":{}}\nfor dp, dn, fn in os.walk(root):\n    if any(s in dp for s in (\".git\", \"__pycache__\", \"node_modules\")): \n        continue\n    for f in fn:\n        p = os.path.join(dp,f)\n        rel = os.path.relpath(p, root)\n        report[\"tree\"].append(rel)\n        if f.endswith((\".py\",\".html\",\".css\",\".js\",\".json\",\".md\",\".txt\")):\n            try:\n                with open(p,\"r\",encoding=\"utf-8\",errors=\"ignore\") as fh:\n                    lines = fh.readlines()\n                report[\"files\"][rel] = {\n                    \"sha\": sha1(p),\n                    \"lines\": len(lines),\n                    \"head\": \"\".join(lines[:120]),\n                }\n            except Exception as e:\n                report[\"files\"][rel] = {\"error\": str(e)}\nwith open(\"kb_manifest.json\",\"w\",encoding=\"utf-8\") as out:\n    json.dump(report, out, indent=2)\nprint(\"Wrote kb_manifest.json\")\n\n"
    },
    "README.txt": {
      "sha": "ed8832acf859",
      "lines": 39,
      "head": "\nFlask project layout (IMPORTANT: 'static' is a top-level folder, not inside 'templates'):\n\ntawrid_kb_flask_verified/\n\u251c\u2500 app.py\n\u251c\u2500 config.py\n\u251c\u2500 requirements.txt\n\u251c\u2500 .env.example\n\u251c\u2500 uploads/\n\u2502  \u251c\u2500 pdf/\n\u2502  \u2502   \u251c\u2500 01_supplier/\n\u2502  \u2502   \u251c\u2500 02_buyer/\n\u2502  \u2502   \u2514\u2500 03_funder/\n\u2502  \u2514\u2500 videos/\n\u2502      \u251c\u2500 01_supplier/\n\u2502      \u251c\u2500 02_buyer/\n\u2502      \u2514\u2500 03_funder/\n\u251c\u2500 static/                 <-- CSS/JS/IMAGES live here\n\u2502  \u251c\u2500 css/\n\u2502  \u2502   \u251c\u2500 normalize.css\n\u2502  \u2502   \u251c\u2500 skeleton.css\n\u2502  \u2502   \u251c\u2500 custom.css\n\u2502  \u2502   \u2514\u2500 (plus any others from your original project)\n\u2502  \u251c\u2500 js/\n\u2502  \u2502   \u251c\u2500 jquery.min.js\n\u2502  \u2502   \u2514\u2500 site.js\n\u2502  \u2514\u2500 images/\n\u2502      \u2514\u2500 default-logo.png (if present in your original project)\n\u2514\u2500 templates/\n   \u251c\u2500 base.html\n   \u251c\u2500 index.html\n   \u2514\u2500 view.html\n\nRun:\n  python -m venv .venv\n  source .venv/bin/activate   (Windows: .venv\\Scripts\\activate)\n  pip install -r requirements.txt\n  cp .env.example .env\n  python app.py\n"
    },
    "requirements.txt": {
      "sha": "bdf841ba4c62",
      "lines": 2,
      "head": "Flask>=3.0\npython-dotenv>=1.0\n"
    },
    ".venv\\Lib\\site-packages\\_virtualenv.py": {
      "sha": "54123c0e17bf",
      "lines": 103,
      "head": "\"\"\"Patches that are applied at runtime to the virtual environment.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport sys\n\nVIRTUALENV_PATCH_FILE = os.path.join(__file__)\n\n\ndef patch_dist(dist):\n    \"\"\"\n    Distutils allows user to configure some arguments via a configuration file:\n    https://docs.python.org/3/install/index.html#distutils-configuration-files.\n\n    Some of this arguments though don't make sense in context of the virtual environment files, let's fix them up.\n    \"\"\"  # noqa: D205\n    # we cannot allow some install config as that would get packages installed outside of the virtual environment\n    old_parse_config_files = dist.Distribution.parse_config_files\n\n    def parse_config_files(self, *args, **kwargs):\n        result = old_parse_config_files(self, *args, **kwargs)\n        install = self.get_option_dict(\"install\")\n\n        if \"prefix\" in install:  # the prefix governs where to install the libraries\n            install[\"prefix\"] = VIRTUALENV_PATCH_FILE, os.path.abspath(sys.prefix)\n        for base in (\"purelib\", \"platlib\", \"headers\", \"scripts\", \"data\"):\n            key = f\"install_{base}\"\n            if key in install:  # do not allow global configs to hijack venv paths\n                install.pop(key, None)\n        return result\n\n    dist.Distribution.parse_config_files = parse_config_files\n\n\n# Import hook that patches some modules to ignore configuration values that break package installation in case\n# of virtual environments.\n_DISTUTILS_PATCH = \"distutils.dist\", \"setuptools.dist\"\n# https://docs.python.org/3/library/importlib.html#setting-up-an-importer\n\n\nclass _Finder:\n    \"\"\"A meta path finder that allows patching the imported distutils modules.\"\"\"\n\n    fullname = None\n\n    # lock[0] is threading.Lock(), but initialized lazily to avoid importing threading very early at startup,\n    # because there are gevent-based applications that need to be first to import threading by themselves.\n    # See https://github.com/pypa/virtualenv/issues/1895 for details.\n    lock = []  # noqa: RUF012\n\n    def find_spec(self, fullname, path, target=None):  # noqa: ARG002\n        if fullname in _DISTUTILS_PATCH and self.fullname is None:  # noqa: PLR1702\n            # initialize lock[0] lazily\n            if len(self.lock) == 0:\n                import threading  # noqa: PLC0415\n\n                lock = threading.Lock()\n                # there is possibility that two threads T1 and T2 are simultaneously running into find_spec,\n                # observing .lock as empty, and further going into hereby initialization. However due to the GIL,\n                # list.append() operation is atomic and this way only one of the threads will \"win\" to put the lock\n                # - that every thread will use - into .lock[0].\n                # https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe\n                self.lock.append(lock)\n\n            from functools import partial  # noqa: PLC0415\n            from importlib.util import find_spec  # noqa: PLC0415\n\n            with self.lock[0]:\n                self.fullname = fullname\n                try:\n                    spec = find_spec(fullname, path)\n                    if spec is not None:\n                        # https://www.python.org/dev/peps/pep-0451/#how-loading-will-work\n                        is_new_api = hasattr(spec.loader, \"exec_module\")\n                        func_name = \"exec_module\" if is_new_api else \"load_module\"\n                        old = getattr(spec.loader, func_name)\n                        func = self.exec_module if is_new_api else self.load_module\n                        if old is not func:\n                            try:  # noqa: SIM105\n                                setattr(spec.loader, func_name, partial(func, old))\n                            except AttributeError:\n                                pass  # C-Extension loaders are r/o such as zipimporter with <3.7\n                        return spec\n                finally:\n                    self.fullname = None\n        return None\n\n    @staticmethod\n    def exec_module(old, module):\n        old(module)\n        if module.__name__ in _DISTUTILS_PATCH:\n            patch_dist(module)\n\n    @staticmethod\n    def load_module(old, name):\n        module = old(name)\n        if module.__name__ in _DISTUTILS_PATCH:\n            patch_dist(module)\n        return module\n\n\nsys.meta_path.insert(0, _Finder())\n"
    },
    ".venv\\Lib\\site-packages\\blinker\\base.py": {
      "sha": "37f3a2d949b1",
      "lines": 512,
      "head": "from __future__ import annotations\n\nimport collections.abc as c\nimport sys\nimport typing as t\nimport weakref\nfrom collections import defaultdict\nfrom contextlib import contextmanager\nfrom functools import cached_property\nfrom inspect import iscoroutinefunction\n\nfrom ._utilities import make_id\nfrom ._utilities import make_ref\nfrom ._utilities import Symbol\n\nF = t.TypeVar(\"F\", bound=c.Callable[..., t.Any])\n\nANY = Symbol(\"ANY\")\n\"\"\"Symbol for \"any sender\".\"\"\"\n\nANY_ID = 0\n\n\nclass Signal:\n    \"\"\"A notification emitter.\n\n    :param doc: The docstring for the signal.\n    \"\"\"\n\n    ANY = ANY\n    \"\"\"An alias for the :data:`~blinker.ANY` sender symbol.\"\"\"\n\n    set_class: type[set[t.Any]] = set\n    \"\"\"The set class to use for tracking connected receivers and senders.\n    Python's ``set`` is unordered. If receivers must be dispatched in the order\n    they were connected, an ordered set implementation can be used.\n\n    .. versionadded:: 1.7\n    \"\"\"\n\n    @cached_property\n    def receiver_connected(self) -> Signal:\n        \"\"\"Emitted at the end of each :meth:`connect` call.\n\n        The signal sender is the signal instance, and the :meth:`connect`\n        arguments are passed through: ``receiver``, ``sender``, and ``weak``.\n\n        .. versionadded:: 1.2\n        \"\"\"\n        return Signal(doc=\"Emitted after a receiver connects.\")\n\n    @cached_property\n    def receiver_disconnected(self) -> Signal:\n        \"\"\"Emitted at the end of each :meth:`disconnect` call.\n\n        The sender is the signal instance, and the :meth:`disconnect` arguments\n        are passed through: ``receiver`` and ``sender``.\n\n        This signal is emitted **only** when :meth:`disconnect` is called\n        explicitly. This signal cannot be emitted by an automatic disconnect\n        when a weakly referenced receiver or sender goes out of scope, as the\n        instance is no longer be available to be used as the sender for this\n        signal.\n\n        An alternative approach is available by subscribing to\n        :attr:`receiver_connected` and setting up a custom weakref cleanup\n        callback on weak receivers and senders.\n\n        .. versionadded:: 1.2\n        \"\"\"\n        return Signal(doc=\"Emitted after a receiver disconnects.\")\n\n    def __init__(self, doc: str | None = None) -> None:\n        if doc:\n            self.__doc__ = doc\n\n        self.receivers: dict[\n            t.Any, weakref.ref[c.Callable[..., t.Any]] | c.Callable[..., t.Any]\n        ] = {}\n        \"\"\"The map of connected receivers. Useful to quickly check if any\n        receivers are connected to the signal: ``if s.receivers:``. The\n        structure and data is not part of the public API, but checking its\n        boolean value is.\n        \"\"\"\n\n        self.is_muted: bool = False\n        self._by_receiver: dict[t.Any, set[t.Any]] = defaultdict(self.set_class)\n        self._by_sender: dict[t.Any, set[t.Any]] = defaultdict(self.set_class)\n        self._weak_senders: dict[t.Any, weakref.ref[t.Any]] = {}\n\n    def connect(self, receiver: F, sender: t.Any = ANY, weak: bool = True) -> F:\n        \"\"\"Connect ``receiver`` to be called when the signal is sent by\n        ``sender``.\n\n        :param receiver: The callable to call when :meth:`send` is called with\n            the given ``sender``, passing ``sender`` as a positional argument\n            along with any extra keyword arguments.\n        :param sender: Any object or :data:`ANY`. ``receiver`` will only be\n            called when :meth:`send` is called with this sender. If ``ANY``, the\n            receiver will be called for any sender. A receiver may be connected\n            to multiple senders by calling :meth:`connect` multiple times.\n        :param weak: Track the receiver with a :mod:`weakref`. The receiver will\n            be automatically disconnected when it is garbage collected. When\n            connecting a receiver defined within a function, set to ``False``,\n            otherwise it will be disconnected when the function scope ends.\n        \"\"\"\n        receiver_id = make_id(receiver)\n        sender_id = ANY_ID if sender is ANY else make_id(sender)\n\n        if weak:\n            self.receivers[receiver_id] = make_ref(\n                receiver, self._make_cleanup_receiver(receiver_id)\n            )\n        else:\n            self.receivers[receiver_id] = receiver\n\n        self._by_sender[sender_id].add(receiver_id)\n        self._by_receiver[receiver_id].add(sender_id)\n\n        if sender is not ANY and sender_id not in self._weak_senders:\n"
    },
    ".venv\\Lib\\site-packages\\blinker\\_utilities.py": {
      "sha": "d36a695ff3a3",
      "lines": 64,
      "head": "from __future__ import annotations\n\nimport collections.abc as c\nimport inspect\nimport typing as t\nfrom weakref import ref\nfrom weakref import WeakMethod\n\nT = t.TypeVar(\"T\")\n\n\nclass Symbol:\n    \"\"\"A constant symbol, nicer than ``object()``. Repeated calls return the\n    same instance.\n\n    >>> Symbol('foo') is Symbol('foo')\n    True\n    >>> Symbol('foo')\n    foo\n    \"\"\"\n\n    symbols: t.ClassVar[dict[str, Symbol]] = {}\n\n    def __new__(cls, name: str) -> Symbol:\n        if name in cls.symbols:\n            return cls.symbols[name]\n\n        obj = super().__new__(cls)\n        cls.symbols[name] = obj\n        return obj\n\n    def __init__(self, name: str) -> None:\n        self.name = name\n\n    def __repr__(self) -> str:\n        return self.name\n\n    def __getnewargs__(self) -> tuple[t.Any, ...]:\n        return (self.name,)\n\n\ndef make_id(obj: object) -> c.Hashable:\n    \"\"\"Get a stable identifier for a receiver or sender, to be used as a dict\n    key or in a set.\n    \"\"\"\n    if inspect.ismethod(obj):\n        # The id of a bound method is not stable, but the id of the unbound\n        # function and instance are.\n        return id(obj.__func__), id(obj.__self__)\n\n    if isinstance(obj, (str, int)):\n        # Instances with the same value always compare equal and have the same\n        # hash, even if the id may change.\n        return obj\n\n    # Assume other types are not hashable but will always be the same instance.\n    return id(obj)\n\n\ndef make_ref(obj: T, callback: c.Callable[[ref[T]], None] | None = None) -> ref[T]:\n    if inspect.ismethod(obj):\n        return WeakMethod(obj, callback)  # type: ignore[arg-type, return-value]\n\n    return ref(obj, callback)\n"
    },
    ".venv\\Lib\\site-packages\\blinker\\__init__.py": {
      "sha": "9eb186f45e34",
      "lines": 17,
      "head": "from __future__ import annotations\n\nfrom .base import ANY\nfrom .base import default_namespace\nfrom .base import NamedSignal\nfrom .base import Namespace\nfrom .base import Signal\nfrom .base import signal\n\n__all__ = [\n    \"ANY\",\n    \"default_namespace\",\n    \"NamedSignal\",\n    \"Namespace\",\n    \"Signal\",\n    \"signal\",\n]\n"
    },
    ".venv\\Lib\\site-packages\\blinker-1.9.0.dist-info\\LICENSE.txt": {
      "sha": "7e4783e85688",
      "lines": 20,
      "head": "Copyright 2010 Jason Kirtland\n\nPermission is hereby granted, free of charge, to any person obtaining a\ncopy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\nOR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
    },
    ".venv\\Lib\\site-packages\\click\\core.py": {
      "sha": "6d1a61a787f1",
      "lines": 3135,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport enum\nimport errno\nimport inspect\nimport os\nimport sys\nimport typing as t\nfrom collections import abc\nfrom collections import Counter\nfrom contextlib import AbstractContextManager\nfrom contextlib import contextmanager\nfrom contextlib import ExitStack\nfrom functools import update_wrapper\nfrom gettext import gettext as _\nfrom gettext import ngettext\nfrom itertools import repeat\nfrom types import TracebackType\n\nfrom . import types\nfrom .exceptions import Abort\nfrom .exceptions import BadParameter\nfrom .exceptions import ClickException\nfrom .exceptions import Exit\nfrom .exceptions import MissingParameter\nfrom .exceptions import NoArgsIsHelpError\nfrom .exceptions import UsageError\nfrom .formatting import HelpFormatter\nfrom .formatting import join_options\nfrom .globals import pop_context\nfrom .globals import push_context\nfrom .parser import _flag_needs_value\nfrom .parser import _OptionParser\nfrom .parser import _split_opt\nfrom .termui import confirm\nfrom .termui import prompt\nfrom .termui import style\nfrom .utils import _detect_program_name\nfrom .utils import _expand_args\nfrom .utils import echo\nfrom .utils import make_default_short_help\nfrom .utils import make_str\nfrom .utils import PacifyFlushWrapper\n\nif t.TYPE_CHECKING:\n    from .shell_completion import CompletionItem\n\nF = t.TypeVar(\"F\", bound=\"t.Callable[..., t.Any]\")\nV = t.TypeVar(\"V\")\n\n\ndef _complete_visible_commands(\n    ctx: Context, incomplete: str\n) -> cabc.Iterator[tuple[str, Command]]:\n    \"\"\"List all the subcommands of a group that start with the\n    incomplete value and aren't hidden.\n\n    :param ctx: Invocation context for the group.\n    :param incomplete: Value being completed. May be empty.\n    \"\"\"\n    multi = t.cast(Group, ctx.command)\n\n    for name in multi.list_commands(ctx):\n        if name.startswith(incomplete):\n            command = multi.get_command(ctx, name)\n\n            if command is not None and not command.hidden:\n                yield name, command\n\n\ndef _check_nested_chain(\n    base_command: Group, cmd_name: str, cmd: Command, register: bool = False\n) -> None:\n    if not base_command.chain or not isinstance(cmd, Group):\n        return\n\n    if register:\n        message = (\n            f\"It is not possible to add the group {cmd_name!r} to another\"\n            f\" group {base_command.name!r} that is in chain mode.\"\n        )\n    else:\n        message = (\n            f\"Found the group {cmd_name!r} as subcommand to another group \"\n            f\" {base_command.name!r} that is in chain mode. This is not supported.\"\n        )\n\n    raise RuntimeError(message)\n\n\ndef batch(iterable: cabc.Iterable[V], batch_size: int) -> list[tuple[V, ...]]:\n    return list(zip(*repeat(iter(iterable), batch_size), strict=False))\n\n\n@contextmanager\ndef augment_usage_errors(\n    ctx: Context, param: Parameter | None = None\n) -> cabc.Iterator[None]:\n    \"\"\"Context manager that attaches extra information to exceptions.\"\"\"\n    try:\n        yield\n    except BadParameter as e:\n        if e.ctx is None:\n            e.ctx = ctx\n        if param is not None and e.param is None:\n            e.param = param\n        raise\n    except UsageError as e:\n        if e.ctx is None:\n            e.ctx = ctx\n        raise\n\n\ndef iter_params_for_processing(\n    invocation_order: cabc.Sequence[Parameter],\n    declaration_order: cabc.Sequence[Parameter],\n) -> list[Parameter]:\n    \"\"\"Returns all declared parameters in the order they should be processed.\n\n"
    },
    ".venv\\Lib\\site-packages\\click\\decorators.py": {
      "sha": "3550d503444d",
      "lines": 551,
      "head": "from __future__ import annotations\n\nimport inspect\nimport typing as t\nfrom functools import update_wrapper\nfrom gettext import gettext as _\n\nfrom .core import Argument\nfrom .core import Command\nfrom .core import Context\nfrom .core import Group\nfrom .core import Option\nfrom .core import Parameter\nfrom .globals import get_current_context\nfrom .utils import echo\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    P = te.ParamSpec(\"P\")\n\nR = t.TypeVar(\"R\")\nT = t.TypeVar(\"T\")\n_AnyCallable = t.Callable[..., t.Any]\nFC = t.TypeVar(\"FC\", bound=\"_AnyCallable | Command\")\n\n\ndef pass_context(f: t.Callable[te.Concatenate[Context, P], R]) -> t.Callable[P, R]:\n    \"\"\"Marks a callback as wanting to receive the current context\n    object as first argument.\n    \"\"\"\n\n    def new_func(*args: P.args, **kwargs: P.kwargs) -> R:\n        return f(get_current_context(), *args, **kwargs)\n\n    return update_wrapper(new_func, f)\n\n\ndef pass_obj(f: t.Callable[te.Concatenate[T, P], R]) -> t.Callable[P, R]:\n    \"\"\"Similar to :func:`pass_context`, but only pass the object on the\n    context onwards (:attr:`Context.obj`).  This is useful if that object\n    represents the state of a nested system.\n    \"\"\"\n\n    def new_func(*args: P.args, **kwargs: P.kwargs) -> R:\n        return f(get_current_context().obj, *args, **kwargs)\n\n    return update_wrapper(new_func, f)\n\n\ndef make_pass_decorator(\n    object_type: type[T], ensure: bool = False\n) -> t.Callable[[t.Callable[te.Concatenate[T, P], R]], t.Callable[P, R]]:\n    \"\"\"Given an object type this creates a decorator that will work\n    similar to :func:`pass_obj` but instead of passing the object of the\n    current context, it will find the innermost context of type\n    :func:`object_type`.\n\n    This generates a decorator that works roughly like this::\n\n        from functools import update_wrapper\n\n        def decorator(f):\n            @pass_context\n            def new_func(ctx, *args, **kwargs):\n                obj = ctx.find_object(object_type)\n                return ctx.invoke(f, obj, *args, **kwargs)\n            return update_wrapper(new_func, f)\n        return decorator\n\n    :param object_type: the type of the object to pass.\n    :param ensure: if set to `True`, a new object will be created and\n                   remembered on the context if it's not there yet.\n    \"\"\"\n\n    def decorator(f: t.Callable[te.Concatenate[T, P], R]) -> t.Callable[P, R]:\n        def new_func(*args: P.args, **kwargs: P.kwargs) -> R:\n            ctx = get_current_context()\n\n            obj: T | None\n            if ensure:\n                obj = ctx.ensure_object(object_type)\n            else:\n                obj = ctx.find_object(object_type)\n\n            if obj is None:\n                raise RuntimeError(\n                    \"Managed to invoke callback without a context\"\n                    f\" object of type {object_type.__name__!r}\"\n                    \" existing.\"\n                )\n\n            return ctx.invoke(f, obj, *args, **kwargs)\n\n        return update_wrapper(new_func, f)\n\n    return decorator\n\n\ndef pass_meta_key(\n    key: str, *, doc_description: str | None = None\n) -> t.Callable[[t.Callable[te.Concatenate[T, P], R]], t.Callable[P, R]]:\n    \"\"\"Create a decorator that passes a key from\n    :attr:`click.Context.meta` as the first argument to the decorated\n    function.\n\n    :param key: Key in ``Context.meta`` to pass.\n    :param doc_description: Description of the object being passed,\n        inserted into the decorator's docstring. Defaults to \"the 'key'\n        key from Context.meta\".\n\n    .. versionadded:: 8.0\n    \"\"\"\n\n    def decorator(f: t.Callable[te.Concatenate[T, P], R]) -> t.Callable[P, R]:\n        def new_func(*args: P.args, **kwargs: P.kwargs) -> R:\n            ctx = get_current_context()\n            obj = ctx.meta[key]\n            return ctx.invoke(f, obj, *args, **kwargs)\n\n"
    },
    ".venv\\Lib\\site-packages\\click\\exceptions.py": {
      "sha": "20f80cfce63a",
      "lines": 308,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom ._compat import get_text_stderr\nfrom .globals import resolve_color_default\nfrom .utils import echo\nfrom .utils import format_filename\n\nif t.TYPE_CHECKING:\n    from .core import Command\n    from .core import Context\n    from .core import Parameter\n\n\ndef _join_param_hints(param_hint: cabc.Sequence[str] | str | None) -> str | None:\n    if param_hint is not None and not isinstance(param_hint, str):\n        return \" / \".join(repr(x) for x in param_hint)\n\n    return param_hint\n\n\nclass ClickException(Exception):\n    \"\"\"An exception that Click can handle and show to the user.\"\"\"\n\n    #: The exit code for this exception.\n    exit_code = 1\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message)\n        # The context will be removed by the time we print the message, so cache\n        # the color settings here to be used later on (in `show`)\n        self.show_color: bool | None = resolve_color_default()\n        self.message = message\n\n    def format_message(self) -> str:\n        return self.message\n\n    def __str__(self) -> str:\n        return self.message\n\n    def show(self, file: t.IO[t.Any] | None = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n\n        echo(\n            _(\"Error: {message}\").format(message=self.format_message()),\n            file=file,\n            color=self.show_color,\n        )\n\n\nclass UsageError(ClickException):\n    \"\"\"An internal exception that signals a usage error.  This typically\n    aborts any further handling.\n\n    :param message: the error message to display.\n    :param ctx: optionally the context that caused this error.  Click will\n                fill in the context automatically in some situations.\n    \"\"\"\n\n    exit_code = 2\n\n    def __init__(self, message: str, ctx: Context | None = None) -> None:\n        super().__init__(message)\n        self.ctx = ctx\n        self.cmd: Command | None = self.ctx.command if self.ctx else None\n\n    def show(self, file: t.IO[t.Any] | None = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n        color = None\n        hint = \"\"\n        if (\n            self.ctx is not None\n            and self.ctx.command.get_help_option(self.ctx) is not None\n        ):\n            hint = _(\"Try '{command} {option}' for help.\").format(\n                command=self.ctx.command_path, option=self.ctx.help_option_names[0]\n            )\n            hint = f\"{hint}\\n\"\n        if self.ctx is not None:\n            color = self.ctx.color\n            echo(f\"{self.ctx.get_usage()}\\n{hint}\", file=file, color=color)\n        echo(\n            _(\"Error: {message}\").format(message=self.format_message()),\n            file=file,\n            color=color,\n        )\n\n\nclass BadParameter(UsageError):\n    \"\"\"An exception that formats out a standardized error message for a\n    bad parameter.  This is useful when thrown from a callback or type as\n    Click will attach contextual information to it (for instance, which\n    parameter it is).\n\n    .. versionadded:: 2.0\n\n    :param param: the parameter object that caused this error.  This can\n                  be left out, and Click will attach this info itself\n                  if possible.\n    :param param_hint: a string that shows up as parameter name.  This\n                       can be used as alternative to `param` in cases\n                       where custom validation should happen.  If it is\n                       a string it's used as such, if it's a list then\n                       each item is quoted and separated.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        ctx: Context | None = None,\n        param: Parameter | None = None,\n        param_hint: str | None = None,\n    ) -> None:\n        super().__init__(message, ctx)\n"
    },
    ".venv\\Lib\\site-packages\\click\\formatting.py": {
      "sha": "039bd3df43b9",
      "lines": 301,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nfrom contextlib import contextmanager\nfrom gettext import gettext as _\n\nfrom ._compat import term_len\nfrom .parser import _split_opt\n\n# Can force a width.  This is used by the test system\nFORCED_WIDTH: int | None = None\n\n\ndef measure_table(rows: cabc.Iterable[tuple[str, str]]) -> tuple[int, ...]:\n    widths: dict[int, int] = {}\n\n    for row in rows:\n        for idx, col in enumerate(row):\n            widths[idx] = max(widths.get(idx, 0), term_len(col))\n\n    return tuple(y for x, y in sorted(widths.items()))\n\n\ndef iter_rows(\n    rows: cabc.Iterable[tuple[str, str]], col_count: int\n) -> cabc.Iterator[tuple[str, ...]]:\n    for row in rows:\n        yield row + (\"\",) * (col_count - len(row))\n\n\ndef wrap_text(\n    text: str,\n    width: int = 78,\n    initial_indent: str = \"\",\n    subsequent_indent: str = \"\",\n    preserve_paragraphs: bool = False,\n) -> str:\n    \"\"\"A helper function that intelligently wraps text.  By default, it\n    assumes that it operates on a single paragraph of text but if the\n    `preserve_paragraphs` parameter is provided it will intelligently\n    handle paragraphs (defined by two empty lines).\n\n    If paragraphs are handled, a paragraph can be prefixed with an empty\n    line containing the ``\\\\b`` character (``\\\\x08``) to indicate that\n    no rewrapping should happen in that block.\n\n    :param text: the text that should be rewrapped.\n    :param width: the maximum width for the text.\n    :param initial_indent: the initial indent that should be placed on the\n                           first line as a string.\n    :param subsequent_indent: the indent string that should be placed on\n                              each consecutive line.\n    :param preserve_paragraphs: if this flag is set then the wrapping will\n                                intelligently handle paragraphs.\n    \"\"\"\n    from ._textwrap import TextWrapper\n\n    text = text.expandtabs()\n    wrapper = TextWrapper(\n        width,\n        initial_indent=initial_indent,\n        subsequent_indent=subsequent_indent,\n        replace_whitespace=False,\n    )\n    if not preserve_paragraphs:\n        return wrapper.fill(text)\n\n    p: list[tuple[int, bool, str]] = []\n    buf: list[str] = []\n    indent = None\n\n    def _flush_par() -> None:\n        if not buf:\n            return\n        if buf[0].strip() == \"\\b\":\n            p.append((indent or 0, True, \"\\n\".join(buf[1:])))\n        else:\n            p.append((indent or 0, False, \" \".join(buf)))\n        del buf[:]\n\n    for line in text.splitlines():\n        if not line:\n            _flush_par()\n            indent = None\n        else:\n            if indent is None:\n                orig_len = term_len(line)\n                line = line.lstrip()\n                indent = orig_len - term_len(line)\n            buf.append(line)\n    _flush_par()\n\n    rv = []\n    for indent, raw, text in p:\n        with wrapper.extra_indent(\" \" * indent):\n            if raw:\n                rv.append(wrapper.indent_only(text))\n            else:\n                rv.append(wrapper.fill(text))\n\n    return \"\\n\\n\".join(rv)\n\n\nclass HelpFormatter:\n    \"\"\"This class helps with formatting text-based help pages.  It's\n    usually just needed for very special internal cases, but it's also\n    exposed so that developers can write their own fancy outputs.\n\n    At present, it always writes into memory.\n\n    :param indent_increment: the additional increment for each level.\n    :param width: the width for the text.  This defaults to the terminal\n                  width clamped to a maximum of 78.\n    \"\"\"\n\n    def __init__(\n        self,\n        indent_increment: int = 2,\n        width: int | None = None,\n        max_width: int | None = None,\n"
    },
    ".venv\\Lib\\site-packages\\click\\globals.py": {
      "sha": "637074e37842",
      "lines": 67,
      "head": "from __future__ import annotations\n\nimport typing as t\nfrom threading import local\n\nif t.TYPE_CHECKING:\n    from .core import Context\n\n_local = local()\n\n\n@t.overload\ndef get_current_context(silent: t.Literal[False] = False) -> Context: ...\n\n\n@t.overload\ndef get_current_context(silent: bool = ...) -> Context | None: ...\n\n\ndef get_current_context(silent: bool = False) -> Context | None:\n    \"\"\"Returns the current click context.  This can be used as a way to\n    access the current context object from anywhere.  This is a more implicit\n    alternative to the :func:`pass_context` decorator.  This function is\n    primarily useful for helpers such as :func:`echo` which might be\n    interested in changing its behavior based on the current context.\n\n    To push the current context, :meth:`Context.scope` can be used.\n\n    .. versionadded:: 5.0\n\n    :param silent: if set to `True` the return value is `None` if no context\n                   is available.  The default behavior is to raise a\n                   :exc:`RuntimeError`.\n    \"\"\"\n    try:\n        return t.cast(\"Context\", _local.stack[-1])\n    except (AttributeError, IndexError) as e:\n        if not silent:\n            raise RuntimeError(\"There is no active click context.\") from e\n\n    return None\n\n\ndef push_context(ctx: Context) -> None:\n    \"\"\"Pushes a new context to the current stack.\"\"\"\n    _local.__dict__.setdefault(\"stack\", []).append(ctx)\n\n\ndef pop_context() -> None:\n    \"\"\"Removes the top level from the stack.\"\"\"\n    _local.stack.pop()\n\n\ndef resolve_color_default(color: bool | None = None) -> bool | None:\n    \"\"\"Internal helper to get the default value of the color flag.  If a\n    value is passed it's returned unchanged, otherwise it's looked up from\n    the current context.\n    \"\"\"\n    if color is not None:\n        return color\n\n    ctx = get_current_context(silent=True)\n\n    if ctx is not None:\n        return ctx.color\n\n    return None\n"
    },
    ".venv\\Lib\\site-packages\\click\\parser.py": {
      "sha": "bdff694cb0d8",
      "lines": 532,
      "head": "\"\"\"\nThis module started out as largely a copy paste from the stdlib's\noptparse module with the features removed that we do not need from\noptparse because we implement them in Click on a higher level (for\ninstance type handling, help formatting and a lot more).\n\nThe plan is to remove more and more from here over time.\n\nThe reason this is a different module and not optparse from the stdlib\nis that there are differences in 2.x and 3.x about the error messages\ngenerated and optparse in the stdlib uses gettext for no good reason\nand might cause us issues.\n\nClick uses parts of optparse written by Gregory P. Ward and maintained\nby the Python Software Foundation. This is limited to code in parser.py.\n\nCopyright 2001-2006 Gregory P. Ward. All rights reserved.\nCopyright 2002-2006 Python Software Foundation. All rights reserved.\n\"\"\"\n\n# This code uses parts of optparse written by Gregory P. Ward and\n# maintained by the Python Software Foundation.\n# Copyright 2001-2006 Gregory P. Ward\n# Copyright 2002-2006 Python Software Foundation\nfrom __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\nfrom collections import deque\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom .exceptions import BadArgumentUsage\nfrom .exceptions import BadOptionUsage\nfrom .exceptions import NoSuchOption\nfrom .exceptions import UsageError\n\nif t.TYPE_CHECKING:\n    from .core import Argument as CoreArgument\n    from .core import Context\n    from .core import Option as CoreOption\n    from .core import Parameter as CoreParameter\n\nV = t.TypeVar(\"V\")\n\n# Sentinel value that indicates an option was passed as a flag without a\n# value but is not a flag option. Option.consume_value uses this to\n# prompt or use the flag_value.\n_flag_needs_value = object()\n\n\ndef _unpack_args(\n    args: cabc.Sequence[str], nargs_spec: cabc.Sequence[int]\n) -> tuple[cabc.Sequence[str | cabc.Sequence[str | None] | None], list[str]]:\n    \"\"\"Given an iterable of arguments and an iterable of nargs specifications,\n    it returns a tuple with all the unpacked arguments at the first index\n    and all remaining arguments as the second.\n\n    The nargs specification is the number of arguments that should be consumed\n    or `-1` to indicate that this position should eat up all the remainders.\n\n    Missing items are filled with `None`.\n    \"\"\"\n    args = deque(args)\n    nargs_spec = deque(nargs_spec)\n    rv: list[str | tuple[str | None, ...] | None] = []\n    spos: int | None = None\n\n    def _fetch(c: deque[V]) -> V | None:\n        try:\n            if spos is None:\n                return c.popleft()\n            else:\n                return c.pop()\n        except IndexError:\n            return None\n\n    while nargs_spec:\n        nargs = _fetch(nargs_spec)\n\n        if nargs is None:\n            continue\n\n        if nargs == 1:\n            rv.append(_fetch(args))\n        elif nargs > 1:\n            x = [_fetch(args) for _ in range(nargs)]\n\n            # If we're reversed, we're pulling in the arguments in reverse,\n            # so we need to turn them around.\n            if spos is not None:\n                x.reverse()\n\n            rv.append(tuple(x))\n        elif nargs < 0:\n            if spos is not None:\n                raise TypeError(\"Cannot have two nargs < 0\")\n\n            spos = len(rv)\n            rv.append(None)\n\n    # spos is the position of the wildcard (star).  If it's not `None`,\n    # we fill it with the remainder.\n    if spos is not None:\n        rv[spos] = tuple(args)\n        args = []\n        rv[spos + 1 :] = reversed(rv[spos + 1 :])\n\n    return tuple(rv), list(args)\n\n\ndef _split_opt(opt: str) -> tuple[str, str]:\n    first = opt[:1]\n    if first.isalnum():\n        return \"\", opt\n    if opt[1:2] == first:\n        return opt[:2], opt[2:]\n    return first, opt[1:]\n\n\n"
    },
    ".venv\\Lib\\site-packages\\click\\shell_completion.py": {
      "sha": "ce917e7f3bf0",
      "lines": 644,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport os\nimport re\nimport typing as t\nfrom gettext import gettext as _\n\nfrom .core import Argument\nfrom .core import Command\nfrom .core import Context\nfrom .core import Group\nfrom .core import Option\nfrom .core import Parameter\nfrom .core import ParameterSource\nfrom .utils import echo\n\n\ndef shell_complete(\n    cli: Command,\n    ctx_args: cabc.MutableMapping[str, t.Any],\n    prog_name: str,\n    complete_var: str,\n    instruction: str,\n) -> int:\n    \"\"\"Perform shell completion for the given CLI program.\n\n    :param cli: Command being called.\n    :param ctx_args: Extra arguments to pass to\n        ``cli.make_context``.\n    :param prog_name: Name of the executable in the shell.\n    :param complete_var: Name of the environment variable that holds\n        the completion instruction.\n    :param instruction: Value of ``complete_var`` with the completion\n        instruction and shell, in the form ``instruction_shell``.\n    :return: Status code to exit with.\n    \"\"\"\n    shell, _, instruction = instruction.partition(\"_\")\n    comp_cls = get_completion_class(shell)\n\n    if comp_cls is None:\n        return 1\n\n    comp = comp_cls(cli, ctx_args, prog_name, complete_var)\n\n    if instruction == \"source\":\n        echo(comp.source())\n        return 0\n\n    if instruction == \"complete\":\n        echo(comp.complete())\n        return 0\n\n    return 1\n\n\nclass CompletionItem:\n    \"\"\"Represents a completion value and metadata about the value. The\n    default metadata is ``type`` to indicate special shell handling,\n    and ``help`` if a shell supports showing a help string next to the\n    value.\n\n    Arbitrary parameters can be passed when creating the object, and\n    accessed using ``item.attr``. If an attribute wasn't passed,\n    accessing it returns ``None``.\n\n    :param value: The completion suggestion.\n    :param type: Tells the shell script to provide special completion\n        support for the type. Click uses ``\"dir\"`` and ``\"file\"``.\n    :param help: String shown next to the value if supported.\n    :param kwargs: Arbitrary metadata. The built-in implementations\n        don't use this, but custom type completions paired with custom\n        shell support could use it.\n    \"\"\"\n\n    __slots__ = (\"value\", \"type\", \"help\", \"_info\")\n\n    def __init__(\n        self,\n        value: t.Any,\n        type: str = \"plain\",\n        help: str | None = None,\n        **kwargs: t.Any,\n    ) -> None:\n        self.value: t.Any = value\n        self.type: str = type\n        self.help: str | None = help\n        self._info = kwargs\n\n    def __getattr__(self, name: str) -> t.Any:\n        return self._info.get(name)\n\n\n# Only Bash >= 4.4 has the nosort option.\n_SOURCE_BASH = \"\"\"\\\n%(complete_func)s() {\n    local IFS=$'\\\\n'\n    local response\n\n    response=$(env COMP_WORDS=\"${COMP_WORDS[*]}\" COMP_CWORD=$COMP_CWORD \\\n%(complete_var)s=bash_complete $1)\n\n    for completion in $response; do\n        IFS=',' read type value <<< \"$completion\"\n\n        if [[ $type == 'dir' ]]; then\n            COMPREPLY=()\n            compopt -o dirnames\n        elif [[ $type == 'file' ]]; then\n            COMPREPLY=()\n            compopt -o default\n        elif [[ $type == 'plain' ]]; then\n            COMPREPLY+=($value)\n        fi\n    done\n\n    return 0\n}\n\n%(complete_func)s_setup() {\n"
    },
    ".venv\\Lib\\site-packages\\click\\termui.py": {
      "sha": "d0ed013ca187",
      "lines": 877,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport inspect\nimport io\nimport itertools\nimport sys\nimport typing as t\nfrom contextlib import AbstractContextManager\nfrom gettext import gettext as _\n\nfrom ._compat import isatty\nfrom ._compat import strip_ansi\nfrom .exceptions import Abort\nfrom .exceptions import UsageError\nfrom .globals import resolve_color_default\nfrom .types import Choice\nfrom .types import convert_type\nfrom .types import ParamType\nfrom .utils import echo\nfrom .utils import LazyFile\n\nif t.TYPE_CHECKING:\n    from ._termui_impl import ProgressBar\n\nV = t.TypeVar(\"V\")\n\n# The prompt functions to use.  The doc tools currently override these\n# functions to customize how they work.\nvisible_prompt_func: t.Callable[[str], str] = input\n\n_ansi_colors = {\n    \"black\": 30,\n    \"red\": 31,\n    \"green\": 32,\n    \"yellow\": 33,\n    \"blue\": 34,\n    \"magenta\": 35,\n    \"cyan\": 36,\n    \"white\": 37,\n    \"reset\": 39,\n    \"bright_black\": 90,\n    \"bright_red\": 91,\n    \"bright_green\": 92,\n    \"bright_yellow\": 93,\n    \"bright_blue\": 94,\n    \"bright_magenta\": 95,\n    \"bright_cyan\": 96,\n    \"bright_white\": 97,\n}\n_ansi_reset_all = \"\\033[0m\"\n\n\ndef hidden_prompt_func(prompt: str) -> str:\n    import getpass\n\n    return getpass.getpass(prompt)\n\n\ndef _build_prompt(\n    text: str,\n    suffix: str,\n    show_default: bool = False,\n    default: t.Any | None = None,\n    show_choices: bool = True,\n    type: ParamType | None = None,\n) -> str:\n    prompt = text\n    if type is not None and show_choices and isinstance(type, Choice):\n        prompt += f\" ({', '.join(map(str, type.choices))})\"\n    if default is not None and show_default:\n        prompt = f\"{prompt} [{_format_default(default)}]\"\n    return f\"{prompt}{suffix}\"\n\n\ndef _format_default(default: t.Any) -> t.Any:\n    if isinstance(default, (io.IOBase, LazyFile)) and hasattr(default, \"name\"):\n        return default.name\n\n    return default\n\n\ndef prompt(\n    text: str,\n    default: t.Any | None = None,\n    hide_input: bool = False,\n    confirmation_prompt: bool | str = False,\n    type: ParamType | t.Any | None = None,\n    value_proc: t.Callable[[str], t.Any] | None = None,\n    prompt_suffix: str = \": \",\n    show_default: bool = True,\n    err: bool = False,\n    show_choices: bool = True,\n) -> t.Any:\n    \"\"\"Prompts a user for input.  This is a convenience function that can\n    be used to prompt a user for input later.\n\n    If the user aborts the input by sending an interrupt signal, this\n    function will catch it and raise a :exc:`Abort` exception.\n\n    :param text: the text to show for the prompt.\n    :param default: the default value to use if no input happens.  If this\n                    is not given it will prompt until it's aborted.\n    :param hide_input: if this is set to true then the input value will\n                       be hidden.\n    :param confirmation_prompt: Prompt a second time to confirm the\n        value. Can be set to a string instead of ``True`` to customize\n        the message.\n    :param type: the type to use to check the value against.\n    :param value_proc: if this parameter is provided it's a function that\n                       is invoked instead of the type conversion to\n                       convert a value.\n    :param prompt_suffix: a suffix that should be added to the prompt.\n    :param show_default: shows or hides the default value in the prompt.\n    :param err: if set to true the file defaults to ``stderr`` instead of\n                ``stdout``, the same as with echo.\n    :param show_choices: Show or hide choices if the passed type is a Choice.\n                         For example if type is a Choice of either day or week,\n                         show_choices is true and text is \"Group by\" then the\n                         prompt will be \"Group by (day, week): \".\n"
    },
    ".venv\\Lib\\site-packages\\click\\testing.py": {
      "sha": "225f959529ee",
      "lines": 565,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport contextlib\nimport io\nimport os\nimport shlex\nimport shutil\nimport sys\nimport tempfile\nimport typing as t\nfrom types import TracebackType\n\nfrom . import _compat\nfrom . import formatting\nfrom . import termui\nfrom . import utils\nfrom ._compat import _find_binary_reader\n\nif t.TYPE_CHECKING:\n    from _typeshed import ReadableBuffer\n\n    from .core import Command\n\n\nclass EchoingStdin:\n    def __init__(self, input: t.BinaryIO, output: t.BinaryIO) -> None:\n        self._input = input\n        self._output = output\n        self._paused = False\n\n    def __getattr__(self, x: str) -> t.Any:\n        return getattr(self._input, x)\n\n    def _echo(self, rv: bytes) -> bytes:\n        if not self._paused:\n            self._output.write(rv)\n\n        return rv\n\n    def read(self, n: int = -1) -> bytes:\n        return self._echo(self._input.read(n))\n\n    def read1(self, n: int = -1) -> bytes:\n        return self._echo(self._input.read1(n))  # type: ignore\n\n    def readline(self, n: int = -1) -> bytes:\n        return self._echo(self._input.readline(n))\n\n    def readlines(self) -> list[bytes]:\n        return [self._echo(x) for x in self._input.readlines()]\n\n    def __iter__(self) -> cabc.Iterator[bytes]:\n        return iter(self._echo(x) for x in self._input)\n\n    def __repr__(self) -> str:\n        return repr(self._input)\n\n\n@contextlib.contextmanager\ndef _pause_echo(stream: EchoingStdin | None) -> cabc.Iterator[None]:\n    if stream is None:\n        yield\n    else:\n        stream._paused = True\n        yield\n        stream._paused = False\n\n\nclass BytesIOCopy(io.BytesIO):\n    \"\"\"Patch ``io.BytesIO`` to let the written stream be copied to another.\n\n    .. versionadded:: 8.2\n    \"\"\"\n\n    def __init__(self, copy_to: io.BytesIO) -> None:\n        super().__init__()\n        self.copy_to = copy_to\n\n    def flush(self) -> None:\n        super().flush()\n        self.copy_to.flush()\n\n    def write(self, b: ReadableBuffer) -> int:\n        self.copy_to.write(b)\n        return super().write(b)\n\n\nclass StreamMixer:\n    \"\"\"Mixes `<stdout>` and `<stderr>` streams.\n\n    The result is available in the ``output`` attribute.\n\n    .. versionadded:: 8.2\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.output: io.BytesIO = io.BytesIO()\n        self.stdout: io.BytesIO = BytesIOCopy(copy_to=self.output)\n        self.stderr: io.BytesIO = BytesIOCopy(copy_to=self.output)\n\n\nclass _NamedTextIOWrapper(io.TextIOWrapper):\n    def __init__(\n        self, buffer: t.BinaryIO, name: str, mode: str, **kwargs: t.Any\n    ) -> None:\n        super().__init__(buffer, **kwargs)\n        self._name = name\n        self._mode = mode\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @property\n    def mode(self) -> str:\n        return self._mode\n\n    def __next__(self) -> str:  # type: ignore\n        try:\n"
    },
    ".venv\\Lib\\site-packages\\click\\types.py": {
      "sha": "1939c9fb916e",
      "lines": 1165,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport enum\nimport os\nimport stat\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom ._compat import _get_argv_encoding\nfrom ._compat import open_stream\nfrom .exceptions import BadParameter\nfrom .utils import format_filename\nfrom .utils import LazyFile\nfrom .utils import safecall\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .core import Context\n    from .core import Parameter\n    from .shell_completion import CompletionItem\n\nParamTypeValue = t.TypeVar(\"ParamTypeValue\")\n\n\nclass ParamType:\n    \"\"\"Represents the type of a parameter. Validates and converts values\n    from the command line or Python into the correct type.\n\n    To implement a custom type, subclass and implement at least the\n    following:\n\n    -   The :attr:`name` class attribute must be set.\n    -   Calling an instance of the type with ``None`` must return\n        ``None``. This is already implemented by default.\n    -   :meth:`convert` must convert string values to the correct type.\n    -   :meth:`convert` must accept values that are already the correct\n        type.\n    -   It must be able to convert a value if the ``ctx`` and ``param``\n        arguments are ``None``. This can occur when converting prompt\n        input.\n    \"\"\"\n\n    is_composite: t.ClassVar[bool] = False\n    arity: t.ClassVar[int] = 1\n\n    #: the descriptive name of this type\n    name: str\n\n    #: if a list of this type is expected and the value is pulled from a\n    #: string environment variable, this is what splits it up.  `None`\n    #: means any whitespace.  For all parameters the general rule is that\n    #: whitespace splits them up.  The exception are paths and files which\n    #: are split by ``os.path.pathsep`` by default (\":\" on Unix and \";\" on\n    #: Windows).\n    envvar_list_splitter: t.ClassVar[str | None] = None\n\n    def to_info_dict(self) -> dict[str, t.Any]:\n        \"\"\"Gather information that could be useful for a tool generating\n        user-facing documentation.\n\n        Use :meth:`click.Context.to_info_dict` to traverse the entire\n        CLI structure.\n\n        .. versionadded:: 8.0\n        \"\"\"\n        # The class name without the \"ParamType\" suffix.\n        param_type = type(self).__name__.partition(\"ParamType\")[0]\n        param_type = param_type.partition(\"ParameterType\")[0]\n\n        # Custom subclasses might not remember to set a name.\n        if hasattr(self, \"name\"):\n            name = self.name\n        else:\n            name = param_type\n\n        return {\"param_type\": param_type, \"name\": name}\n\n    def __call__(\n        self,\n        value: t.Any,\n        param: Parameter | None = None,\n        ctx: Context | None = None,\n    ) -> t.Any:\n        if value is not None:\n            return self.convert(value, param, ctx)\n\n    def get_metavar(self, param: Parameter, ctx: Context) -> str | None:\n        \"\"\"Returns the metavar default for this param if it provides one.\"\"\"\n\n    def get_missing_message(self, param: Parameter, ctx: Context | None) -> str | None:\n        \"\"\"Optionally might return extra information about a missing\n        parameter.\n\n        .. versionadded:: 2.0\n        \"\"\"\n\n    def convert(\n        self, value: t.Any, param: Parameter | None, ctx: Context | None\n    ) -> t.Any:\n        \"\"\"Convert the value to the correct type. This is not called if\n        the value is ``None`` (the missing value).\n\n        This must accept string values from the command line, as well as\n        values that are already the correct type. It may also convert\n        other compatible types.\n\n        The ``param`` and ``ctx`` arguments may be ``None`` in certain\n        situations, such as when converting prompt input.\n\n        If the value cannot be converted, call :meth:`fail` with a\n        descriptive message.\n\n        :param value: The value to convert.\n        :param param: The parameter that is using this type to convert\n            its value. May be ``None``.\n"
    },
    ".venv\\Lib\\site-packages\\click\\utils.py": {
      "sha": "67cd3dccfdef",
      "lines": 627,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport os\nimport re\nimport sys\nimport typing as t\nfrom functools import update_wrapper\nfrom types import ModuleType\nfrom types import TracebackType\n\nfrom ._compat import _default_text_stderr\nfrom ._compat import _default_text_stdout\nfrom ._compat import _find_binary_writer\nfrom ._compat import auto_wrap_for_ansi\nfrom ._compat import binary_streams\nfrom ._compat import open_stream\nfrom ._compat import should_strip_ansi\nfrom ._compat import strip_ansi\nfrom ._compat import text_streams\nfrom ._compat import WIN\nfrom .globals import resolve_color_default\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    P = te.ParamSpec(\"P\")\n\nR = t.TypeVar(\"R\")\n\n\ndef _posixify(name: str) -> str:\n    return \"-\".join(name.split()).lower()\n\n\ndef safecall(func: t.Callable[P, R]) -> t.Callable[P, R | None]:\n    \"\"\"Wraps a function so that it swallows exceptions.\"\"\"\n\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R | None:\n        try:\n            return func(*args, **kwargs)\n        except Exception:\n            pass\n        return None\n\n    return update_wrapper(wrapper, func)\n\n\ndef make_str(value: t.Any) -> str:\n    \"\"\"Converts a value into a valid string.\"\"\"\n    if isinstance(value, bytes):\n        try:\n            return value.decode(sys.getfilesystemencoding())\n        except UnicodeError:\n            return value.decode(\"utf-8\", \"replace\")\n    return str(value)\n\n\ndef make_default_short_help(help: str, max_length: int = 45) -> str:\n    \"\"\"Returns a condensed version of help string.\"\"\"\n    # Consider only the first paragraph.\n    paragraph_end = help.find(\"\\n\\n\")\n\n    if paragraph_end != -1:\n        help = help[:paragraph_end]\n\n    # Collapse newlines, tabs, and spaces.\n    words = help.split()\n\n    if not words:\n        return \"\"\n\n    # The first paragraph started with a \"no rewrap\" marker, ignore it.\n    if words[0] == \"\\b\":\n        words = words[1:]\n\n    total_length = 0\n    last_index = len(words) - 1\n\n    for i, word in enumerate(words):\n        total_length += len(word) + (i > 0)\n\n        if total_length > max_length:  # too long, truncate\n            break\n\n        if word[-1] == \".\":  # sentence end, truncate without \"...\"\n            return \" \".join(words[: i + 1])\n\n        if total_length == max_length and i != last_index:\n            break  # not at sentence end, truncate with \"...\"\n    else:\n        return \" \".join(words)  # no truncation needed\n\n    # Account for the length of the suffix.\n    total_length += len(\"...\")\n\n    # remove words until the length is short enough\n    while i > 0:\n        total_length -= len(words[i]) + (i > 0)\n\n        if total_length <= max_length:\n            break\n\n        i -= 1\n\n    return \" \".join(words[:i]) + \"...\"\n\n\nclass LazyFile:\n    \"\"\"A lazy file works like a regular file but it does not fully open\n    the file but it does perform some basic checks early to see if the\n    filename parameter does make sense.  This is useful for safely opening\n    files for writing.\n    \"\"\"\n\n    def __init__(\n        self,\n        filename: str | os.PathLike[str],\n        mode: str = \"r\",\n        encoding: str | None = None,\n"
    },
    ".venv\\Lib\\site-packages\\click\\_compat.py": {
      "sha": "3fb619ba82fd",
      "lines": 622,
      "head": "from __future__ import annotations\n\nimport codecs\nimport collections.abc as cabc\nimport io\nimport os\nimport re\nimport sys\nimport typing as t\nfrom types import TracebackType\nfrom weakref import WeakKeyDictionary\n\nCYGWIN = sys.platform.startswith(\"cygwin\")\nWIN = sys.platform.startswith(\"win\")\nauto_wrap_for_ansi: t.Callable[[t.TextIO], t.TextIO] | None = None\n_ansi_re = re.compile(r\"\\033\\[[;?0-9]*[a-zA-Z]\")\n\n\ndef _make_text_stream(\n    stream: t.BinaryIO,\n    encoding: str | None,\n    errors: str | None,\n    force_readable: bool = False,\n    force_writable: bool = False,\n) -> t.TextIO:\n    if encoding is None:\n        encoding = get_best_encoding(stream)\n    if errors is None:\n        errors = \"replace\"\n    return _NonClosingTextIOWrapper(\n        stream,\n        encoding,\n        errors,\n        line_buffering=True,\n        force_readable=force_readable,\n        force_writable=force_writable,\n    )\n\n\ndef is_ascii_encoding(encoding: str) -> bool:\n    \"\"\"Checks if a given encoding is ascii.\"\"\"\n    try:\n        return codecs.lookup(encoding).name == \"ascii\"\n    except LookupError:\n        return False\n\n\ndef get_best_encoding(stream: t.IO[t.Any]) -> str:\n    \"\"\"Returns the default stream encoding if not found.\"\"\"\n    rv = getattr(stream, \"encoding\", None) or sys.getdefaultencoding()\n    if is_ascii_encoding(rv):\n        return \"utf-8\"\n    return rv\n\n\nclass _NonClosingTextIOWrapper(io.TextIOWrapper):\n    def __init__(\n        self,\n        stream: t.BinaryIO,\n        encoding: str | None,\n        errors: str | None,\n        force_readable: bool = False,\n        force_writable: bool = False,\n        **extra: t.Any,\n    ) -> None:\n        self._stream = stream = t.cast(\n            t.BinaryIO, _FixupStream(stream, force_readable, force_writable)\n        )\n        super().__init__(stream, encoding, errors, **extra)\n\n    def __del__(self) -> None:\n        try:\n            self.detach()\n        except Exception:\n            pass\n\n    def isatty(self) -> bool:\n        # https://bitbucket.org/pypy/pypy/issue/1803\n        return self._stream.isatty()\n\n\nclass _FixupStream:\n    \"\"\"The new io interface needs more from streams than streams\n    traditionally implement.  As such, this fix-up code is necessary in\n    some circumstances.\n\n    The forcing of readable and writable flags are there because some tools\n    put badly patched objects on sys (one such offender are certain version\n    of jupyter notebook).\n    \"\"\"\n\n    def __init__(\n        self,\n        stream: t.BinaryIO,\n        force_readable: bool = False,\n        force_writable: bool = False,\n    ):\n        self._stream = stream\n        self._force_readable = force_readable\n        self._force_writable = force_writable\n\n    def __getattr__(self, name: str) -> t.Any:\n        return getattr(self._stream, name)\n\n    def read1(self, size: int) -> bytes:\n        f = getattr(self._stream, \"read1\", None)\n\n        if f is not None:\n            return t.cast(bytes, f(size))\n\n        return self._stream.read(size)\n\n    def readable(self) -> bool:\n        if self._force_readable:\n            return True\n        x = getattr(self._stream, \"readable\", None)\n        if x is not None:\n            return t.cast(bool, x())\n        try:\n            self._stream.read(0)\n"
    },
    ".venv\\Lib\\site-packages\\click\\_termui_impl.py": {
      "sha": "3bb2ba513d81",
      "lines": 839,
      "head": "\"\"\"\nThis module contains implementations for the termui module. To keep the\nimport time of Click down, some infrequently used functionality is\nplaced in this module and only imported as needed.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport collections.abc as cabc\nimport contextlib\nimport math\nimport os\nimport shlex\nimport sys\nimport time\nimport typing as t\nfrom gettext import gettext as _\nfrom io import StringIO\nfrom pathlib import Path\nfrom shutil import which\nfrom types import TracebackType\n\nfrom ._compat import _default_text_stdout\nfrom ._compat import CYGWIN\nfrom ._compat import get_best_encoding\nfrom ._compat import isatty\nfrom ._compat import open_stream\nfrom ._compat import strip_ansi\nfrom ._compat import term_len\nfrom ._compat import WIN\nfrom .exceptions import ClickException\nfrom .utils import echo\n\nV = t.TypeVar(\"V\")\n\nif os.name == \"nt\":\n    BEFORE_BAR = \"\\r\"\n    AFTER_BAR = \"\\n\"\nelse:\n    BEFORE_BAR = \"\\r\\033[?25l\"\n    AFTER_BAR = \"\\033[?25h\\n\"\n\n\nclass ProgressBar(t.Generic[V]):\n    def __init__(\n        self,\n        iterable: cabc.Iterable[V] | None,\n        length: int | None = None,\n        fill_char: str = \"#\",\n        empty_char: str = \" \",\n        bar_template: str = \"%(bar)s\",\n        info_sep: str = \"  \",\n        hidden: bool = False,\n        show_eta: bool = True,\n        show_percent: bool | None = None,\n        show_pos: bool = False,\n        item_show_func: t.Callable[[V | None], str | None] | None = None,\n        label: str | None = None,\n        file: t.TextIO | None = None,\n        color: bool | None = None,\n        update_min_steps: int = 1,\n        width: int = 30,\n    ) -> None:\n        self.fill_char = fill_char\n        self.empty_char = empty_char\n        self.bar_template = bar_template\n        self.info_sep = info_sep\n        self.hidden = hidden\n        self.show_eta = show_eta\n        self.show_percent = show_percent\n        self.show_pos = show_pos\n        self.item_show_func = item_show_func\n        self.label: str = label or \"\"\n\n        if file is None:\n            file = _default_text_stdout()\n\n            # There are no standard streams attached to write to. For example,\n            # pythonw on Windows.\n            if file is None:\n                file = StringIO()\n\n        self.file = file\n        self.color = color\n        self.update_min_steps = update_min_steps\n        self._completed_intervals = 0\n        self.width: int = width\n        self.autowidth: bool = width == 0\n\n        if length is None:\n            from operator import length_hint\n\n            length = length_hint(iterable, -1)\n\n            if length == -1:\n                length = None\n        if iterable is None:\n            if length is None:\n                raise TypeError(\"iterable or length is required\")\n            iterable = t.cast(\"cabc.Iterable[V]\", range(length))\n        self.iter: cabc.Iterable[V] = iter(iterable)\n        self.length = length\n        self.pos: int = 0\n        self.avg: list[float] = []\n        self.last_eta: float\n        self.start: float\n        self.start = self.last_eta = time.time()\n        self.eta_known: bool = False\n        self.finished: bool = False\n        self.max_width: int | None = None\n        self.entered: bool = False\n        self.current_item: V | None = None\n        self._is_atty = isatty(self.file)\n        self._last_line: str | None = None\n\n    def __enter__(self) -> ProgressBar[V]:\n        self.entered = True\n        self.render_progress()\n        return self\n\n"
    },
    ".venv\\Lib\\site-packages\\click\\_textwrap.py": {
      "sha": "2cf25aa2021c",
      "lines": 51,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport textwrap\nfrom contextlib import contextmanager\n\n\nclass TextWrapper(textwrap.TextWrapper):\n    def _handle_long_word(\n        self,\n        reversed_chunks: list[str],\n        cur_line: list[str],\n        cur_len: int,\n        width: int,\n    ) -> None:\n        space_left = max(width - cur_len, 1)\n\n        if self.break_long_words:\n            last = reversed_chunks[-1]\n            cut = last[:space_left]\n            res = last[space_left:]\n            cur_line.append(cut)\n            reversed_chunks[-1] = res\n        elif not cur_line:\n            cur_line.append(reversed_chunks.pop())\n\n    @contextmanager\n    def extra_indent(self, indent: str) -> cabc.Iterator[None]:\n        old_initial_indent = self.initial_indent\n        old_subsequent_indent = self.subsequent_indent\n        self.initial_indent += indent\n        self.subsequent_indent += indent\n\n        try:\n            yield\n        finally:\n            self.initial_indent = old_initial_indent\n            self.subsequent_indent = old_subsequent_indent\n\n    def indent_only(self, text: str) -> str:\n        rv = []\n\n        for idx, line in enumerate(text.splitlines()):\n            indent = self.initial_indent\n\n            if idx > 0:\n                indent = self.subsequent_indent\n\n            rv.append(f\"{indent}{line}\")\n\n        return \"\\n\".join(rv)\n"
    },
    ".venv\\Lib\\site-packages\\click\\_winconsole.py": {
      "sha": "f5fdebd0969b",
      "lines": 296,
      "head": "# This module is based on the excellent work by Adam Barto\u0161 who\n# provided a lot of what went into the implementation here in\n# the discussion to issue1602 in the Python bug tracker.\n#\n# There are some general differences in regards to how this works\n# compared to the original patches as we do not need to patch\n# the entire interpreter but just work in our little world of\n# echo and prompt.\nfrom __future__ import annotations\n\nimport collections.abc as cabc\nimport io\nimport sys\nimport time\nimport typing as t\nfrom ctypes import Array\nfrom ctypes import byref\nfrom ctypes import c_char\nfrom ctypes import c_char_p\nfrom ctypes import c_int\nfrom ctypes import c_ssize_t\nfrom ctypes import c_ulong\nfrom ctypes import c_void_p\nfrom ctypes import POINTER\nfrom ctypes import py_object\nfrom ctypes import Structure\nfrom ctypes.wintypes import DWORD\nfrom ctypes.wintypes import HANDLE\nfrom ctypes.wintypes import LPCWSTR\nfrom ctypes.wintypes import LPWSTR\n\nfrom ._compat import _NonClosingTextIOWrapper\n\nassert sys.platform == \"win32\"\nimport msvcrt  # noqa: E402\nfrom ctypes import windll  # noqa: E402\nfrom ctypes import WINFUNCTYPE  # noqa: E402\n\nc_ssize_p = POINTER(c_ssize_t)\n\nkernel32 = windll.kernel32\nGetStdHandle = kernel32.GetStdHandle\nReadConsoleW = kernel32.ReadConsoleW\nWriteConsoleW = kernel32.WriteConsoleW\nGetConsoleMode = kernel32.GetConsoleMode\nGetLastError = kernel32.GetLastError\nGetCommandLineW = WINFUNCTYPE(LPWSTR)((\"GetCommandLineW\", windll.kernel32))\nCommandLineToArgvW = WINFUNCTYPE(POINTER(LPWSTR), LPCWSTR, POINTER(c_int))(\n    (\"CommandLineToArgvW\", windll.shell32)\n)\nLocalFree = WINFUNCTYPE(c_void_p, c_void_p)((\"LocalFree\", windll.kernel32))\n\nSTDIN_HANDLE = GetStdHandle(-10)\nSTDOUT_HANDLE = GetStdHandle(-11)\nSTDERR_HANDLE = GetStdHandle(-12)\n\nPyBUF_SIMPLE = 0\nPyBUF_WRITABLE = 1\n\nERROR_SUCCESS = 0\nERROR_NOT_ENOUGH_MEMORY = 8\nERROR_OPERATION_ABORTED = 995\n\nSTDIN_FILENO = 0\nSTDOUT_FILENO = 1\nSTDERR_FILENO = 2\n\nEOF = b\"\\x1a\"\nMAX_BYTES_WRITTEN = 32767\n\nif t.TYPE_CHECKING:\n    try:\n        # Using `typing_extensions.Buffer` instead of `collections.abc`\n        # on Windows for some reason does not have `Sized` implemented.\n        from collections.abc import Buffer  # type: ignore\n    except ImportError:\n        from typing_extensions import Buffer\n\ntry:\n    from ctypes import pythonapi\nexcept ImportError:\n    # On PyPy we cannot get buffers so our ability to operate here is\n    # severely limited.\n    get_buffer = None\nelse:\n\n    class Py_buffer(Structure):\n        _fields_ = [  # noqa: RUF012\n            (\"buf\", c_void_p),\n            (\"obj\", py_object),\n            (\"len\", c_ssize_t),\n            (\"itemsize\", c_ssize_t),\n            (\"readonly\", c_int),\n            (\"ndim\", c_int),\n            (\"format\", c_char_p),\n            (\"shape\", c_ssize_p),\n            (\"strides\", c_ssize_p),\n            (\"suboffsets\", c_ssize_p),\n            (\"internal\", c_void_p),\n        ]\n\n    PyObject_GetBuffer = pythonapi.PyObject_GetBuffer\n    PyBuffer_Release = pythonapi.PyBuffer_Release\n\n    def get_buffer(obj: Buffer, writable: bool = False) -> Array[c_char]:\n        buf = Py_buffer()\n        flags: int = PyBUF_WRITABLE if writable else PyBUF_SIMPLE\n        PyObject_GetBuffer(py_object(obj), byref(buf), flags)\n\n        try:\n            buffer_type = c_char * buf.len\n            out: Array[c_char] = buffer_type.from_address(buf.buf)\n            return out\n        finally:\n            PyBuffer_Release(byref(buf))\n\n\nclass _WindowsConsoleRawIOBase(io.RawIOBase):\n    def __init__(self, handle: int | None) -> None:\n        self.handle = handle\n"
    },
    ".venv\\Lib\\site-packages\\click\\__init__.py": {
      "sha": "226513412024",
      "lines": 123,
      "head": "\"\"\"\nClick is a simple Python module inspired by the stdlib optparse to make\nwriting command line scripts fun. Unlike other modules, it's based\naround a simple API that does not come with too much magic and is\ncomposable.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom .core import Argument as Argument\nfrom .core import Command as Command\nfrom .core import CommandCollection as CommandCollection\nfrom .core import Context as Context\nfrom .core import Group as Group\nfrom .core import Option as Option\nfrom .core import Parameter as Parameter\nfrom .decorators import argument as argument\nfrom .decorators import command as command\nfrom .decorators import confirmation_option as confirmation_option\nfrom .decorators import group as group\nfrom .decorators import help_option as help_option\nfrom .decorators import make_pass_decorator as make_pass_decorator\nfrom .decorators import option as option\nfrom .decorators import pass_context as pass_context\nfrom .decorators import pass_obj as pass_obj\nfrom .decorators import password_option as password_option\nfrom .decorators import version_option as version_option\nfrom .exceptions import Abort as Abort\nfrom .exceptions import BadArgumentUsage as BadArgumentUsage\nfrom .exceptions import BadOptionUsage as BadOptionUsage\nfrom .exceptions import BadParameter as BadParameter\nfrom .exceptions import ClickException as ClickException\nfrom .exceptions import FileError as FileError\nfrom .exceptions import MissingParameter as MissingParameter\nfrom .exceptions import NoSuchOption as NoSuchOption\nfrom .exceptions import UsageError as UsageError\nfrom .formatting import HelpFormatter as HelpFormatter\nfrom .formatting import wrap_text as wrap_text\nfrom .globals import get_current_context as get_current_context\nfrom .termui import clear as clear\nfrom .termui import confirm as confirm\nfrom .termui import echo_via_pager as echo_via_pager\nfrom .termui import edit as edit\nfrom .termui import getchar as getchar\nfrom .termui import launch as launch\nfrom .termui import pause as pause\nfrom .termui import progressbar as progressbar\nfrom .termui import prompt as prompt\nfrom .termui import secho as secho\nfrom .termui import style as style\nfrom .termui import unstyle as unstyle\nfrom .types import BOOL as BOOL\nfrom .types import Choice as Choice\nfrom .types import DateTime as DateTime\nfrom .types import File as File\nfrom .types import FLOAT as FLOAT\nfrom .types import FloatRange as FloatRange\nfrom .types import INT as INT\nfrom .types import IntRange as IntRange\nfrom .types import ParamType as ParamType\nfrom .types import Path as Path\nfrom .types import STRING as STRING\nfrom .types import Tuple as Tuple\nfrom .types import UNPROCESSED as UNPROCESSED\nfrom .types import UUID as UUID\nfrom .utils import echo as echo\nfrom .utils import format_filename as format_filename\nfrom .utils import get_app_dir as get_app_dir\nfrom .utils import get_binary_stream as get_binary_stream\nfrom .utils import get_text_stream as get_text_stream\nfrom .utils import open_file as open_file\n\n\ndef __getattr__(name: str) -> object:\n    import warnings\n\n    if name == \"BaseCommand\":\n        from .core import _BaseCommand\n\n        warnings.warn(\n            \"'BaseCommand' is deprecated and will be removed in Click 9.0. Use\"\n            \" 'Command' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _BaseCommand\n\n    if name == \"MultiCommand\":\n        from .core import _MultiCommand\n\n        warnings.warn(\n            \"'MultiCommand' is deprecated and will be removed in Click 9.0. Use\"\n            \" 'Group' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _MultiCommand\n\n    if name == \"OptionParser\":\n        from .parser import _OptionParser\n\n        warnings.warn(\n            \"'OptionParser' is deprecated and will be removed in Click 9.0. The\"\n            \" old parser is available in 'optparse'.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _OptionParser\n\n    if name == \"__version__\":\n        import importlib.metadata\n        import warnings\n\n        warnings.warn(\n            \"The '__version__' attribute is deprecated and will be removed in\"\n            \" Click 9.1. Use feature detection or\"\n            \" 'importlib.metadata.version(\\\"click\\\")' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n"
    },
    ".venv\\Lib\\site-packages\\click-8.2.1.dist-info\\licenses\\LICENSE.txt": {
      "sha": "6fb11e02ffe0",
      "lines": 28,
      "head": "Copyright 2014 Pallets\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n1.  Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n2.  Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\n3.  Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\ansi.py": {
      "sha": "a46f95349f8d",
      "lines": 102,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\n'''\nThis module generates ANSI character codes to printing colors to terminals.\nSee: http://en.wikipedia.org/wiki/ANSI_escape_code\n'''\n\nCSI = '\\033['\nOSC = '\\033]'\nBEL = '\\a'\n\n\ndef code_to_chars(code):\n    return CSI + str(code) + 'm'\n\ndef set_title(title):\n    return OSC + '2;' + title + BEL\n\ndef clear_screen(mode=2):\n    return CSI + str(mode) + 'J'\n\ndef clear_line(mode=2):\n    return CSI + str(mode) + 'K'\n\n\nclass AnsiCodes(object):\n    def __init__(self):\n        # the subclasses declare class attributes which are numbers.\n        # Upon instantiation we define instance attributes, which are the same\n        # as the class attributes but wrapped with the ANSI escape sequence\n        for name in dir(self):\n            if not name.startswith('_'):\n                value = getattr(self, name)\n                setattr(self, name, code_to_chars(value))\n\n\nclass AnsiCursor(object):\n    def UP(self, n=1):\n        return CSI + str(n) + 'A'\n    def DOWN(self, n=1):\n        return CSI + str(n) + 'B'\n    def FORWARD(self, n=1):\n        return CSI + str(n) + 'C'\n    def BACK(self, n=1):\n        return CSI + str(n) + 'D'\n    def POS(self, x=1, y=1):\n        return CSI + str(y) + ';' + str(x) + 'H'\n\n\nclass AnsiFore(AnsiCodes):\n    BLACK           = 30\n    RED             = 31\n    GREEN           = 32\n    YELLOW          = 33\n    BLUE            = 34\n    MAGENTA         = 35\n    CYAN            = 36\n    WHITE           = 37\n    RESET           = 39\n\n    # These are fairly well supported, but not part of the standard.\n    LIGHTBLACK_EX   = 90\n    LIGHTRED_EX     = 91\n    LIGHTGREEN_EX   = 92\n    LIGHTYELLOW_EX  = 93\n    LIGHTBLUE_EX    = 94\n    LIGHTMAGENTA_EX = 95\n    LIGHTCYAN_EX    = 96\n    LIGHTWHITE_EX   = 97\n\n\nclass AnsiBack(AnsiCodes):\n    BLACK           = 40\n    RED             = 41\n    GREEN           = 42\n    YELLOW          = 43\n    BLUE            = 44\n    MAGENTA         = 45\n    CYAN            = 46\n    WHITE           = 47\n    RESET           = 49\n\n    # These are fairly well supported, but not part of the standard.\n    LIGHTBLACK_EX   = 100\n    LIGHTRED_EX     = 101\n    LIGHTGREEN_EX   = 102\n    LIGHTYELLOW_EX  = 103\n    LIGHTBLUE_EX    = 104\n    LIGHTMAGENTA_EX = 105\n    LIGHTCYAN_EX    = 106\n    LIGHTWHITE_EX   = 107\n\n\nclass AnsiStyle(AnsiCodes):\n    BRIGHT    = 1\n    DIM       = 2\n    NORMAL    = 22\n    RESET_ALL = 0\n\nFore   = AnsiFore()\nBack   = AnsiBack()\nStyle  = AnsiStyle()\nCursor = AnsiCursor()\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\ansitowin32.py": {
      "sha": "8d34ce03d750",
      "lines": 277,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nimport re\nimport sys\nimport os\n\nfrom .ansi import AnsiFore, AnsiBack, AnsiStyle, Style, BEL\nfrom .winterm import enable_vt_processing, WinTerm, WinColor, WinStyle\nfrom .win32 import windll, winapi_test\n\n\nwinterm = None\nif windll is not None:\n    winterm = WinTerm()\n\n\nclass StreamWrapper(object):\n    '''\n    Wraps a stream (such as stdout), acting as a transparent proxy for all\n    attribute access apart from method 'write()', which is delegated to our\n    Converter instance.\n    '''\n    def __init__(self, wrapped, converter):\n        # double-underscore everything to prevent clashes with names of\n        # attributes on the wrapped stream object.\n        self.__wrapped = wrapped\n        self.__convertor = converter\n\n    def __getattr__(self, name):\n        return getattr(self.__wrapped, name)\n\n    def __enter__(self, *args, **kwargs):\n        # special method lookup bypasses __getattr__/__getattribute__, see\n        # https://stackoverflow.com/questions/12632894/why-doesnt-getattr-work-with-exit\n        # thus, contextlib magic methods are not proxied via __getattr__\n        return self.__wrapped.__enter__(*args, **kwargs)\n\n    def __exit__(self, *args, **kwargs):\n        return self.__wrapped.__exit__(*args, **kwargs)\n\n    def __setstate__(self, state):\n        self.__dict__ = state\n\n    def __getstate__(self):\n        return self.__dict__\n\n    def write(self, text):\n        self.__convertor.write(text)\n\n    def isatty(self):\n        stream = self.__wrapped\n        if 'PYCHARM_HOSTED' in os.environ:\n            if stream is not None and (stream is sys.__stdout__ or stream is sys.__stderr__):\n                return True\n        try:\n            stream_isatty = stream.isatty\n        except AttributeError:\n            return False\n        else:\n            return stream_isatty()\n\n    @property\n    def closed(self):\n        stream = self.__wrapped\n        try:\n            return stream.closed\n        # AttributeError in the case that the stream doesn't support being closed\n        # ValueError for the case that the stream has already been detached when atexit runs\n        except (AttributeError, ValueError):\n            return True\n\n\nclass AnsiToWin32(object):\n    '''\n    Implements a 'write()' method which, on Windows, will strip ANSI character\n    sequences from the text, and if outputting to a tty, will convert them into\n    win32 function calls.\n    '''\n    ANSI_CSI_RE = re.compile('\\001?\\033\\\\[((?:\\\\d|;)*)([a-zA-Z])\\002?')   # Control Sequence Introducer\n    ANSI_OSC_RE = re.compile('\\001?\\033\\\\]([^\\a]*)(\\a)\\002?')             # Operating System Command\n\n    def __init__(self, wrapped, convert=None, strip=None, autoreset=False):\n        # The wrapped stream (normally sys.stdout or sys.stderr)\n        self.wrapped = wrapped\n\n        # should we reset colors to defaults after every .write()\n        self.autoreset = autoreset\n\n        # create the proxy wrapping our output stream\n        self.stream = StreamWrapper(wrapped, self)\n\n        on_windows = os.name == 'nt'\n        # We test if the WinAPI works, because even if we are on Windows\n        # we may be using a terminal that doesn't support the WinAPI\n        # (e.g. Cygwin Terminal). In this case it's up to the terminal\n        # to support the ANSI codes.\n        conversion_supported = on_windows and winapi_test()\n        try:\n            fd = wrapped.fileno()\n        except Exception:\n            fd = -1\n        system_has_native_ansi = not on_windows or enable_vt_processing(fd)\n        have_tty = not self.stream.closed and self.stream.isatty()\n        need_conversion = conversion_supported and not system_has_native_ansi\n\n        # should we strip ANSI sequences from our output?\n        if strip is None:\n            strip = need_conversion or not have_tty\n        self.strip = strip\n\n        # should we should convert ANSI sequences into win32 calls?\n        if convert is None:\n            convert = need_conversion and have_tty\n        self.convert = convert\n\n        # dict of ansi codes to win32 functions and parameters\n        self.win32_calls = self.get_win32_calls()\n\n        # are we wrapping stderr?\n        self.on_stderr = self.wrapped is sys.stderr\n\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\initialise.py": {
      "sha": "0cfa12dfbf9e",
      "lines": 121,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nimport atexit\nimport contextlib\nimport sys\n\nfrom .ansitowin32 import AnsiToWin32\n\n\ndef _wipe_internal_state_for_tests():\n    global orig_stdout, orig_stderr\n    orig_stdout = None\n    orig_stderr = None\n\n    global wrapped_stdout, wrapped_stderr\n    wrapped_stdout = None\n    wrapped_stderr = None\n\n    global atexit_done\n    atexit_done = False\n\n    global fixed_windows_console\n    fixed_windows_console = False\n\n    try:\n        # no-op if it wasn't registered\n        atexit.unregister(reset_all)\n    except AttributeError:\n        # python 2: no atexit.unregister. Oh well, we did our best.\n        pass\n\n\ndef reset_all():\n    if AnsiToWin32 is not None:    # Issue #74: objects might become None at exit\n        AnsiToWin32(orig_stdout).reset_all()\n\n\ndef init(autoreset=False, convert=None, strip=None, wrap=True):\n\n    if not wrap and any([autoreset, convert, strip]):\n        raise ValueError('wrap=False conflicts with any other arg=True')\n\n    global wrapped_stdout, wrapped_stderr\n    global orig_stdout, orig_stderr\n\n    orig_stdout = sys.stdout\n    orig_stderr = sys.stderr\n\n    if sys.stdout is None:\n        wrapped_stdout = None\n    else:\n        sys.stdout = wrapped_stdout = \\\n            wrap_stream(orig_stdout, convert, strip, autoreset, wrap)\n    if sys.stderr is None:\n        wrapped_stderr = None\n    else:\n        sys.stderr = wrapped_stderr = \\\n            wrap_stream(orig_stderr, convert, strip, autoreset, wrap)\n\n    global atexit_done\n    if not atexit_done:\n        atexit.register(reset_all)\n        atexit_done = True\n\n\ndef deinit():\n    if orig_stdout is not None:\n        sys.stdout = orig_stdout\n    if orig_stderr is not None:\n        sys.stderr = orig_stderr\n\n\ndef just_fix_windows_console():\n    global fixed_windows_console\n\n    if sys.platform != \"win32\":\n        return\n    if fixed_windows_console:\n        return\n    if wrapped_stdout is not None or wrapped_stderr is not None:\n        # Someone already ran init() and it did stuff, so we won't second-guess them\n        return\n\n    # On newer versions of Windows, AnsiToWin32.__init__ will implicitly enable the\n    # native ANSI support in the console as a side-effect. We only need to actually\n    # replace sys.stdout/stderr if we're in the old-style conversion mode.\n    new_stdout = AnsiToWin32(sys.stdout, convert=None, strip=None, autoreset=False)\n    if new_stdout.convert:\n        sys.stdout = new_stdout\n    new_stderr = AnsiToWin32(sys.stderr, convert=None, strip=None, autoreset=False)\n    if new_stderr.convert:\n        sys.stderr = new_stderr\n\n    fixed_windows_console = True\n\n@contextlib.contextmanager\ndef colorama_text(*args, **kwargs):\n    init(*args, **kwargs)\n    try:\n        yield\n    finally:\n        deinit()\n\n\ndef reinit():\n    if wrapped_stdout is not None:\n        sys.stdout = wrapped_stdout\n    if wrapped_stderr is not None:\n        sys.stderr = wrapped_stderr\n\n\ndef wrap_stream(stream, convert, strip, autoreset, wrap):\n    if wrap:\n        wrapper = AnsiToWin32(stream,\n            convert=convert, strip=strip, autoreset=autoreset)\n        if wrapper.should_wrap():\n            stream = wrapper.stream\n    return stream\n\n\n# Use this for initial setup as well, to reduce code duplication\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\win32.py": {
      "sha": "e62a37bd5263",
      "lines": 180,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\n\n# from winbase.h\nSTDOUT = -11\nSTDERR = -12\n\nENABLE_VIRTUAL_TERMINAL_PROCESSING = 0x0004\n\ntry:\n    import ctypes\n    from ctypes import LibraryLoader\n    windll = LibraryLoader(ctypes.WinDLL)\n    from ctypes import wintypes\nexcept (AttributeError, ImportError):\n    windll = None\n    SetConsoleTextAttribute = lambda *_: None\n    winapi_test = lambda *_: None\nelse:\n    from ctypes import byref, Structure, c_char, POINTER\n\n    COORD = wintypes._COORD\n\n    class CONSOLE_SCREEN_BUFFER_INFO(Structure):\n        \"\"\"struct in wincon.h.\"\"\"\n        _fields_ = [\n            (\"dwSize\", COORD),\n            (\"dwCursorPosition\", COORD),\n            (\"wAttributes\", wintypes.WORD),\n            (\"srWindow\", wintypes.SMALL_RECT),\n            (\"dwMaximumWindowSize\", COORD),\n        ]\n        def __str__(self):\n            return '(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d)' % (\n                self.dwSize.Y, self.dwSize.X\n                , self.dwCursorPosition.Y, self.dwCursorPosition.X\n                , self.wAttributes\n                , self.srWindow.Top, self.srWindow.Left, self.srWindow.Bottom, self.srWindow.Right\n                , self.dwMaximumWindowSize.Y, self.dwMaximumWindowSize.X\n            )\n\n    _GetStdHandle = windll.kernel32.GetStdHandle\n    _GetStdHandle.argtypes = [\n        wintypes.DWORD,\n    ]\n    _GetStdHandle.restype = wintypes.HANDLE\n\n    _GetConsoleScreenBufferInfo = windll.kernel32.GetConsoleScreenBufferInfo\n    _GetConsoleScreenBufferInfo.argtypes = [\n        wintypes.HANDLE,\n        POINTER(CONSOLE_SCREEN_BUFFER_INFO),\n    ]\n    _GetConsoleScreenBufferInfo.restype = wintypes.BOOL\n\n    _SetConsoleTextAttribute = windll.kernel32.SetConsoleTextAttribute\n    _SetConsoleTextAttribute.argtypes = [\n        wintypes.HANDLE,\n        wintypes.WORD,\n    ]\n    _SetConsoleTextAttribute.restype = wintypes.BOOL\n\n    _SetConsoleCursorPosition = windll.kernel32.SetConsoleCursorPosition\n    _SetConsoleCursorPosition.argtypes = [\n        wintypes.HANDLE,\n        COORD,\n    ]\n    _SetConsoleCursorPosition.restype = wintypes.BOOL\n\n    _FillConsoleOutputCharacterA = windll.kernel32.FillConsoleOutputCharacterA\n    _FillConsoleOutputCharacterA.argtypes = [\n        wintypes.HANDLE,\n        c_char,\n        wintypes.DWORD,\n        COORD,\n        POINTER(wintypes.DWORD),\n    ]\n    _FillConsoleOutputCharacterA.restype = wintypes.BOOL\n\n    _FillConsoleOutputAttribute = windll.kernel32.FillConsoleOutputAttribute\n    _FillConsoleOutputAttribute.argtypes = [\n        wintypes.HANDLE,\n        wintypes.WORD,\n        wintypes.DWORD,\n        COORD,\n        POINTER(wintypes.DWORD),\n    ]\n    _FillConsoleOutputAttribute.restype = wintypes.BOOL\n\n    _SetConsoleTitleW = windll.kernel32.SetConsoleTitleW\n    _SetConsoleTitleW.argtypes = [\n        wintypes.LPCWSTR\n    ]\n    _SetConsoleTitleW.restype = wintypes.BOOL\n\n    _GetConsoleMode = windll.kernel32.GetConsoleMode\n    _GetConsoleMode.argtypes = [\n        wintypes.HANDLE,\n        POINTER(wintypes.DWORD)\n    ]\n    _GetConsoleMode.restype = wintypes.BOOL\n\n    _SetConsoleMode = windll.kernel32.SetConsoleMode\n    _SetConsoleMode.argtypes = [\n        wintypes.HANDLE,\n        wintypes.DWORD\n    ]\n    _SetConsoleMode.restype = wintypes.BOOL\n\n    def _winapi_test(handle):\n        csbi = CONSOLE_SCREEN_BUFFER_INFO()\n        success = _GetConsoleScreenBufferInfo(\n            handle, byref(csbi))\n        return bool(success)\n\n    def winapi_test():\n        return any(_winapi_test(h) for h in\n                   (_GetStdHandle(STDOUT), _GetStdHandle(STDERR)))\n\n    def GetConsoleScreenBufferInfo(stream_id=STDOUT):\n        handle = _GetStdHandle(stream_id)\n        csbi = CONSOLE_SCREEN_BUFFER_INFO()\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\winterm.py": {
      "sha": "a48da4f9ccf9",
      "lines": 195,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\ntry:\n    from msvcrt import get_osfhandle\nexcept ImportError:\n    def get_osfhandle(_):\n        raise OSError(\"This isn't windows!\")\n\n\nfrom . import win32\n\n# from wincon.h\nclass WinColor(object):\n    BLACK   = 0\n    BLUE    = 1\n    GREEN   = 2\n    CYAN    = 3\n    RED     = 4\n    MAGENTA = 5\n    YELLOW  = 6\n    GREY    = 7\n\n# from wincon.h\nclass WinStyle(object):\n    NORMAL              = 0x00 # dim text, dim background\n    BRIGHT              = 0x08 # bright text, dim background\n    BRIGHT_BACKGROUND   = 0x80 # dim text, bright background\n\nclass WinTerm(object):\n\n    def __init__(self):\n        self._default = win32.GetConsoleScreenBufferInfo(win32.STDOUT).wAttributes\n        self.set_attrs(self._default)\n        self._default_fore = self._fore\n        self._default_back = self._back\n        self._default_style = self._style\n        # In order to emulate LIGHT_EX in windows, we borrow the BRIGHT style.\n        # So that LIGHT_EX colors and BRIGHT style do not clobber each other,\n        # we track them separately, since LIGHT_EX is overwritten by Fore/Back\n        # and BRIGHT is overwritten by Style codes.\n        self._light = 0\n\n    def get_attrs(self):\n        return self._fore + self._back * 16 + (self._style | self._light)\n\n    def set_attrs(self, value):\n        self._fore = value & 7\n        self._back = (value >> 4) & 7\n        self._style = value & (WinStyle.BRIGHT | WinStyle.BRIGHT_BACKGROUND)\n\n    def reset_all(self, on_stderr=None):\n        self.set_attrs(self._default)\n        self.set_console(attrs=self._default)\n        self._light = 0\n\n    def fore(self, fore=None, light=False, on_stderr=False):\n        if fore is None:\n            fore = self._default_fore\n        self._fore = fore\n        # Emulate LIGHT_EX with BRIGHT Style\n        if light:\n            self._light |= WinStyle.BRIGHT\n        else:\n            self._light &= ~WinStyle.BRIGHT\n        self.set_console(on_stderr=on_stderr)\n\n    def back(self, back=None, light=False, on_stderr=False):\n        if back is None:\n            back = self._default_back\n        self._back = back\n        # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style\n        if light:\n            self._light |= WinStyle.BRIGHT_BACKGROUND\n        else:\n            self._light &= ~WinStyle.BRIGHT_BACKGROUND\n        self.set_console(on_stderr=on_stderr)\n\n    def style(self, style=None, on_stderr=False):\n        if style is None:\n            style = self._default_style\n        self._style = style\n        self.set_console(on_stderr=on_stderr)\n\n    def set_console(self, attrs=None, on_stderr=False):\n        if attrs is None:\n            attrs = self.get_attrs()\n        handle = win32.STDOUT\n        if on_stderr:\n            handle = win32.STDERR\n        win32.SetConsoleTextAttribute(handle, attrs)\n\n    def get_position(self, handle):\n        position = win32.GetConsoleScreenBufferInfo(handle).dwCursorPosition\n        # Because Windows coordinates are 0-based,\n        # and win32.SetConsoleCursorPosition expects 1-based.\n        position.X += 1\n        position.Y += 1\n        return position\n\n    def set_cursor_position(self, position=None, on_stderr=False):\n        if position is None:\n            # I'm not currently tracking the position, so there is no default.\n            # position = self.get_position()\n            return\n        handle = win32.STDOUT\n        if on_stderr:\n            handle = win32.STDERR\n        win32.SetConsoleCursorPosition(handle, position)\n\n    def cursor_adjust(self, x, y, on_stderr=False):\n        handle = win32.STDOUT\n        if on_stderr:\n            handle = win32.STDERR\n        position = self.get_position(handle)\n        adjusted_position = (position.Y + y, position.X + x)\n        win32.SetConsoleCursorPosition(handle, adjusted_position, adjust=False)\n\n    def erase_screen(self, mode=0, on_stderr=False):\n        # 0 should clear from the cursor to the end of the screen.\n        # 1 should clear from the cursor to the beginning of the screen.\n        # 2 should clear the entire screen, and move cursor to (1,1)\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\__init__.py": {
      "sha": "e8a71d394bdb",
      "lines": 7,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nfrom .initialise import init, deinit, reinit, colorama_text, just_fix_windows_console\nfrom .ansi import Fore, Back, Style, Cursor\nfrom .ansitowin32 import AnsiToWin32\n\n__version__ = '0.4.6'\n\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\tests\\ansitowin32_test.py": {
      "sha": "f12536366df3",
      "lines": 294,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nfrom io import StringIO, TextIOWrapper\nfrom unittest import TestCase, main\ntry:\n    from contextlib import ExitStack\nexcept ImportError:\n    # python 2\n    from contextlib2 import ExitStack\n\ntry:\n    from unittest.mock import MagicMock, Mock, patch\nexcept ImportError:\n    from mock import MagicMock, Mock, patch\n\nfrom ..ansitowin32 import AnsiToWin32, StreamWrapper\nfrom ..win32 import ENABLE_VIRTUAL_TERMINAL_PROCESSING\nfrom .utils import osname\n\n\nclass StreamWrapperTest(TestCase):\n\n    def testIsAProxy(self):\n        mockStream = Mock()\n        wrapper = StreamWrapper(mockStream, None)\n        self.assertTrue( wrapper.random_attr is mockStream.random_attr )\n\n    def testDelegatesWrite(self):\n        mockStream = Mock()\n        mockConverter = Mock()\n        wrapper = StreamWrapper(mockStream, mockConverter)\n        wrapper.write('hello')\n        self.assertTrue(mockConverter.write.call_args, (('hello',), {}))\n\n    def testDelegatesContext(self):\n        mockConverter = Mock()\n        s = StringIO()\n        with StreamWrapper(s, mockConverter) as fp:\n            fp.write(u'hello')\n        self.assertTrue(s.closed)\n\n    def testProxyNoContextManager(self):\n        mockStream = MagicMock()\n        mockStream.__enter__.side_effect = AttributeError()\n        mockConverter = Mock()\n        with self.assertRaises(AttributeError) as excinfo:\n            with StreamWrapper(mockStream, mockConverter) as wrapper:\n                wrapper.write('hello')\n\n    def test_closed_shouldnt_raise_on_closed_stream(self):\n        stream = StringIO()\n        stream.close()\n        wrapper = StreamWrapper(stream, None)\n        self.assertEqual(wrapper.closed, True)\n\n    def test_closed_shouldnt_raise_on_detached_stream(self):\n        stream = TextIOWrapper(StringIO())\n        stream.detach()\n        wrapper = StreamWrapper(stream, None)\n        self.assertEqual(wrapper.closed, True)\n\nclass AnsiToWin32Test(TestCase):\n\n    def testInit(self):\n        mockStdout = Mock()\n        auto = Mock()\n        stream = AnsiToWin32(mockStdout, autoreset=auto)\n        self.assertEqual(stream.wrapped, mockStdout)\n        self.assertEqual(stream.autoreset, auto)\n\n    @patch('colorama.ansitowin32.winterm', None)\n    @patch('colorama.ansitowin32.winapi_test', lambda *_: True)\n    def testStripIsTrueOnWindows(self):\n        with osname('nt'):\n            mockStdout = Mock()\n            stream = AnsiToWin32(mockStdout)\n            self.assertTrue(stream.strip)\n\n    def testStripIsFalseOffWindows(self):\n        with osname('posix'):\n            mockStdout = Mock(closed=False)\n            stream = AnsiToWin32(mockStdout)\n            self.assertFalse(stream.strip)\n\n    def testWriteStripsAnsi(self):\n        mockStdout = Mock()\n        stream = AnsiToWin32(mockStdout)\n        stream.wrapped = Mock()\n        stream.write_and_convert = Mock()\n        stream.strip = True\n\n        stream.write('abc')\n\n        self.assertFalse(stream.wrapped.write.called)\n        self.assertEqual(stream.write_and_convert.call_args, (('abc',), {}))\n\n    def testWriteDoesNotStripAnsi(self):\n        mockStdout = Mock()\n        stream = AnsiToWin32(mockStdout)\n        stream.wrapped = Mock()\n        stream.write_and_convert = Mock()\n        stream.strip = False\n        stream.convert = False\n\n        stream.write('abc')\n\n        self.assertFalse(stream.write_and_convert.called)\n        self.assertEqual(stream.wrapped.write.call_args, (('abc',), {}))\n\n    def assert_autoresets(self, convert, autoreset=True):\n        stream = AnsiToWin32(Mock())\n        stream.convert = convert\n        stream.reset_all = Mock()\n        stream.autoreset = autoreset\n        stream.winterm = Mock()\n\n        stream.write('abc')\n\n        self.assertEqual(stream.reset_all.called, autoreset)\n\n    def testWriteAutoresets(self):\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\tests\\ansi_test.py": {
      "sha": "5b77e5699470",
      "lines": 76,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nimport sys\nfrom unittest import TestCase, main\n\nfrom ..ansi import Back, Fore, Style\nfrom ..ansitowin32 import AnsiToWin32\n\nstdout_orig = sys.stdout\nstderr_orig = sys.stderr\n\n\nclass AnsiTest(TestCase):\n\n    def setUp(self):\n        # sanity check: stdout should be a file or StringIO object.\n        # It will only be AnsiToWin32 if init() has previously wrapped it\n        self.assertNotEqual(type(sys.stdout), AnsiToWin32)\n        self.assertNotEqual(type(sys.stderr), AnsiToWin32)\n\n    def tearDown(self):\n        sys.stdout = stdout_orig\n        sys.stderr = stderr_orig\n\n\n    def testForeAttributes(self):\n        self.assertEqual(Fore.BLACK, '\\033[30m')\n        self.assertEqual(Fore.RED, '\\033[31m')\n        self.assertEqual(Fore.GREEN, '\\033[32m')\n        self.assertEqual(Fore.YELLOW, '\\033[33m')\n        self.assertEqual(Fore.BLUE, '\\033[34m')\n        self.assertEqual(Fore.MAGENTA, '\\033[35m')\n        self.assertEqual(Fore.CYAN, '\\033[36m')\n        self.assertEqual(Fore.WHITE, '\\033[37m')\n        self.assertEqual(Fore.RESET, '\\033[39m')\n\n        # Check the light, extended versions.\n        self.assertEqual(Fore.LIGHTBLACK_EX, '\\033[90m')\n        self.assertEqual(Fore.LIGHTRED_EX, '\\033[91m')\n        self.assertEqual(Fore.LIGHTGREEN_EX, '\\033[92m')\n        self.assertEqual(Fore.LIGHTYELLOW_EX, '\\033[93m')\n        self.assertEqual(Fore.LIGHTBLUE_EX, '\\033[94m')\n        self.assertEqual(Fore.LIGHTMAGENTA_EX, '\\033[95m')\n        self.assertEqual(Fore.LIGHTCYAN_EX, '\\033[96m')\n        self.assertEqual(Fore.LIGHTWHITE_EX, '\\033[97m')\n\n\n    def testBackAttributes(self):\n        self.assertEqual(Back.BLACK, '\\033[40m')\n        self.assertEqual(Back.RED, '\\033[41m')\n        self.assertEqual(Back.GREEN, '\\033[42m')\n        self.assertEqual(Back.YELLOW, '\\033[43m')\n        self.assertEqual(Back.BLUE, '\\033[44m')\n        self.assertEqual(Back.MAGENTA, '\\033[45m')\n        self.assertEqual(Back.CYAN, '\\033[46m')\n        self.assertEqual(Back.WHITE, '\\033[47m')\n        self.assertEqual(Back.RESET, '\\033[49m')\n\n        # Check the light, extended versions.\n        self.assertEqual(Back.LIGHTBLACK_EX, '\\033[100m')\n        self.assertEqual(Back.LIGHTRED_EX, '\\033[101m')\n        self.assertEqual(Back.LIGHTGREEN_EX, '\\033[102m')\n        self.assertEqual(Back.LIGHTYELLOW_EX, '\\033[103m')\n        self.assertEqual(Back.LIGHTBLUE_EX, '\\033[104m')\n        self.assertEqual(Back.LIGHTMAGENTA_EX, '\\033[105m')\n        self.assertEqual(Back.LIGHTCYAN_EX, '\\033[106m')\n        self.assertEqual(Back.LIGHTWHITE_EX, '\\033[107m')\n\n\n    def testStyleAttributes(self):\n        self.assertEqual(Style.DIM, '\\033[2m')\n        self.assertEqual(Style.NORMAL, '\\033[22m')\n        self.assertEqual(Style.BRIGHT, '\\033[1m')\n\n\nif __name__ == '__main__':\n    main()\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\tests\\initialise_test.py": {
      "sha": "16afa8a34506",
      "lines": 189,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nimport sys\nfrom unittest import TestCase, main, skipUnless\n\ntry:\n    from unittest.mock import patch, Mock\nexcept ImportError:\n    from mock import patch, Mock\n\nfrom ..ansitowin32 import StreamWrapper\nfrom ..initialise import init, just_fix_windows_console, _wipe_internal_state_for_tests\nfrom .utils import osname, replace_by\n\norig_stdout = sys.stdout\norig_stderr = sys.stderr\n\n\nclass InitTest(TestCase):\n\n    @skipUnless(sys.stdout.isatty(), \"sys.stdout is not a tty\")\n    def setUp(self):\n        # sanity check\n        self.assertNotWrapped()\n\n    def tearDown(self):\n        _wipe_internal_state_for_tests()\n        sys.stdout = orig_stdout\n        sys.stderr = orig_stderr\n\n    def assertWrapped(self):\n        self.assertIsNot(sys.stdout, orig_stdout, 'stdout should be wrapped')\n        self.assertIsNot(sys.stderr, orig_stderr, 'stderr should be wrapped')\n        self.assertTrue(isinstance(sys.stdout, StreamWrapper),\n            'bad stdout wrapper')\n        self.assertTrue(isinstance(sys.stderr, StreamWrapper),\n            'bad stderr wrapper')\n\n    def assertNotWrapped(self):\n        self.assertIs(sys.stdout, orig_stdout, 'stdout should not be wrapped')\n        self.assertIs(sys.stderr, orig_stderr, 'stderr should not be wrapped')\n\n    @patch('colorama.initialise.reset_all')\n    @patch('colorama.ansitowin32.winapi_test', lambda *_: True)\n    @patch('colorama.ansitowin32.enable_vt_processing', lambda *_: False)\n    def testInitWrapsOnWindows(self, _):\n        with osname(\"nt\"):\n            init()\n            self.assertWrapped()\n\n    @patch('colorama.initialise.reset_all')\n    @patch('colorama.ansitowin32.winapi_test', lambda *_: False)\n    def testInitDoesntWrapOnEmulatedWindows(self, _):\n        with osname(\"nt\"):\n            init()\n            self.assertNotWrapped()\n\n    def testInitDoesntWrapOnNonWindows(self):\n        with osname(\"posix\"):\n            init()\n            self.assertNotWrapped()\n\n    def testInitDoesntWrapIfNone(self):\n        with replace_by(None):\n            init()\n            # We can't use assertNotWrapped here because replace_by(None)\n            # changes stdout/stderr already.\n            self.assertIsNone(sys.stdout)\n            self.assertIsNone(sys.stderr)\n\n    def testInitAutoresetOnWrapsOnAllPlatforms(self):\n        with osname(\"posix\"):\n            init(autoreset=True)\n            self.assertWrapped()\n\n    def testInitWrapOffDoesntWrapOnWindows(self):\n        with osname(\"nt\"):\n            init(wrap=False)\n            self.assertNotWrapped()\n\n    def testInitWrapOffIncompatibleWithAutoresetOn(self):\n        self.assertRaises(ValueError, lambda: init(autoreset=True, wrap=False))\n\n    @patch('colorama.win32.SetConsoleTextAttribute')\n    @patch('colorama.initialise.AnsiToWin32')\n    def testAutoResetPassedOn(self, mockATW32, _):\n        with osname(\"nt\"):\n            init(autoreset=True)\n            self.assertEqual(len(mockATW32.call_args_list), 2)\n            self.assertEqual(mockATW32.call_args_list[1][1]['autoreset'], True)\n            self.assertEqual(mockATW32.call_args_list[0][1]['autoreset'], True)\n\n    @patch('colorama.initialise.AnsiToWin32')\n    def testAutoResetChangeable(self, mockATW32):\n        with osname(\"nt\"):\n            init()\n\n            init(autoreset=True)\n            self.assertEqual(len(mockATW32.call_args_list), 4)\n            self.assertEqual(mockATW32.call_args_list[2][1]['autoreset'], True)\n            self.assertEqual(mockATW32.call_args_list[3][1]['autoreset'], True)\n\n            init()\n            self.assertEqual(len(mockATW32.call_args_list), 6)\n            self.assertEqual(\n                mockATW32.call_args_list[4][1]['autoreset'], False)\n            self.assertEqual(\n                mockATW32.call_args_list[5][1]['autoreset'], False)\n\n\n    @patch('colorama.initialise.atexit.register')\n    def testAtexitRegisteredOnlyOnce(self, mockRegister):\n        init()\n        self.assertTrue(mockRegister.called)\n        mockRegister.reset_mock()\n        init()\n        self.assertFalse(mockRegister.called)\n\n\nclass JustFixWindowsConsoleTest(TestCase):\n    def _reset(self):\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\tests\\isatty_test.py": {
      "sha": "f3d9e6e2455a",
      "lines": 57,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nimport sys\nfrom unittest import TestCase, main\n\nfrom ..ansitowin32 import StreamWrapper, AnsiToWin32\nfrom .utils import pycharm, replace_by, replace_original_by, StreamTTY, StreamNonTTY\n\n\ndef is_a_tty(stream):\n    return StreamWrapper(stream, None).isatty()\n\nclass IsattyTest(TestCase):\n\n    def test_TTY(self):\n        tty = StreamTTY()\n        self.assertTrue(is_a_tty(tty))\n        with pycharm():\n            self.assertTrue(is_a_tty(tty))\n\n    def test_nonTTY(self):\n        non_tty = StreamNonTTY()\n        self.assertFalse(is_a_tty(non_tty))\n        with pycharm():\n            self.assertFalse(is_a_tty(non_tty))\n\n    def test_withPycharm(self):\n        with pycharm():\n            self.assertTrue(is_a_tty(sys.stderr))\n            self.assertTrue(is_a_tty(sys.stdout))\n\n    def test_withPycharmTTYOverride(self):\n        tty = StreamTTY()\n        with pycharm(), replace_by(tty):\n            self.assertTrue(is_a_tty(tty))\n\n    def test_withPycharmNonTTYOverride(self):\n        non_tty = StreamNonTTY()\n        with pycharm(), replace_by(non_tty):\n            self.assertFalse(is_a_tty(non_tty))\n\n    def test_withPycharmNoneOverride(self):\n        with pycharm():\n            with replace_by(None), replace_original_by(None):\n                self.assertFalse(is_a_tty(None))\n                self.assertFalse(is_a_tty(StreamNonTTY()))\n                self.assertTrue(is_a_tty(StreamTTY()))\n\n    def test_withPycharmStreamWrapped(self):\n        with pycharm():\n            self.assertTrue(AnsiToWin32(StreamTTY()).stream.isatty())\n            self.assertFalse(AnsiToWin32(StreamNonTTY()).stream.isatty())\n            self.assertTrue(AnsiToWin32(sys.stdout).stream.isatty())\n            self.assertTrue(AnsiToWin32(sys.stderr).stream.isatty())\n\n\nif __name__ == '__main__':\n    main()\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\tests\\utils.py": {
      "sha": "783c1793406e",
      "lines": 49,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nfrom contextlib import contextmanager\nfrom io import StringIO\nimport sys\nimport os\n\n\nclass StreamTTY(StringIO):\n    def isatty(self):\n        return True\n\nclass StreamNonTTY(StringIO):\n    def isatty(self):\n        return False\n\n@contextmanager\ndef osname(name):\n    orig = os.name\n    os.name = name\n    yield\n    os.name = orig\n\n@contextmanager\ndef replace_by(stream):\n    orig_stdout = sys.stdout\n    orig_stderr = sys.stderr\n    sys.stdout = stream\n    sys.stderr = stream\n    yield\n    sys.stdout = orig_stdout\n    sys.stderr = orig_stderr\n\n@contextmanager\ndef replace_original_by(stream):\n    orig_stdout = sys.__stdout__\n    orig_stderr = sys.__stderr__\n    sys.__stdout__ = stream\n    sys.__stderr__ = stream\n    yield\n    sys.__stdout__ = orig_stdout\n    sys.__stderr__ = orig_stderr\n\n@contextmanager\ndef pycharm():\n    os.environ[\"PYCHARM_HOSTED\"] = \"1\"\n    non_tty = StreamNonTTY()\n    with replace_by(non_tty), replace_original_by(non_tty):\n        yield\n    del os.environ[\"PYCHARM_HOSTED\"]\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\tests\\winterm_test.py": {
      "sha": "93f6f19aa15e",
      "lines": 131,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\nimport sys\nfrom unittest import TestCase, main, skipUnless\n\ntry:\n    from unittest.mock import Mock, patch\nexcept ImportError:\n    from mock import Mock, patch\n\nfrom ..winterm import WinColor, WinStyle, WinTerm\n\n\nclass WinTermTest(TestCase):\n\n    @patch('colorama.winterm.win32')\n    def testInit(self, mockWin32):\n        mockAttr = Mock()\n        mockAttr.wAttributes = 7 + 6 * 16 + 8\n        mockWin32.GetConsoleScreenBufferInfo.return_value = mockAttr\n        term = WinTerm()\n        self.assertEqual(term._fore, 7)\n        self.assertEqual(term._back, 6)\n        self.assertEqual(term._style, 8)\n\n    @skipUnless(sys.platform.startswith(\"win\"), \"requires Windows\")\n    def testGetAttrs(self):\n        term = WinTerm()\n\n        term._fore = 0\n        term._back = 0\n        term._style = 0\n        self.assertEqual(term.get_attrs(), 0)\n\n        term._fore = WinColor.YELLOW\n        self.assertEqual(term.get_attrs(), WinColor.YELLOW)\n\n        term._back = WinColor.MAGENTA\n        self.assertEqual(\n            term.get_attrs(),\n            WinColor.YELLOW + WinColor.MAGENTA * 16)\n\n        term._style = WinStyle.BRIGHT\n        self.assertEqual(\n            term.get_attrs(),\n            WinColor.YELLOW + WinColor.MAGENTA * 16 + WinStyle.BRIGHT)\n\n    @patch('colorama.winterm.win32')\n    def testResetAll(self, mockWin32):\n        mockAttr = Mock()\n        mockAttr.wAttributes = 1 + 2 * 16 + 8\n        mockWin32.GetConsoleScreenBufferInfo.return_value = mockAttr\n        term = WinTerm()\n\n        term.set_console = Mock()\n        term._fore = -1\n        term._back = -1\n        term._style = -1\n\n        term.reset_all()\n\n        self.assertEqual(term._fore, 1)\n        self.assertEqual(term._back, 2)\n        self.assertEqual(term._style, 8)\n        self.assertEqual(term.set_console.called, True)\n\n    @skipUnless(sys.platform.startswith(\"win\"), \"requires Windows\")\n    def testFore(self):\n        term = WinTerm()\n        term.set_console = Mock()\n        term._fore = 0\n\n        term.fore(5)\n\n        self.assertEqual(term._fore, 5)\n        self.assertEqual(term.set_console.called, True)\n\n    @skipUnless(sys.platform.startswith(\"win\"), \"requires Windows\")\n    def testBack(self):\n        term = WinTerm()\n        term.set_console = Mock()\n        term._back = 0\n\n        term.back(5)\n\n        self.assertEqual(term._back, 5)\n        self.assertEqual(term.set_console.called, True)\n\n    @skipUnless(sys.platform.startswith(\"win\"), \"requires Windows\")\n    def testStyle(self):\n        term = WinTerm()\n        term.set_console = Mock()\n        term._style = 0\n\n        term.style(22)\n\n        self.assertEqual(term._style, 22)\n        self.assertEqual(term.set_console.called, True)\n\n    @patch('colorama.winterm.win32')\n    def testSetConsole(self, mockWin32):\n        mockAttr = Mock()\n        mockAttr.wAttributes = 0\n        mockWin32.GetConsoleScreenBufferInfo.return_value = mockAttr\n        term = WinTerm()\n        term.windll = Mock()\n\n        term.set_console()\n\n        self.assertEqual(\n            mockWin32.SetConsoleTextAttribute.call_args,\n            ((mockWin32.STDOUT, term.get_attrs()), {})\n        )\n\n    @patch('colorama.winterm.win32')\n    def testSetConsoleOnStderr(self, mockWin32):\n        mockAttr = Mock()\n        mockAttr.wAttributes = 0\n        mockWin32.GetConsoleScreenBufferInfo.return_value = mockAttr\n        term = WinTerm()\n        term.windll = Mock()\n"
    },
    ".venv\\Lib\\site-packages\\colorama\\tests\\__init__.py": {
      "sha": "9e20db9e5344",
      "lines": 1,
      "head": "# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.\n"
    },
    ".venv\\Lib\\site-packages\\colorama-0.4.6.dist-info\\licenses\\LICENSE.txt": {
      "sha": "151478b5f4a6",
      "lines": 27,
      "head": "Copyright (c) 2010 Jonathan Hartley\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holders, nor those of its contributors\n  may be used to endorse or promote products derived from this software without\n  specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
    },
    ".venv\\Lib\\site-packages\\dotenv\\cli.py": {
      "sha": "5177a96d618c",
      "lines": 205,
      "head": "import json\nimport os\nimport shlex\nimport sys\nfrom contextlib import contextmanager\nfrom typing import Any, Dict, IO, Iterator, List, Optional\n\nif sys.platform == 'win32':\n    from subprocess import Popen\n\ntry:\n    import click\nexcept ImportError:\n    sys.stderr.write('It seems python-dotenv is not installed with cli option. \\n'\n                     'Run pip install \"python-dotenv[cli]\" to fix this.')\n    sys.exit(1)\n\nfrom .main import dotenv_values, set_key, unset_key\nfrom .version import __version__\n\n\ndef enumerate_env() -> Optional[str]:\n    \"\"\"\n    Return a path for the ${pwd}/.env file.\n\n    If pwd does not exist, return None.\n    \"\"\"\n    try:\n        cwd = os.getcwd()\n    except FileNotFoundError:\n        return None\n    path = os.path.join(cwd, '.env')\n    return path\n\n\n@click.group()\n@click.option('-f', '--file', default=enumerate_env(),\n              type=click.Path(file_okay=True),\n              help=\"Location of the .env file, defaults to .env file in current working directory.\")\n@click.option('-q', '--quote', default='always',\n              type=click.Choice(['always', 'never', 'auto']),\n              help=\"Whether to quote or not the variable values. Default mode is always. This does not affect parsing.\")\n@click.option('-e', '--export', default=False,\n              type=click.BOOL,\n              help=\"Whether to write the dot file as an executable bash script.\")\n@click.version_option(version=__version__)\n@click.pass_context\ndef cli(ctx: click.Context, file: Any, quote: Any, export: Any) -> None:\n    \"\"\"This script is used to set, get or unset values from a .env file.\"\"\"\n    ctx.obj = {'QUOTE': quote, 'EXPORT': export, 'FILE': file}\n\n\n@contextmanager\ndef stream_file(path: os.PathLike) -> Iterator[IO[str]]:\n    \"\"\"\n    Open a file and yield the corresponding (decoded) stream.\n\n    Exits with error code 2 if the file cannot be opened.\n    \"\"\"\n\n    try:\n        with open(path) as stream:\n            yield stream\n    except OSError as exc:\n        print(f\"Error opening env file: {exc}\", file=sys.stderr)\n        exit(2)\n\n\n@cli.command()\n@click.pass_context\n@click.option('--format', default='simple',\n              type=click.Choice(['simple', 'json', 'shell', 'export']),\n              help=\"The format in which to display the list. Default format is simple, \"\n                   \"which displays name=value without quotes.\")\ndef list(ctx: click.Context, format: bool) -> None:\n    \"\"\"Display all the stored key/value.\"\"\"\n    file = ctx.obj['FILE']\n\n    with stream_file(file) as stream:\n        values = dotenv_values(stream=stream)\n\n    if format == 'json':\n        click.echo(json.dumps(values, indent=2, sort_keys=True))\n    else:\n        prefix = 'export ' if format == 'export' else ''\n        for k in sorted(values):\n            v = values[k]\n            if v is not None:\n                if format in ('export', 'shell'):\n                    v = shlex.quote(v)\n                click.echo(f'{prefix}{k}={v}')\n\n\n@cli.command()\n@click.pass_context\n@click.argument('key', required=True)\n@click.argument('value', required=True)\ndef set(ctx: click.Context, key: Any, value: Any) -> None:\n    \"\"\"Store the given key/value.\"\"\"\n    file = ctx.obj['FILE']\n    quote = ctx.obj['QUOTE']\n    export = ctx.obj['EXPORT']\n    success, key, value = set_key(file, key, value, quote, export)\n    if success:\n        click.echo(f'{key}={value}')\n    else:\n        exit(1)\n\n\n@cli.command()\n@click.pass_context\n@click.argument('key', required=True)\ndef get(ctx: click.Context, key: Any) -> None:\n    \"\"\"Retrieve the value for the given key.\"\"\"\n    file = ctx.obj['FILE']\n\n    with stream_file(file) as stream:\n        values = dotenv_values(stream=stream)\n\n    stored_value = values.get(key)\n"
    },
    ".venv\\Lib\\site-packages\\dotenv\\ipython.py": {
      "sha": "defce419ce4a",
      "lines": 39,
      "head": "from IPython.core.magic import Magics, line_magic, magics_class  # type: ignore\nfrom IPython.core.magic_arguments import (argument, magic_arguments,  # type: ignore\n                                          parse_argstring)  # type: ignore\n\nfrom .main import find_dotenv, load_dotenv\n\n\n@magics_class\nclass IPythonDotEnv(Magics):\n\n    @magic_arguments()\n    @argument(\n        '-o', '--override', action='store_true',\n        help=\"Indicate to override existing variables\"\n    )\n    @argument(\n        '-v', '--verbose', action='store_true',\n        help=\"Indicate function calls to be verbose\"\n    )\n    @argument('dotenv_path', nargs='?', type=str, default='.env',\n              help='Search in increasingly higher folders for the `dotenv_path`')\n    @line_magic\n    def dotenv(self, line):\n        args = parse_argstring(self.dotenv, line)\n        # Locate the .env file\n        dotenv_path = args.dotenv_path\n        try:\n            dotenv_path = find_dotenv(dotenv_path, True, True)\n        except IOError:\n            print(\"cannot find .env file\")\n            return\n\n        # Load the .env file\n        load_dotenv(dotenv_path, verbose=args.verbose, override=args.override)\n\n\ndef load_ipython_extension(ipython):\n    \"\"\"Register the %dotenv magic.\"\"\"\n    ipython.register_magics(IPythonDotEnv)\n"
    },
    ".venv\\Lib\\site-packages\\dotenv\\main.py": {
      "sha": "c09c41a89f00",
      "lines": 400,
      "head": "import io\nimport logging\nimport os\nimport pathlib\nimport shutil\nimport sys\nimport tempfile\nfrom collections import OrderedDict\nfrom contextlib import contextmanager\nfrom typing import IO, Dict, Iterable, Iterator, Mapping, Optional, Tuple, Union\n\nfrom .parser import Binding, parse_stream\nfrom .variables import parse_variables\n\n# A type alias for a string path to be used for the paths in this file.\n# These paths may flow to `open()` and `shutil.move()`; `shutil.move()`\n# only accepts string paths, not byte paths or file descriptors. See\n# https://github.com/python/typeshed/pull/6832.\nStrPath = Union[str, \"os.PathLike[str]\"]\n\nlogger = logging.getLogger(__name__)\n\n\ndef with_warn_for_invalid_lines(mappings: Iterator[Binding]) -> Iterator[Binding]:\n    for mapping in mappings:\n        if mapping.error:\n            logger.warning(\n                \"python-dotenv could not parse statement starting at line %s\",\n                mapping.original.line,\n            )\n        yield mapping\n\n\nclass DotEnv:\n    def __init__(\n        self,\n        dotenv_path: Optional[StrPath],\n        stream: Optional[IO[str]] = None,\n        verbose: bool = False,\n        encoding: Optional[str] = None,\n        interpolate: bool = True,\n        override: bool = True,\n    ) -> None:\n        self.dotenv_path: Optional[StrPath] = dotenv_path\n        self.stream: Optional[IO[str]] = stream\n        self._dict: Optional[Dict[str, Optional[str]]] = None\n        self.verbose: bool = verbose\n        self.encoding: Optional[str] = encoding\n        self.interpolate: bool = interpolate\n        self.override: bool = override\n\n    @contextmanager\n    def _get_stream(self) -> Iterator[IO[str]]:\n        if self.dotenv_path and os.path.isfile(self.dotenv_path):\n            with open(self.dotenv_path, encoding=self.encoding) as stream:\n                yield stream\n        elif self.stream is not None:\n            yield self.stream\n        else:\n            if self.verbose:\n                logger.info(\n                    \"python-dotenv could not find configuration file %s.\",\n                    self.dotenv_path or \".env\",\n                )\n            yield io.StringIO(\"\")\n\n    def dict(self) -> Dict[str, Optional[str]]:\n        \"\"\"Return dotenv as dict\"\"\"\n        if self._dict:\n            return self._dict\n\n        raw_values = self.parse()\n\n        if self.interpolate:\n            self._dict = OrderedDict(\n                resolve_variables(raw_values, override=self.override)\n            )\n        else:\n            self._dict = OrderedDict(raw_values)\n\n        return self._dict\n\n    def parse(self) -> Iterator[Tuple[str, Optional[str]]]:\n        with self._get_stream() as stream:\n            for mapping in with_warn_for_invalid_lines(parse_stream(stream)):\n                if mapping.key is not None:\n                    yield mapping.key, mapping.value\n\n    def set_as_environment_variables(self) -> bool:\n        \"\"\"\n        Load the current dotenv as system environment variable.\n        \"\"\"\n        if not self.dict():\n            return False\n\n        for k, v in self.dict().items():\n            if k in os.environ and not self.override:\n                continue\n            if v is not None:\n                os.environ[k] = v\n\n        return True\n\n    def get(self, key: str) -> Optional[str]:\n        \"\"\" \"\"\"\n        data = self.dict()\n\n        if key in data:\n            return data[key]\n\n        if self.verbose:\n            logger.warning(\"Key %s not found in %s.\", key, self.dotenv_path)\n\n        return None\n\n\ndef get_key(\n    dotenv_path: StrPath,\n    key_to_get: str,\n    encoding: Optional[str] = \"utf-8\",\n"
    },
    ".venv\\Lib\\site-packages\\dotenv\\parser.py": {
      "sha": "823e8c8b9e75",
      "lines": 175,
      "head": "import codecs\nimport re\nfrom typing import (IO, Iterator, Match, NamedTuple, Optional,  # noqa:F401\n                    Pattern, Sequence, Tuple)\n\n\ndef make_regex(string: str, extra_flags: int = 0) -> Pattern[str]:\n    return re.compile(string, re.UNICODE | extra_flags)\n\n\n_newline = make_regex(r\"(\\r\\n|\\n|\\r)\")\n_multiline_whitespace = make_regex(r\"\\s*\", extra_flags=re.MULTILINE)\n_whitespace = make_regex(r\"[^\\S\\r\\n]*\")\n_export = make_regex(r\"(?:export[^\\S\\r\\n]+)?\")\n_single_quoted_key = make_regex(r\"'([^']+)'\")\n_unquoted_key = make_regex(r\"([^=\\#\\s]+)\")\n_equal_sign = make_regex(r\"(=[^\\S\\r\\n]*)\")\n_single_quoted_value = make_regex(r\"'((?:\\\\'|[^'])*)'\")\n_double_quoted_value = make_regex(r'\"((?:\\\\\"|[^\"])*)\"')\n_unquoted_value = make_regex(r\"([^\\r\\n]*)\")\n_comment = make_regex(r\"(?:[^\\S\\r\\n]*#[^\\r\\n]*)?\")\n_end_of_line = make_regex(r\"[^\\S\\r\\n]*(?:\\r\\n|\\n|\\r|$)\")\n_rest_of_line = make_regex(r\"[^\\r\\n]*(?:\\r|\\n|\\r\\n)?\")\n_double_quote_escapes = make_regex(r\"\\\\[\\\\'\\\"abfnrtv]\")\n_single_quote_escapes = make_regex(r\"\\\\[\\\\']\")\n\n\nclass Original(NamedTuple):\n    string: str\n    line: int\n\n\nclass Binding(NamedTuple):\n    key: Optional[str]\n    value: Optional[str]\n    original: Original\n    error: bool\n\n\nclass Position:\n    def __init__(self, chars: int, line: int) -> None:\n        self.chars = chars\n        self.line = line\n\n    @classmethod\n    def start(cls) -> \"Position\":\n        return cls(chars=0, line=1)\n\n    def set(self, other: \"Position\") -> None:\n        self.chars = other.chars\n        self.line = other.line\n\n    def advance(self, string: str) -> None:\n        self.chars += len(string)\n        self.line += len(re.findall(_newline, string))\n\n\nclass Error(Exception):\n    pass\n\n\nclass Reader:\n    def __init__(self, stream: IO[str]) -> None:\n        self.string = stream.read()\n        self.position = Position.start()\n        self.mark = Position.start()\n\n    def has_next(self) -> bool:\n        return self.position.chars < len(self.string)\n\n    def set_mark(self) -> None:\n        self.mark.set(self.position)\n\n    def get_marked(self) -> Original:\n        return Original(\n            string=self.string[self.mark.chars:self.position.chars],\n            line=self.mark.line,\n        )\n\n    def peek(self, count: int) -> str:\n        return self.string[self.position.chars:self.position.chars + count]\n\n    def read(self, count: int) -> str:\n        result = self.string[self.position.chars:self.position.chars + count]\n        if len(result) < count:\n            raise Error(\"read: End of string\")\n        self.position.advance(result)\n        return result\n\n    def read_regex(self, regex: Pattern[str]) -> Sequence[str]:\n        match = regex.match(self.string, self.position.chars)\n        if match is None:\n            raise Error(\"read_regex: Pattern not found\")\n        self.position.advance(self.string[match.start():match.end()])\n        return match.groups()\n\n\ndef decode_escapes(regex: Pattern[str], string: str) -> str:\n    def decode_match(match: Match[str]) -> str:\n        return codecs.decode(match.group(0), 'unicode-escape')  # type: ignore\n\n    return regex.sub(decode_match, string)\n\n\ndef parse_key(reader: Reader) -> Optional[str]:\n    char = reader.peek(1)\n    if char == \"#\":\n        return None\n    elif char == \"'\":\n        (key,) = reader.read_regex(_single_quoted_key)\n    else:\n        (key,) = reader.read_regex(_unquoted_key)\n    return key\n\n\ndef parse_unquoted_value(reader: Reader) -> str:\n    (part,) = reader.read_regex(_unquoted_value)\n    return re.sub(r\"\\s+#.*\", \"\", part).rstrip()\n\n\n"
    },
    ".venv\\Lib\\site-packages\\dotenv\\variables.py": {
      "sha": "364b07ac4632",
      "lines": 86,
      "head": "import re\nfrom abc import ABCMeta, abstractmethod\nfrom typing import Iterator, Mapping, Optional, Pattern\n\n_posix_variable: Pattern[str] = re.compile(\n    r\"\"\"\n    \\$\\{\n        (?P<name>[^\\}:]*)\n        (?::-\n            (?P<default>[^\\}]*)\n        )?\n    \\}\n    \"\"\",\n    re.VERBOSE,\n)\n\n\nclass Atom(metaclass=ABCMeta):\n    def __ne__(self, other: object) -> bool:\n        result = self.__eq__(other)\n        if result is NotImplemented:\n            return NotImplemented\n        return not result\n\n    @abstractmethod\n    def resolve(self, env: Mapping[str, Optional[str]]) -> str: ...\n\n\nclass Literal(Atom):\n    def __init__(self, value: str) -> None:\n        self.value = value\n\n    def __repr__(self) -> str:\n        return f\"Literal(value={self.value})\"\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.value == other.value\n\n    def __hash__(self) -> int:\n        return hash((self.__class__, self.value))\n\n    def resolve(self, env: Mapping[str, Optional[str]]) -> str:\n        return self.value\n\n\nclass Variable(Atom):\n    def __init__(self, name: str, default: Optional[str]) -> None:\n        self.name = name\n        self.default = default\n\n    def __repr__(self) -> str:\n        return f\"Variable(name={self.name}, default={self.default})\"\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return (self.name, self.default) == (other.name, other.default)\n\n    def __hash__(self) -> int:\n        return hash((self.__class__, self.name, self.default))\n\n    def resolve(self, env: Mapping[str, Optional[str]]) -> str:\n        default = self.default if self.default is not None else \"\"\n        result = env.get(self.name, default)\n        return result if result is not None else \"\"\n\n\ndef parse_variables(value: str) -> Iterator[Atom]:\n    cursor = 0\n\n    for match in _posix_variable.finditer(value):\n        (start, end) = match.span()\n        name = match[\"name\"]\n        default = match[\"default\"]\n\n        if start > cursor:\n            yield Literal(value=value[cursor:start])\n\n        yield Variable(name=name, default=default)\n        cursor = end\n\n    length = len(value)\n    if cursor < length:\n        yield Literal(value=value[cursor:length])\n"
    },
    ".venv\\Lib\\site-packages\\dotenv\\version.py": {
      "sha": "464a6409b00f",
      "lines": 1,
      "head": "__version__ = \"1.1.1\"\n"
    },
    ".venv\\Lib\\site-packages\\dotenv\\__init__.py": {
      "sha": "170d43e6c9e6",
      "lines": 49,
      "head": "from typing import Any, Optional\n\nfrom .main import (dotenv_values, find_dotenv, get_key, load_dotenv, set_key,\n                   unset_key)\n\n\ndef load_ipython_extension(ipython: Any) -> None:\n    from .ipython import load_ipython_extension\n    load_ipython_extension(ipython)\n\n\ndef get_cli_string(\n    path: Optional[str] = None,\n    action: Optional[str] = None,\n    key: Optional[str] = None,\n    value: Optional[str] = None,\n    quote: Optional[str] = None,\n):\n    \"\"\"Returns a string suitable for running as a shell script.\n\n    Useful for converting a arguments passed to a fabric task\n    to be passed to a `local` or `run` command.\n    \"\"\"\n    command = ['dotenv']\n    if quote:\n        command.append(f'-q {quote}')\n    if path:\n        command.append(f'-f {path}')\n    if action:\n        command.append(action)\n        if key:\n            command.append(key)\n            if value:\n                if ' ' in value:\n                    command.append(f'\"{value}\"')\n                else:\n                    command.append(value)\n\n    return ' '.join(command).strip()\n\n\n__all__ = ['get_cli_string',\n           'load_dotenv',\n           'dotenv_values',\n           'get_key',\n           'set_key',\n           'unset_key',\n           'find_dotenv',\n           'load_ipython_extension']\n"
    },
    ".venv\\Lib\\site-packages\\dotenv\\__main__.py": {
      "sha": "5577d91802f9",
      "lines": 6,
      "head": "\"\"\"Entry point for cli, enables execution with `python -m dotenv`\"\"\"\n\nfrom .cli import cli\n\nif __name__ == \"__main__\":\n    cli()\n"
    },
    ".venv\\Lib\\site-packages\\flask\\app.py": {
      "sha": "e05c8f80af25",
      "lines": 1536,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport os\nimport sys\nimport typing as t\nimport weakref\nfrom datetime import timedelta\nfrom inspect import iscoroutinefunction\nfrom itertools import chain\nfrom types import TracebackType\nfrom urllib.parse import quote as _url_quote\n\nimport click\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.datastructures import ImmutableDict\nfrom werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import InternalServerError\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import MapAdapter\nfrom werkzeug.routing import RequestRedirect\nfrom werkzeug.routing import RoutingException\nfrom werkzeug.routing import Rule\nfrom werkzeug.serving import is_running_from_reloader\nfrom werkzeug.wrappers import Response as BaseResponse\nfrom werkzeug.wsgi import get_host\n\nfrom . import cli\nfrom . import typing as ft\nfrom .ctx import AppContext\nfrom .ctx import RequestContext\nfrom .globals import _cv_app\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import g\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .helpers import get_debug_flag\nfrom .helpers import get_flashed_messages\nfrom .helpers import get_load_dotenv\nfrom .helpers import send_from_directory\nfrom .sansio.app import App\nfrom .sansio.scaffold import _sentinel\nfrom .sessions import SecureCookieSessionInterface\nfrom .sessions import SessionInterface\nfrom .signals import appcontext_tearing_down\nfrom .signals import got_request_exception\nfrom .signals import request_finished\nfrom .signals import request_started\nfrom .signals import request_tearing_down\nfrom .templating import Environment\nfrom .wrappers import Request\nfrom .wrappers import Response\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .testing import FlaskClient\n    from .testing import FlaskCliRunner\n    from .typing import HeadersValue\n\nT_shell_context_processor = t.TypeVar(\n    \"T_shell_context_processor\", bound=ft.ShellContextProcessorCallable\n)\nT_teardown = t.TypeVar(\"T_teardown\", bound=ft.TeardownCallable)\nT_template_filter = t.TypeVar(\"T_template_filter\", bound=ft.TemplateFilterCallable)\nT_template_global = t.TypeVar(\"T_template_global\", bound=ft.TemplateGlobalCallable)\nT_template_test = t.TypeVar(\"T_template_test\", bound=ft.TemplateTestCallable)\n\n\ndef _make_timedelta(value: timedelta | int | None) -> timedelta | None:\n    if value is None or isinstance(value, timedelta):\n        return value\n\n    return timedelta(seconds=value)\n\n\nclass Flask(App):\n    \"\"\"The flask object implements a WSGI application and acts as the central\n    object.  It is passed the name of the module or package of the\n    application.  Once it is created it will act as a central registry for\n    the view functions, the URL rules, template configuration and much more.\n\n    The name of the package is used to resolve resources from inside the\n    package or the folder the module is contained in depending on if the\n    package parameter resolves to an actual python package (a folder with\n    an :file:`__init__.py` file inside) or a standard module (just a ``.py`` file).\n\n    For more information about resource loading, see :func:`open_resource`.\n\n    Usually you create a :class:`Flask` instance in your main module or\n    in the :file:`__init__.py` file of your package like this::\n\n        from flask import Flask\n        app = Flask(__name__)\n\n    .. admonition:: About the First Parameter\n\n        The idea of the first parameter is to give Flask an idea of what\n        belongs to your application.  This name is used to find resources\n        on the filesystem, can be used by extensions to improve debugging\n        information and a lot more.\n\n        So it's important what you provide there.  If you are using a single\n        module, `__name__` is always the correct value.  If you however are\n        using a package, it's usually recommended to hardcode the name of\n        your package there.\n\n        For example if your application is defined in :file:`yourapplication/app.py`\n        you should create it with one of the two versions below::\n\n            app = Flask('yourapplication')\n            app = Flask(__name__.split('.')[0])\n\n        Why is that?  The application will work even with `__name__`, thanks\n        to how resources are looked up.  However it will make debugging more\n        painful.  Certain extensions can make assumptions based on the\n"
    },
    ".venv\\Lib\\site-packages\\flask\\blueprints.py": {
      "sha": "9ec3c242801f",
      "lines": 128,
      "head": "from __future__ import annotations\n\nimport os\nimport typing as t\nfrom datetime import timedelta\n\nfrom .cli import AppGroup\nfrom .globals import current_app\nfrom .helpers import send_from_directory\nfrom .sansio.blueprints import Blueprint as SansioBlueprint\nfrom .sansio.blueprints import BlueprintSetupState as BlueprintSetupState  # noqa\nfrom .sansio.scaffold import _sentinel\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\nclass Blueprint(SansioBlueprint):\n    def __init__(\n        self,\n        name: str,\n        import_name: str,\n        static_folder: str | os.PathLike[str] | None = None,\n        static_url_path: str | None = None,\n        template_folder: str | os.PathLike[str] | None = None,\n        url_prefix: str | None = None,\n        subdomain: str | None = None,\n        url_defaults: dict[str, t.Any] | None = None,\n        root_path: str | None = None,\n        cli_group: str | None = _sentinel,  # type: ignore\n    ) -> None:\n        super().__init__(\n            name,\n            import_name,\n            static_folder,\n            static_url_path,\n            template_folder,\n            url_prefix,\n            subdomain,\n            url_defaults,\n            root_path,\n            cli_group,\n        )\n\n        #: The Click command group for registering CLI commands for this\n        #: object. The commands are available from the ``flask`` command\n        #: once the application has been discovered and blueprints have\n        #: been registered.\n        self.cli = AppGroup()\n\n        # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name\n\n    def get_send_file_max_age(self, filename: str | None) -> int | None:\n        \"\"\"Used by :func:`send_file` to determine the ``max_age`` cache\n        value for a given file path if it wasn't passed.\n\n        By default, this returns :data:`SEND_FILE_MAX_AGE_DEFAULT` from\n        the configuration of :data:`~flask.current_app`. This defaults\n        to ``None``, which tells the browser to use conditional requests\n        instead of a timed cache, which is usually preferable.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionchanged:: 2.0\n            The default configuration is ``None`` instead of 12 hours.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        value = current_app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n\n        if value is None:\n            return None\n\n        if isinstance(value, timedelta):\n            return int(value.total_seconds())\n\n        return value  # type: ignore[no-any-return]\n\n    def send_static_file(self, filename: str) -> Response:\n        \"\"\"The view function used to serve files from\n        :attr:`static_folder`. A route is automatically registered for\n        this view at :attr:`static_url_path` if :attr:`static_folder` is\n        set.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionadded:: 0.5\n\n        \"\"\"\n        if not self.has_static_folder:\n            raise RuntimeError(\"'static_folder' must be set to serve static_files.\")\n\n        # send_file only knows to call get_send_file_max_age on the app,\n        # call it here so it works for blueprints too.\n        max_age = self.get_send_file_max_age(filename)\n        return send_from_directory(\n            t.cast(str, self.static_folder), filename, max_age=max_age\n        )\n\n    def open_resource(\n        self, resource: str, mode: str = \"rb\", encoding: str | None = \"utf-8\"\n    ) -> t.IO[t.AnyStr]:\n        \"\"\"Open a resource file relative to :attr:`root_path` for reading. The\n        blueprint-relative equivalent of the app's :meth:`~.Flask.open_resource`\n        method.\n\n        :param resource: Path to the resource relative to :attr:`root_path`.\n        :param mode: Open the file in this mode. Only reading is supported,\n            valid values are ``\"r\"`` (or ``\"rt\"``) and ``\"rb\"``.\n        :param encoding: Open the file with this encoding when opening in text\n            mode. This is ignored when opening in binary mode.\n\n        .. versionchanged:: 3.1\n            Added the ``encoding`` parameter.\n        \"\"\"\n        if mode not in {\"r\", \"rt\", \"rb\"}:\n"
    },
    ".venv\\Lib\\site-packages\\flask\\cli.py": {
      "sha": "9a94e72e3718",
      "lines": 1135,
      "head": "from __future__ import annotations\n\nimport ast\nimport collections.abc as cabc\nimport importlib.metadata\nimport inspect\nimport os\nimport platform\nimport re\nimport sys\nimport traceback\nimport typing as t\nfrom functools import update_wrapper\nfrom operator import itemgetter\nfrom types import ModuleType\n\nimport click\nfrom click.core import ParameterSource\nfrom werkzeug import run_simple\nfrom werkzeug.serving import is_running_from_reloader\nfrom werkzeug.utils import import_string\n\nfrom .globals import current_app\nfrom .helpers import get_debug_flag\nfrom .helpers import get_load_dotenv\n\nif t.TYPE_CHECKING:\n    import ssl\n\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .app import Flask\n\n\nclass NoAppException(click.UsageError):\n    \"\"\"Raised if an application cannot be found or loaded.\"\"\"\n\n\ndef find_best_app(module: ModuleType) -> Flask:\n    \"\"\"Given a module instance this tries to find the best possible\n    application in the module or raises an exception.\n    \"\"\"\n    from . import Flask\n\n    # Search for the most common names first.\n    for attr_name in (\"app\", \"application\"):\n        app = getattr(module, attr_name, None)\n\n        if isinstance(app, Flask):\n            return app\n\n    # Otherwise find the only object that is a Flask instance.\n    matches = [v for v in module.__dict__.values() if isinstance(v, Flask)]\n\n    if len(matches) == 1:\n        return matches[0]\n    elif len(matches) > 1:\n        raise NoAppException(\n            \"Detected multiple Flask applications in module\"\n            f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n            \" to specify the correct one.\"\n        )\n\n    # Search for app factory functions.\n    for attr_name in (\"create_app\", \"make_app\"):\n        app_factory = getattr(module, attr_name, None)\n\n        if inspect.isfunction(app_factory):\n            try:\n                app = app_factory()\n\n                if isinstance(app, Flask):\n                    return app\n            except TypeError as e:\n                if not _called_with_wrong_args(app_factory):\n                    raise\n\n                raise NoAppException(\n                    f\"Detected factory '{attr_name}' in module '{module.__name__}',\"\n                    \" but could not call it without arguments. Use\"\n                    f\" '{module.__name__}:{attr_name}(args)'\"\n                    \" to specify arguments.\"\n                ) from e\n\n    raise NoAppException(\n        \"Failed to find Flask application or factory in module\"\n        f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n        \" to specify one.\"\n    )\n\n\ndef _called_with_wrong_args(f: t.Callable[..., Flask]) -> bool:\n    \"\"\"Check whether calling a function raised a ``TypeError`` because\n    the call failed or because something in the factory raised the\n    error.\n\n    :param f: The function that was called.\n    :return: ``True`` if the call failed.\n    \"\"\"\n    tb = sys.exc_info()[2]\n\n    try:\n        while tb is not None:\n            if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully.\n                return False\n\n            tb = tb.tb_next\n\n        # Didn't reach the function.\n        return True\n    finally:\n        # Delete tb to break a circular reference.\n        # https://docs.python.org/2/library/sys.html#sys.exc_info\n        del tb\n\n\ndef find_app_by_string(module: ModuleType, app_name: str) -> Flask:\n"
    },
    ".venv\\Lib\\site-packages\\flask\\config.py": {
      "sha": "09a720058d28",
      "lines": 367,
      "head": "from __future__ import annotations\n\nimport errno\nimport json\nimport os\nimport types\nimport typing as t\n\nfrom werkzeug.utils import import_string\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .sansio.app import App\n\n\nT = t.TypeVar(\"T\")\n\n\nclass ConfigAttribute(t.Generic[T]):\n    \"\"\"Makes an attribute forward to the config\"\"\"\n\n    def __init__(\n        self, name: str, get_converter: t.Callable[[t.Any], T] | None = None\n    ) -> None:\n        self.__name__ = name\n        self.get_converter = get_converter\n\n    @t.overload\n    def __get__(self, obj: None, owner: None) -> te.Self: ...\n\n    @t.overload\n    def __get__(self, obj: App, owner: type[App]) -> T: ...\n\n    def __get__(self, obj: App | None, owner: type[App] | None = None) -> T | te.Self:\n        if obj is None:\n            return self\n\n        rv = obj.config[self.__name__]\n\n        if self.get_converter is not None:\n            rv = self.get_converter(rv)\n\n        return rv  # type: ignore[no-any-return]\n\n    def __set__(self, obj: App, value: t.Any) -> None:\n        obj.config[self.__name__] = value\n\n\nclass Config(dict):  # type: ignore[type-arg]\n    \"\"\"Works exactly like a dict but provides ways to fill it from files\n    or special dictionaries.  There are two common patterns to populate the\n    config.\n\n    Either you can fill the config from a config file::\n\n        app.config.from_pyfile('yourconfig.cfg')\n\n    Or alternatively you can define the configuration options in the\n    module that calls :meth:`from_object` or provide an import path to\n    a module that should be loaded.  It is also possible to tell it to\n    use the same module and with that provide the configuration values\n    just before the call::\n\n        DEBUG = True\n        SECRET_KEY = 'development key'\n        app.config.from_object(__name__)\n\n    In both cases (loading from any Python file or loading from modules),\n    only uppercase keys are added to the config.  This makes it possible to use\n    lowercase values in the config file for temporary values that are not added\n    to the config or to define the config keys in the same file that implements\n    the application.\n\n    Probably the most interesting way to load configurations is from an\n    environment variable pointing to a file::\n\n        app.config.from_envvar('YOURAPPLICATION_SETTINGS')\n\n    In this case before launching the application you have to set this\n    environment variable to the file you want to use.  On Linux and OS X\n    use the export statement::\n\n        export YOURAPPLICATION_SETTINGS='/path/to/config/file'\n\n    On windows use `set` instead.\n\n    :param root_path: path to which files are read relative from.  When the\n                      config object is created by the application, this is\n                      the application's :attr:`~flask.Flask.root_path`.\n    :param defaults: an optional dictionary of default values\n    \"\"\"\n\n    def __init__(\n        self,\n        root_path: str | os.PathLike[str],\n        defaults: dict[str, t.Any] | None = None,\n    ) -> None:\n        super().__init__(defaults or {})\n        self.root_path = root_path\n\n    def from_envvar(self, variable_name: str, silent: bool = False) -> bool:\n        \"\"\"Loads a configuration from an environment variable pointing to\n        a configuration file.  This is basically just a shortcut with nicer\n        error messages for this line of code::\n\n            app.config.from_pyfile(os.environ['YOURAPPLICATION_SETTINGS'])\n\n        :param variable_name: name of the environment variable\n        :param silent: set to ``True`` if you want silent failure for missing\n                       files.\n        :return: ``True`` if the file was loaded successfully.\n        \"\"\"\n        rv = os.environ.get(variable_name)\n        if not rv:\n            if silent:\n                return False\n            raise RuntimeError(\n                f\"The environment variable {variable_name!r} is not set\"\n                \" and as such configuration could not be loaded. Set\"\n"
    },
    ".venv\\Lib\\site-packages\\flask\\ctx.py": {
      "sha": "ccc16d5cef40",
      "lines": 449,
      "head": "from __future__ import annotations\n\nimport contextvars\nimport sys\nimport typing as t\nfrom functools import update_wrapper\nfrom types import TracebackType\n\nfrom werkzeug.exceptions import HTTPException\n\nfrom . import typing as ft\nfrom .globals import _cv_app\nfrom .globals import _cv_request\nfrom .signals import appcontext_popped\nfrom .signals import appcontext_pushed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .app import Flask\n    from .sessions import SessionMixin\n    from .wrappers import Request\n\n\n# a singleton sentinel value for parameter defaults\n_sentinel = object()\n\n\nclass _AppCtxGlobals:\n    \"\"\"A plain object. Used as a namespace for storing data during an\n    application context.\n\n    Creating an app context automatically creates this object, which is\n    made available as the :data:`g` proxy.\n\n    .. describe:: 'key' in g\n\n        Check whether an attribute is present.\n\n        .. versionadded:: 0.10\n\n    .. describe:: iter(g)\n\n        Return an iterator over the attribute names.\n\n        .. versionadded:: 0.10\n    \"\"\"\n\n    # Define attr methods to let mypy know this is a namespace object\n    # that has arbitrary attributes.\n\n    def __getattr__(self, name: str) -> t.Any:\n        try:\n            return self.__dict__[name]\n        except KeyError:\n            raise AttributeError(name) from None\n\n    def __setattr__(self, name: str, value: t.Any) -> None:\n        self.__dict__[name] = value\n\n    def __delattr__(self, name: str) -> None:\n        try:\n            del self.__dict__[name]\n        except KeyError:\n            raise AttributeError(name) from None\n\n    def get(self, name: str, default: t.Any | None = None) -> t.Any:\n        \"\"\"Get an attribute by name, or a default value. Like\n        :meth:`dict.get`.\n\n        :param name: Name of attribute to get.\n        :param default: Value to return if the attribute is not present.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return self.__dict__.get(name, default)\n\n    def pop(self, name: str, default: t.Any = _sentinel) -> t.Any:\n        \"\"\"Get and remove an attribute by name. Like :meth:`dict.pop`.\n\n        :param name: Name of attribute to pop.\n        :param default: Value to return if the attribute is not present,\n            instead of raising a ``KeyError``.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        if default is _sentinel:\n            return self.__dict__.pop(name)\n        else:\n            return self.__dict__.pop(name, default)\n\n    def setdefault(self, name: str, default: t.Any = None) -> t.Any:\n        \"\"\"Get the value of an attribute if it is present, otherwise\n        set and return a default value. Like :meth:`dict.setdefault`.\n\n        :param name: Name of attribute to get.\n        :param default: Value to set and return if the attribute is not\n            present.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        return self.__dict__.setdefault(name, default)\n\n    def __contains__(self, item: str) -> bool:\n        return item in self.__dict__\n\n    def __iter__(self) -> t.Iterator[str]:\n        return iter(self.__dict__)\n\n    def __repr__(self) -> str:\n        ctx = _cv_app.get(None)\n        if ctx is not None:\n            return f\"<flask.g of '{ctx.app.name}'>\"\n        return object.__repr__(self)\n\n\ndef after_this_request(\n    f: ft.AfterRequestCallable[t.Any],\n) -> ft.AfterRequestCallable[t.Any]:\n    \"\"\"Executes a function after this request.  This is useful to modify\n"
    },
    ".venv\\Lib\\site-packages\\flask\\debughelpers.py": {
      "sha": "a04e5a2ebdd2",
      "lines": 178,
      "head": "from __future__ import annotations\n\nimport typing as t\n\nfrom jinja2.loaders import BaseLoader\nfrom werkzeug.routing import RequestRedirect\n\nfrom .blueprints import Blueprint\nfrom .globals import request_ctx\nfrom .sansio.app import App\n\nif t.TYPE_CHECKING:\n    from .sansio.scaffold import Scaffold\n    from .wrappers import Request\n\n\nclass UnexpectedUnicodeError(AssertionError, UnicodeError):\n    \"\"\"Raised in places where we want some better error reporting for\n    unexpected unicode or binary data.\n    \"\"\"\n\n\nclass DebugFilesKeyError(KeyError, AssertionError):\n    \"\"\"Raised from request.files during debugging.  The idea is that it can\n    provide a better error message than just a generic KeyError/BadRequest.\n    \"\"\"\n\n    def __init__(self, request: Request, key: str) -> None:\n        form_matches = request.form.getlist(key)\n        buf = [\n            f\"You tried to access the file {key!r} in the request.files\"\n            \" dictionary but it does not exist. The mimetype for the\"\n            f\" request is {request.mimetype!r} instead of\"\n            \" 'multipart/form-data' which means that no file contents\"\n            \" were transmitted. To fix this error you should provide\"\n            ' enctype=\"multipart/form-data\" in your form.'\n        ]\n        if form_matches:\n            names = \", \".join(repr(x) for x in form_matches)\n            buf.append(\n                \"\\n\\nThe browser instead transmitted some file names. \"\n                f\"This was submitted: {names}\"\n            )\n        self.msg = \"\".join(buf)\n\n    def __str__(self) -> str:\n        return self.msg\n\n\nclass FormDataRoutingRedirect(AssertionError):\n    \"\"\"This exception is raised in debug mode if a routing redirect\n    would cause the browser to drop the method or body. This happens\n    when method is not GET, HEAD or OPTIONS and the status code is not\n    307 or 308.\n    \"\"\"\n\n    def __init__(self, request: Request) -> None:\n        exc = request.routing_exception\n        assert isinstance(exc, RequestRedirect)\n        buf = [\n            f\"A request was sent to '{request.url}', but routing issued\"\n            f\" a redirect to the canonical URL '{exc.new_url}'.\"\n        ]\n\n        if f\"{request.base_url}/\" == exc.new_url.partition(\"?\")[0]:\n            buf.append(\n                \" The URL was defined with a trailing slash. Flask\"\n                \" will redirect to the URL with a trailing slash if it\"\n                \" was accessed without one.\"\n            )\n\n        buf.append(\n            \" Send requests to the canonical URL, or use 307 or 308 for\"\n            \" routing redirects. Otherwise, browsers will drop form\"\n            \" data.\\n\\n\"\n            \"This exception is only raised in debug mode.\"\n        )\n        super().__init__(\"\".join(buf))\n\n\ndef attach_enctype_error_multidict(request: Request) -> None:\n    \"\"\"Patch ``request.files.__getitem__`` to raise a descriptive error\n    about ``enctype=multipart/form-data``.\n\n    :param request: The request to patch.\n    :meta private:\n    \"\"\"\n    oldcls = request.files.__class__\n\n    class newcls(oldcls):  # type: ignore[valid-type, misc]\n        def __getitem__(self, key: str) -> t.Any:\n            try:\n                return super().__getitem__(key)\n            except KeyError as e:\n                if key not in request.form:\n                    raise\n\n                raise DebugFilesKeyError(request, key).with_traceback(\n                    e.__traceback__\n                ) from None\n\n    newcls.__name__ = oldcls.__name__\n    newcls.__module__ = oldcls.__module__\n    request.files.__class__ = newcls\n\n\ndef _dump_loader_info(loader: BaseLoader) -> t.Iterator[str]:\n    yield f\"class: {type(loader).__module__}.{type(loader).__name__}\"\n    for key, value in sorted(loader.__dict__.items()):\n        if key.startswith(\"_\"):\n            continue\n        if isinstance(value, (tuple, list)):\n            if not all(isinstance(x, str) for x in value):\n                continue\n            yield f\"{key}:\"\n            for item in value:\n                yield f\"  - {item}\"\n            continue\n        elif not isinstance(value, (str, int, float, bool)):\n            continue\n"
    },
    ".venv\\Lib\\site-packages\\flask\\globals.py": {
      "sha": "a0c723e6e39c",
      "lines": 51,
      "head": "from __future__ import annotations\n\nimport typing as t\nfrom contextvars import ContextVar\n\nfrom werkzeug.local import LocalProxy\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .app import Flask\n    from .ctx import _AppCtxGlobals\n    from .ctx import AppContext\n    from .ctx import RequestContext\n    from .sessions import SessionMixin\n    from .wrappers import Request\n\n\n_no_app_msg = \"\"\"\\\nWorking outside of application context.\n\nThis typically means that you attempted to use functionality that needed\nthe current application. To solve this, set up an application context\nwith app.app_context(). See the documentation for more information.\\\n\"\"\"\n_cv_app: ContextVar[AppContext] = ContextVar(\"flask.app_ctx\")\napp_ctx: AppContext = LocalProxy(  # type: ignore[assignment]\n    _cv_app, unbound_message=_no_app_msg\n)\ncurrent_app: Flask = LocalProxy(  # type: ignore[assignment]\n    _cv_app, \"app\", unbound_message=_no_app_msg\n)\ng: _AppCtxGlobals = LocalProxy(  # type: ignore[assignment]\n    _cv_app, \"g\", unbound_message=_no_app_msg\n)\n\n_no_req_msg = \"\"\"\\\nWorking outside of request context.\n\nThis typically means that you attempted to use functionality that needed\nan active HTTP request. Consult the documentation on testing for\ninformation about how to avoid this problem.\\\n\"\"\"\n_cv_request: ContextVar[RequestContext] = ContextVar(\"flask.request_ctx\")\nrequest_ctx: RequestContext = LocalProxy(  # type: ignore[assignment]\n    _cv_request, unbound_message=_no_req_msg\n)\nrequest: Request = LocalProxy(  # type: ignore[assignment]\n    _cv_request, \"request\", unbound_message=_no_req_msg\n)\nsession: SessionMixin = LocalProxy(  # type: ignore[assignment]\n    _cv_request, \"session\", unbound_message=_no_req_msg\n)\n"
    },
    ".venv\\Lib\\site-packages\\flask\\helpers.py": {
      "sha": "d516b3a433af",
      "lines": 641,
      "head": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_app\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr],\n) -> t.Iterator[t.AnyStr]: ...\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]: ...\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr] | t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]:\n    \"\"\"Wrap a response generator function so that it runs inside the current\n    request context. This keeps :data:`request`, :data:`session`, and :data:`g`\n    available, even though at the point the generator runs the request context\n    will typically have ended.\n\n    Use it as a decorator on a generator function:\n\n    .. code-block:: python\n\n        from flask import stream_with_context, request, Response\n\n        @app.get(\"/stream\")\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield \"Hello \"\n                yield request.args[\"name\"]\n                yield \"!\"\n\n            return Response(generate())\n\n    Or use it as a wrapper around a created generator:\n\n    .. code-block:: python\n\n        from flask import stream_with_context, request, Response\n\n        @app.get(\"/stream\")\n        def streamed_response():\n            def generate():\n                yield \"Hello \"\n                yield request.args[\"name\"]\n                yield \"!\"\n\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr]:\n        if (req_ctx := _cv_request.get(None)) is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n\n"
    },
    ".venv\\Lib\\site-packages\\flask\\logging.py": {
      "sha": "6d8f21ab856f",
      "lines": 79,
      "head": "from __future__ import annotations\n\nimport logging\nimport sys\nimport typing as t\n\nfrom werkzeug.local import LocalProxy\n\nfrom .globals import request\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .sansio.app import App\n\n\n@LocalProxy\ndef wsgi_errors_stream() -> t.TextIO:\n    \"\"\"Find the most appropriate error stream for the application. If a request\n    is active, log to ``wsgi.errors``, otherwise use ``sys.stderr``.\n\n    If you configure your own :class:`logging.StreamHandler`, you may want to\n    use this for the stream. If you are using file or dict configuration and\n    can't import this directly, you can refer to it as\n    ``ext://flask.logging.wsgi_errors_stream``.\n    \"\"\"\n    if request:\n        return request.environ[\"wsgi.errors\"]  # type: ignore[no-any-return]\n\n    return sys.stderr\n\n\ndef has_level_handler(logger: logging.Logger) -> bool:\n    \"\"\"Check if there is a handler in the logging chain that will handle the\n    given logger's :meth:`effective level <~logging.Logger.getEffectiveLevel>`.\n    \"\"\"\n    level = logger.getEffectiveLevel()\n    current = logger\n\n    while current:\n        if any(handler.level <= level for handler in current.handlers):\n            return True\n\n        if not current.propagate:\n            break\n\n        current = current.parent  # type: ignore\n\n    return False\n\n\n#: Log messages to :func:`~flask.logging.wsgi_errors_stream` with the format\n#: ``[%(asctime)s] %(levelname)s in %(module)s: %(message)s``.\ndefault_handler = logging.StreamHandler(wsgi_errors_stream)  # type: ignore\ndefault_handler.setFormatter(\n    logging.Formatter(\"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\")\n)\n\n\ndef create_logger(app: App) -> logging.Logger:\n    \"\"\"Get the Flask app's logger and configure it if needed.\n\n    The logger name will be the same as\n    :attr:`app.import_name <flask.Flask.name>`.\n\n    When :attr:`~flask.Flask.debug` is enabled, set the logger level to\n    :data:`logging.DEBUG` if it is not set.\n\n    If there is no handler for the logger's effective level, add a\n    :class:`~logging.StreamHandler` for\n    :func:`~flask.logging.wsgi_errors_stream` with a basic format.\n    \"\"\"\n    logger = logging.getLogger(app.name)\n\n    if app.debug and not logger.level:\n        logger.setLevel(logging.DEBUG)\n\n    if not has_level_handler(logger):\n        logger.addHandler(default_handler)\n\n    return logger\n"
    },
    ".venv\\Lib\\site-packages\\flask\\sessions.py": {
      "sha": "b57db68951d6",
      "lines": 399,
      "head": "from __future__ import annotations\n\nimport collections.abc as c\nimport hashlib\nimport typing as t\nfrom collections.abc import MutableMapping\nfrom datetime import datetime\nfrom datetime import timezone\n\nfrom itsdangerous import BadSignature\nfrom itsdangerous import URLSafeTimedSerializer\nfrom werkzeug.datastructures import CallbackDict\n\nfrom .json.tag import TaggedJSONSerializer\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    import typing_extensions as te\n\n    from .app import Flask\n    from .wrappers import Request\n    from .wrappers import Response\n\n\nclass SessionMixin(MutableMapping[str, t.Any]):\n    \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n\n    @property\n    def permanent(self) -> bool:\n        \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\"\n        return self.get(\"_permanent\", False)\n\n    @permanent.setter\n    def permanent(self, value: bool) -> None:\n        self[\"_permanent\"] = bool(value)\n\n    #: Some implementations can detect whether a session is newly\n    #: created, but that is not guaranteed. Use with caution. The mixin\n    # default is hard-coded ``False``.\n    new = False\n\n    #: Some implementations can detect changes to the session and set\n    #: this when that happens. The mixin default is hard coded to\n    #: ``True``.\n    modified = True\n\n    #: Some implementations can detect when session data is read or\n    #: written and set this when that happens. The mixin default is hard\n    #: coded to ``True``.\n    accessed = True\n\n\nclass SecureCookieSession(CallbackDict[str, t.Any], SessionMixin):\n    \"\"\"Base class for sessions based on signed cookies.\n\n    This session backend will set the :attr:`modified` and\n    :attr:`accessed` attributes. It cannot reliably track whether a\n    session is new (vs. empty), so :attr:`new` remains hard coded to\n    ``False``.\n    \"\"\"\n\n    #: When data is changed, this is set to ``True``. Only the session\n    #: dictionary itself is tracked; if the session contains mutable\n    #: data (for example a nested dict) then this must be set to\n    #: ``True`` manually when modifying that data. The session cookie\n    #: will only be written to the response if this is ``True``.\n    modified = False\n\n    #: When data is read or written, this is set to ``True``. Used by\n    # :class:`.SecureCookieSessionInterface` to add a ``Vary: Cookie``\n    #: header, which allows caching proxies to cache different pages for\n    #: different users.\n    accessed = False\n\n    def __init__(\n        self,\n        initial: c.Mapping[str, t.Any] | c.Iterable[tuple[str, t.Any]] | None = None,\n    ) -> None:\n        def on_update(self: te.Self) -> None:\n            self.modified = True\n            self.accessed = True\n\n        super().__init__(initial, on_update)\n\n    def __getitem__(self, key: str) -> t.Any:\n        self.accessed = True\n        return super().__getitem__(key)\n\n    def get(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().get(key, default)\n\n    def setdefault(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().setdefault(key, default)\n\n\nclass NullSession(SecureCookieSession):\n    \"\"\"Class used to generate nicer error messages if sessions are not\n    available.  Will still allow read-only access to the empty session\n    but fail on setting.\n    \"\"\"\n\n    def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n        raise RuntimeError(\n            \"The session is unavailable because no secret \"\n            \"key was set.  Set the secret_key on the \"\n            \"application to something unique and secret.\"\n        )\n\n    __setitem__ = __delitem__ = clear = pop = popitem = update = setdefault = _fail  # noqa: B950\n    del _fail\n\n\nclass SessionInterface:\n    \"\"\"The basic interface you have to implement in order to replace the\n    default session interface which uses werkzeug's securecookie\n    implementation.  The only methods you have to implement are\n    :meth:`open_session` and :meth:`save_session`, the others have\n    useful defaults which you don't need to change.\n\n"
    },
    ".venv\\Lib\\site-packages\\flask\\signals.py": {
      "sha": "81c4cdba4dfb",
      "lines": 17,
      "head": "from __future__ import annotations\n\nfrom blinker import Namespace\n\n# This namespace is only for signals provided by Flask itself.\n_signals = Namespace()\n\ntemplate_rendered = _signals.signal(\"template-rendered\")\nbefore_render_template = _signals.signal(\"before-render-template\")\nrequest_started = _signals.signal(\"request-started\")\nrequest_finished = _signals.signal(\"request-finished\")\nrequest_tearing_down = _signals.signal(\"request-tearing-down\")\ngot_request_exception = _signals.signal(\"got-request-exception\")\nappcontext_tearing_down = _signals.signal(\"appcontext-tearing-down\")\nappcontext_pushed = _signals.signal(\"appcontext-pushed\")\nappcontext_popped = _signals.signal(\"appcontext-popped\")\nmessage_flashed = _signals.signal(\"message-flashed\")\n"
    },
    ".venv\\Lib\\site-packages\\flask\\templating.py": {
      "sha": "f908d517ea68",
      "lines": 219,
      "head": "from __future__ import annotations\n\nimport typing as t\n\nfrom jinja2 import BaseLoader\nfrom jinja2 import Environment as BaseEnvironment\nfrom jinja2 import Template\nfrom jinja2 import TemplateNotFound\n\nfrom .globals import _cv_app\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .helpers import stream_with_context\nfrom .signals import before_render_template\nfrom .signals import template_rendered\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .app import Flask\n    from .sansio.app import App\n    from .sansio.scaffold import Scaffold\n\n\ndef _default_template_ctx_processor() -> dict[str, t.Any]:\n    \"\"\"Default template context processor.  Injects `request`,\n    `session` and `g`.\n    \"\"\"\n    appctx = _cv_app.get(None)\n    reqctx = _cv_request.get(None)\n    rv: dict[str, t.Any] = {}\n    if appctx is not None:\n        rv[\"g\"] = appctx.g\n    if reqctx is not None:\n        rv[\"request\"] = reqctx.request\n        rv[\"session\"] = reqctx.session\n    return rv\n\n\nclass Environment(BaseEnvironment):\n    \"\"\"Works like a regular Jinja environment but has some additional\n    knowledge of how Flask's blueprint works so that it can prepend the\n    name of the blueprint to referenced templates if necessary.\n    \"\"\"\n\n    def __init__(self, app: App, **options: t.Any) -> None:\n        if \"loader\" not in options:\n            options[\"loader\"] = app.create_global_jinja_loader()\n        BaseEnvironment.__init__(self, **options)\n        self.app = app\n\n\nclass DispatchingJinjaLoader(BaseLoader):\n    \"\"\"A loader that looks for templates in the application and all\n    the blueprint folders.\n    \"\"\"\n\n    def __init__(self, app: App) -> None:\n        self.app = app\n\n    def get_source(\n        self, environment: BaseEnvironment, template: str\n    ) -> tuple[str, str | None, t.Callable[[], bool] | None]:\n        if self.app.config[\"EXPLAIN_TEMPLATE_LOADING\"]:\n            return self._get_source_explained(environment, template)\n        return self._get_source_fast(environment, template)\n\n    def _get_source_explained(\n        self, environment: BaseEnvironment, template: str\n    ) -> tuple[str, str | None, t.Callable[[], bool] | None]:\n        attempts = []\n        rv: tuple[str, str | None, t.Callable[[], bool] | None] | None\n        trv: None | (tuple[str, str | None, t.Callable[[], bool] | None]) = None\n\n        for srcobj, loader in self._iter_loaders(template):\n            try:\n                rv = loader.get_source(environment, template)\n                if trv is None:\n                    trv = rv\n            except TemplateNotFound:\n                rv = None\n            attempts.append((loader, srcobj, rv))\n\n        from .debughelpers import explain_template_loading_attempts\n\n        explain_template_loading_attempts(self.app, template, attempts)\n\n        if trv is not None:\n            return trv\n        raise TemplateNotFound(template)\n\n    def _get_source_fast(\n        self, environment: BaseEnvironment, template: str\n    ) -> tuple[str, str | None, t.Callable[[], bool] | None]:\n        for _srcobj, loader in self._iter_loaders(template):\n            try:\n                return loader.get_source(environment, template)\n            except TemplateNotFound:\n                continue\n        raise TemplateNotFound(template)\n\n    def _iter_loaders(self, template: str) -> t.Iterator[tuple[Scaffold, BaseLoader]]:\n        loader = self.app.jinja_loader\n        if loader is not None:\n            yield self.app, loader\n\n        for blueprint in self.app.iter_blueprints():\n            loader = blueprint.jinja_loader\n            if loader is not None:\n                yield blueprint, loader\n\n    def list_templates(self) -> list[str]:\n        result = set()\n        loader = self.app.jinja_loader\n        if loader is not None:\n            result.update(loader.list_templates())\n\n        for blueprint in self.app.iter_blueprints():\n            loader = blueprint.jinja_loader\n            if loader is not None:\n                for template in loader.list_templates():\n"
    },
    ".venv\\Lib\\site-packages\\flask\\testing.py": {
      "sha": "be771b5537eb",
      "lines": 298,
      "head": "from __future__ import annotations\n\nimport importlib.metadata\nimport typing as t\nfrom contextlib import contextmanager\nfrom contextlib import ExitStack\nfrom copy import copy\nfrom types import TracebackType\nfrom urllib.parse import urlsplit\n\nimport werkzeug.test\nfrom click.testing import CliRunner\nfrom click.testing import Result\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import Request as BaseRequest\n\nfrom .cli import ScriptInfo\nfrom .sessions import SessionMixin\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import WSGIEnvironment\n    from werkzeug.test import TestResponse\n\n    from .app import Flask\n\n\nclass EnvironBuilder(werkzeug.test.EnvironBuilder):\n    \"\"\"An :class:`~werkzeug.test.EnvironBuilder`, that takes defaults from the\n    application.\n\n    :param app: The Flask application to configure the environment from.\n    :param path: URL path being requested.\n    :param base_url: Base URL where the app is being served, which\n        ``path`` is relative to. If not given, built from\n        :data:`PREFERRED_URL_SCHEME`, ``subdomain``,\n        :data:`SERVER_NAME`, and :data:`APPLICATION_ROOT`.\n    :param subdomain: Subdomain name to append to :data:`SERVER_NAME`.\n    :param url_scheme: Scheme to use instead of\n        :data:`PREFERRED_URL_SCHEME`.\n    :param json: If given, this is serialized as JSON and passed as\n        ``data``. Also defaults ``content_type`` to\n        ``application/json``.\n    :param args: other positional arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    :param kwargs: other keyword arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: Flask,\n        path: str = \"/\",\n        base_url: str | None = None,\n        subdomain: str | None = None,\n        url_scheme: str | None = None,\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -> None:\n        assert not (base_url or subdomain or url_scheme) or (\n            base_url is not None\n        ) != bool(subdomain or url_scheme), (\n            'Cannot pass \"subdomain\" or \"url_scheme\" with \"base_url\".'\n        )\n\n        if base_url is None:\n            http_host = app.config.get(\"SERVER_NAME\") or \"localhost\"\n            app_root = app.config[\"APPLICATION_ROOT\"]\n\n            if subdomain:\n                http_host = f\"{subdomain}.{http_host}\"\n\n            if url_scheme is None:\n                url_scheme = app.config[\"PREFERRED_URL_SCHEME\"]\n\n            url = urlsplit(path)\n            base_url = (\n                f\"{url.scheme or url_scheme}://{url.netloc or http_host}\"\n                f\"/{app_root.lstrip('/')}\"\n            )\n            path = url.path\n\n            if url.query:\n                path = f\"{path}?{url.query}\"\n\n        self.app = app\n        super().__init__(path, base_url, *args, **kwargs)\n\n    def json_dumps(self, obj: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"Serialize ``obj`` to a JSON-formatted string.\n\n        The serialization will be configured according to the config associated\n        with this EnvironBuilder's ``app``.\n        \"\"\"\n        return self.app.json.dumps(obj, **kwargs)\n\n\n_werkzeug_version = \"\"\n\n\ndef _get_werkzeug_version() -> str:\n    global _werkzeug_version\n\n    if not _werkzeug_version:\n        _werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    return _werkzeug_version\n\n\nclass FlaskClient(Client):\n    \"\"\"Works like a regular Werkzeug test client but has knowledge about\n    Flask's contexts to defer the cleanup of the request context until\n    the end of a ``with`` block. For general information about how to\n    use this class refer to :class:`werkzeug.test.Client`.\n\n    .. versionchanged:: 0.12\n       `app.test_client()` includes preset default environment, which can be\n       set after instantiation of the `app.test_client()` object in\n       `client.environ_base`.\n\n    Basic usage is outlined in the :doc:`/testing` chapter.\n"
    },
    ".venv\\Lib\\site-packages\\flask\\typing.py": {
      "sha": "56bc246e7048",
      "lines": 93,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import WSGIApplication  # noqa: F401\n    from werkzeug.datastructures import Headers  # noqa: F401\n    from werkzeug.sansio.response import Response  # noqa: F401\n\n# The possible types that are directly convertible or are a Response object.\nResponseValue = t.Union[\n    \"Response\",\n    str,\n    bytes,\n    list[t.Any],\n    # Only dict is actually accepted, but Mapping allows for TypedDict.\n    t.Mapping[str, t.Any],\n    t.Iterator[str],\n    t.Iterator[bytes],\n    cabc.AsyncIterable[str],  # for Quart, until App is generic.\n    cabc.AsyncIterable[bytes],\n]\n\n# the possible types for an individual HTTP header\n# This should be a Union, but mypy doesn't pass unless it's a TypeVar.\nHeaderValue = t.Union[str, list[str], tuple[str, ...]]\n\n# the possible types for HTTP headers\nHeadersValue = t.Union[\n    \"Headers\",\n    t.Mapping[str, HeaderValue],\n    t.Sequence[tuple[str, HeaderValue]],\n]\n\n# The possible types returned by a route function.\nResponseReturnValue = t.Union[\n    ResponseValue,\n    tuple[ResponseValue, HeadersValue],\n    tuple[ResponseValue, int],\n    tuple[ResponseValue, int, HeadersValue],\n    \"WSGIApplication\",\n]\n\n# Allow any subclass of werkzeug.Response, such as the one from Flask,\n# as a callback argument. Using werkzeug.Response directly makes a\n# callback annotated with flask.Response fail type checking.\nResponseClass = t.TypeVar(\"ResponseClass\", bound=\"Response\")\n\nAppOrBlueprintKey = t.Optional[str]  # The App key is None, whereas blueprints are named\nAfterRequestCallable = t.Union[\n    t.Callable[[ResponseClass], ResponseClass],\n    t.Callable[[ResponseClass], t.Awaitable[ResponseClass]],\n]\nBeforeFirstRequestCallable = t.Union[\n    t.Callable[[], None], t.Callable[[], t.Awaitable[None]]\n]\nBeforeRequestCallable = t.Union[\n    t.Callable[[], t.Optional[ResponseReturnValue]],\n    t.Callable[[], t.Awaitable[t.Optional[ResponseReturnValue]]],\n]\nShellContextProcessorCallable = t.Callable[[], dict[str, t.Any]]\nTeardownCallable = t.Union[\n    t.Callable[[t.Optional[BaseException]], None],\n    t.Callable[[t.Optional[BaseException]], t.Awaitable[None]],\n]\nTemplateContextProcessorCallable = t.Union[\n    t.Callable[[], dict[str, t.Any]],\n    t.Callable[[], t.Awaitable[dict[str, t.Any]]],\n]\nTemplateFilterCallable = t.Callable[..., t.Any]\nTemplateGlobalCallable = t.Callable[..., t.Any]\nTemplateTestCallable = t.Callable[..., bool]\nURLDefaultCallable = t.Callable[[str, dict[str, t.Any]], None]\nURLValuePreprocessorCallable = t.Callable[\n    [t.Optional[str], t.Optional[dict[str, t.Any]]], None\n]\n\n# This should take Exception, but that either breaks typing the argument\n# with a specific exception, or decorating multiple times with different\n# exceptions (and using a union type on the argument).\n# https://github.com/pallets/flask/issues/4095\n# https://github.com/pallets/flask/issues/4295\n# https://github.com/pallets/flask/issues/4297\nErrorHandlerCallable = t.Union[\n    t.Callable[[t.Any], ResponseReturnValue],\n    t.Callable[[t.Any], t.Awaitable[ResponseReturnValue]],\n]\n\nRouteCallable = t.Union[\n    t.Callable[..., ResponseReturnValue],\n    t.Callable[..., t.Awaitable[ResponseReturnValue]],\n]\n"
    },
    ".venv\\Lib\\site-packages\\flask\\views.py": {
      "sha": "f6b5a90651c6",
      "lines": 191,
      "head": "from __future__ import annotations\n\nimport typing as t\n\nfrom . import typing as ft\nfrom .globals import current_app\nfrom .globals import request\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\nhttp_method_funcs = frozenset(\n    [\"get\", \"post\", \"head\", \"options\", \"delete\", \"put\", \"trace\", \"patch\"]\n)\n\n\nclass View:\n    \"\"\"Subclass this class and override :meth:`dispatch_request` to\n    create a generic class-based view. Call :meth:`as_view` to create a\n    view function that creates an instance of the class with the given\n    arguments and calls its ``dispatch_request`` method with any URL\n    variables.\n\n    See :doc:`views` for a detailed guide.\n\n    .. code-block:: python\n\n        class Hello(View):\n            init_every_request = False\n\n            def dispatch_request(self, name):\n                return f\"Hello, {name}!\"\n\n        app.add_url_rule(\n            \"/hello/<name>\", view_func=Hello.as_view(\"hello\")\n        )\n\n    Set :attr:`methods` on the class to change what methods the view\n    accepts.\n\n    Set :attr:`decorators` on the class to apply a list of decorators to\n    the generated view function. Decorators applied to the class itself\n    will not be applied to the generated view function!\n\n    Set :attr:`init_every_request` to ``False`` for efficiency, unless\n    you need to store request-global data on ``self``.\n    \"\"\"\n\n    #: The methods this view is registered for. Uses the same default\n    #: (``[\"GET\", \"HEAD\", \"OPTIONS\"]``) as ``route`` and\n    #: ``add_url_rule`` by default.\n    methods: t.ClassVar[t.Collection[str] | None] = None\n\n    #: Control whether the ``OPTIONS`` method is handled automatically.\n    #: Uses the same default (``True``) as ``route`` and\n    #: ``add_url_rule`` by default.\n    provide_automatic_options: t.ClassVar[bool | None] = None\n\n    #: A list of decorators to apply, in order, to the generated view\n    #: function. Remember that ``@decorator`` syntax is applied bottom\n    #: to top, so the first decorator in the list would be the bottom\n    #: decorator.\n    #:\n    #: .. versionadded:: 0.8\n    decorators: t.ClassVar[list[t.Callable[..., t.Any]]] = []\n\n    #: Create a new instance of this view class for every request by\n    #: default. If a view subclass sets this to ``False``, the same\n    #: instance is used for every request.\n    #:\n    #: A single instance is more efficient, especially if complex setup\n    #: is done during init. However, storing data on ``self`` is no\n    #: longer safe across requests, and :data:`~flask.g` should be used\n    #: instead.\n    #:\n    #: .. versionadded:: 2.2\n    init_every_request: t.ClassVar[bool] = True\n\n    def dispatch_request(self) -> ft.ResponseReturnValue:\n        \"\"\"The actual view function behavior. Subclasses must override\n        this and return a valid response. Any variables from the URL\n        rule are passed as keyword arguments.\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def as_view(\n        cls, name: str, *class_args: t.Any, **class_kwargs: t.Any\n    ) -> ft.RouteCallable:\n        \"\"\"Convert the class into a view function that can be registered\n        for a route.\n\n        By default, the generated view will create a new instance of the\n        view class for every request and call its\n        :meth:`dispatch_request` method. If the view class sets\n        :attr:`init_every_request` to ``False``, the same instance will\n        be used for every request.\n\n        Except for ``name``, all other arguments passed to this method\n        are forwarded to the view class ``__init__`` method.\n\n        .. versionchanged:: 2.2\n            Added the ``init_every_request`` class attribute.\n        \"\"\"\n        if cls.init_every_request:\n\n            def view(**kwargs: t.Any) -> ft.ResponseReturnValue:\n                self = view.view_class(  # type: ignore[attr-defined]\n                    *class_args, **class_kwargs\n                )\n                return current_app.ensure_sync(self.dispatch_request)(**kwargs)  # type: ignore[no-any-return]\n\n        else:\n            self = cls(*class_args, **class_kwargs)  # pyright: ignore\n\n            def view(**kwargs: t.Any) -> ft.ResponseReturnValue:\n                return current_app.ensure_sync(self.dispatch_request)(**kwargs)  # type: ignore[no-any-return]\n\n        if cls.decorators:\n            view.__name__ = name\n            view.__module__ = cls.__module__\n"
    },
    ".venv\\Lib\\site-packages\\flask\\wrappers.py": {
      "sha": "22974913f851",
      "lines": 257,
      "head": "from __future__ import annotations\n\nimport typing as t\n\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.wrappers import Request as RequestBase\nfrom werkzeug.wrappers import Response as ResponseBase\n\nfrom . import json\nfrom .globals import current_app\nfrom .helpers import _split_blueprint_path\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.routing import Rule\n\n\nclass Request(RequestBase):\n    \"\"\"The request object used by default in Flask.  Remembers the\n    matched endpoint and view arguments.\n\n    It is what ends up as :class:`~flask.request`.  If you want to replace\n    the request object used you can subclass this and set\n    :attr:`~flask.Flask.request_class` to your subclass.\n\n    The request object is a :class:`~werkzeug.wrappers.Request` subclass and\n    provides all of the attributes Werkzeug defines plus a few Flask\n    specific ones.\n    \"\"\"\n\n    json_module: t.Any = json\n\n    #: The internal URL rule that matched the request.  This can be\n    #: useful to inspect which methods are allowed for the URL from\n    #: a before/after handler (``request.url_rule.methods``) etc.\n    #: Though if the request's method was invalid for the URL rule,\n    #: the valid list is available in ``routing_exception.valid_methods``\n    #: instead (an attribute of the Werkzeug exception\n    #: :exc:`~werkzeug.exceptions.MethodNotAllowed`)\n    #: because the request was never internally bound.\n    #:\n    #: .. versionadded:: 0.6\n    url_rule: Rule | None = None\n\n    #: A dict of view arguments that matched the request.  If an exception\n    #: happened when matching, this will be ``None``.\n    view_args: dict[str, t.Any] | None = None\n\n    #: If matching the URL failed, this is the exception that will be\n    #: raised / was raised as part of the request handling.  This is\n    #: usually a :exc:`~werkzeug.exceptions.NotFound` exception or\n    #: something similar.\n    routing_exception: HTTPException | None = None\n\n    _max_content_length: int | None = None\n    _max_form_memory_size: int | None = None\n    _max_form_parts: int | None = None\n\n    @property\n    def max_content_length(self) -> int | None:\n        \"\"\"The maximum number of bytes that will be read during this request. If\n        this limit is exceeded, a 413 :exc:`~werkzeug.exceptions.RequestEntityTooLarge`\n        error is raised. If it is set to ``None``, no limit is enforced at the\n        Flask application level. However, if it is ``None`` and the request has\n        no ``Content-Length`` header and the WSGI server does not indicate that\n        it terminates the stream, then no data is read to avoid an infinite\n        stream.\n\n        Each request defaults to the :data:`MAX_CONTENT_LENGTH` config, which\n        defaults to ``None``. It can be set on a specific ``request`` to apply\n        the limit to that specific view. This should be set appropriately based\n        on an application's or view's specific needs.\n\n        .. versionchanged:: 3.1\n            This can be set per-request.\n\n        .. versionchanged:: 0.6\n            This is configurable through Flask config.\n        \"\"\"\n        if self._max_content_length is not None:\n            return self._max_content_length\n\n        if not current_app:\n            return super().max_content_length\n\n        return current_app.config[\"MAX_CONTENT_LENGTH\"]  # type: ignore[no-any-return]\n\n    @max_content_length.setter\n    def max_content_length(self, value: int | None) -> None:\n        self._max_content_length = value\n\n    @property\n    def max_form_memory_size(self) -> int | None:\n        \"\"\"The maximum size in bytes any non-file form field may be in a\n        ``multipart/form-data`` body. If this limit is exceeded, a 413\n        :exc:`~werkzeug.exceptions.RequestEntityTooLarge` error is raised. If it\n        is set to ``None``, no limit is enforced at the Flask application level.\n\n        Each request defaults to the :data:`MAX_FORM_MEMORY_SIZE` config, which\n        defaults to ``500_000``. It can be set on a specific ``request`` to\n        apply the limit to that specific view. This should be set appropriately\n        based on an application's or view's specific needs.\n\n        .. versionchanged:: 3.1\n            This is configurable through Flask config.\n        \"\"\"\n        if self._max_form_memory_size is not None:\n            return self._max_form_memory_size\n\n        if not current_app:\n            return super().max_form_memory_size\n\n        return current_app.config[\"MAX_FORM_MEMORY_SIZE\"]  # type: ignore[no-any-return]\n\n    @max_form_memory_size.setter\n    def max_form_memory_size(self, value: int | None) -> None:\n        self._max_form_memory_size = value\n\n    @property  # type: ignore[override]\n    def max_form_parts(self) -> int | None:\n"
    },
    ".venv\\Lib\\site-packages\\flask\\__init__.py": {
      "sha": "1fdca1fcb870",
      "lines": 61,
      "head": "from __future__ import annotations\n\nimport typing as t\n\nfrom . import json as json\nfrom .app import Flask as Flask\nfrom .blueprints import Blueprint as Blueprint\nfrom .config import Config as Config\nfrom .ctx import after_this_request as after_this_request\nfrom .ctx import copy_current_request_context as copy_current_request_context\nfrom .ctx import has_app_context as has_app_context\nfrom .ctx import has_request_context as has_request_context\nfrom .globals import current_app as current_app\nfrom .globals import g as g\nfrom .globals import request as request\nfrom .globals import session as session\nfrom .helpers import abort as abort\nfrom .helpers import flash as flash\nfrom .helpers import get_flashed_messages as get_flashed_messages\nfrom .helpers import get_template_attribute as get_template_attribute\nfrom .helpers import make_response as make_response\nfrom .helpers import redirect as redirect\nfrom .helpers import send_file as send_file\nfrom .helpers import send_from_directory as send_from_directory\nfrom .helpers import stream_with_context as stream_with_context\nfrom .helpers import url_for as url_for\nfrom .json import jsonify as jsonify\nfrom .signals import appcontext_popped as appcontext_popped\nfrom .signals import appcontext_pushed as appcontext_pushed\nfrom .signals import appcontext_tearing_down as appcontext_tearing_down\nfrom .signals import before_render_template as before_render_template\nfrom .signals import got_request_exception as got_request_exception\nfrom .signals import message_flashed as message_flashed\nfrom .signals import request_finished as request_finished\nfrom .signals import request_started as request_started\nfrom .signals import request_tearing_down as request_tearing_down\nfrom .signals import template_rendered as template_rendered\nfrom .templating import render_template as render_template\nfrom .templating import render_template_string as render_template_string\nfrom .templating import stream_template as stream_template\nfrom .templating import stream_template_string as stream_template_string\nfrom .wrappers import Request as Request\nfrom .wrappers import Response as Response\n\nif not t.TYPE_CHECKING:\n\n    def __getattr__(name: str) -> t.Any:\n        if name == \"__version__\":\n            import importlib.metadata\n            import warnings\n\n            warnings.warn(\n                \"The '__version__' attribute is deprecated and will be removed in\"\n                \" Flask 3.2. Use feature detection or\"\n                \" 'importlib.metadata.version(\\\"flask\\\")' instead.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return importlib.metadata.version(\"flask\")\n\n        raise AttributeError(name)\n"
    },
    ".venv\\Lib\\site-packages\\flask\\__main__.py": {
      "sha": "235727669d23",
      "lines": 3,
      "head": "from .cli import main\n\nmain()\n"
    },
    ".venv\\Lib\\site-packages\\flask\\json\\provider.py": {
      "sha": "78e222a34c36",
      "lines": 215,
      "head": "from __future__ import annotations\n\nimport dataclasses\nimport decimal\nimport json\nimport typing as t\nimport uuid\nimport weakref\nfrom datetime import date\n\nfrom werkzeug.http import http_date\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.sansio.response import Response\n\n    from ..sansio.app import App\n\n\nclass JSONProvider:\n    \"\"\"A standard set of JSON operations for an application. Subclasses\n    of this can be used to customize JSON behavior or use different\n    JSON libraries.\n\n    To implement a provider for a specific library, subclass this base\n    class and implement at least :meth:`dumps` and :meth:`loads`. All\n    other methods have default implementations.\n\n    To use a different provider, either subclass ``Flask`` and set\n    :attr:`~flask.Flask.json_provider_class` to a provider class, or set\n    :attr:`app.json <flask.Flask.json>` to an instance of the class.\n\n    :param app: An application instance. This will be stored as a\n        :class:`weakref.proxy` on the :attr:`_app` attribute.\n\n    .. versionadded:: 2.2\n    \"\"\"\n\n    def __init__(self, app: App) -> None:\n        self._app: App = weakref.proxy(app)\n\n    def dumps(self, obj: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"Serialize data as JSON.\n\n        :param obj: The data to serialize.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        raise NotImplementedError\n\n    def dump(self, obj: t.Any, fp: t.IO[str], **kwargs: t.Any) -> None:\n        \"\"\"Serialize data as JSON and write to a file.\n\n        :param obj: The data to serialize.\n        :param fp: A file opened for writing text. Should use the UTF-8\n            encoding to be valid JSON.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        fp.write(self.dumps(obj, **kwargs))\n\n    def loads(self, s: str | bytes, **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON.\n\n        :param s: Text or UTF-8 bytes.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        raise NotImplementedError\n\n    def load(self, fp: t.IO[t.AnyStr], **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON read from a file.\n\n        :param fp: A file opened for reading text or UTF-8 bytes.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        return self.loads(fp.read(), **kwargs)\n\n    def _prepare_response_obj(\n        self, args: tuple[t.Any, ...], kwargs: dict[str, t.Any]\n    ) -> t.Any:\n        if args and kwargs:\n            raise TypeError(\"app.json.response() takes either args or kwargs, not both\")\n\n        if not args and not kwargs:\n            return None\n\n        if len(args) == 1:\n            return args[0]\n\n        return args or kwargs\n\n    def response(self, *args: t.Any, **kwargs: t.Any) -> Response:\n        \"\"\"Serialize the given arguments as JSON, and return a\n        :class:`~flask.Response` object with the ``application/json``\n        mimetype.\n\n        The :func:`~flask.json.jsonify` function calls this method for\n        the current application.\n\n        Either positional or keyword arguments can be given, not both.\n        If no arguments are given, ``None`` is serialized.\n\n        :param args: A single value to serialize, or multiple values to\n            treat as a list to serialize.\n        :param kwargs: Treat as a dict to serialize.\n        \"\"\"\n        obj = self._prepare_response_obj(args, kwargs)\n        return self._app.response_class(self.dumps(obj), mimetype=\"application/json\")\n\n\ndef _default(o: t.Any) -> t.Any:\n    if isinstance(o, date):\n        return http_date(o)\n\n    if isinstance(o, (decimal.Decimal, uuid.UUID)):\n        return str(o)\n\n    if dataclasses and dataclasses.is_dataclass(o):\n        return dataclasses.asdict(o)  # type: ignore[arg-type]\n\n    if hasattr(o, \"__html__\"):\n        return str(o.__html__())\n\n"
    },
    ".venv\\Lib\\site-packages\\flask\\json\\tag.py": {
      "sha": "e2e644a394e8",
      "lines": 327,
      "head": "\"\"\"\nTagged JSON\n~~~~~~~~~~~\n\nA compact representation for lossless serialization of non-standard JSON\ntypes. :class:`~flask.sessions.SecureCookieSessionInterface` uses this\nto serialize the session data, but it may be useful in other places. It\ncan be extended to support other types.\n\n.. autoclass:: TaggedJSONSerializer\n    :members:\n\n.. autoclass:: JSONTag\n    :members:\n\nLet's see an example that adds support for\n:class:`~collections.OrderedDict`. Dicts don't have an order in JSON, so\nto handle this we will dump the items as a list of ``[key, value]``\npairs. Subclass :class:`JSONTag` and give it the new key ``' od'`` to\nidentify the type. The session serializer processes dicts first, so\ninsert the new tag at the front of the order since ``OrderedDict`` must\nbe processed before ``dict``.\n\n.. code-block:: python\n\n    from flask.json.tag import JSONTag\n\n    class TagOrderedDict(JSONTag):\n        __slots__ = ('serializer',)\n        key = ' od'\n\n        def check(self, value):\n            return isinstance(value, OrderedDict)\n\n        def to_json(self, value):\n            return [[k, self.serializer.tag(v)] for k, v in iteritems(value)]\n\n        def to_python(self, value):\n            return OrderedDict(value)\n\n    app.session_interface.serializer.register(TagOrderedDict, index=0)\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom base64 import b64decode\nfrom base64 import b64encode\nfrom datetime import datetime\nfrom uuid import UUID\n\nfrom markupsafe import Markup\nfrom werkzeug.http import http_date\nfrom werkzeug.http import parse_date\n\nfrom ..json import dumps\nfrom ..json import loads\n\n\nclass JSONTag:\n    \"\"\"Base class for defining type tags for :class:`TaggedJSONSerializer`.\"\"\"\n\n    __slots__ = (\"serializer\",)\n\n    #: The tag to mark the serialized object with. If empty, this tag is\n    #: only used as an intermediate step during tagging.\n    key: str = \"\"\n\n    def __init__(self, serializer: TaggedJSONSerializer) -> None:\n        \"\"\"Create a tagger for the given serializer.\"\"\"\n        self.serializer = serializer\n\n    def check(self, value: t.Any) -> bool:\n        \"\"\"Check if the given value should be tagged by this tag.\"\"\"\n        raise NotImplementedError\n\n    def to_json(self, value: t.Any) -> t.Any:\n        \"\"\"Convert the Python object to an object that is a valid JSON type.\n        The tag will be added later.\"\"\"\n        raise NotImplementedError\n\n    def to_python(self, value: t.Any) -> t.Any:\n        \"\"\"Convert the JSON representation back to the correct type. The tag\n        will already be removed.\"\"\"\n        raise NotImplementedError\n\n    def tag(self, value: t.Any) -> dict[str, t.Any]:\n        \"\"\"Convert the value to a valid JSON type and add the tag structure\n        around it.\"\"\"\n        return {self.key: self.to_json(value)}\n\n\nclass TagDict(JSONTag):\n    \"\"\"Tag for 1-item dicts whose only key matches a registered tag.\n\n    Internally, the dict key is suffixed with `__`, and the suffix is removed\n    when deserializing.\n    \"\"\"\n\n    __slots__ = ()\n    key = \" di\"\n\n    def check(self, value: t.Any) -> bool:\n        return (\n            isinstance(value, dict)\n            and len(value) == 1\n            and next(iter(value)) in self.serializer.tags\n        )\n\n    def to_json(self, value: t.Any) -> t.Any:\n        key = next(iter(value))\n        return {f\"{key}__\": self.serializer.tag(value[key])}\n\n    def to_python(self, value: t.Any) -> t.Any:\n        key = next(iter(value))\n        return {key[:-2]: value[key]}\n\n\nclass PassDict(JSONTag):\n    __slots__ = ()\n"
    },
    ".venv\\Lib\\site-packages\\flask\\json\\__init__.py": {
      "sha": "b015d9e69100",
      "lines": 170,
      "head": "from __future__ import annotations\n\nimport json as _json\nimport typing as t\n\nfrom ..globals import current_app\nfrom .provider import _default\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from ..wrappers import Response\n\n\ndef dumps(obj: t.Any, **kwargs: t.Any) -> str:\n    \"\"\"Serialize data as JSON.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`app.json.dumps() <flask.json.provider.JSONProvider.dumps>`\n    method, otherwise it will use :func:`json.dumps`.\n\n    :param obj: The data to serialize.\n    :param kwargs: Arguments passed to the ``dumps`` implementation.\n\n    .. versionchanged:: 2.3\n        The ``app`` parameter was removed.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.json.dumps``, allowing an app to override\n        the behavior.\n\n    .. versionchanged:: 2.0.2\n        :class:`decimal.Decimal` is supported by converting to a string.\n\n    .. versionchanged:: 2.0\n        ``encoding`` will be removed in Flask 2.1.\n\n    .. versionchanged:: 1.0.3\n        ``app`` can be passed directly, rather than requiring an app\n        context for configuration.\n    \"\"\"\n    if current_app:\n        return current_app.json.dumps(obj, **kwargs)\n\n    kwargs.setdefault(\"default\", _default)\n    return _json.dumps(obj, **kwargs)\n\n\ndef dump(obj: t.Any, fp: t.IO[str], **kwargs: t.Any) -> None:\n    \"\"\"Serialize data as JSON and write to a file.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`app.json.dump() <flask.json.provider.JSONProvider.dump>`\n    method, otherwise it will use :func:`json.dump`.\n\n    :param obj: The data to serialize.\n    :param fp: A file opened for writing text. Should use the UTF-8\n        encoding to be valid JSON.\n    :param kwargs: Arguments passed to the ``dump`` implementation.\n\n    .. versionchanged:: 2.3\n        The ``app`` parameter was removed.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.json.dump``, allowing an app to override\n        the behavior.\n\n    .. versionchanged:: 2.0\n        Writing to a binary file, and the ``encoding`` argument, will be\n        removed in Flask 2.1.\n    \"\"\"\n    if current_app:\n        current_app.json.dump(obj, fp, **kwargs)\n    else:\n        kwargs.setdefault(\"default\", _default)\n        _json.dump(obj, fp, **kwargs)\n\n\ndef loads(s: str | bytes, **kwargs: t.Any) -> t.Any:\n    \"\"\"Deserialize data as JSON.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`app.json.loads() <flask.json.provider.JSONProvider.loads>`\n    method, otherwise it will use :func:`json.loads`.\n\n    :param s: Text or UTF-8 bytes.\n    :param kwargs: Arguments passed to the ``loads`` implementation.\n\n    .. versionchanged:: 2.3\n        The ``app`` parameter was removed.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.json.loads``, allowing an app to override\n        the behavior.\n\n    .. versionchanged:: 2.0\n        ``encoding`` will be removed in Flask 2.1. The data must be a\n        string or UTF-8 bytes.\n\n    .. versionchanged:: 1.0.3\n        ``app`` can be passed directly, rather than requiring an app\n        context for configuration.\n    \"\"\"\n    if current_app:\n        return current_app.json.loads(s, **kwargs)\n\n    return _json.loads(s, **kwargs)\n\n\ndef load(fp: t.IO[t.AnyStr], **kwargs: t.Any) -> t.Any:\n    \"\"\"Deserialize data as JSON read from a file.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`app.json.load() <flask.json.provider.JSONProvider.load>`\n    method, otherwise it will use :func:`json.load`.\n\n    :param fp: A file opened for reading text or UTF-8 bytes.\n    :param kwargs: Arguments passed to the ``load`` implementation.\n\n    .. versionchanged:: 2.3\n        The ``app`` parameter was removed.\n\n"
    },
    ".venv\\Lib\\site-packages\\flask\\sansio\\app.py": {
      "sha": "080610783787",
      "lines": 964,
      "head": "from __future__ import annotations\n\nimport logging\nimport os\nimport sys\nimport typing as t\nfrom datetime import timedelta\nfrom itertools import chain\n\nfrom werkzeug.exceptions import Aborter\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.sansio.response import Response\nfrom werkzeug.utils import cached_property\nfrom werkzeug.utils import redirect as _wz_redirect\n\nfrom .. import typing as ft\nfrom ..config import Config\nfrom ..config import ConfigAttribute\nfrom ..ctx import _AppCtxGlobals\nfrom ..helpers import _split_blueprint_path\nfrom ..helpers import get_debug_flag\nfrom ..json.provider import DefaultJSONProvider\nfrom ..json.provider import JSONProvider\nfrom ..logging import create_logger\nfrom ..templating import DispatchingJinjaLoader\nfrom ..templating import Environment\nfrom .scaffold import _endpoint_from_view_func\nfrom .scaffold import find_package\nfrom .scaffold import Scaffold\nfrom .scaffold import setupmethod\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.wrappers import Response as BaseResponse\n\n    from ..testing import FlaskClient\n    from ..testing import FlaskCliRunner\n    from .blueprints import Blueprint\n\nT_shell_context_processor = t.TypeVar(\n    \"T_shell_context_processor\", bound=ft.ShellContextProcessorCallable\n)\nT_teardown = t.TypeVar(\"T_teardown\", bound=ft.TeardownCallable)\nT_template_filter = t.TypeVar(\"T_template_filter\", bound=ft.TemplateFilterCallable)\nT_template_global = t.TypeVar(\"T_template_global\", bound=ft.TemplateGlobalCallable)\nT_template_test = t.TypeVar(\"T_template_test\", bound=ft.TemplateTestCallable)\n\n\ndef _make_timedelta(value: timedelta | int | None) -> timedelta | None:\n    if value is None or isinstance(value, timedelta):\n        return value\n\n    return timedelta(seconds=value)\n\n\nclass App(Scaffold):\n    \"\"\"The flask object implements a WSGI application and acts as the central\n    object.  It is passed the name of the module or package of the\n    application.  Once it is created it will act as a central registry for\n    the view functions, the URL rules, template configuration and much more.\n\n    The name of the package is used to resolve resources from inside the\n    package or the folder the module is contained in depending on if the\n    package parameter resolves to an actual python package (a folder with\n    an :file:`__init__.py` file inside) or a standard module (just a ``.py`` file).\n\n    For more information about resource loading, see :func:`open_resource`.\n\n    Usually you create a :class:`Flask` instance in your main module or\n    in the :file:`__init__.py` file of your package like this::\n\n        from flask import Flask\n        app = Flask(__name__)\n\n    .. admonition:: About the First Parameter\n\n        The idea of the first parameter is to give Flask an idea of what\n        belongs to your application.  This name is used to find resources\n        on the filesystem, can be used by extensions to improve debugging\n        information and a lot more.\n\n        So it's important what you provide there.  If you are using a single\n        module, `__name__` is always the correct value.  If you however are\n        using a package, it's usually recommended to hardcode the name of\n        your package there.\n\n        For example if your application is defined in :file:`yourapplication/app.py`\n        you should create it with one of the two versions below::\n\n            app = Flask('yourapplication')\n            app = Flask(__name__.split('.')[0])\n\n        Why is that?  The application will work even with `__name__`, thanks\n        to how resources are looked up.  However it will make debugging more\n        painful.  Certain extensions can make assumptions based on the\n        import name of your application.  For example the Flask-SQLAlchemy\n        extension will look for the code in your application that triggered\n        an SQL query in debug mode.  If the import name is not properly set\n        up, that debugging information is lost.  (For example it would only\n        pick up SQL queries in `yourapplication.app` and not\n        `yourapplication.views.frontend`)\n\n    .. versionadded:: 0.7\n       The `static_url_path`, `static_folder`, and `template_folder`\n       parameters were added.\n\n    .. versionadded:: 0.8\n       The `instance_path` and `instance_relative_config` parameters were\n       added.\n\n    .. versionadded:: 0.11\n       The `root_path` parameter was added.\n\n    .. versionadded:: 1.0\n       The ``host_matching`` and ``static_host`` parameters were added.\n\n    .. versionadded:: 1.0\n"
    },
    ".venv\\Lib\\site-packages\\flask\\sansio\\blueprints.py": {
      "sha": "8fa1083cf91f",
      "lines": 632,
      "head": "from __future__ import annotations\n\nimport os\nimport typing as t\nfrom collections import defaultdict\nfrom functools import update_wrapper\n\nfrom .. import typing as ft\nfrom .scaffold import _endpoint_from_view_func\nfrom .scaffold import _sentinel\nfrom .scaffold import Scaffold\nfrom .scaffold import setupmethod\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .app import App\n\nDeferredSetupFunction = t.Callable[[\"BlueprintSetupState\"], None]\nT_after_request = t.TypeVar(\"T_after_request\", bound=ft.AfterRequestCallable[t.Any])\nT_before_request = t.TypeVar(\"T_before_request\", bound=ft.BeforeRequestCallable)\nT_error_handler = t.TypeVar(\"T_error_handler\", bound=ft.ErrorHandlerCallable)\nT_teardown = t.TypeVar(\"T_teardown\", bound=ft.TeardownCallable)\nT_template_context_processor = t.TypeVar(\n    \"T_template_context_processor\", bound=ft.TemplateContextProcessorCallable\n)\nT_template_filter = t.TypeVar(\"T_template_filter\", bound=ft.TemplateFilterCallable)\nT_template_global = t.TypeVar(\"T_template_global\", bound=ft.TemplateGlobalCallable)\nT_template_test = t.TypeVar(\"T_template_test\", bound=ft.TemplateTestCallable)\nT_url_defaults = t.TypeVar(\"T_url_defaults\", bound=ft.URLDefaultCallable)\nT_url_value_preprocessor = t.TypeVar(\n    \"T_url_value_preprocessor\", bound=ft.URLValuePreprocessorCallable\n)\n\n\nclass BlueprintSetupState:\n    \"\"\"Temporary holder object for registering a blueprint with the\n    application.  An instance of this class is created by the\n    :meth:`~flask.Blueprint.make_setup_state` method and later passed\n    to all register callback functions.\n    \"\"\"\n\n    def __init__(\n        self,\n        blueprint: Blueprint,\n        app: App,\n        options: t.Any,\n        first_registration: bool,\n    ) -> None:\n        #: a reference to the current application\n        self.app = app\n\n        #: a reference to the blueprint that created this setup state.\n        self.blueprint = blueprint\n\n        #: a dictionary with all options that were passed to the\n        #: :meth:`~flask.Flask.register_blueprint` method.\n        self.options = options\n\n        #: as blueprints can be registered multiple times with the\n        #: application and not everything wants to be registered\n        #: multiple times on it, this attribute can be used to figure\n        #: out if the blueprint was registered in the past already.\n        self.first_registration = first_registration\n\n        subdomain = self.options.get(\"subdomain\")\n        if subdomain is None:\n            subdomain = self.blueprint.subdomain\n\n        #: The subdomain that the blueprint should be active for, ``None``\n        #: otherwise.\n        self.subdomain = subdomain\n\n        url_prefix = self.options.get(\"url_prefix\")\n        if url_prefix is None:\n            url_prefix = self.blueprint.url_prefix\n        #: The prefix that should be used for all URLs defined on the\n        #: blueprint.\n        self.url_prefix = url_prefix\n\n        self.name = self.options.get(\"name\", blueprint.name)\n        self.name_prefix = self.options.get(\"name_prefix\", \"\")\n\n        #: A dictionary with URL defaults that is added to each and every\n        #: URL that was defined with the blueprint.\n        self.url_defaults = dict(self.blueprint.url_values_defaults)\n        self.url_defaults.update(self.options.get(\"url_defaults\", ()))\n\n    def add_url_rule(\n        self,\n        rule: str,\n        endpoint: str | None = None,\n        view_func: ft.RouteCallable | None = None,\n        **options: t.Any,\n    ) -> None:\n        \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\"\n        if self.url_prefix is not None:\n            if rule:\n                rule = \"/\".join((self.url_prefix.rstrip(\"/\"), rule.lstrip(\"/\")))\n            else:\n                rule = self.url_prefix\n        options.setdefault(\"subdomain\", self.subdomain)\n        if endpoint is None:\n            endpoint = _endpoint_from_view_func(view_func)  # type: ignore\n        defaults = self.url_defaults\n        if \"defaults\" in options:\n            defaults = dict(defaults, **options.pop(\"defaults\"))\n\n        self.app.add_url_rule(\n            rule,\n            f\"{self.name_prefix}.{self.name}.{endpoint}\".lstrip(\".\"),\n            view_func,\n            defaults=defaults,\n            **options,\n        )\n\n\nclass Blueprint(Scaffold):\n    \"\"\"Represents a blueprint, a collection of routes and other\n"
    },
    ".venv\\Lib\\site-packages\\flask\\sansio\\README.md": {
      "sha": "7f05a6b9cf60",
      "lines": 6,
      "head": "# Sansio\n\nThis folder contains code that can be used by alternative Flask\nimplementations, for example Quart. The code therefore cannot do any\nIO, nor be part of a likely IO path. Finally this code cannot use the\nFlask globals.\n"
    },
    ".venv\\Lib\\site-packages\\flask\\sansio\\scaffold.py": {
      "sha": "6397d2a888c0",
      "lines": 792,
      "head": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport pathlib\nimport sys\nimport typing as t\nfrom collections import defaultdict\nfrom functools import update_wrapper\n\nfrom jinja2 import BaseLoader\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.exceptions import default_exceptions\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.utils import cached_property\n\nfrom .. import typing as ft\nfrom ..helpers import get_root_path\nfrom ..templating import _default_template_ctx_processor\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from click import Group\n\n# a singleton sentinel value for parameter defaults\n_sentinel = object()\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\nT_after_request = t.TypeVar(\"T_after_request\", bound=ft.AfterRequestCallable[t.Any])\nT_before_request = t.TypeVar(\"T_before_request\", bound=ft.BeforeRequestCallable)\nT_error_handler = t.TypeVar(\"T_error_handler\", bound=ft.ErrorHandlerCallable)\nT_teardown = t.TypeVar(\"T_teardown\", bound=ft.TeardownCallable)\nT_template_context_processor = t.TypeVar(\n    \"T_template_context_processor\", bound=ft.TemplateContextProcessorCallable\n)\nT_url_defaults = t.TypeVar(\"T_url_defaults\", bound=ft.URLDefaultCallable)\nT_url_value_preprocessor = t.TypeVar(\n    \"T_url_value_preprocessor\", bound=ft.URLValuePreprocessorCallable\n)\nT_route = t.TypeVar(\"T_route\", bound=ft.RouteCallable)\n\n\ndef setupmethod(f: F) -> F:\n    f_name = f.__name__\n\n    def wrapper_func(self: Scaffold, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        self._check_setup_finished(f_name)\n        return f(self, *args, **kwargs)\n\n    return t.cast(F, update_wrapper(wrapper_func, f))\n\n\nclass Scaffold:\n    \"\"\"Common behavior shared between :class:`~flask.Flask` and\n    :class:`~flask.blueprints.Blueprint`.\n\n    :param import_name: The import name of the module where this object\n        is defined. Usually :attr:`__name__` should be used.\n    :param static_folder: Path to a folder of static files to serve.\n        If this is set, a static route will be added.\n    :param static_url_path: URL prefix for the static route.\n    :param template_folder: Path to a folder containing template files.\n        for rendering. If this is set, a Jinja loader will be added.\n    :param root_path: The path that static, template, and resource files\n        are relative to. Typically not set, it is discovered based on\n        the ``import_name``.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    cli: Group\n    name: str\n    _static_folder: str | None = None\n    _static_url_path: str | None = None\n\n    def __init__(\n        self,\n        import_name: str,\n        static_folder: str | os.PathLike[str] | None = None,\n        static_url_path: str | None = None,\n        template_folder: str | os.PathLike[str] | None = None,\n        root_path: str | None = None,\n    ):\n        #: The name of the package or module that this object belongs\n        #: to. Do not change this once it is set by the constructor.\n        self.import_name = import_name\n\n        self.static_folder = static_folder\n        self.static_url_path = static_url_path\n\n        #: The path to the templates folder, relative to\n        #: :attr:`root_path`, to add to the template loader. ``None`` if\n        #: templates should not be added.\n        self.template_folder = template_folder\n\n        if root_path is None:\n            root_path = get_root_path(self.import_name)\n\n        #: Absolute path to the package on the filesystem. Used to look\n        #: up resources contained in the package.\n        self.root_path = root_path\n\n        #: A dictionary mapping endpoint names to view functions.\n        #:\n        #: To register a view function, use the :meth:`route` decorator.\n        #:\n        #: This data structure is internal. It should not be modified\n        #: directly and its format may change at any time.\n        self.view_functions: dict[str, ft.RouteCallable] = {}\n\n        #: A data structure of registered error handlers, in the format\n        #: ``{scope: {code: {class: handler}}}``. The ``scope`` key is\n        #: the name of a blueprint the handlers are active for, or\n        #: ``None`` for all requests. The ``code`` key is the HTTP\n        #: status code for ``HTTPException``, or ``None`` for\n        #: other exceptions. The innermost dictionary maps exception\n        #: classes to handler functions.\n        #:\n        #: To register an error handler, use the :meth:`errorhandler`\n        #: decorator.\n        #:\n"
    },
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\entry_points.txt": {
      "sha": "27e3e9826bf2",
      "lines": 3,
      "head": "[console_scripts]\nflask=flask.cli:main\n\n"
    },
    ".venv\\Lib\\site-packages\\flask-3.1.2.dist-info\\licenses\\LICENSE.txt": {
      "sha": "e32a549b135c",
      "lines": 28,
      "head": "Copyright 2010 Pallets\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n1.  Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n2.  Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\n3.  Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous\\encoding.py": {
      "sha": "90d89ec30c52",
      "lines": 54,
      "head": "from __future__ import annotations\n\nimport base64\nimport string\nimport struct\nimport typing as t\n\nfrom .exc import BadData\n\n\ndef want_bytes(\n    s: str | bytes, encoding: str = \"utf-8\", errors: str = \"strict\"\n) -> bytes:\n    if isinstance(s, str):\n        s = s.encode(encoding, errors)\n\n    return s\n\n\ndef base64_encode(string: str | bytes) -> bytes:\n    \"\"\"Base64 encode a string of bytes or text. The resulting bytes are\n    safe to use in URLs.\n    \"\"\"\n    string = want_bytes(string)\n    return base64.urlsafe_b64encode(string).rstrip(b\"=\")\n\n\ndef base64_decode(string: str | bytes) -> bytes:\n    \"\"\"Base64 decode a URL-safe string of bytes or text. The result is\n    bytes.\n    \"\"\"\n    string = want_bytes(string, encoding=\"ascii\", errors=\"ignore\")\n    string += b\"=\" * (-len(string) % 4)\n\n    try:\n        return base64.urlsafe_b64decode(string)\n    except (TypeError, ValueError) as e:\n        raise BadData(\"Invalid base64-encoded data\") from e\n\n\n# The alphabet used by base64.urlsafe_*\n_base64_alphabet = f\"{string.ascii_letters}{string.digits}-_=\".encode(\"ascii\")\n\n_int64_struct = struct.Struct(\">Q\")\n_int_to_bytes = _int64_struct.pack\n_bytes_to_int = t.cast(\"t.Callable[[bytes], tuple[int]]\", _int64_struct.unpack)\n\n\ndef int_to_bytes(num: int) -> bytes:\n    return _int_to_bytes(num).lstrip(b\"\\x00\")\n\n\ndef bytes_to_int(bytestr: bytes) -> int:\n    return _bytes_to_int(bytestr.rjust(8, b\"\\x00\"))[0]\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous\\exc.py": {
      "sha": "cdc4feb0cdca",
      "lines": 106,
      "head": "from __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\n\n\nclass BadData(Exception):\n    \"\"\"Raised if bad data of any sort was encountered. This is the base\n    for all exceptions that ItsDangerous defines.\n\n    .. versionadded:: 0.15\n    \"\"\"\n\n    def __init__(self, message: str):\n        super().__init__(message)\n        self.message = message\n\n    def __str__(self) -> str:\n        return self.message\n\n\nclass BadSignature(BadData):\n    \"\"\"Raised if a signature does not match.\"\"\"\n\n    def __init__(self, message: str, payload: t.Any | None = None):\n        super().__init__(message)\n\n        #: The payload that failed the signature test. In some\n        #: situations you might still want to inspect this, even if\n        #: you know it was tampered with.\n        #:\n        #: .. versionadded:: 0.14\n        self.payload: t.Any | None = payload\n\n\nclass BadTimeSignature(BadSignature):\n    \"\"\"Raised if a time-based signature is invalid. This is a subclass\n    of :class:`BadSignature`.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        payload: t.Any | None = None,\n        date_signed: datetime | None = None,\n    ):\n        super().__init__(message, payload)\n\n        #: If the signature expired this exposes the date of when the\n        #: signature was created. This can be helpful in order to\n        #: tell the user how long a link has been gone stale.\n        #:\n        #: .. versionchanged:: 2.0\n        #:     The datetime value is timezone-aware rather than naive.\n        #:\n        #: .. versionadded:: 0.14\n        self.date_signed = date_signed\n\n\nclass SignatureExpired(BadTimeSignature):\n    \"\"\"Raised if a signature timestamp is older than ``max_age``. This\n    is a subclass of :exc:`BadTimeSignature`.\n    \"\"\"\n\n\nclass BadHeader(BadSignature):\n    \"\"\"Raised if a signed header is invalid in some form. This only\n    happens for serializers that have a header that goes with the\n    signature.\n\n    .. versionadded:: 0.24\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        payload: t.Any | None = None,\n        header: t.Any | None = None,\n        original_error: Exception | None = None,\n    ):\n        super().__init__(message, payload)\n\n        #: If the header is actually available but just malformed it\n        #: might be stored here.\n        self.header: t.Any | None = header\n\n        #: If available, the error that indicates why the payload was\n        #: not valid. This might be ``None``.\n        self.original_error: Exception | None = original_error\n\n\nclass BadPayload(BadData):\n    \"\"\"Raised if a payload is invalid. This could happen if the payload\n    is loaded despite an invalid signature, or if there is a mismatch\n    between the serializer and deserializer. The original exception\n    that occurred during loading is stored on as :attr:`original_error`.\n\n    .. versionadded:: 0.15\n    \"\"\"\n\n    def __init__(self, message: str, original_error: Exception | None = None):\n        super().__init__(message)\n\n        #: If available, the error that indicates why the payload was\n        #: not valid. This might be ``None``.\n        self.original_error: Exception | None = original_error\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous\\serializer.py": {
      "sha": "470de65d5264",
      "lines": 406,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport json\nimport typing as t\n\nfrom .encoding import want_bytes\nfrom .exc import BadPayload\nfrom .exc import BadSignature\nfrom .signer import _make_keys_list\nfrom .signer import Signer\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    # This should be either be str or bytes. To avoid having to specify the\n    # bound type, it falls back to a union if structural matching fails.\n    _TSerialized = te.TypeVar(\n        \"_TSerialized\", bound=t.Union[str, bytes], default=t.Union[str, bytes]\n    )\nelse:\n    # Still available at runtime on Python < 3.13, but without the default.\n    _TSerialized = t.TypeVar(\"_TSerialized\", bound=t.Union[str, bytes])\n\n\nclass _PDataSerializer(t.Protocol[_TSerialized]):\n    def loads(self, payload: _TSerialized, /) -> t.Any: ...\n    # A signature with additional arguments is not handled correctly by type\n    # checkers right now, so an overload is used below for serializers that\n    # don't match this strict protocol.\n    def dumps(self, obj: t.Any, /) -> _TSerialized: ...\n\n\n# Use TypeIs once it's available in typing_extensions or 3.13.\ndef is_text_serializer(\n    serializer: _PDataSerializer[t.Any],\n) -> te.TypeGuard[_PDataSerializer[str]]:\n    \"\"\"Checks whether a serializer generates text or binary.\"\"\"\n    return isinstance(serializer.dumps({}), str)\n\n\nclass Serializer(t.Generic[_TSerialized]):\n    \"\"\"A serializer wraps a :class:`~itsdangerous.signer.Signer` to\n    enable serializing and securely signing data other than bytes. It\n    can unsign to verify that the data hasn't been changed.\n\n    The serializer provides :meth:`dumps` and :meth:`loads`, similar to\n    :mod:`json`, and by default uses :mod:`json` internally to serialize\n    the data to bytes.\n\n    The secret key should be a random string of ``bytes`` and should not\n    be saved to code or version control. Different salts should be used\n    to distinguish signing in different contexts. See :doc:`/concepts`\n    for information about the security of the secret key and salt.\n\n    :param secret_key: The secret key to sign and verify with. Can be a\n        list of keys, oldest to newest, to support key rotation.\n    :param salt: Extra key to combine with ``secret_key`` to distinguish\n        signatures in different contexts.\n    :param serializer: An object that provides ``dumps`` and ``loads``\n        methods for serializing data to a string. Defaults to\n        :attr:`default_serializer`, which defaults to :mod:`json`.\n    :param serializer_kwargs: Keyword arguments to pass when calling\n        ``serializer.dumps``.\n    :param signer: A ``Signer`` class to instantiate when signing data.\n        Defaults to :attr:`default_signer`, which defaults to\n        :class:`~itsdangerous.signer.Signer`.\n    :param signer_kwargs: Keyword arguments to pass when instantiating\n        the ``Signer`` class.\n    :param fallback_signers: List of signer parameters to try when\n        unsigning with the default signer fails. Each item can be a dict\n        of ``signer_kwargs``, a ``Signer`` class, or a tuple of\n        ``(signer, signer_kwargs)``. Defaults to\n        :attr:`default_fallback_signers`.\n\n    .. versionchanged:: 2.0\n        Added support for key rotation by passing a list to\n        ``secret_key``.\n\n    .. versionchanged:: 2.0\n        Removed the default SHA-512 fallback signer from\n        ``default_fallback_signers``.\n\n    .. versionchanged:: 1.1\n        Added support for ``fallback_signers`` and configured a default\n        SHA-512 fallback. This fallback is for users who used the yanked\n        1.0.0 release which defaulted to SHA-512.\n\n    .. versionchanged:: 0.14\n        The ``signer`` and ``signer_kwargs`` parameters were added to\n        the constructor.\n    \"\"\"\n\n    #: The default serialization module to use to serialize data to a\n    #: string internally. The default is :mod:`json`, but can be changed\n    #: to any object that provides ``dumps`` and ``loads`` methods.\n    default_serializer: _PDataSerializer[t.Any] = json\n\n    #: The default ``Signer`` class to instantiate when signing data.\n    #: The default is :class:`itsdangerous.signer.Signer`.\n    default_signer: type[Signer] = Signer\n\n    #: The default fallback signers to try when unsigning fails.\n    default_fallback_signers: list[\n        dict[str, t.Any] | tuple[type[Signer], dict[str, t.Any]] | type[Signer]\n    ] = []\n\n    # Serializer[str] if no data serializer is provided, or if it returns str.\n    @t.overload\n    def __init__(\n        self: Serializer[str],\n        secret_key: str | bytes | cabc.Iterable[str] | cabc.Iterable[bytes],\n        salt: str | bytes | None = b\"itsdangerous\",\n        serializer: None | _PDataSerializer[str] = None,\n        serializer_kwargs: dict[str, t.Any] | None = None,\n        signer: type[Signer] | None = None,\n        signer_kwargs: dict[str, t.Any] | None = None,\n        fallback_signers: list[\n            dict[str, t.Any] | tuple[type[Signer], dict[str, t.Any]] | type[Signer]\n        ]\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous\\signer.py": {
      "sha": "a4b78b2aa917",
      "lines": 266,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport hashlib\nimport hmac\nimport typing as t\n\nfrom .encoding import _base64_alphabet\nfrom .encoding import base64_decode\nfrom .encoding import base64_encode\nfrom .encoding import want_bytes\nfrom .exc import BadSignature\n\n\nclass SigningAlgorithm:\n    \"\"\"Subclasses must implement :meth:`get_signature` to provide\n    signature generation functionality.\n    \"\"\"\n\n    def get_signature(self, key: bytes, value: bytes) -> bytes:\n        \"\"\"Returns the signature for the given key and value.\"\"\"\n        raise NotImplementedError()\n\n    def verify_signature(self, key: bytes, value: bytes, sig: bytes) -> bool:\n        \"\"\"Verifies the given signature matches the expected\n        signature.\n        \"\"\"\n        return hmac.compare_digest(sig, self.get_signature(key, value))\n\n\nclass NoneAlgorithm(SigningAlgorithm):\n    \"\"\"Provides an algorithm that does not perform any signing and\n    returns an empty signature.\n    \"\"\"\n\n    def get_signature(self, key: bytes, value: bytes) -> bytes:\n        return b\"\"\n\n\ndef _lazy_sha1(string: bytes = b\"\") -> t.Any:\n    \"\"\"Don't access ``hashlib.sha1`` until runtime. FIPS builds may not include\n    SHA-1, in which case the import and use as a default would fail before the\n    developer can configure something else.\n    \"\"\"\n    return hashlib.sha1(string)\n\n\nclass HMACAlgorithm(SigningAlgorithm):\n    \"\"\"Provides signature generation using HMACs.\"\"\"\n\n    #: The digest method to use with the MAC algorithm. This defaults to\n    #: SHA1, but can be changed to any other function in the hashlib\n    #: module.\n    default_digest_method: t.Any = staticmethod(_lazy_sha1)\n\n    def __init__(self, digest_method: t.Any = None):\n        if digest_method is None:\n            digest_method = self.default_digest_method\n\n        self.digest_method: t.Any = digest_method\n\n    def get_signature(self, key: bytes, value: bytes) -> bytes:\n        mac = hmac.new(key, msg=value, digestmod=self.digest_method)\n        return mac.digest()\n\n\ndef _make_keys_list(\n    secret_key: str | bytes | cabc.Iterable[str] | cabc.Iterable[bytes],\n) -> list[bytes]:\n    if isinstance(secret_key, (str, bytes)):\n        return [want_bytes(secret_key)]\n\n    return [want_bytes(s) for s in secret_key]  # pyright: ignore\n\n\nclass Signer:\n    \"\"\"A signer securely signs bytes, then unsigns them to verify that\n    the value hasn't been changed.\n\n    The secret key should be a random string of ``bytes`` and should not\n    be saved to code or version control. Different salts should be used\n    to distinguish signing in different contexts. See :doc:`/concepts`\n    for information about the security of the secret key and salt.\n\n    :param secret_key: The secret key to sign and verify with. Can be a\n        list of keys, oldest to newest, to support key rotation.\n    :param salt: Extra key to combine with ``secret_key`` to distinguish\n        signatures in different contexts.\n    :param sep: Separator between the signature and value.\n    :param key_derivation: How to derive the signing key from the secret\n        key and salt. Possible values are ``concat``, ``django-concat``,\n        or ``hmac``. Defaults to :attr:`default_key_derivation`, which\n        defaults to ``django-concat``.\n    :param digest_method: Hash function to use when generating the HMAC\n        signature. Defaults to :attr:`default_digest_method`, which\n        defaults to :func:`hashlib.sha1`. Note that the security of the\n        hash alone doesn't apply when used intermediately in HMAC.\n    :param algorithm: A :class:`SigningAlgorithm` instance to use\n        instead of building a default :class:`HMACAlgorithm` with the\n        ``digest_method``.\n\n    .. versionchanged:: 2.0\n        Added support for key rotation by passing a list to\n        ``secret_key``.\n\n    .. versionchanged:: 0.18\n        ``algorithm`` was added as an argument to the class constructor.\n\n    .. versionchanged:: 0.14\n        ``key_derivation`` and ``digest_method`` were added as arguments\n        to the class constructor.\n    \"\"\"\n\n    #: The default digest method to use for the signer. The default is\n    #: :func:`hashlib.sha1`, but can be changed to any :mod:`hashlib` or\n    #: compatible object. Note that the security of the hash alone\n    #: doesn't apply when used intermediately in HMAC.\n    #:\n    #: .. versionadded:: 0.14\n    default_digest_method: t.Any = staticmethod(_lazy_sha1)\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous\\timed.py": {
      "sha": "bda4543da3a6",
      "lines": 228,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport time\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timezone\n\nfrom .encoding import base64_decode\nfrom .encoding import base64_encode\nfrom .encoding import bytes_to_int\nfrom .encoding import int_to_bytes\nfrom .encoding import want_bytes\nfrom .exc import BadSignature\nfrom .exc import BadTimeSignature\nfrom .exc import SignatureExpired\nfrom .serializer import _TSerialized\nfrom .serializer import Serializer\nfrom .signer import Signer\n\n\nclass TimestampSigner(Signer):\n    \"\"\"Works like the regular :class:`.Signer` but also records the time\n    of the signing and can be used to expire signatures. The\n    :meth:`unsign` method can raise :exc:`.SignatureExpired` if the\n    unsigning failed because the signature is expired.\n    \"\"\"\n\n    def get_timestamp(self) -> int:\n        \"\"\"Returns the current timestamp. The function must return an\n        integer.\n        \"\"\"\n        return int(time.time())\n\n    def timestamp_to_datetime(self, ts: int) -> datetime:\n        \"\"\"Convert the timestamp from :meth:`get_timestamp` into an\n        aware :class`datetime.datetime` in UTC.\n\n        .. versionchanged:: 2.0\n            The timestamp is returned as a timezone-aware ``datetime``\n            in UTC rather than a naive ``datetime`` assumed to be UTC.\n        \"\"\"\n        return datetime.fromtimestamp(ts, tz=timezone.utc)\n\n    def sign(self, value: str | bytes) -> bytes:\n        \"\"\"Signs the given string and also attaches time information.\"\"\"\n        value = want_bytes(value)\n        timestamp = base64_encode(int_to_bytes(self.get_timestamp()))\n        sep = want_bytes(self.sep)\n        value = value + sep + timestamp\n        return value + sep + self.get_signature(value)\n\n    # Ignore overlapping signatures check, return_timestamp is the only\n    # parameter that affects the return type.\n\n    @t.overload\n    def unsign(  # type: ignore[overload-overlap]\n        self,\n        signed_value: str | bytes,\n        max_age: int | None = None,\n        return_timestamp: t.Literal[False] = False,\n    ) -> bytes: ...\n\n    @t.overload\n    def unsign(\n        self,\n        signed_value: str | bytes,\n        max_age: int | None = None,\n        return_timestamp: t.Literal[True] = True,\n    ) -> tuple[bytes, datetime]: ...\n\n    def unsign(\n        self,\n        signed_value: str | bytes,\n        max_age: int | None = None,\n        return_timestamp: bool = False,\n    ) -> tuple[bytes, datetime] | bytes:\n        \"\"\"Works like the regular :meth:`.Signer.unsign` but can also\n        validate the time. See the base docstring of the class for\n        the general behavior. If ``return_timestamp`` is ``True`` the\n        timestamp of the signature will be returned as an aware\n        :class:`datetime.datetime` object in UTC.\n\n        .. versionchanged:: 2.0\n            The timestamp is returned as a timezone-aware ``datetime``\n            in UTC rather than a naive ``datetime`` assumed to be UTC.\n        \"\"\"\n        try:\n            result = super().unsign(signed_value)\n            sig_error = None\n        except BadSignature as e:\n            sig_error = e\n            result = e.payload or b\"\"\n\n        sep = want_bytes(self.sep)\n\n        # If there is no timestamp in the result there is something\n        # seriously wrong. In case there was a signature error, we raise\n        # that one directly, otherwise we have a weird situation in\n        # which we shouldn't have come except someone uses a time-based\n        # serializer on non-timestamp data, so catch that.\n        if sep not in result:\n            if sig_error:\n                raise sig_error\n\n            raise BadTimeSignature(\"timestamp missing\", payload=result)\n\n        value, ts_bytes = result.rsplit(sep, 1)\n        ts_int: int | None = None\n        ts_dt: datetime | None = None\n\n        try:\n            ts_int = bytes_to_int(base64_decode(ts_bytes))\n        except Exception:\n            pass\n\n        # Signature is *not* okay. Raise a proper error now that we have\n        # split the value and the timestamp.\n        if sig_error is not None:\n            if ts_int is not None:\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous\\url_safe.py": {
      "sha": "0697db08d1ce",
      "lines": 83,
      "head": "from __future__ import annotations\n\nimport typing as t\nimport zlib\n\nfrom ._json import _CompactJSON\nfrom .encoding import base64_decode\nfrom .encoding import base64_encode\nfrom .exc import BadPayload\nfrom .serializer import _PDataSerializer\nfrom .serializer import Serializer\nfrom .timed import TimedSerializer\n\n\nclass URLSafeSerializerMixin(Serializer[str]):\n    \"\"\"Mixed in with a regular serializer it will attempt to zlib\n    compress the string to make it shorter if necessary. It will also\n    base64 encode the string so that it can safely be placed in a URL.\n    \"\"\"\n\n    default_serializer: _PDataSerializer[str] = _CompactJSON\n\n    def load_payload(\n        self,\n        payload: bytes,\n        *args: t.Any,\n        serializer: t.Any | None = None,\n        **kwargs: t.Any,\n    ) -> t.Any:\n        decompress = False\n\n        if payload.startswith(b\".\"):\n            payload = payload[1:]\n            decompress = True\n\n        try:\n            json = base64_decode(payload)\n        except Exception as e:\n            raise BadPayload(\n                \"Could not base64 decode the payload because of an exception\",\n                original_error=e,\n            ) from e\n\n        if decompress:\n            try:\n                json = zlib.decompress(json)\n            except Exception as e:\n                raise BadPayload(\n                    \"Could not zlib decompress the payload before decoding the payload\",\n                    original_error=e,\n                ) from e\n\n        return super().load_payload(json, *args, **kwargs)\n\n    def dump_payload(self, obj: t.Any) -> bytes:\n        json = super().dump_payload(obj)\n        is_compressed = False\n        compressed = zlib.compress(json)\n\n        if len(compressed) < (len(json) - 1):\n            json = compressed\n            is_compressed = True\n\n        base64d = base64_encode(json)\n\n        if is_compressed:\n            base64d = b\".\" + base64d\n\n        return base64d\n\n\nclass URLSafeSerializer(URLSafeSerializerMixin, Serializer[str]):\n    \"\"\"Works like :class:`.Serializer` but dumps and loads into a URL\n    safe string consisting of the upper and lowercase character of the\n    alphabet as well as ``'_'``, ``'-'`` and ``'.'``.\n    \"\"\"\n\n\nclass URLSafeTimedSerializer(URLSafeSerializerMixin, TimedSerializer[str]):\n    \"\"\"Works like :class:`.TimedSerializer` but dumps and loads into a\n    URL safe string consisting of the upper and lowercase character of\n    the alphabet as well as ``'_'``, ``'-'`` and ``'.'``.\n    \"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous\\_json.py": {
      "sha": "15f674c19eec",
      "lines": 18,
      "head": "from __future__ import annotations\n\nimport json as _json\nimport typing as t\n\n\nclass _CompactJSON:\n    \"\"\"Wrapper around json module that strips whitespace.\"\"\"\n\n    @staticmethod\n    def loads(payload: str | bytes) -> t.Any:\n        return _json.loads(payload)\n\n    @staticmethod\n    def dumps(obj: t.Any, **kwargs: t.Any) -> str:\n        kwargs.setdefault(\"ensure_ascii\", False)\n        kwargs.setdefault(\"separators\", (\",\", \":\"))\n        return _json.dumps(obj, **kwargs)\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous\\__init__.py": {
      "sha": "8af114b5e5ae",
      "lines": 38,
      "head": "from __future__ import annotations\n\nimport typing as t\n\nfrom .encoding import base64_decode as base64_decode\nfrom .encoding import base64_encode as base64_encode\nfrom .encoding import want_bytes as want_bytes\nfrom .exc import BadData as BadData\nfrom .exc import BadHeader as BadHeader\nfrom .exc import BadPayload as BadPayload\nfrom .exc import BadSignature as BadSignature\nfrom .exc import BadTimeSignature as BadTimeSignature\nfrom .exc import SignatureExpired as SignatureExpired\nfrom .serializer import Serializer as Serializer\nfrom .signer import HMACAlgorithm as HMACAlgorithm\nfrom .signer import NoneAlgorithm as NoneAlgorithm\nfrom .signer import Signer as Signer\nfrom .timed import TimedSerializer as TimedSerializer\nfrom .timed import TimestampSigner as TimestampSigner\nfrom .url_safe import URLSafeSerializer as URLSafeSerializer\nfrom .url_safe import URLSafeTimedSerializer as URLSafeTimedSerializer\n\n\ndef __getattr__(name: str) -> t.Any:\n    if name == \"__version__\":\n        import importlib.metadata\n        import warnings\n\n        warnings.warn(\n            \"The '__version__' attribute is deprecated and will be removed in\"\n            \" ItsDangerous 2.3. Use feature detection or\"\n            \" 'importlib.metadata.version(\\\"itsdangerous\\\")' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return importlib.metadata.version(\"itsdangerous\")\n\n    raise AttributeError(name)\n"
    },
    ".venv\\Lib\\site-packages\\itsdangerous-2.2.0.dist-info\\LICENSE.txt": {
      "sha": "a814758bca3d",
      "lines": 28,
      "head": "Copyright 2011 Pallets\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n1.  Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n2.  Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\n3.  Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\async_utils.py": {
      "sha": "3fe488738eda",
      "lines": 99,
      "head": "import inspect\nimport typing as t\nfrom functools import WRAPPER_ASSIGNMENTS\nfrom functools import wraps\n\nfrom .utils import _PassArg\nfrom .utils import pass_eval_context\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\nV = t.TypeVar(\"V\")\n\n\ndef async_variant(normal_func):  # type: ignore\n    def decorator(async_func):  # type: ignore\n        pass_arg = _PassArg.from_obj(normal_func)\n        need_eval_context = pass_arg is None\n\n        if pass_arg is _PassArg.environment:\n\n            def is_async(args: t.Any) -> bool:\n                return t.cast(bool, args[0].is_async)\n\n        else:\n\n            def is_async(args: t.Any) -> bool:\n                return t.cast(bool, args[0].environment.is_async)\n\n        # Take the doc and annotations from the sync function, but the\n        # name from the async function. Pallets-Sphinx-Themes\n        # build_function_directive expects __wrapped__ to point to the\n        # sync function.\n        async_func_attrs = (\"__module__\", \"__name__\", \"__qualname__\")\n        normal_func_attrs = tuple(set(WRAPPER_ASSIGNMENTS).difference(async_func_attrs))\n\n        @wraps(normal_func, assigned=normal_func_attrs)\n        @wraps(async_func, assigned=async_func_attrs, updated=())\n        def wrapper(*args, **kwargs):  # type: ignore\n            b = is_async(args)\n\n            if need_eval_context:\n                args = args[1:]\n\n            if b:\n                return async_func(*args, **kwargs)\n\n            return normal_func(*args, **kwargs)\n\n        if need_eval_context:\n            wrapper = pass_eval_context(wrapper)\n\n        wrapper.jinja_async_variant = True  # type: ignore[attr-defined]\n        return wrapper\n\n    return decorator\n\n\n_common_primitives = {int, float, bool, str, list, dict, tuple, type(None)}\n\n\nasync def auto_await(value: t.Union[t.Awaitable[\"V\"], \"V\"]) -> \"V\":\n    # Avoid a costly call to isawaitable\n    if type(value) in _common_primitives:\n        return t.cast(\"V\", value)\n\n    if inspect.isawaitable(value):\n        return await t.cast(\"t.Awaitable[V]\", value)\n\n    return value\n\n\nclass _IteratorToAsyncIterator(t.Generic[V]):\n    def __init__(self, iterator: \"t.Iterator[V]\"):\n        self._iterator = iterator\n\n    def __aiter__(self) -> \"te.Self\":\n        return self\n\n    async def __anext__(self) -> V:\n        try:\n            return next(self._iterator)\n        except StopIteration as e:\n            raise StopAsyncIteration(e.value) from e\n\n\ndef auto_aiter(\n    iterable: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n) -> \"t.AsyncIterator[V]\":\n    if hasattr(iterable, \"__aiter__\"):\n        return iterable.__aiter__()\n    else:\n        return _IteratorToAsyncIterator(iter(iterable))\n\n\nasync def auto_to_list(\n    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n) -> t.List[\"V\"]:\n    return [x async for x in auto_aiter(value)]\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\bccache.py": {
      "sha": "c5ce6a9873ae",
      "lines": 408,
      "head": "\"\"\"The optional bytecode cache system. This is useful if you have very\ncomplex template situations and the compilation of all those templates\nslows down your application too much.\n\nSituations where this is useful are often forking web applications that\nare initialized on the first request.\n\"\"\"\n\nimport errno\nimport fnmatch\nimport marshal\nimport os\nimport pickle\nimport stat\nimport sys\nimport tempfile\nimport typing as t\nfrom hashlib import sha1\nfrom io import BytesIO\nfrom types import CodeType\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .environment import Environment\n\n    class _MemcachedClient(te.Protocol):\n        def get(self, key: str) -> bytes: ...\n\n        def set(\n            self, key: str, value: bytes, timeout: t.Optional[int] = None\n        ) -> None: ...\n\n\nbc_version = 5\n# Magic bytes to identify Jinja bytecode cache files. Contains the\n# Python major and minor version to avoid loading incompatible bytecode\n# if a project upgrades its Python version.\nbc_magic = (\n    b\"j2\"\n    + pickle.dumps(bc_version, 2)\n    + pickle.dumps((sys.version_info[0] << 24) | sys.version_info[1], 2)\n)\n\n\nclass Bucket:\n    \"\"\"Buckets are used to store the bytecode for one template.  It's created\n    and initialized by the bytecode cache and passed to the loading functions.\n\n    The buckets get an internal checksum from the cache assigned and use this\n    to automatically reject outdated cache material.  Individual bytecode\n    cache subclasses don't have to care about cache invalidation.\n    \"\"\"\n\n    def __init__(self, environment: \"Environment\", key: str, checksum: str) -> None:\n        self.environment = environment\n        self.key = key\n        self.checksum = checksum\n        self.reset()\n\n    def reset(self) -> None:\n        \"\"\"Resets the bucket (unloads the bytecode).\"\"\"\n        self.code: t.Optional[CodeType] = None\n\n    def load_bytecode(self, f: t.BinaryIO) -> None:\n        \"\"\"Loads bytecode from a file or file like object.\"\"\"\n        # make sure the magic header is correct\n        magic = f.read(len(bc_magic))\n        if magic != bc_magic:\n            self.reset()\n            return\n        # the source code of the file changed, we need to reload\n        checksum = pickle.load(f)\n        if self.checksum != checksum:\n            self.reset()\n            return\n        # if marshal_load fails then we need to reload\n        try:\n            self.code = marshal.load(f)\n        except (EOFError, ValueError, TypeError):\n            self.reset()\n            return\n\n    def write_bytecode(self, f: t.IO[bytes]) -> None:\n        \"\"\"Dump the bytecode into the file or file like object passed.\"\"\"\n        if self.code is None:\n            raise TypeError(\"can't write empty bucket\")\n        f.write(bc_magic)\n        pickle.dump(self.checksum, f, 2)\n        marshal.dump(self.code, f)\n\n    def bytecode_from_string(self, string: bytes) -> None:\n        \"\"\"Load bytecode from bytes.\"\"\"\n        self.load_bytecode(BytesIO(string))\n\n    def bytecode_to_string(self) -> bytes:\n        \"\"\"Return the bytecode as bytes.\"\"\"\n        out = BytesIO()\n        self.write_bytecode(out)\n        return out.getvalue()\n\n\nclass BytecodeCache:\n    \"\"\"To implement your own bytecode cache you have to subclass this class\n    and override :meth:`load_bytecode` and :meth:`dump_bytecode`.  Both of\n    these methods are passed a :class:`~jinja2.bccache.Bucket`.\n\n    A very basic bytecode cache that saves the bytecode on the file system::\n\n        from os import path\n\n        class MyCache(BytecodeCache):\n\n            def __init__(self, directory):\n                self.directory = directory\n\n            def load_bytecode(self, bucket):\n                filename = path.join(self.directory, bucket.key)\n                if path.exists(filename):\n                    with open(filename, 'rb') as f:\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\compiler.py": {
      "sha": "ecce1e5613e0",
      "lines": 1998,
      "head": "\"\"\"Compiles nodes from the parser into Python code.\"\"\"\n\nimport typing as t\nfrom contextlib import contextmanager\nfrom functools import update_wrapper\nfrom io import StringIO\nfrom itertools import chain\nfrom keyword import iskeyword as is_python_keyword\n\nfrom markupsafe import escape\nfrom markupsafe import Markup\n\nfrom . import nodes\nfrom .exceptions import TemplateAssertionError\nfrom .idtracking import Symbols\nfrom .idtracking import VAR_LOAD_ALIAS\nfrom .idtracking import VAR_LOAD_PARAMETER\nfrom .idtracking import VAR_LOAD_RESOLVE\nfrom .idtracking import VAR_LOAD_UNDEFINED\nfrom .nodes import EvalContext\nfrom .optimizer import Optimizer\nfrom .utils import _PassArg\nfrom .utils import concat\nfrom .visitor import NodeVisitor\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .environment import Environment\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\noperators = {\n    \"eq\": \"==\",\n    \"ne\": \"!=\",\n    \"gt\": \">\",\n    \"gteq\": \">=\",\n    \"lt\": \"<\",\n    \"lteq\": \"<=\",\n    \"in\": \"in\",\n    \"notin\": \"not in\",\n}\n\n\ndef optimizeconst(f: F) -> F:\n    def new_func(\n        self: \"CodeGenerator\", node: nodes.Expr, frame: \"Frame\", **kwargs: t.Any\n    ) -> t.Any:\n        # Only optimize if the frame is not volatile\n        if self.optimizer is not None and not frame.eval_ctx.volatile:\n            new_node = self.optimizer.visit(node, frame.eval_ctx)\n\n            if new_node != node:\n                return self.visit(new_node, frame)\n\n        return f(self, node, frame, **kwargs)\n\n    return update_wrapper(new_func, f)  # type: ignore[return-value]\n\n\ndef _make_binop(op: str) -> t.Callable[[\"CodeGenerator\", nodes.BinExpr, \"Frame\"], None]:\n    @optimizeconst\n    def visitor(self: \"CodeGenerator\", node: nodes.BinExpr, frame: Frame) -> None:\n        if (\n            self.environment.sandboxed and op in self.environment.intercepted_binops  # type: ignore\n        ):\n            self.write(f\"environment.call_binop(context, {op!r}, \")\n            self.visit(node.left, frame)\n            self.write(\", \")\n            self.visit(node.right, frame)\n        else:\n            self.write(\"(\")\n            self.visit(node.left, frame)\n            self.write(f\" {op} \")\n            self.visit(node.right, frame)\n\n        self.write(\")\")\n\n    return visitor\n\n\ndef _make_unop(\n    op: str,\n) -> t.Callable[[\"CodeGenerator\", nodes.UnaryExpr, \"Frame\"], None]:\n    @optimizeconst\n    def visitor(self: \"CodeGenerator\", node: nodes.UnaryExpr, frame: Frame) -> None:\n        if (\n            self.environment.sandboxed and op in self.environment.intercepted_unops  # type: ignore\n        ):\n            self.write(f\"environment.call_unop(context, {op!r}, \")\n            self.visit(node.node, frame)\n        else:\n            self.write(\"(\" + op)\n            self.visit(node.node, frame)\n\n        self.write(\")\")\n\n    return visitor\n\n\ndef generate(\n    node: nodes.Template,\n    environment: \"Environment\",\n    name: t.Optional[str],\n    filename: t.Optional[str],\n    stream: t.Optional[t.TextIO] = None,\n    defer_init: bool = False,\n    optimized: bool = True,\n) -> t.Optional[str]:\n    \"\"\"Generate the python source for a node tree.\"\"\"\n    if not isinstance(node, nodes.Template):\n        raise TypeError(\"Can't compile non template nodes\")\n\n    generator = environment.code_generator_class(\n        environment, name, filename, stream, defer_init, optimized\n    )\n    generator.visit(node)\n\n    if stream is None:\n        return generator.stream.getvalue()  # type: ignore\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\constants.py": {
      "sha": "64d1675afe76",
      "lines": 20,
      "head": "#: list of lorem ipsum words used by the lipsum() helper function\nLOREM_IPSUM_WORDS = \"\"\"\\\na ac accumsan ad adipiscing aenean aliquam aliquet amet ante aptent arcu at\nauctor augue bibendum blandit class commodo condimentum congue consectetuer\nconsequat conubia convallis cras cubilia cum curabitur curae cursus dapibus\ndiam dictum dictumst dignissim dis dolor donec dui duis egestas eget eleifend\nelementum elit enim erat eros est et etiam eu euismod facilisi facilisis fames\nfaucibus felis fermentum feugiat fringilla fusce gravida habitant habitasse hac\nhendrerit hymenaeos iaculis id imperdiet in inceptos integer interdum ipsum\njusto lacinia lacus laoreet lectus leo libero ligula litora lobortis lorem\nluctus maecenas magna magnis malesuada massa mattis mauris metus mi molestie\nmollis montes morbi mus nam nascetur natoque nec neque netus nibh nisi nisl non\nnonummy nostra nulla nullam nunc odio orci ornare parturient pede pellentesque\npenatibus per pharetra phasellus placerat platea porta porttitor posuere\npotenti praesent pretium primis proin pulvinar purus quam quis quisque rhoncus\nridiculus risus rutrum sagittis sapien scelerisque sed sem semper senectus sit\nsociis sociosqu sodales sollicitudin suscipit suspendisse taciti tellus tempor\ntempus tincidunt torquent tortor tristique turpis ullamcorper ultrices\nultricies urna ut varius vehicula vel velit venenatis vestibulum vitae vivamus\nviverra volutpat vulputate\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\debug.py": {
      "sha": "528a0dde0433",
      "lines": 191,
      "head": "import sys\nimport typing as t\nfrom types import CodeType\nfrom types import TracebackType\n\nfrom .exceptions import TemplateSyntaxError\nfrom .utils import internal_code\nfrom .utils import missing\n\nif t.TYPE_CHECKING:\n    from .runtime import Context\n\n\ndef rewrite_traceback_stack(source: t.Optional[str] = None) -> BaseException:\n    \"\"\"Rewrite the current exception to replace any tracebacks from\n    within compiled template code with tracebacks that look like they\n    came from the template source.\n\n    This must be called within an ``except`` block.\n\n    :param source: For ``TemplateSyntaxError``, the original source if\n        known.\n    :return: The original exception with the rewritten traceback.\n    \"\"\"\n    _, exc_value, tb = sys.exc_info()\n    exc_value = t.cast(BaseException, exc_value)\n    tb = t.cast(TracebackType, tb)\n\n    if isinstance(exc_value, TemplateSyntaxError) and not exc_value.translated:\n        exc_value.translated = True\n        exc_value.source = source\n        # Remove the old traceback, otherwise the frames from the\n        # compiler still show up.\n        exc_value.with_traceback(None)\n        # Outside of runtime, so the frame isn't executing template\n        # code, but it still needs to point at the template.\n        tb = fake_traceback(\n            exc_value, None, exc_value.filename or \"<unknown>\", exc_value.lineno\n        )\n    else:\n        # Skip the frame for the render function.\n        tb = tb.tb_next\n\n    stack = []\n\n    # Build the stack of traceback object, replacing any in template\n    # code with the source file and line information.\n    while tb is not None:\n        # Skip frames decorated with @internalcode. These are internal\n        # calls that aren't useful in template debugging output.\n        if tb.tb_frame.f_code in internal_code:\n            tb = tb.tb_next\n            continue\n\n        template = tb.tb_frame.f_globals.get(\"__jinja_template__\")\n\n        if template is not None:\n            lineno = template.get_corresponding_lineno(tb.tb_lineno)\n            fake_tb = fake_traceback(exc_value, tb, template.filename, lineno)\n            stack.append(fake_tb)\n        else:\n            stack.append(tb)\n\n        tb = tb.tb_next\n\n    tb_next = None\n\n    # Assign tb_next in reverse to avoid circular references.\n    for tb in reversed(stack):\n        tb.tb_next = tb_next\n        tb_next = tb\n\n    return exc_value.with_traceback(tb_next)\n\n\ndef fake_traceback(  # type: ignore\n    exc_value: BaseException, tb: t.Optional[TracebackType], filename: str, lineno: int\n) -> TracebackType:\n    \"\"\"Produce a new traceback object that looks like it came from the\n    template source instead of the compiled code. The filename, line\n    number, and location name will point to the template, and the local\n    variables will be the current template context.\n\n    :param exc_value: The original exception to be re-raised to create\n        the new traceback.\n    :param tb: The original traceback to get the local variables and\n        code info from.\n    :param filename: The template filename.\n    :param lineno: The line number in the template source.\n    \"\"\"\n    if tb is not None:\n        # Replace the real locals with the context that would be\n        # available at that point in the template.\n        locals = get_template_locals(tb.tb_frame.f_locals)\n        locals.pop(\"__jinja_exception__\", None)\n    else:\n        locals = {}\n\n    globals = {\n        \"__name__\": filename,\n        \"__file__\": filename,\n        \"__jinja_exception__\": exc_value,\n    }\n    # Raise an exception at the correct line number.\n    code: CodeType = compile(\n        \"\\n\" * (lineno - 1) + \"raise __jinja_exception__\", filename, \"exec\"\n    )\n\n    # Build a new code object that points to the template file and\n    # replaces the location with a block name.\n    location = \"template\"\n\n    if tb is not None:\n        function = tb.tb_frame.f_code.co_name\n\n        if function == \"root\":\n            location = \"top-level template code\"\n        elif function.startswith(\"block_\"):\n            location = f\"block {function[6:]!r}\"\n\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\defaults.py": {
      "sha": "33c803c94828",
      "lines": 48,
      "head": "import typing as t\n\nfrom .filters import FILTERS as DEFAULT_FILTERS  # noqa: F401\nfrom .tests import TESTS as DEFAULT_TESTS  # noqa: F401\nfrom .utils import Cycler\nfrom .utils import generate_lorem_ipsum\nfrom .utils import Joiner\nfrom .utils import Namespace\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n# defaults for the parser / lexer\nBLOCK_START_STRING = \"{%\"\nBLOCK_END_STRING = \"%}\"\nVARIABLE_START_STRING = \"{{\"\nVARIABLE_END_STRING = \"}}\"\nCOMMENT_START_STRING = \"{#\"\nCOMMENT_END_STRING = \"#}\"\nLINE_STATEMENT_PREFIX: t.Optional[str] = None\nLINE_COMMENT_PREFIX: t.Optional[str] = None\nTRIM_BLOCKS = False\nLSTRIP_BLOCKS = False\nNEWLINE_SEQUENCE: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = \"\\n\"\nKEEP_TRAILING_NEWLINE = False\n\n# default filters, tests and namespace\n\nDEFAULT_NAMESPACE = {\n    \"range\": range,\n    \"dict\": dict,\n    \"lipsum\": generate_lorem_ipsum,\n    \"cycler\": Cycler,\n    \"joiner\": Joiner,\n    \"namespace\": Namespace,\n}\n\n# default policies\nDEFAULT_POLICIES: t.Dict[str, t.Any] = {\n    \"compiler.ascii_str\": True,\n    \"urlize.rel\": \"noopener\",\n    \"urlize.target\": None,\n    \"urlize.extra_schemes\": None,\n    \"truncate.leeway\": 5,\n    \"json.dumps_function\": None,\n    \"json.dumps_kwargs\": {\"sort_keys\": True},\n    \"ext.i18n.trimmed\": False,\n}\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\environment.py": {
      "sha": "df489a1b8583",
      "lines": 1672,
      "head": "\"\"\"Classes for managing templates and their runtime and compile time\noptions.\n\"\"\"\n\nimport os\nimport typing\nimport typing as t\nimport weakref\nfrom collections import ChainMap\nfrom functools import lru_cache\nfrom functools import partial\nfrom functools import reduce\nfrom types import CodeType\n\nfrom markupsafe import Markup\n\nfrom . import nodes\nfrom .compiler import CodeGenerator\nfrom .compiler import generate\nfrom .defaults import BLOCK_END_STRING\nfrom .defaults import BLOCK_START_STRING\nfrom .defaults import COMMENT_END_STRING\nfrom .defaults import COMMENT_START_STRING\nfrom .defaults import DEFAULT_FILTERS  # type: ignore[attr-defined]\nfrom .defaults import DEFAULT_NAMESPACE\nfrom .defaults import DEFAULT_POLICIES\nfrom .defaults import DEFAULT_TESTS  # type: ignore[attr-defined]\nfrom .defaults import KEEP_TRAILING_NEWLINE\nfrom .defaults import LINE_COMMENT_PREFIX\nfrom .defaults import LINE_STATEMENT_PREFIX\nfrom .defaults import LSTRIP_BLOCKS\nfrom .defaults import NEWLINE_SEQUENCE\nfrom .defaults import TRIM_BLOCKS\nfrom .defaults import VARIABLE_END_STRING\nfrom .defaults import VARIABLE_START_STRING\nfrom .exceptions import TemplateNotFound\nfrom .exceptions import TemplateRuntimeError\nfrom .exceptions import TemplatesNotFound\nfrom .exceptions import TemplateSyntaxError\nfrom .exceptions import UndefinedError\nfrom .lexer import get_lexer\nfrom .lexer import Lexer\nfrom .lexer import TokenStream\nfrom .nodes import EvalContext\nfrom .parser import Parser\nfrom .runtime import Context\nfrom .runtime import new_context\nfrom .runtime import Undefined\nfrom .utils import _PassArg\nfrom .utils import concat\nfrom .utils import consume\nfrom .utils import import_string\nfrom .utils import internalcode\nfrom .utils import LRUCache\nfrom .utils import missing\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .bccache import BytecodeCache\n    from .ext import Extension\n    from .loaders import BaseLoader\n\n_env_bound = t.TypeVar(\"_env_bound\", bound=\"Environment\")\n\n\n# for direct template usage we have up to ten living environments\n@lru_cache(maxsize=10)\ndef get_spontaneous_environment(cls: t.Type[_env_bound], *args: t.Any) -> _env_bound:\n    \"\"\"Return a new spontaneous environment. A spontaneous environment\n    is used for templates created directly rather than through an\n    existing environment.\n\n    :param cls: Environment class to create.\n    :param args: Positional arguments passed to environment.\n    \"\"\"\n    env = cls(*args)\n    env.shared = True\n    return env\n\n\ndef create_cache(\n    size: int,\n) -> t.Optional[t.MutableMapping[t.Tuple[\"weakref.ref[t.Any]\", str], \"Template\"]]:\n    \"\"\"Return the cache class for the given size.\"\"\"\n    if size == 0:\n        return None\n\n    if size < 0:\n        return {}\n\n    return LRUCache(size)  # type: ignore\n\n\ndef copy_cache(\n    cache: t.Optional[t.MutableMapping[t.Any, t.Any]],\n) -> t.Optional[t.MutableMapping[t.Tuple[\"weakref.ref[t.Any]\", str], \"Template\"]]:\n    \"\"\"Create an empty copy of the given cache.\"\"\"\n    if cache is None:\n        return None\n\n    if type(cache) is dict:  # noqa E721\n        return {}\n\n    return LRUCache(cache.capacity)  # type: ignore\n\n\ndef load_extensions(\n    environment: \"Environment\",\n    extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]],\n) -> t.Dict[str, \"Extension\"]:\n    \"\"\"Load the extensions from the list and bind it to the environment.\n    Returns a dict of instantiated extensions.\n    \"\"\"\n    result = {}\n\n    for extension in extensions:\n        if isinstance(extension, str):\n            extension = t.cast(t.Type[\"Extension\"], import_string(extension))\n\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\exceptions.py": {
      "sha": "dcc4a315066a",
      "lines": 166,
      "head": "import typing as t\n\nif t.TYPE_CHECKING:\n    from .runtime import Undefined\n\n\nclass TemplateError(Exception):\n    \"\"\"Baseclass for all template errors.\"\"\"\n\n    def __init__(self, message: t.Optional[str] = None) -> None:\n        super().__init__(message)\n\n    @property\n    def message(self) -> t.Optional[str]:\n        return self.args[0] if self.args else None\n\n\nclass TemplateNotFound(IOError, LookupError, TemplateError):\n    \"\"\"Raised if a template does not exist.\n\n    .. versionchanged:: 2.11\n        If the given name is :class:`Undefined` and no message was\n        provided, an :exc:`UndefinedError` is raised.\n    \"\"\"\n\n    # Silence the Python warning about message being deprecated since\n    # it's not valid here.\n    message: t.Optional[str] = None\n\n    def __init__(\n        self,\n        name: t.Optional[t.Union[str, \"Undefined\"]],\n        message: t.Optional[str] = None,\n    ) -> None:\n        IOError.__init__(self, name)\n\n        if message is None:\n            from .runtime import Undefined\n\n            if isinstance(name, Undefined):\n                name._fail_with_undefined_error()\n\n            message = name\n\n        self.message = message\n        self.name = name\n        self.templates = [name]\n\n    def __str__(self) -> str:\n        return str(self.message)\n\n\nclass TemplatesNotFound(TemplateNotFound):\n    \"\"\"Like :class:`TemplateNotFound` but raised if multiple templates\n    are selected.  This is a subclass of :class:`TemplateNotFound`\n    exception, so just catching the base exception will catch both.\n\n    .. versionchanged:: 2.11\n        If a name in the list of names is :class:`Undefined`, a message\n        about it being undefined is shown rather than the empty string.\n\n    .. versionadded:: 2.2\n    \"\"\"\n\n    def __init__(\n        self,\n        names: t.Sequence[t.Union[str, \"Undefined\"]] = (),\n        message: t.Optional[str] = None,\n    ) -> None:\n        if message is None:\n            from .runtime import Undefined\n\n            parts = []\n\n            for name in names:\n                if isinstance(name, Undefined):\n                    parts.append(name._undefined_message)\n                else:\n                    parts.append(name)\n\n            parts_str = \", \".join(map(str, parts))\n            message = f\"none of the templates given were found: {parts_str}\"\n\n        super().__init__(names[-1] if names else None, message)\n        self.templates = list(names)\n\n\nclass TemplateSyntaxError(TemplateError):\n    \"\"\"Raised to tell the user that there is a problem with the template.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        lineno: int,\n        name: t.Optional[str] = None,\n        filename: t.Optional[str] = None,\n    ) -> None:\n        super().__init__(message)\n        self.lineno = lineno\n        self.name = name\n        self.filename = filename\n        self.source: t.Optional[str] = None\n\n        # this is set to True if the debug.translate_syntax_error\n        # function translated the syntax error into a new traceback\n        self.translated = False\n\n    def __str__(self) -> str:\n        # for translated errors we only return the message\n        if self.translated:\n            return t.cast(str, self.message)\n\n        # otherwise attach some stuff\n        location = f\"line {self.lineno}\"\n        name = self.filename or self.name\n        if name:\n            location = f'File \"{name}\", {location}'\n        lines = [t.cast(str, self.message), \"  \" + location]\n\n        # if the source is set, add the line to the output\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\ext.py": {
      "sha": "1877575d1a80",
      "lines": 870,
      "head": "\"\"\"Extension API for adding custom tags and behavior.\"\"\"\n\nimport pprint\nimport re\nimport typing as t\n\nfrom markupsafe import Markup\n\nfrom . import defaults\nfrom . import nodes\nfrom .environment import Environment\nfrom .exceptions import TemplateAssertionError\nfrom .exceptions import TemplateSyntaxError\nfrom .runtime import concat  # type: ignore\nfrom .runtime import Context\nfrom .runtime import Undefined\nfrom .utils import import_string\nfrom .utils import pass_context\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .lexer import Token\n    from .lexer import TokenStream\n    from .parser import Parser\n\n    class _TranslationsBasic(te.Protocol):\n        def gettext(self, message: str) -> str: ...\n\n        def ngettext(self, singular: str, plural: str, n: int) -> str:\n            pass\n\n    class _TranslationsContext(_TranslationsBasic):\n        def pgettext(self, context: str, message: str) -> str: ...\n\n        def npgettext(\n            self, context: str, singular: str, plural: str, n: int\n        ) -> str: ...\n\n    _SupportedTranslations = t.Union[_TranslationsBasic, _TranslationsContext]\n\n\n# I18N functions available in Jinja templates. If the I18N library\n# provides ugettext, it will be assigned to gettext.\nGETTEXT_FUNCTIONS: t.Tuple[str, ...] = (\n    \"_\",\n    \"gettext\",\n    \"ngettext\",\n    \"pgettext\",\n    \"npgettext\",\n)\n_ws_re = re.compile(r\"\\s*\\n\\s*\")\n\n\nclass Extension:\n    \"\"\"Extensions can be used to add extra functionality to the Jinja template\n    system at the parser level.  Custom extensions are bound to an environment\n    but may not store environment specific data on `self`.  The reason for\n    this is that an extension can be bound to another environment (for\n    overlays) by creating a copy and reassigning the `environment` attribute.\n\n    As extensions are created by the environment they cannot accept any\n    arguments for configuration.  One may want to work around that by using\n    a factory function, but that is not possible as extensions are identified\n    by their import name.  The correct way to configure the extension is\n    storing the configuration values on the environment.  Because this way the\n    environment ends up acting as central configuration storage the\n    attributes may clash which is why extensions have to ensure that the names\n    they choose for configuration are not too generic.  ``prefix`` for example\n    is a terrible name, ``fragment_cache_prefix`` on the other hand is a good\n    name as includes the name of the extension (fragment cache).\n    \"\"\"\n\n    identifier: t.ClassVar[str]\n\n    def __init_subclass__(cls) -> None:\n        cls.identifier = f\"{cls.__module__}.{cls.__name__}\"\n\n    #: if this extension parses this is the list of tags it's listening to.\n    tags: t.Set[str] = set()\n\n    #: the priority of that extension.  This is especially useful for\n    #: extensions that preprocess values.  A lower value means higher\n    #: priority.\n    #:\n    #: .. versionadded:: 2.4\n    priority = 100\n\n    def __init__(self, environment: Environment) -> None:\n        self.environment = environment\n\n    def bind(self, environment: Environment) -> \"te.Self\":\n        \"\"\"Create a copy of this extension bound to another environment.\"\"\"\n        rv = object.__new__(self.__class__)\n        rv.__dict__.update(self.__dict__)\n        rv.environment = environment\n        return rv\n\n    def preprocess(\n        self, source: str, name: t.Optional[str], filename: t.Optional[str] = None\n    ) -> str:\n        \"\"\"This method is called before the actual lexing and can be used to\n        preprocess the source.  The `filename` is optional.  The return value\n        must be the preprocessed source.\n        \"\"\"\n        return source\n\n    def filter_stream(\n        self, stream: \"TokenStream\"\n    ) -> t.Union[\"TokenStream\", t.Iterable[\"Token\"]]:\n        \"\"\"It's passed a :class:`~jinja2.lexer.TokenStream` that can be used\n        to filter tokens returned.  This method has to return an iterable of\n        :class:`~jinja2.lexer.Token`\\\\s, but it doesn't have to return a\n        :class:`~jinja2.lexer.TokenStream`.\n        \"\"\"\n        return stream\n\n    def parse(self, parser: \"Parser\") -> t.Union[nodes.Node, t.List[nodes.Node]]:\n        \"\"\"If any of the :attr:`tags` matched this method is called with the\n        parser as first argument.  The token the parser stream is pointing at\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\filters.py": {
      "sha": "43ccd078892a",
      "lines": 1873,
      "head": "\"\"\"Built-in template filters used with the ``|`` operator.\"\"\"\n\nimport math\nimport random\nimport re\nimport typing\nimport typing as t\nfrom collections import abc\nfrom inspect import getattr_static\nfrom itertools import chain\nfrom itertools import groupby\n\nfrom markupsafe import escape\nfrom markupsafe import Markup\nfrom markupsafe import soft_str\n\nfrom .async_utils import async_variant\nfrom .async_utils import auto_aiter\nfrom .async_utils import auto_await\nfrom .async_utils import auto_to_list\nfrom .exceptions import FilterArgumentError\nfrom .runtime import Undefined\nfrom .utils import htmlsafe_json_dumps\nfrom .utils import pass_context\nfrom .utils import pass_environment\nfrom .utils import pass_eval_context\nfrom .utils import pformat\nfrom .utils import url_quote\nfrom .utils import urlize\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .environment import Environment\n    from .nodes import EvalContext\n    from .runtime import Context\n    from .sandbox import SandboxedEnvironment  # noqa: F401\n\n    class HasHTML(te.Protocol):\n        def __html__(self) -> str:\n            pass\n\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\nK = t.TypeVar(\"K\")\nV = t.TypeVar(\"V\")\n\n\ndef ignore_case(value: V) -> V:\n    \"\"\"For use as a postprocessor for :func:`make_attrgetter`. Converts strings\n    to lowercase and returns other types as-is.\"\"\"\n    if isinstance(value, str):\n        return t.cast(V, value.lower())\n\n    return value\n\n\ndef make_attrgetter(\n    environment: \"Environment\",\n    attribute: t.Optional[t.Union[str, int]],\n    postprocess: t.Optional[t.Callable[[t.Any], t.Any]] = None,\n    default: t.Optional[t.Any] = None,\n) -> t.Callable[[t.Any], t.Any]:\n    \"\"\"Returns a callable that looks up the given attribute from a\n    passed object with the rules of the environment.  Dots are allowed\n    to access attributes of attributes.  Integer parts in paths are\n    looked up as integers.\n    \"\"\"\n    parts = _prepare_attribute_parts(attribute)\n\n    def attrgetter(item: t.Any) -> t.Any:\n        for part in parts:\n            item = environment.getitem(item, part)\n\n            if default is not None and isinstance(item, Undefined):\n                item = default\n\n        if postprocess is not None:\n            item = postprocess(item)\n\n        return item\n\n    return attrgetter\n\n\ndef make_multi_attrgetter(\n    environment: \"Environment\",\n    attribute: t.Optional[t.Union[str, int]],\n    postprocess: t.Optional[t.Callable[[t.Any], t.Any]] = None,\n) -> t.Callable[[t.Any], t.List[t.Any]]:\n    \"\"\"Returns a callable that looks up the given comma separated\n    attributes from a passed object with the rules of the environment.\n    Dots are allowed to access attributes of each attribute.  Integer\n    parts in paths are looked up as integers.\n\n    The value returned by the returned callable is a list of extracted\n    attribute values.\n\n    Examples of attribute: \"attr1,attr2\", \"attr1.inner1.0,attr2.inner2.0\", etc.\n    \"\"\"\n    if isinstance(attribute, str):\n        split: t.Sequence[t.Union[str, int, None]] = attribute.split(\",\")\n    else:\n        split = [attribute]\n\n    parts = [_prepare_attribute_parts(item) for item in split]\n\n    def attrgetter(item: t.Any) -> t.List[t.Any]:\n        items = [None] * len(parts)\n\n        for i, attribute_part in enumerate(parts):\n            item_i = item\n\n            for part in attribute_part:\n                item_i = environment.getitem(item_i, part)\n\n            if postprocess is not None:\n                item_i = postprocess(item_i)\n\n            items[i] = item_i\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\idtracking.py": {
      "sha": "36fd256b7485",
      "lines": 318,
      "head": "import typing as t\n\nfrom . import nodes\nfrom .visitor import NodeVisitor\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\nVAR_LOAD_PARAMETER = \"param\"\nVAR_LOAD_RESOLVE = \"resolve\"\nVAR_LOAD_ALIAS = \"alias\"\nVAR_LOAD_UNDEFINED = \"undefined\"\n\n\ndef find_symbols(\n    nodes: t.Iterable[nodes.Node], parent_symbols: t.Optional[\"Symbols\"] = None\n) -> \"Symbols\":\n    sym = Symbols(parent=parent_symbols)\n    visitor = FrameSymbolVisitor(sym)\n    for node in nodes:\n        visitor.visit(node)\n    return sym\n\n\ndef symbols_for_node(\n    node: nodes.Node, parent_symbols: t.Optional[\"Symbols\"] = None\n) -> \"Symbols\":\n    sym = Symbols(parent=parent_symbols)\n    sym.analyze_node(node)\n    return sym\n\n\nclass Symbols:\n    def __init__(\n        self, parent: t.Optional[\"Symbols\"] = None, level: t.Optional[int] = None\n    ) -> None:\n        if level is None:\n            if parent is None:\n                level = 0\n            else:\n                level = parent.level + 1\n\n        self.level: int = level\n        self.parent = parent\n        self.refs: t.Dict[str, str] = {}\n        self.loads: t.Dict[str, t.Any] = {}\n        self.stores: t.Set[str] = set()\n\n    def analyze_node(self, node: nodes.Node, **kwargs: t.Any) -> None:\n        visitor = RootVisitor(self)\n        visitor.visit(node, **kwargs)\n\n    def _define_ref(\n        self, name: str, load: t.Optional[t.Tuple[str, t.Optional[str]]] = None\n    ) -> str:\n        ident = f\"l_{self.level}_{name}\"\n        self.refs[name] = ident\n        if load is not None:\n            self.loads[ident] = load\n        return ident\n\n    def find_load(self, target: str) -> t.Optional[t.Any]:\n        if target in self.loads:\n            return self.loads[target]\n\n        if self.parent is not None:\n            return self.parent.find_load(target)\n\n        return None\n\n    def find_ref(self, name: str) -> t.Optional[str]:\n        if name in self.refs:\n            return self.refs[name]\n\n        if self.parent is not None:\n            return self.parent.find_ref(name)\n\n        return None\n\n    def ref(self, name: str) -> str:\n        rv = self.find_ref(name)\n        if rv is None:\n            raise AssertionError(\n                \"Tried to resolve a name to a reference that was\"\n                f\" unknown to the frame ({name!r})\"\n            )\n        return rv\n\n    def copy(self) -> \"te.Self\":\n        rv = object.__new__(self.__class__)\n        rv.__dict__.update(self.__dict__)\n        rv.refs = self.refs.copy()\n        rv.loads = self.loads.copy()\n        rv.stores = self.stores.copy()\n        return rv\n\n    def store(self, name: str) -> None:\n        self.stores.add(name)\n\n        # If we have not see the name referenced yet, we need to figure\n        # out what to set it to.\n        if name not in self.refs:\n            # If there is a parent scope we check if the name has a\n            # reference there.  If it does it means we might have to alias\n            # to a variable there.\n            if self.parent is not None:\n                outer_ref = self.parent.find_ref(name)\n                if outer_ref is not None:\n                    self._define_ref(name, load=(VAR_LOAD_ALIAS, outer_ref))\n                    return\n\n            # Otherwise we can just set it to undefined.\n            self._define_ref(name, load=(VAR_LOAD_UNDEFINED, None))\n\n    def declare_parameter(self, name: str) -> str:\n        self.stores.add(name)\n        return self._define_ref(name, load=(VAR_LOAD_PARAMETER, None))\n\n    def load(self, name: str) -> None:\n        if self.find_ref(name) is None:\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\lexer.py": {
      "sha": "6fd3ef4a01be",
      "lines": 868,
      "head": "\"\"\"Implements a Jinja / Python combination lexer. The ``Lexer`` class\nis used to do some preprocessing. It filters out invalid operators like\nthe bitshift operators we don't allow in templates. It separates\ntemplate code and python code in expressions.\n\"\"\"\n\nimport re\nimport typing as t\nfrom ast import literal_eval\nfrom collections import deque\nfrom sys import intern\n\nfrom ._identifier import pattern as name_re\nfrom .exceptions import TemplateSyntaxError\nfrom .utils import LRUCache\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .environment import Environment\n\n# cache for the lexers. Exists in order to be able to have multiple\n# environments with the same lexer\n_lexer_cache: t.MutableMapping[t.Tuple, \"Lexer\"] = LRUCache(50)  # type: ignore\n\n# static regular expressions\nwhitespace_re = re.compile(r\"\\s+\")\nnewline_re = re.compile(r\"(\\r\\n|\\r|\\n)\")\nstring_re = re.compile(\n    r\"('([^'\\\\]*(?:\\\\.[^'\\\\]*)*)'\" r'|\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\")', re.S\n)\ninteger_re = re.compile(\n    r\"\"\"\n    (\n        0b(_?[0-1])+ # binary\n    |\n        0o(_?[0-7])+ # octal\n    |\n        0x(_?[\\da-f])+ # hex\n    |\n        [1-9](_?\\d)* # decimal\n    |\n        0(_?0)* # decimal zero\n    )\n    \"\"\",\n    re.IGNORECASE | re.VERBOSE,\n)\nfloat_re = re.compile(\n    r\"\"\"\n    (?<!\\.)  # doesn't start with a .\n    (\\d+_)*\\d+  # digits, possibly _ separated\n    (\n        (\\.(\\d+_)*\\d+)?  # optional fractional part\n        e[+\\-]?(\\d+_)*\\d+  # exponent part\n    |\n        \\.(\\d+_)*\\d+  # required fractional part\n    )\n    \"\"\",\n    re.IGNORECASE | re.VERBOSE,\n)\n\n# internal the tokens and keep references to them\nTOKEN_ADD = intern(\"add\")\nTOKEN_ASSIGN = intern(\"assign\")\nTOKEN_COLON = intern(\"colon\")\nTOKEN_COMMA = intern(\"comma\")\nTOKEN_DIV = intern(\"div\")\nTOKEN_DOT = intern(\"dot\")\nTOKEN_EQ = intern(\"eq\")\nTOKEN_FLOORDIV = intern(\"floordiv\")\nTOKEN_GT = intern(\"gt\")\nTOKEN_GTEQ = intern(\"gteq\")\nTOKEN_LBRACE = intern(\"lbrace\")\nTOKEN_LBRACKET = intern(\"lbracket\")\nTOKEN_LPAREN = intern(\"lparen\")\nTOKEN_LT = intern(\"lt\")\nTOKEN_LTEQ = intern(\"lteq\")\nTOKEN_MOD = intern(\"mod\")\nTOKEN_MUL = intern(\"mul\")\nTOKEN_NE = intern(\"ne\")\nTOKEN_PIPE = intern(\"pipe\")\nTOKEN_POW = intern(\"pow\")\nTOKEN_RBRACE = intern(\"rbrace\")\nTOKEN_RBRACKET = intern(\"rbracket\")\nTOKEN_RPAREN = intern(\"rparen\")\nTOKEN_SEMICOLON = intern(\"semicolon\")\nTOKEN_SUB = intern(\"sub\")\nTOKEN_TILDE = intern(\"tilde\")\nTOKEN_WHITESPACE = intern(\"whitespace\")\nTOKEN_FLOAT = intern(\"float\")\nTOKEN_INTEGER = intern(\"integer\")\nTOKEN_NAME = intern(\"name\")\nTOKEN_STRING = intern(\"string\")\nTOKEN_OPERATOR = intern(\"operator\")\nTOKEN_BLOCK_BEGIN = intern(\"block_begin\")\nTOKEN_BLOCK_END = intern(\"block_end\")\nTOKEN_VARIABLE_BEGIN = intern(\"variable_begin\")\nTOKEN_VARIABLE_END = intern(\"variable_end\")\nTOKEN_RAW_BEGIN = intern(\"raw_begin\")\nTOKEN_RAW_END = intern(\"raw_end\")\nTOKEN_COMMENT_BEGIN = intern(\"comment_begin\")\nTOKEN_COMMENT_END = intern(\"comment_end\")\nTOKEN_COMMENT = intern(\"comment\")\nTOKEN_LINESTATEMENT_BEGIN = intern(\"linestatement_begin\")\nTOKEN_LINESTATEMENT_END = intern(\"linestatement_end\")\nTOKEN_LINECOMMENT_BEGIN = intern(\"linecomment_begin\")\nTOKEN_LINECOMMENT_END = intern(\"linecomment_end\")\nTOKEN_LINECOMMENT = intern(\"linecomment\")\nTOKEN_DATA = intern(\"data\")\nTOKEN_INITIAL = intern(\"initial\")\nTOKEN_EOF = intern(\"eof\")\n\n# bind operators to token types\noperators = {\n    \"+\": TOKEN_ADD,\n    \"-\": TOKEN_SUB,\n    \"/\": TOKEN_DIV,\n    \"//\": TOKEN_FLOORDIV,\n    \"*\": TOKEN_MUL,\n    \"%\": TOKEN_MOD,\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\loaders.py": {
      "sha": "ea4f28ed559a",
      "lines": 693,
      "head": "\"\"\"API and implementations for loading templates from different data\nsources.\n\"\"\"\n\nimport importlib.util\nimport os\nimport posixpath\nimport sys\nimport typing as t\nimport weakref\nimport zipimport\nfrom collections import abc\nfrom hashlib import sha1\nfrom importlib import import_module\nfrom types import ModuleType\n\nfrom .exceptions import TemplateNotFound\nfrom .utils import internalcode\n\nif t.TYPE_CHECKING:\n    from .environment import Environment\n    from .environment import Template\n\n\ndef split_template_path(template: str) -> t.List[str]:\n    \"\"\"Split a path into segments and perform a sanity check.  If it detects\n    '..' in the path it will raise a `TemplateNotFound` error.\n    \"\"\"\n    pieces = []\n    for piece in template.split(\"/\"):\n        if (\n            os.path.sep in piece\n            or (os.path.altsep and os.path.altsep in piece)\n            or piece == os.path.pardir\n        ):\n            raise TemplateNotFound(template)\n        elif piece and piece != \".\":\n            pieces.append(piece)\n    return pieces\n\n\nclass BaseLoader:\n    \"\"\"Baseclass for all loaders.  Subclass this and override `get_source` to\n    implement a custom loading mechanism.  The environment provides a\n    `get_template` method that calls the loader's `load` method to get the\n    :class:`Template` object.\n\n    A very basic example for a loader that looks up templates on the file\n    system could look like this::\n\n        from jinja2 import BaseLoader, TemplateNotFound\n        from os.path import join, exists, getmtime\n\n        class MyLoader(BaseLoader):\n\n            def __init__(self, path):\n                self.path = path\n\n            def get_source(self, environment, template):\n                path = join(self.path, template)\n                if not exists(path):\n                    raise TemplateNotFound(template)\n                mtime = getmtime(path)\n                with open(path) as f:\n                    source = f.read()\n                return source, path, lambda: mtime == getmtime(path)\n    \"\"\"\n\n    #: if set to `False` it indicates that the loader cannot provide access\n    #: to the source of templates.\n    #:\n    #: .. versionadded:: 2.4\n    has_source_access = True\n\n    def get_source(\n        self, environment: \"Environment\", template: str\n    ) -> t.Tuple[str, t.Optional[str], t.Optional[t.Callable[[], bool]]]:\n        \"\"\"Get the template source, filename and reload helper for a template.\n        It's passed the environment and template name and has to return a\n        tuple in the form ``(source, filename, uptodate)`` or raise a\n        `TemplateNotFound` error if it can't locate the template.\n\n        The source part of the returned tuple must be the source of the\n        template as a string. The filename should be the name of the\n        file on the filesystem if it was loaded from there, otherwise\n        ``None``. The filename is used by Python for the tracebacks\n        if no loader extension is used.\n\n        The last item in the tuple is the `uptodate` function.  If auto\n        reloading is enabled it's always called to check if the template\n        changed.  No arguments are passed so the function must store the\n        old state somewhere (for example in a closure).  If it returns `False`\n        the template will be reloaded.\n        \"\"\"\n        if not self.has_source_access:\n            raise RuntimeError(\n                f\"{type(self).__name__} cannot provide access to the source\"\n            )\n        raise TemplateNotFound(template)\n\n    def list_templates(self) -> t.List[str]:\n        \"\"\"Iterates over all templates.  If the loader does not support that\n        it should raise a :exc:`TypeError` which is the default behavior.\n        \"\"\"\n        raise TypeError(\"this loader cannot iterate over all templates\")\n\n    @internalcode\n    def load(\n        self,\n        environment: \"Environment\",\n        name: str,\n        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n    ) -> \"Template\":\n        \"\"\"Loads a template.  This method looks up the template in the cache\n        or loads one by calling :meth:`get_source`.  Subclasses should not\n        override this method as loaders working on collections of other\n        loaders (such as :class:`PrefixLoader` or :class:`ChoiceLoader`)\n        will not call this method but `get_source` directly.\n        \"\"\"\n        code = None\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\meta.py": {
      "sha": "655b180706d0",
      "lines": 112,
      "head": "\"\"\"Functions that expose information about templates that might be\ninteresting for introspection.\n\"\"\"\n\nimport typing as t\n\nfrom . import nodes\nfrom .compiler import CodeGenerator\nfrom .compiler import Frame\n\nif t.TYPE_CHECKING:\n    from .environment import Environment\n\n\nclass TrackingCodeGenerator(CodeGenerator):\n    \"\"\"We abuse the code generator for introspection.\"\"\"\n\n    def __init__(self, environment: \"Environment\") -> None:\n        super().__init__(environment, \"<introspection>\", \"<introspection>\")\n        self.undeclared_identifiers: t.Set[str] = set()\n\n    def write(self, x: str) -> None:\n        \"\"\"Don't write.\"\"\"\n\n    def enter_frame(self, frame: Frame) -> None:\n        \"\"\"Remember all undeclared identifiers.\"\"\"\n        super().enter_frame(frame)\n\n        for _, (action, param) in frame.symbols.loads.items():\n            if action == \"resolve\" and param not in self.environment.globals:\n                self.undeclared_identifiers.add(param)\n\n\ndef find_undeclared_variables(ast: nodes.Template) -> t.Set[str]:\n    \"\"\"Returns a set of all variables in the AST that will be looked up from\n    the context at runtime.  Because at compile time it's not known which\n    variables will be used depending on the path the execution takes at\n    runtime, all variables are returned.\n\n    >>> from jinja2 import Environment, meta\n    >>> env = Environment()\n    >>> ast = env.parse('{% set foo = 42 %}{{ bar + foo }}')\n    >>> meta.find_undeclared_variables(ast) == {'bar'}\n    True\n\n    .. admonition:: Implementation\n\n       Internally the code generator is used for finding undeclared variables.\n       This is good to know because the code generator might raise a\n       :exc:`TemplateAssertionError` during compilation and as a matter of\n       fact this function can currently raise that exception as well.\n    \"\"\"\n    codegen = TrackingCodeGenerator(ast.environment)  # type: ignore\n    codegen.visit(ast)\n    return codegen.undeclared_identifiers\n\n\n_ref_types = (nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include)\n_RefType = t.Union[nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include]\n\n\ndef find_referenced_templates(ast: nodes.Template) -> t.Iterator[t.Optional[str]]:\n    \"\"\"Finds all the referenced templates from the AST.  This will return an\n    iterator over all the hardcoded template extensions, inclusions and\n    imports.  If dynamic inheritance or inclusion is used, `None` will be\n    yielded.\n\n    >>> from jinja2 import Environment, meta\n    >>> env = Environment()\n    >>> ast = env.parse('{% extends \"layout.html\" %}{% include helper %}')\n    >>> list(meta.find_referenced_templates(ast))\n    ['layout.html', None]\n\n    This function is useful for dependency tracking.  For example if you want\n    to rebuild parts of the website after a layout template has changed.\n    \"\"\"\n    template_name: t.Any\n\n    for node in ast.find_all(_ref_types):\n        template: nodes.Expr = node.template  # type: ignore\n\n        if not isinstance(template, nodes.Const):\n            # a tuple with some non consts in there\n            if isinstance(template, (nodes.Tuple, nodes.List)):\n                for template_name in template.items:\n                    # something const, only yield the strings and ignore\n                    # non-string consts that really just make no sense\n                    if isinstance(template_name, nodes.Const):\n                        if isinstance(template_name.value, str):\n                            yield template_name.value\n                    # something dynamic in there\n                    else:\n                        yield None\n            # something dynamic we don't know about here\n            else:\n                yield None\n            continue\n        # constant is a basestring, direct template name\n        if isinstance(template.value, str):\n            yield template.value\n        # a tuple or list (latter *should* not happen) made of consts,\n        # yield the consts that are strings.  We could warn here for\n        # non string values\n        elif isinstance(node, nodes.Include) and isinstance(\n            template.value, (tuple, list)\n        ):\n            for template_name in template.value:\n                if isinstance(template_name, str):\n                    yield template_name\n        # something else we don't care about, we could warn here\n        else:\n            yield None\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\nativetypes.py": {
      "sha": "e08b3aaf4645",
      "lines": 130,
      "head": "import typing as t\nfrom ast import literal_eval\nfrom ast import parse\nfrom itertools import chain\nfrom itertools import islice\nfrom types import GeneratorType\n\nfrom . import nodes\nfrom .compiler import CodeGenerator\nfrom .compiler import Frame\nfrom .compiler import has_safe_repr\nfrom .environment import Environment\nfrom .environment import Template\n\n\ndef native_concat(values: t.Iterable[t.Any]) -> t.Optional[t.Any]:\n    \"\"\"Return a native Python type from the list of compiled nodes. If\n    the result is a single node, its value is returned. Otherwise, the\n    nodes are concatenated as strings. If the result can be parsed with\n    :func:`ast.literal_eval`, the parsed value is returned. Otherwise,\n    the string is returned.\n\n    :param values: Iterable of outputs to concatenate.\n    \"\"\"\n    head = list(islice(values, 2))\n\n    if not head:\n        return None\n\n    if len(head) == 1:\n        raw = head[0]\n        if not isinstance(raw, str):\n            return raw\n    else:\n        if isinstance(values, GeneratorType):\n            values = chain(head, values)\n        raw = \"\".join([str(v) for v in values])\n\n    try:\n        return literal_eval(\n            # In Python 3.10+ ast.literal_eval removes leading spaces/tabs\n            # from the given string. For backwards compatibility we need to\n            # parse the string ourselves without removing leading spaces/tabs.\n            parse(raw, mode=\"eval\")\n        )\n    except (ValueError, SyntaxError, MemoryError):\n        return raw\n\n\nclass NativeCodeGenerator(CodeGenerator):\n    \"\"\"A code generator which renders Python types by not adding\n    ``str()`` around output nodes.\n    \"\"\"\n\n    @staticmethod\n    def _default_finalize(value: t.Any) -> t.Any:\n        return value\n\n    def _output_const_repr(self, group: t.Iterable[t.Any]) -> str:\n        return repr(\"\".join([str(v) for v in group]))\n\n    def _output_child_to_const(\n        self, node: nodes.Expr, frame: Frame, finalize: CodeGenerator._FinalizeInfo\n    ) -> t.Any:\n        const = node.as_const(frame.eval_ctx)\n\n        if not has_safe_repr(const):\n            raise nodes.Impossible()\n\n        if isinstance(node, nodes.TemplateData):\n            return const\n\n        return finalize.const(const)  # type: ignore\n\n    def _output_child_pre(\n        self, node: nodes.Expr, frame: Frame, finalize: CodeGenerator._FinalizeInfo\n    ) -> None:\n        if finalize.src is not None:\n            self.write(finalize.src)\n\n    def _output_child_post(\n        self, node: nodes.Expr, frame: Frame, finalize: CodeGenerator._FinalizeInfo\n    ) -> None:\n        if finalize.src is not None:\n            self.write(\")\")\n\n\nclass NativeEnvironment(Environment):\n    \"\"\"An environment that renders templates to native Python types.\"\"\"\n\n    code_generator_class = NativeCodeGenerator\n    concat = staticmethod(native_concat)  # type: ignore\n\n\nclass NativeTemplate(Template):\n    environment_class = NativeEnvironment\n\n    def render(self, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        \"\"\"Render the template to produce a native Python type. If the\n        result is a single node, its value is returned. Otherwise, the\n        nodes are concatenated as strings. If the result can be parsed\n        with :func:`ast.literal_eval`, the parsed value is returned.\n        Otherwise, the string is returned.\n        \"\"\"\n        ctx = self.new_context(dict(*args, **kwargs))\n\n        try:\n            return self.environment_class.concat(  # type: ignore\n                self.root_render_func(ctx)\n            )\n        except Exception:\n            return self.environment.handle_exception()\n\n    async def render_async(self, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        if not self.environment.is_async:\n            raise RuntimeError(\n                \"The environment was not created with async mode enabled.\"\n            )\n\n        ctx = self.new_context(dict(*args, **kwargs))\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\nodes.py": {
      "sha": "b2d9f8a3c65b",
      "lines": 1206,
      "head": "\"\"\"AST nodes generated by the parser for the compiler. Also provides\nsome node tree helper functions used by the parser and compiler in order\nto normalize nodes.\n\"\"\"\n\nimport inspect\nimport operator\nimport typing as t\nfrom collections import deque\n\nfrom markupsafe import Markup\n\nfrom .utils import _PassArg\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .environment import Environment\n\n_NodeBound = t.TypeVar(\"_NodeBound\", bound=\"Node\")\n\n_binop_to_func: t.Dict[str, t.Callable[[t.Any, t.Any], t.Any]] = {\n    \"*\": operator.mul,\n    \"/\": operator.truediv,\n    \"//\": operator.floordiv,\n    \"**\": operator.pow,\n    \"%\": operator.mod,\n    \"+\": operator.add,\n    \"-\": operator.sub,\n}\n\n_uaop_to_func: t.Dict[str, t.Callable[[t.Any], t.Any]] = {\n    \"not\": operator.not_,\n    \"+\": operator.pos,\n    \"-\": operator.neg,\n}\n\n_cmpop_to_func: t.Dict[str, t.Callable[[t.Any, t.Any], t.Any]] = {\n    \"eq\": operator.eq,\n    \"ne\": operator.ne,\n    \"gt\": operator.gt,\n    \"gteq\": operator.ge,\n    \"lt\": operator.lt,\n    \"lteq\": operator.le,\n    \"in\": lambda a, b: a in b,\n    \"notin\": lambda a, b: a not in b,\n}\n\n\nclass Impossible(Exception):\n    \"\"\"Raised if the node could not perform a requested action.\"\"\"\n\n\nclass NodeType(type):\n    \"\"\"A metaclass for nodes that handles the field and attribute\n    inheritance.  fields and attributes from the parent class are\n    automatically forwarded to the child.\"\"\"\n\n    def __new__(mcs, name, bases, d):  # type: ignore\n        for attr in \"fields\", \"attributes\":\n            storage: t.List[t.Tuple[str, ...]] = []\n            storage.extend(getattr(bases[0] if bases else object, attr, ()))\n            storage.extend(d.get(attr, ()))\n            assert len(bases) <= 1, \"multiple inheritance not allowed\"\n            assert len(storage) == len(set(storage)), \"layout conflict\"\n            d[attr] = tuple(storage)\n        d.setdefault(\"abstract\", False)\n        return type.__new__(mcs, name, bases, d)\n\n\nclass EvalContext:\n    \"\"\"Holds evaluation time information.  Custom attributes can be attached\n    to it in extensions.\n    \"\"\"\n\n    def __init__(\n        self, environment: \"Environment\", template_name: t.Optional[str] = None\n    ) -> None:\n        self.environment = environment\n        if callable(environment.autoescape):\n            self.autoescape = environment.autoescape(template_name)\n        else:\n            self.autoescape = environment.autoescape\n        self.volatile = False\n\n    def save(self) -> t.Mapping[str, t.Any]:\n        return self.__dict__.copy()\n\n    def revert(self, old: t.Mapping[str, t.Any]) -> None:\n        self.__dict__.clear()\n        self.__dict__.update(old)\n\n\ndef get_eval_context(node: \"Node\", ctx: t.Optional[EvalContext]) -> EvalContext:\n    if ctx is None:\n        if node.environment is None:\n            raise RuntimeError(\n                \"if no eval context is passed, the node must have an\"\n                \" attached environment.\"\n            )\n        return EvalContext(node.environment)\n    return ctx\n\n\nclass Node(metaclass=NodeType):\n    \"\"\"Baseclass for all Jinja nodes.  There are a number of nodes available\n    of different types.  There are four major types:\n\n    -   :class:`Stmt`: statements\n    -   :class:`Expr`: expressions\n    -   :class:`Helper`: helper nodes\n    -   :class:`Template`: the outermost wrapper node\n\n    All nodes have fields and attributes.  Fields may be other nodes, lists,\n    or arbitrary values.  Fields are passed to the constructor as regular\n    positional arguments, attributes as keyword arguments.  Each node has\n    two attributes: `lineno` (the line number of the node) and `environment`.\n    The `environment` attribute is set at the end of the parsing process for\n    all nodes automatically.\n    \"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\optimizer.py": {
      "sha": "9d8182766f53",
      "lines": 48,
      "head": "\"\"\"The optimizer tries to constant fold expressions and modify the AST\nin place so that it should be faster to evaluate.\n\nBecause the AST does not contain all the scoping information and the\ncompiler has to find that out, we cannot do all the optimizations we\nwant. For example, loop unrolling doesn't work because unrolled loops\nwould have a different scope. The solution would be a second syntax tree\nthat stored the scoping rules.\n\"\"\"\n\nimport typing as t\n\nfrom . import nodes\nfrom .visitor import NodeTransformer\n\nif t.TYPE_CHECKING:\n    from .environment import Environment\n\n\ndef optimize(node: nodes.Node, environment: \"Environment\") -> nodes.Node:\n    \"\"\"The context hint can be used to perform an static optimization\n    based on the context given.\"\"\"\n    optimizer = Optimizer(environment)\n    return t.cast(nodes.Node, optimizer.visit(node))\n\n\nclass Optimizer(NodeTransformer):\n    def __init__(self, environment: \"t.Optional[Environment]\") -> None:\n        self.environment = environment\n\n    def generic_visit(\n        self, node: nodes.Node, *args: t.Any, **kwargs: t.Any\n    ) -> nodes.Node:\n        node = super().generic_visit(node, *args, **kwargs)\n\n        # Do constant folding. Some other nodes besides Expr have\n        # as_const, but folding them causes errors later on.\n        if isinstance(node, nodes.Expr):\n            try:\n                return nodes.Const.from_untrusted(\n                    node.as_const(args[0] if args else None),\n                    lineno=node.lineno,\n                    environment=self.environment,\n                )\n            except nodes.Impossible:\n                pass\n\n        return node\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\parser.py": {
      "sha": "a2dec10dae42",
      "lines": 1049,
      "head": "\"\"\"Parse tokens from the lexer into nodes for the compiler.\"\"\"\n\nimport typing\nimport typing as t\n\nfrom . import nodes\nfrom .exceptions import TemplateAssertionError\nfrom .exceptions import TemplateSyntaxError\nfrom .lexer import describe_token\nfrom .lexer import describe_token_expr\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .environment import Environment\n\n_ImportInclude = t.TypeVar(\"_ImportInclude\", nodes.Import, nodes.Include)\n_MacroCall = t.TypeVar(\"_MacroCall\", nodes.Macro, nodes.CallBlock)\n\n_statement_keywords = frozenset(\n    [\n        \"for\",\n        \"if\",\n        \"block\",\n        \"extends\",\n        \"print\",\n        \"macro\",\n        \"include\",\n        \"from\",\n        \"import\",\n        \"set\",\n        \"with\",\n        \"autoescape\",\n    ]\n)\n_compare_operators = frozenset([\"eq\", \"ne\", \"lt\", \"lteq\", \"gt\", \"gteq\"])\n\n_math_nodes: t.Dict[str, t.Type[nodes.Expr]] = {\n    \"add\": nodes.Add,\n    \"sub\": nodes.Sub,\n    \"mul\": nodes.Mul,\n    \"div\": nodes.Div,\n    \"floordiv\": nodes.FloorDiv,\n    \"mod\": nodes.Mod,\n}\n\n\nclass Parser:\n    \"\"\"This is the central parsing class Jinja uses.  It's passed to\n    extensions and can be used to parse expressions or statements.\n    \"\"\"\n\n    def __init__(\n        self,\n        environment: \"Environment\",\n        source: str,\n        name: t.Optional[str] = None,\n        filename: t.Optional[str] = None,\n        state: t.Optional[str] = None,\n    ) -> None:\n        self.environment = environment\n        self.stream = environment._tokenize(source, name, filename, state)\n        self.name = name\n        self.filename = filename\n        self.closed = False\n        self.extensions: t.Dict[\n            str, t.Callable[[Parser], t.Union[nodes.Node, t.List[nodes.Node]]]\n        ] = {}\n        for extension in environment.iter_extensions():\n            for tag in extension.tags:\n                self.extensions[tag] = extension.parse\n        self._last_identifier = 0\n        self._tag_stack: t.List[str] = []\n        self._end_token_stack: t.List[t.Tuple[str, ...]] = []\n\n    def fail(\n        self,\n        msg: str,\n        lineno: t.Optional[int] = None,\n        exc: t.Type[TemplateSyntaxError] = TemplateSyntaxError,\n    ) -> \"te.NoReturn\":\n        \"\"\"Convenience method that raises `exc` with the message, passed\n        line number or last line number as well as the current name and\n        filename.\n        \"\"\"\n        if lineno is None:\n            lineno = self.stream.current.lineno\n        raise exc(msg, lineno, self.name, self.filename)\n\n    def _fail_ut_eof(\n        self,\n        name: t.Optional[str],\n        end_token_stack: t.List[t.Tuple[str, ...]],\n        lineno: t.Optional[int],\n    ) -> \"te.NoReturn\":\n        expected: t.Set[str] = set()\n        for exprs in end_token_stack:\n            expected.update(map(describe_token_expr, exprs))\n        if end_token_stack:\n            currently_looking: t.Optional[str] = \" or \".join(\n                map(repr, map(describe_token_expr, end_token_stack[-1]))\n            )\n        else:\n            currently_looking = None\n\n        if name is None:\n            message = [\"Unexpected end of template.\"]\n        else:\n            message = [f\"Encountered unknown tag {name!r}.\"]\n\n        if currently_looking:\n            if name is not None and name in expected:\n                message.append(\n                    \"You probably made a nesting mistake. Jinja is expecting this tag,\"\n                    f\" but currently looking for {currently_looking}.\"\n                )\n            else:\n                message.append(\n                    f\"Jinja was looking for the following tags: {currently_looking}.\"\n                )\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\runtime.py": {
      "sha": "3cef3905608d",
      "lines": 1062,
      "head": "\"\"\"The runtime functions and state used by compiled templates.\"\"\"\n\nimport functools\nimport sys\nimport typing as t\nfrom collections import abc\nfrom itertools import chain\n\nfrom markupsafe import escape  # noqa: F401\nfrom markupsafe import Markup\nfrom markupsafe import soft_str\n\nfrom .async_utils import auto_aiter\nfrom .async_utils import auto_await  # noqa: F401\nfrom .exceptions import TemplateNotFound  # noqa: F401\nfrom .exceptions import TemplateRuntimeError  # noqa: F401\nfrom .exceptions import UndefinedError\nfrom .nodes import EvalContext\nfrom .utils import _PassArg\nfrom .utils import concat\nfrom .utils import internalcode\nfrom .utils import missing\nfrom .utils import Namespace  # noqa: F401\nfrom .utils import object_type_repr\nfrom .utils import pass_eval_context\n\nV = t.TypeVar(\"V\")\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\nif t.TYPE_CHECKING:\n    import logging\n\n    import typing_extensions as te\n\n    from .environment import Environment\n\n    class LoopRenderFunc(te.Protocol):\n        def __call__(\n            self,\n            reciter: t.Iterable[V],\n            loop_render_func: \"LoopRenderFunc\",\n            depth: int = 0,\n        ) -> str: ...\n\n\n# these variables are exported to the template runtime\nexported = [\n    \"LoopContext\",\n    \"TemplateReference\",\n    \"Macro\",\n    \"Markup\",\n    \"TemplateRuntimeError\",\n    \"missing\",\n    \"escape\",\n    \"markup_join\",\n    \"str_join\",\n    \"identity\",\n    \"TemplateNotFound\",\n    \"Namespace\",\n    \"Undefined\",\n    \"internalcode\",\n]\nasync_exported = [\n    \"AsyncLoopContext\",\n    \"auto_aiter\",\n    \"auto_await\",\n]\n\n\ndef identity(x: V) -> V:\n    \"\"\"Returns its argument. Useful for certain things in the\n    environment.\n    \"\"\"\n    return x\n\n\ndef markup_join(seq: t.Iterable[t.Any]) -> str:\n    \"\"\"Concatenation that escapes if necessary and converts to string.\"\"\"\n    buf = []\n    iterator = map(soft_str, seq)\n    for arg in iterator:\n        buf.append(arg)\n        if hasattr(arg, \"__html__\"):\n            return Markup(\"\").join(chain(buf, iterator))\n    return concat(buf)\n\n\ndef str_join(seq: t.Iterable[t.Any]) -> str:\n    \"\"\"Simple args to string conversion and concatenation.\"\"\"\n    return concat(map(str, seq))\n\n\ndef new_context(\n    environment: \"Environment\",\n    template_name: t.Optional[str],\n    blocks: t.Dict[str, t.Callable[[\"Context\"], t.Iterator[str]]],\n    vars: t.Optional[t.Dict[str, t.Any]] = None,\n    shared: bool = False,\n    globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n    locals: t.Optional[t.Mapping[str, t.Any]] = None,\n) -> \"Context\":\n    \"\"\"Internal helper for context creation.\"\"\"\n    if vars is None:\n        vars = {}\n    if shared:\n        parent = vars\n    else:\n        parent = dict(globals or (), **vars)\n    if locals:\n        # if the parent is shared a copy should be created because\n        # we don't want to modify the dict passed\n        if shared:\n            parent = dict(parent)\n        for key, value in locals.items():\n            if value is not missing:\n                parent[key] = value\n    return environment.context_class(\n        environment, parent, template_name, blocks, globals=globals\n    )\n\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\sandbox.py": {
      "sha": "40e9149d70eb",
      "lines": 436,
      "head": "\"\"\"A sandbox layer that ensures unsafe operations cannot be performed.\nUseful when the template itself comes from an untrusted source.\n\"\"\"\n\nimport operator\nimport types\nimport typing as t\nfrom _string import formatter_field_name_split  # type: ignore\nfrom collections import abc\nfrom collections import deque\nfrom functools import update_wrapper\nfrom string import Formatter\n\nfrom markupsafe import EscapeFormatter\nfrom markupsafe import Markup\n\nfrom .environment import Environment\nfrom .exceptions import SecurityError\nfrom .runtime import Context\nfrom .runtime import Undefined\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n#: maximum number of items a range may produce\nMAX_RANGE = 100000\n\n#: Unsafe function attributes.\nUNSAFE_FUNCTION_ATTRIBUTES: t.Set[str] = set()\n\n#: Unsafe method attributes. Function attributes are unsafe for methods too.\nUNSAFE_METHOD_ATTRIBUTES: t.Set[str] = set()\n\n#: unsafe generator attributes.\nUNSAFE_GENERATOR_ATTRIBUTES = {\"gi_frame\", \"gi_code\"}\n\n#: unsafe attributes on coroutines\nUNSAFE_COROUTINE_ATTRIBUTES = {\"cr_frame\", \"cr_code\"}\n\n#: unsafe attributes on async generators\nUNSAFE_ASYNC_GENERATOR_ATTRIBUTES = {\"ag_code\", \"ag_frame\"}\n\n_mutable_spec: t.Tuple[t.Tuple[t.Type[t.Any], t.FrozenSet[str]], ...] = (\n    (\n        abc.MutableSet,\n        frozenset(\n            [\n                \"add\",\n                \"clear\",\n                \"difference_update\",\n                \"discard\",\n                \"pop\",\n                \"remove\",\n                \"symmetric_difference_update\",\n                \"update\",\n            ]\n        ),\n    ),\n    (\n        abc.MutableMapping,\n        frozenset([\"clear\", \"pop\", \"popitem\", \"setdefault\", \"update\"]),\n    ),\n    (\n        abc.MutableSequence,\n        frozenset(\n            [\"append\", \"clear\", \"pop\", \"reverse\", \"insert\", \"sort\", \"extend\", \"remove\"]\n        ),\n    ),\n    (\n        deque,\n        frozenset(\n            [\n                \"append\",\n                \"appendleft\",\n                \"clear\",\n                \"extend\",\n                \"extendleft\",\n                \"pop\",\n                \"popleft\",\n                \"remove\",\n                \"rotate\",\n            ]\n        ),\n    ),\n)\n\n\ndef safe_range(*args: int) -> range:\n    \"\"\"A range that can't generate ranges with a length of more than\n    MAX_RANGE items.\n    \"\"\"\n    rng = range(*args)\n\n    if len(rng) > MAX_RANGE:\n        raise OverflowError(\n            \"Range too big. The sandbox blocks ranges larger than\"\n            f\" MAX_RANGE ({MAX_RANGE}).\"\n        )\n\n    return rng\n\n\ndef unsafe(f: F) -> F:\n    \"\"\"Marks a function or method as unsafe.\n\n    .. code-block: python\n\n        @unsafe\n        def delete(self):\n            pass\n    \"\"\"\n    f.unsafe_callable = True  # type: ignore\n    return f\n\n\ndef is_internal_attribute(obj: t.Any, attr: str) -> bool:\n    \"\"\"Test if the attribute given is an internal python attribute.  For\n    example this function returns `True` for the `func_code` attribute of\n    python objects.  This is useful if the environment method\n    :meth:`~SandboxedEnvironment.is_safe_attribute` is overridden.\n\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\tests.py": {
      "sha": "cc9cfd9778fb",
      "lines": 256,
      "head": "\"\"\"Built-in template tests used with the ``is`` operator.\"\"\"\n\nimport operator\nimport typing as t\nfrom collections import abc\nfrom numbers import Number\n\nfrom .runtime import Undefined\nfrom .utils import pass_environment\n\nif t.TYPE_CHECKING:\n    from .environment import Environment\n\n\ndef test_odd(value: int) -> bool:\n    \"\"\"Return true if the variable is odd.\"\"\"\n    return value % 2 == 1\n\n\ndef test_even(value: int) -> bool:\n    \"\"\"Return true if the variable is even.\"\"\"\n    return value % 2 == 0\n\n\ndef test_divisibleby(value: int, num: int) -> bool:\n    \"\"\"Check if a variable is divisible by a number.\"\"\"\n    return value % num == 0\n\n\ndef test_defined(value: t.Any) -> bool:\n    \"\"\"Return true if the variable is defined:\n\n    .. sourcecode:: jinja\n\n        {% if variable is defined %}\n            value of variable: {{ variable }}\n        {% else %}\n            variable is not defined\n        {% endif %}\n\n    See the :func:`default` filter for a simple way to set undefined\n    variables.\n    \"\"\"\n    return not isinstance(value, Undefined)\n\n\ndef test_undefined(value: t.Any) -> bool:\n    \"\"\"Like :func:`defined` but the other way round.\"\"\"\n    return isinstance(value, Undefined)\n\n\n@pass_environment\ndef test_filter(env: \"Environment\", value: str) -> bool:\n    \"\"\"Check if a filter exists by name. Useful if a filter may be\n    optionally available.\n\n    .. code-block:: jinja\n\n        {% if 'markdown' is filter %}\n            {{ value | markdown }}\n        {% else %}\n            {{ value }}\n        {% endif %}\n\n    .. versionadded:: 3.0\n    \"\"\"\n    return value in env.filters\n\n\n@pass_environment\ndef test_test(env: \"Environment\", value: str) -> bool:\n    \"\"\"Check if a test exists by name. Useful if a test may be\n    optionally available.\n\n    .. code-block:: jinja\n\n        {% if 'loud' is test %}\n            {% if value is loud %}\n                {{ value|upper }}\n            {% else %}\n                {{ value|lower }}\n            {% endif %}\n        {% else %}\n            {{ value }}\n        {% endif %}\n\n    .. versionadded:: 3.0\n    \"\"\"\n    return value in env.tests\n\n\ndef test_none(value: t.Any) -> bool:\n    \"\"\"Return true if the variable is none.\"\"\"\n    return value is None\n\n\ndef test_boolean(value: t.Any) -> bool:\n    \"\"\"Return true if the object is a boolean value.\n\n    .. versionadded:: 2.11\n    \"\"\"\n    return value is True or value is False\n\n\ndef test_false(value: t.Any) -> bool:\n    \"\"\"Return true if the object is False.\n\n    .. versionadded:: 2.11\n    \"\"\"\n    return value is False\n\n\ndef test_true(value: t.Any) -> bool:\n    \"\"\"Return true if the object is True.\n\n    .. versionadded:: 2.11\n    \"\"\"\n    return value is True\n\n\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\utils.py": {
      "sha": "299758301091",
      "lines": 766,
      "head": "import enum\nimport json\nimport os\nimport re\nimport typing as t\nfrom collections import abc\nfrom collections import deque\nfrom random import choice\nfrom random import randrange\nfrom threading import Lock\nfrom types import CodeType\nfrom urllib.parse import quote_from_bytes\n\nimport markupsafe\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\nclass _MissingType:\n    def __repr__(self) -> str:\n        return \"missing\"\n\n    def __reduce__(self) -> str:\n        return \"missing\"\n\n\nmissing: t.Any = _MissingType()\n\"\"\"Special singleton representing missing values for the runtime.\"\"\"\n\ninternal_code: t.MutableSet[CodeType] = set()\n\nconcat = \"\".join\n\n\ndef pass_context(f: F) -> F:\n    \"\"\"Pass the :class:`~jinja2.runtime.Context` as the first argument\n    to the decorated function when called while rendering a template.\n\n    Can be used on functions, filters, and tests.\n\n    If only ``Context.eval_context`` is needed, use\n    :func:`pass_eval_context`. If only ``Context.environment`` is\n    needed, use :func:`pass_environment`.\n\n    .. versionadded:: 3.0.0\n        Replaces ``contextfunction`` and ``contextfilter``.\n    \"\"\"\n    f.jinja_pass_arg = _PassArg.context  # type: ignore\n    return f\n\n\ndef pass_eval_context(f: F) -> F:\n    \"\"\"Pass the :class:`~jinja2.nodes.EvalContext` as the first argument\n    to the decorated function when called while rendering a template.\n    See :ref:`eval-context`.\n\n    Can be used on functions, filters, and tests.\n\n    If only ``EvalContext.environment`` is needed, use\n    :func:`pass_environment`.\n\n    .. versionadded:: 3.0.0\n        Replaces ``evalcontextfunction`` and ``evalcontextfilter``.\n    \"\"\"\n    f.jinja_pass_arg = _PassArg.eval_context  # type: ignore\n    return f\n\n\ndef pass_environment(f: F) -> F:\n    \"\"\"Pass the :class:`~jinja2.Environment` as the first argument to\n    the decorated function when called while rendering a template.\n\n    Can be used on functions, filters, and tests.\n\n    .. versionadded:: 3.0.0\n        Replaces ``environmentfunction`` and ``environmentfilter``.\n    \"\"\"\n    f.jinja_pass_arg = _PassArg.environment  # type: ignore\n    return f\n\n\nclass _PassArg(enum.Enum):\n    context = enum.auto()\n    eval_context = enum.auto()\n    environment = enum.auto()\n\n    @classmethod\n    def from_obj(cls, obj: F) -> t.Optional[\"_PassArg\"]:\n        if hasattr(obj, \"jinja_pass_arg\"):\n            return obj.jinja_pass_arg  # type: ignore\n\n        return None\n\n\ndef internalcode(f: F) -> F:\n    \"\"\"Marks the function as internally used\"\"\"\n    internal_code.add(f.__code__)\n    return f\n\n\ndef is_undefined(obj: t.Any) -> bool:\n    \"\"\"Check if the object passed is undefined.  This does nothing more than\n    performing an instance check against :class:`Undefined` but looks nicer.\n    This can be used for custom filters or tests that want to react to\n    undefined variables.  For example a custom default filter can look like\n    this::\n\n        def default(var, default=''):\n            if is_undefined(var):\n                return default\n            return var\n    \"\"\"\n    from .runtime import Undefined\n\n    return isinstance(obj, Undefined)\n\n\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\visitor.py": {
      "sha": "5f77dec07cd3",
      "lines": 92,
      "head": "\"\"\"API for traversing the AST nodes. Implemented by the compiler and\nmeta introspection.\n\"\"\"\n\nimport typing as t\n\nfrom .nodes import Node\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    class VisitCallable(te.Protocol):\n        def __call__(self, node: Node, *args: t.Any, **kwargs: t.Any) -> t.Any: ...\n\n\nclass NodeVisitor:\n    \"\"\"Walks the abstract syntax tree and call visitor functions for every\n    node found.  The visitor functions may return values which will be\n    forwarded by the `visit` method.\n\n    Per default the visitor functions for the nodes are ``'visit_'`` +\n    class name of the node.  So a `TryFinally` node visit function would\n    be `visit_TryFinally`.  This behavior can be changed by overriding\n    the `get_visitor` function.  If no visitor function exists for a node\n    (return value `None`) the `generic_visit` visitor is used instead.\n    \"\"\"\n\n    def get_visitor(self, node: Node) -> \"t.Optional[VisitCallable]\":\n        \"\"\"Return the visitor function for this node or `None` if no visitor\n        exists for this node.  In that case the generic visit function is\n        used instead.\n        \"\"\"\n        return getattr(self, f\"visit_{type(node).__name__}\", None)\n\n    def visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        \"\"\"Visit a node.\"\"\"\n        f = self.get_visitor(node)\n\n        if f is not None:\n            return f(node, *args, **kwargs)\n\n        return self.generic_visit(node, *args, **kwargs)\n\n    def generic_visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        \"\"\"Called if no explicit visitor function exists for a node.\"\"\"\n        for child_node in node.iter_child_nodes():\n            self.visit(child_node, *args, **kwargs)\n\n\nclass NodeTransformer(NodeVisitor):\n    \"\"\"Walks the abstract syntax tree and allows modifications of nodes.\n\n    The `NodeTransformer` will walk the AST and use the return value of the\n    visitor functions to replace or remove the old node.  If the return\n    value of the visitor function is `None` the node will be removed\n    from the previous location otherwise it's replaced with the return\n    value.  The return value may be the original node in which case no\n    replacement takes place.\n    \"\"\"\n\n    def generic_visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -> Node:\n        for field, old_value in node.iter_fields():\n            if isinstance(old_value, list):\n                new_values = []\n                for value in old_value:\n                    if isinstance(value, Node):\n                        value = self.visit(value, *args, **kwargs)\n                        if value is None:\n                            continue\n                        elif not isinstance(value, Node):\n                            new_values.extend(value)\n                            continue\n                    new_values.append(value)\n                old_value[:] = new_values\n            elif isinstance(old_value, Node):\n                new_node = self.visit(old_value, *args, **kwargs)\n                if new_node is None:\n                    delattr(node, field)\n                else:\n                    setattr(node, field, new_node)\n        return node\n\n    def visit_list(self, node: Node, *args: t.Any, **kwargs: t.Any) -> t.List[Node]:\n        \"\"\"As transformers may return lists in some places this method\n        can be used to enforce a list as return value.\n        \"\"\"\n        rv = self.visit(node, *args, **kwargs)\n\n        if not isinstance(rv, list):\n            return [rv]\n\n        return rv\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\_identifier.py": {
      "sha": "7350c0318a19",
      "lines": 6,
      "head": "import re\n\n# generated by scripts/generate_identifier_pattern.py\npattern = re.compile(\n    r\"[\\w\u00b7\u0300-\u036f\u0387\u0483-\u0487\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065f\u0670\u06d6-\u06dc\u06df-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u07fd\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0859-\u085b\u08d3-\u08e1\u08e3-\u0903\u093a-\u093c\u093e-\u094f\u0951-\u0957\u0962\u0963\u0981-\u0983\u09bc\u09be-\u09c4\u09c7\u09c8\u09cb-\u09cd\u09d7\u09e2\u09e3\u09fe\u0a01-\u0a03\u0a3c\u0a3e-\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81-\u0a83\u0abc\u0abe-\u0ac5\u0ac7-\u0ac9\u0acb-\u0acd\u0ae2\u0ae3\u0afa-\u0aff\u0b01-\u0b03\u0b3c\u0b3e-\u0b44\u0b47\u0b48\u0b4b-\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe-\u0bc2\u0bc6-\u0bc8\u0bca-\u0bcd\u0bd7\u0c00-\u0c04\u0c3e-\u0c44\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0c81-\u0c83\u0cbc\u0cbe-\u0cc4\u0cc6-\u0cc8\u0cca-\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d00-\u0d03\u0d3b\u0d3c\u0d3e-\u0d44\u0d46-\u0d48\u0d4a-\u0d4d\u0d57\u0d62\u0d63\u0d82\u0d83\u0dca\u0dcf-\u0dd4\u0dd6\u0dd8-\u0ddf\u0df2\u0df3\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f3e\u0f3f\u0f71-\u0f84\u0f86\u0f87\u0f8d-\u0f97\u0f99-\u0fbc\u0fc6\u102b-\u103e\u1056-\u1059\u105e-\u1060\u1062-\u1064\u1067-\u106d\u1071-\u1074\u1082-\u108d\u108f\u109a-\u109d\u135d-\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b4-\u17d3\u17dd\u180b-\u180d\u1885\u1886\u18a9\u1920-\u192b\u1930-\u193b\u1a17-\u1a1b\u1a55-\u1a5e\u1a60-\u1a7c\u1a7f\u1ab0-\u1abd\u1b00-\u1b04\u1b34-\u1b44\u1b6b-\u1b73\u1b80-\u1b82\u1ba1-\u1bad\u1be6-\u1bf3\u1c24-\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce8\u1ced\u1cf2-\u1cf4\u1cf7-\u1cf9\u1dc0-\u1df9\u1dfb-\u1dff\u203f\u2040\u2054\u20d0-\u20dc\u20e1\u20e5-\u20f0\u2118\u212e\u2cef-\u2cf1\u2d7f\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f\ua674-\ua67d\ua69e\ua69f\ua6f0\ua6f1\ua802\ua806\ua80b\ua823-\ua827\ua880\ua881\ua8b4-\ua8c5\ua8e0-\ua8f1\ua8ff\ua926-\ua92d\ua947-\ua953\ua980-\ua983\ua9b3-\ua9c0\ua9e5\uaa29-\uaa36\uaa43\uaa4c\uaa4d\uaa7b-\uaa7d\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uaaeb-\uaaef\uaaf5\uaaf6\uabe3-\uabea\uabec\uabed\ufb1e\ufe00-\ufe0f\ufe20-\ufe2f\ufe33\ufe34\ufe4d-\ufe4f\uff3f\ud800\uddfd\ud800\udee0\ud800\udf76-\ud800\udf7a\ud802\ude01-\ud802\ude03\ud802\ude05\ud802\ude06\ud802\ude0c-\ud802\ude0f\ud802\ude38-\ud802\ude3a\ud802\ude3f\ud802\udee5\ud802\udee6\ud803\udd24-\ud803\udd27\ud803\udf46-\ud803\udf50\ud804\udc00-\ud804\udc02\ud804\udc38-\ud804\udc46\ud804\udc7f-\ud804\udc82\ud804\udcb0-\ud804\udcba\ud804\udd00-\ud804\udd02\ud804\udd27-\ud804\udd34\ud804\udd45\ud804\udd46\ud804\udd73\ud804\udd80-\ud804\udd82\ud804\uddb3-\ud804\uddc0\ud804\uddc9-\ud804\uddcc\ud804\ude2c-\ud804\ude37\ud804\ude3e\ud804\udedf-\ud804\udeea\ud804\udf00-\ud804\udf03\ud804\udf3b\ud804\udf3c\ud804\udf3e-\ud804\udf44\ud804\udf47\ud804\udf48\ud804\udf4b-\ud804\udf4d\ud804\udf57\ud804\udf62\ud804\udf63\ud804\udf66-\ud804\udf6c\ud804\udf70-\ud804\udf74\ud805\udc35-\ud805\udc46\ud805\udc5e\ud805\udcb0-\ud805\udcc3\ud805\uddaf-\ud805\uddb5\ud805\uddb8-\ud805\uddc0\ud805\udddc\ud805\udddd\ud805\ude30-\ud805\ude40\ud805\udeab-\ud805\udeb7\ud805\udf1d-\ud805\udf2b\ud806\udc2c-\ud806\udc3a\ud806\ude01-\ud806\ude0a\ud806\ude33-\ud806\ude39\ud806\ude3b-\ud806\ude3e\ud806\ude47\ud806\ude51-\ud806\ude5b\ud806\ude8a-\ud806\ude99\ud807\udc2f-\ud807\udc36\ud807\udc38-\ud807\udc3f\ud807\udc92-\ud807\udca7\ud807\udca9-\ud807\udcb6\ud807\udd31-\ud807\udd36\ud807\udd3a\ud807\udd3c\ud807\udd3d\ud807\udd3f-\ud807\udd45\ud807\udd47\ud807\udd8a-\ud807\udd8e\ud807\udd90\ud807\udd91\ud807\udd93-\ud807\udd97\ud807\udef3-\ud807\udef6\ud81a\udef0-\ud81a\udef4\ud81a\udf30-\ud81a\udf36\ud81b\udf51-\ud81b\udf7e\ud81b\udf8f-\ud81b\udf92\ud82f\udc9d\ud82f\udc9e\ud834\udd65-\ud834\udd69\ud834\udd6d-\ud834\udd72\ud834\udd7b-\ud834\udd82\ud834\udd85-\ud834\udd8b\ud834\uddaa-\ud834\uddad\ud834\ude42-\ud834\ude44\ud836\ude00-\ud836\ude36\ud836\ude3b-\ud836\ude6c\ud836\ude75\ud836\ude84\ud836\ude9b-\ud836\ude9f\ud836\udea1-\ud836\udeaf\ud838\udc00-\ud838\udc06\ud838\udc08-\ud838\udc18\ud838\udc1b-\ud838\udc21\ud838\udc23\ud838\udc24\ud838\udc26-\ud838\udc2a\ud83a\udcd0-\ud83a\udcd6\ud83a\udd44-\ud83a\udd4a\udb40\udd00-\udb40\uddef]+\"  # noqa: B950\n)\n"
    },
    ".venv\\Lib\\site-packages\\jinja2\\__init__.py": {
      "sha": "0c5c5e15615e",
      "lines": 38,
      "head": "\"\"\"Jinja is a template engine written in pure Python. It provides a\nnon-XML syntax that supports inline expressions and an optional\nsandboxed environment.\n\"\"\"\n\nfrom .bccache import BytecodeCache as BytecodeCache\nfrom .bccache import FileSystemBytecodeCache as FileSystemBytecodeCache\nfrom .bccache import MemcachedBytecodeCache as MemcachedBytecodeCache\nfrom .environment import Environment as Environment\nfrom .environment import Template as Template\nfrom .exceptions import TemplateAssertionError as TemplateAssertionError\nfrom .exceptions import TemplateError as TemplateError\nfrom .exceptions import TemplateNotFound as TemplateNotFound\nfrom .exceptions import TemplateRuntimeError as TemplateRuntimeError\nfrom .exceptions import TemplatesNotFound as TemplatesNotFound\nfrom .exceptions import TemplateSyntaxError as TemplateSyntaxError\nfrom .exceptions import UndefinedError as UndefinedError\nfrom .loaders import BaseLoader as BaseLoader\nfrom .loaders import ChoiceLoader as ChoiceLoader\nfrom .loaders import DictLoader as DictLoader\nfrom .loaders import FileSystemLoader as FileSystemLoader\nfrom .loaders import FunctionLoader as FunctionLoader\nfrom .loaders import ModuleLoader as ModuleLoader\nfrom .loaders import PackageLoader as PackageLoader\nfrom .loaders import PrefixLoader as PrefixLoader\nfrom .runtime import ChainableUndefined as ChainableUndefined\nfrom .runtime import DebugUndefined as DebugUndefined\nfrom .runtime import make_logging_undefined as make_logging_undefined\nfrom .runtime import StrictUndefined as StrictUndefined\nfrom .runtime import Undefined as Undefined\nfrom .utils import clear_caches as clear_caches\nfrom .utils import is_undefined as is_undefined\nfrom .utils import pass_context as pass_context\nfrom .utils import pass_environment as pass_environment\nfrom .utils import pass_eval_context as pass_eval_context\nfrom .utils import select_autoescape as select_autoescape\n\n__version__ = \"3.1.6\"\n"
    },
    ".venv\\Lib\\site-packages\\jinja2-3.1.6.dist-info\\entry_points.txt": {
      "sha": "40da89cecb87",
      "lines": 3,
      "head": "[babel.extractors]\njinja2=jinja2.ext:babel_extract[i18n]\n\n"
    },
    ".venv\\Lib\\site-packages\\jinja2-3.1.6.dist-info\\licenses\\LICENSE.txt": {
      "sha": "c4dbdbc12926",
      "lines": 28,
      "head": "Copyright 2007 Pallets\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n1.  Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n2.  Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\n3.  Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
    },
    ".venv\\Lib\\site-packages\\markupsafe\\_native.py": {
      "sha": "1df98dee68d7",
      "lines": 8,
      "head": "def _escape_inner(s: str, /) -> str:\n    return (\n        s.replace(\"&\", \"&amp;\")\n        .replace(\">\", \"&gt;\")\n        .replace(\"<\", \"&lt;\")\n        .replace(\"'\", \"&#39;\")\n        .replace('\"', \"&#34;\")\n    )\n"
    },
    ".venv\\Lib\\site-packages\\markupsafe\\__init__.py": {
      "sha": "05e3fc110c94",
      "lines": 395,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport string\nimport typing as t\n\ntry:\n    from ._speedups import _escape_inner\nexcept ImportError:\n    from ._native import _escape_inner\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n\nclass _HasHTML(t.Protocol):\n    def __html__(self, /) -> str: ...\n\n\nclass _TPEscape(t.Protocol):\n    def __call__(self, s: t.Any, /) -> Markup: ...\n\n\ndef escape(s: t.Any, /) -> Markup:\n    \"\"\"Replace the characters ``&``, ``<``, ``>``, ``'``, and ``\"`` in\n    the string with HTML-safe sequences. Use this if you need to display\n    text that might contain such characters in HTML.\n\n    If the object has an ``__html__`` method, it is called and the\n    return value is assumed to already be safe for HTML.\n\n    :param s: An object to be converted to a string and escaped.\n    :return: A :class:`Markup` string with the escaped text.\n    \"\"\"\n    # If the object is already a plain string, skip __html__ check and string\n    # conversion. This is the most common use case.\n    # Use type(s) instead of s.__class__ because a proxy object may be reporting\n    # the __class__ of the proxied value.\n    if type(s) is str:\n        return Markup(_escape_inner(s))\n\n    if hasattr(s, \"__html__\"):\n        return Markup(s.__html__())\n\n    return Markup(_escape_inner(str(s)))\n\n\ndef escape_silent(s: t.Any | None, /) -> Markup:\n    \"\"\"Like :func:`escape` but treats ``None`` as the empty string.\n    Useful with optional values, as otherwise you get the string\n    ``'None'`` when the value is ``None``.\n\n    >>> escape(None)\n    Markup('None')\n    >>> escape_silent(None)\n    Markup('')\n    \"\"\"\n    if s is None:\n        return Markup()\n\n    return escape(s)\n\n\ndef soft_str(s: t.Any, /) -> str:\n    \"\"\"Convert an object to a string if it isn't already. This preserves\n    a :class:`Markup` string rather than converting it back to a basic\n    string, so it will still be marked as safe and won't be escaped\n    again.\n\n    >>> value = escape(\"<User 1>\")\n    >>> value\n    Markup('&lt;User 1&gt;')\n    >>> escape(str(value))\n    Markup('&amp;lt;User 1&amp;gt;')\n    >>> escape(soft_str(value))\n    Markup('&lt;User 1&gt;')\n    \"\"\"\n    if not isinstance(s, str):\n        return str(s)\n\n    return s\n\n\nclass Markup(str):\n    \"\"\"A string that is ready to be safely inserted into an HTML or XML\n    document, either because it was escaped or because it was marked\n    safe.\n\n    Passing an object to the constructor converts it to text and wraps\n    it to mark it safe without escaping. To escape the text, use the\n    :meth:`escape` class method instead.\n\n    >>> Markup(\"Hello, <em>World</em>!\")\n    Markup('Hello, <em>World</em>!')\n    >>> Markup(42)\n    Markup('42')\n    >>> Markup.escape(\"Hello, <em>World</em>!\")\n    Markup('Hello &lt;em&gt;World&lt;/em&gt;!')\n\n    This implements the ``__html__()`` interface that some frameworks\n    use. Passing an object that implements ``__html__()`` will wrap the\n    output of that method, marking it safe.\n\n    >>> class Foo:\n    ...     def __html__(self):\n    ...         return '<a href=\"/foo\">foo</a>'\n    ...\n    >>> Markup(Foo())\n    Markup('<a href=\"/foo\">foo</a>')\n\n    This is a subclass of :class:`str`. It has the same methods, but\n    escapes their arguments and returns a ``Markup`` instance.\n\n    >>> Markup(\"<em>%s</em>\") % (\"foo & bar\",)\n    Markup('<em>foo &amp; bar</em>')\n    >>> Markup(\"<em>Hello</em> \") + \"<foo>\"\n    Markup('<em>Hello</em> &lt;foo&gt;')\n    \"\"\"\n\n    __slots__ = ()\n"
    },
    ".venv\\Lib\\site-packages\\MarkupSafe-3.0.2.dist-info\\LICENSE.txt": {
      "sha": "fc9c6859d601",
      "lines": 28,
      "head": "Copyright 2010 Pallets\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n1.  Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n2.  Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\n3.  Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
    },
    ".venv\\Lib\\site-packages\\MarkupSafe-3.0.2.dist-info\\top_level.txt": {
      "sha": "f53e3e1c5d96",
      "lines": 1,
      "head": "markupsafe\n"
    },
    ".venv\\Lib\\site-packages\\pip\\__init__.py": {
      "sha": "bbaf8f0cc416",
      "lines": 13,
      "head": "from typing import List, Optional\n\n__version__ = \"25.1.1\"\n\n\ndef main(args: Optional[List[str]] = None) -> int:\n    \"\"\"This is an internal API only meant for use by pip's own console scripts.\n\n    For additional details, see https://github.com/pypa/pip/issues/7498.\n    \"\"\"\n    from pip._internal.utils.entrypoints import _wrapper\n\n    return _wrapper(args)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\__main__.py": {
      "sha": "4f4087af34a5",
      "lines": 24,
      "head": "import os\nimport sys\n\n# Remove '' and current working directory from the first entry\n# of sys.path, if present to avoid using current directory\n# in pip commands check, freeze, install, list and show,\n# when invoked as python -m pip <command>\nif sys.path[0] in (\"\", os.getcwd()):\n    sys.path.pop(0)\n\n# If we are running from a wheel, add the wheel to sys.path\n# This allows the usage python pip-*.whl/pip install pip-*.whl\nif __package__ == \"\":\n    # __file__ is pip-*.whl/pip/__main__.py\n    # first dirname call strips of '/__main__.py', second strips off '/pip'\n    # Resulting path is the name of the wheel itself\n    # Add that to sys.path so we can import pip\n    path = os.path.dirname(os.path.dirname(__file__))\n    sys.path.insert(0, path)\n\nif __name__ == \"__main__\":\n    from pip._internal.cli.main import main as _main\n\n    sys.exit(_main())\n"
    },
    ".venv\\Lib\\site-packages\\pip\\__pip-runner__.py": {
      "sha": "0a363590f97d",
      "lines": 50,
      "head": "\"\"\"Execute exactly this copy of pip, within a different environment.\n\nThis file is named as it is, to ensure that this module can't be imported via\nan import statement.\n\"\"\"\n\n# /!\\ This version compatibility check section must be Python 2 compatible. /!\\\n\nimport sys\n\n# Copied from pyproject.toml\nPYTHON_REQUIRES = (3, 9)\n\n\ndef version_str(version):  # type: ignore\n    return \".\".join(str(v) for v in version)\n\n\nif sys.version_info[:2] < PYTHON_REQUIRES:\n    raise SystemExit(\n        \"This version of pip does not support python {} (requires >={}).\".format(\n            version_str(sys.version_info[:2]), version_str(PYTHON_REQUIRES)\n        )\n    )\n\n# From here on, we can use Python 3 features, but the syntax must remain\n# Python 2 compatible.\n\nimport runpy  # noqa: E402\nfrom importlib.machinery import PathFinder  # noqa: E402\nfrom os.path import dirname  # noqa: E402\n\nPIP_SOURCES_ROOT = dirname(dirname(__file__))\n\n\nclass PipImportRedirectingFinder:\n    @classmethod\n    def find_spec(self, fullname, path=None, target=None):  # type: ignore\n        if fullname != \"pip\":\n            return None\n\n        spec = PathFinder.find_spec(fullname, [PIP_SOURCES_ROOT], target)\n        assert spec, (PIP_SOURCES_ROOT, fullname)\n        return spec\n\n\nsys.meta_path.insert(0, PipImportRedirectingFinder())\n\nassert __name__ == \"__main__\", \"Cannot run __pip-runner__.py as a non-main module\"\nrunpy.run_module(\"pip\", run_name=\"__main__\", alter_sys=True)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\build_env.py": {
      "sha": "67638a71b3e2",
      "lines": 325,
      "head": "\"\"\"Build Environment used for isolation during sdist building\"\"\"\n\nimport logging\nimport os\nimport pathlib\nimport site\nimport sys\nimport textwrap\nfrom collections import OrderedDict\nfrom types import TracebackType\nfrom typing import TYPE_CHECKING, Iterable, List, Optional, Set, Tuple, Type, Union\n\nfrom pip._vendor.packaging.version import Version\n\nfrom pip import __file__ as pip_location\nfrom pip._internal.cli.spinners import open_spinner\nfrom pip._internal.locations import get_platlib, get_purelib, get_scheme\nfrom pip._internal.metadata import get_default_environment, get_environment\nfrom pip._internal.utils.logging import VERBOSE\nfrom pip._internal.utils.packaging import get_requirement\nfrom pip._internal.utils.subprocess import call_subprocess\nfrom pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds\n\nif TYPE_CHECKING:\n    from pip._internal.index.package_finder import PackageFinder\n\nlogger = logging.getLogger(__name__)\n\n\ndef _dedup(a: str, b: str) -> Union[Tuple[str], Tuple[str, str]]:\n    return (a, b) if a != b else (a,)\n\n\nclass _Prefix:\n    def __init__(self, path: str) -> None:\n        self.path = path\n        self.setup = False\n        scheme = get_scheme(\"\", prefix=path)\n        self.bin_dir = scheme.scripts\n        self.lib_dirs = _dedup(scheme.purelib, scheme.platlib)\n\n\ndef get_runnable_pip() -> str:\n    \"\"\"Get a file to pass to a Python executable, to run the currently-running pip.\n\n    This is used to run a pip subprocess, for installing requirements into the build\n    environment.\n    \"\"\"\n    source = pathlib.Path(pip_location).resolve().parent\n\n    if not source.is_dir():\n        # This would happen if someone is using pip from inside a zip file. In that\n        # case, we can use that directly.\n        return str(source)\n\n    return os.fsdecode(source / \"__pip-runner__.py\")\n\n\ndef _get_system_sitepackages() -> Set[str]:\n    \"\"\"Get system site packages\n\n    Usually from site.getsitepackages,\n    but fallback on `get_purelib()/get_platlib()` if unavailable\n    (e.g. in a virtualenv created by virtualenv<20)\n\n    Returns normalized set of strings.\n    \"\"\"\n    if hasattr(site, \"getsitepackages\"):\n        system_sites = site.getsitepackages()\n    else:\n        # virtualenv < 20 overwrites site.py without getsitepackages\n        # fallback on get_purelib/get_platlib.\n        # this is known to miss things, but shouldn't in the cases\n        # where getsitepackages() has been removed (inside a virtualenv)\n        system_sites = [get_purelib(), get_platlib()]\n    return {os.path.normcase(path) for path in system_sites}\n\n\nclass BuildEnvironment:\n    \"\"\"Creates and manages an isolated environment to install build deps\"\"\"\n\n    def __init__(self) -> None:\n        temp_dir = TempDirectory(kind=tempdir_kinds.BUILD_ENV, globally_managed=True)\n\n        self._prefixes = OrderedDict(\n            (name, _Prefix(os.path.join(temp_dir.path, name)))\n            for name in (\"normal\", \"overlay\")\n        )\n\n        self._bin_dirs: List[str] = []\n        self._lib_dirs: List[str] = []\n        for prefix in reversed(list(self._prefixes.values())):\n            self._bin_dirs.append(prefix.bin_dir)\n            self._lib_dirs.extend(prefix.lib_dirs)\n\n        # Customize site to:\n        # - ensure .pth files are honored\n        # - prevent access to system site packages\n        system_sites = _get_system_sitepackages()\n\n        self._site_dir = os.path.join(temp_dir.path, \"site\")\n        if not os.path.exists(self._site_dir):\n            os.mkdir(self._site_dir)\n        with open(\n            os.path.join(self._site_dir, \"sitecustomize.py\"), \"w\", encoding=\"utf-8\"\n        ) as fp:\n            fp.write(\n                textwrap.dedent(\n                    \"\"\"\n                import os, site, sys\n\n                # First, drop system-sites related paths.\n                original_sys_path = sys.path[:]\n                known_paths = set()\n                for path in {system_sites!r}:\n                    site.addsitedir(path, known_paths=known_paths)\n                system_paths = set(\n                    os.path.normcase(path)\n                    for path in sys.path[len(original_sys_path):]\n                )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cache.py": {
      "sha": "d657be43eae8",
      "lines": 289,
      "head": "\"\"\"Cache Management\"\"\"\n\nimport hashlib\nimport json\nimport logging\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\nfrom pip._vendor.packaging.tags import Tag, interpreter_name, interpreter_version\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.exceptions import InvalidWheelFilename\nfrom pip._internal.models.direct_url import DirectUrl\nfrom pip._internal.models.link import Link\nfrom pip._internal.models.wheel import Wheel\nfrom pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds\nfrom pip._internal.utils.urls import path_to_url\n\nlogger = logging.getLogger(__name__)\n\nORIGIN_JSON_NAME = \"origin.json\"\n\n\ndef _hash_dict(d: Dict[str, str]) -> str:\n    \"\"\"Return a stable sha224 of a dictionary.\"\"\"\n    s = json.dumps(d, sort_keys=True, separators=(\",\", \":\"), ensure_ascii=True)\n    return hashlib.sha224(s.encode(\"ascii\")).hexdigest()\n\n\nclass Cache:\n    \"\"\"An abstract class - provides cache directories for data from links\n\n    :param cache_dir: The root of the cache.\n    \"\"\"\n\n    def __init__(self, cache_dir: str) -> None:\n        super().__init__()\n        assert not cache_dir or os.path.isabs(cache_dir)\n        self.cache_dir = cache_dir or None\n\n    def _get_cache_path_parts(self, link: Link) -> List[str]:\n        \"\"\"Get parts of part that must be os.path.joined with cache_dir\"\"\"\n\n        # We want to generate an url to use as our cache key, we don't want to\n        # just reuse the URL because it might have other items in the fragment\n        # and we don't care about those.\n        key_parts = {\"url\": link.url_without_fragment}\n        if link.hash_name is not None and link.hash is not None:\n            key_parts[link.hash_name] = link.hash\n        if link.subdirectory_fragment:\n            key_parts[\"subdirectory\"] = link.subdirectory_fragment\n\n        # Include interpreter name, major and minor version in cache key\n        # to cope with ill-behaved sdists that build a different wheel\n        # depending on the python version their setup.py is being run on,\n        # and don't encode the difference in compatibility tags.\n        # https://github.com/pypa/pip/issues/7296\n        key_parts[\"interpreter_name\"] = interpreter_name()\n        key_parts[\"interpreter_version\"] = interpreter_version()\n\n        # Encode our key url with sha224, we'll use this because it has similar\n        # security properties to sha256, but with a shorter total output (and\n        # thus less secure). However the differences don't make a lot of\n        # difference for our use case here.\n        hashed = _hash_dict(key_parts)\n\n        # We want to nest the directories some to prevent having a ton of top\n        # level directories where we might run out of sub directories on some\n        # FS.\n        parts = [hashed[:2], hashed[2:4], hashed[4:6], hashed[6:]]\n\n        return parts\n\n    def _get_candidates(self, link: Link, canonical_package_name: str) -> List[Any]:\n        can_not_cache = not self.cache_dir or not canonical_package_name or not link\n        if can_not_cache:\n            return []\n\n        path = self.get_path_for_link(link)\n        if os.path.isdir(path):\n            return [(candidate, path) for candidate in os.listdir(path)]\n        return []\n\n    def get_path_for_link(self, link: Link) -> str:\n        \"\"\"Return a directory to store cached items in for link.\"\"\"\n        raise NotImplementedError()\n\n    def get(\n        self,\n        link: Link,\n        package_name: Optional[str],\n        supported_tags: List[Tag],\n    ) -> Link:\n        \"\"\"Returns a link to a cached item if it exists, otherwise returns the\n        passed link.\n        \"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWheelCache(Cache):\n    \"\"\"A cache of wheels for future installs.\"\"\"\n\n    def __init__(self, cache_dir: str) -> None:\n        super().__init__(cache_dir)\n\n    def get_path_for_link(self, link: Link) -> str:\n        \"\"\"Return a directory to store cached wheels for link\n\n        Because there are M wheels for any one sdist, we provide a directory\n        to cache them in, and then consult that directory when looking up\n        cache hits.\n\n        We only insert things into the cache if they have plausible version\n        numbers, so that we don't contaminate the cache with things that were\n        not unique. E.g. ./package might have dozens of installs done for it\n        and build a version of 0.0...and if we built and cached a wheel, we'd\n        end up using the same wheel even if the source has been edited.\n\n        :param link: The link of the sdist for which this will cache wheels.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\configuration.py": {
      "sha": "08dd42388222",
      "lines": 383,
      "head": "\"\"\"Configuration management setup\n\nSome terminology:\n- name\n  As written in config files.\n- value\n  Value associated with a name\n- key\n  Name combined with it's section (section.name)\n- variant\n  A single word describing where the configuration key-value pair came from\n\"\"\"\n\nimport configparser\nimport locale\nimport os\nimport sys\nfrom typing import Any, Dict, Iterable, List, NewType, Optional, Tuple\n\nfrom pip._internal.exceptions import (\n    ConfigurationError,\n    ConfigurationFileCouldNotBeLoaded,\n)\nfrom pip._internal.utils import appdirs\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.logging import getLogger\nfrom pip._internal.utils.misc import ensure_dir, enum\n\nRawConfigParser = configparser.RawConfigParser  # Shorthand\nKind = NewType(\"Kind\", str)\n\nCONFIG_BASENAME = \"pip.ini\" if WINDOWS else \"pip.conf\"\nENV_NAMES_IGNORED = \"version\", \"help\"\n\n# The kinds of configurations there are.\nkinds = enum(\n    USER=\"user\",  # User Specific\n    GLOBAL=\"global\",  # System Wide\n    SITE=\"site\",  # [Virtual] Environment Specific\n    ENV=\"env\",  # from PIP_CONFIG_FILE\n    ENV_VAR=\"env-var\",  # from Environment Variables\n)\nOVERRIDE_ORDER = kinds.GLOBAL, kinds.USER, kinds.SITE, kinds.ENV, kinds.ENV_VAR\nVALID_LOAD_ONLY = kinds.USER, kinds.GLOBAL, kinds.SITE\n\nlogger = getLogger(__name__)\n\n\n# NOTE: Maybe use the optionx attribute to normalize keynames.\ndef _normalize_name(name: str) -> str:\n    \"\"\"Make a name consistent regardless of source (environment or file)\"\"\"\n    name = name.lower().replace(\"_\", \"-\")\n    if name.startswith(\"--\"):\n        name = name[2:]  # only prefer long opts\n    return name\n\n\ndef _disassemble_key(name: str) -> List[str]:\n    if \".\" not in name:\n        error_message = (\n            \"Key does not contain dot separated section and key. \"\n            f\"Perhaps you wanted to use 'global.{name}' instead?\"\n        )\n        raise ConfigurationError(error_message)\n    return name.split(\".\", 1)\n\n\ndef get_configuration_files() -> Dict[Kind, List[str]]:\n    global_config_files = [\n        os.path.join(path, CONFIG_BASENAME) for path in appdirs.site_config_dirs(\"pip\")\n    ]\n\n    site_config_file = os.path.join(sys.prefix, CONFIG_BASENAME)\n    legacy_config_file = os.path.join(\n        os.path.expanduser(\"~\"),\n        \"pip\" if WINDOWS else \".pip\",\n        CONFIG_BASENAME,\n    )\n    new_config_file = os.path.join(appdirs.user_config_dir(\"pip\"), CONFIG_BASENAME)\n    return {\n        kinds.GLOBAL: global_config_files,\n        kinds.SITE: [site_config_file],\n        kinds.USER: [legacy_config_file, new_config_file],\n    }\n\n\nclass Configuration:\n    \"\"\"Handles management of configuration.\n\n    Provides an interface to accessing and managing configuration files.\n\n    This class converts provides an API that takes \"section.key-name\" style\n    keys and stores the value associated with it as \"key-name\" under the\n    section \"section\".\n\n    This allows for a clean interface wherein the both the section and the\n    key-name are preserved in an easy to manage form in the configuration files\n    and the data stored is also nice.\n    \"\"\"\n\n    def __init__(self, isolated: bool, load_only: Optional[Kind] = None) -> None:\n        super().__init__()\n\n        if load_only is not None and load_only not in VALID_LOAD_ONLY:\n            raise ConfigurationError(\n                \"Got invalid value for load_only - should be one of {}\".format(\n                    \", \".join(map(repr, VALID_LOAD_ONLY))\n                )\n            )\n        self.isolated = isolated\n        self.load_only = load_only\n\n        # Because we keep track of where we got the data from\n        self._parsers: Dict[Kind, List[Tuple[str, RawConfigParser]]] = {\n            variant: [] for variant in OVERRIDE_ORDER\n        }\n        self._config: Dict[Kind, Dict[str, Any]] = {\n            variant: {} for variant in OVERRIDE_ORDER\n        }\n        self._modified_parsers: List[Tuple[str, RawConfigParser]] = []\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\exceptions.py": {
      "sha": "b8c9d50b11ec",
      "lines": 862,
      "head": "\"\"\"Exceptions used throughout package.\n\nThis module MUST NOT try to import from anything within `pip._internal` to\noperate. This is expected to be importable from any/all files within the\nsubpackage and, thus, should not depend on them.\n\"\"\"\n\nimport configparser\nimport contextlib\nimport locale\nimport logging\nimport pathlib\nimport re\nimport sys\nfrom itertools import chain, groupby, repeat\nfrom typing import TYPE_CHECKING, Dict, Iterator, List, Literal, Optional, Union\n\nfrom pip._vendor.packaging.requirements import InvalidRequirement\nfrom pip._vendor.packaging.version import InvalidVersion\nfrom pip._vendor.rich.console import Console, ConsoleOptions, RenderResult\nfrom pip._vendor.rich.markup import escape\nfrom pip._vendor.rich.text import Text\n\nif TYPE_CHECKING:\n    from hashlib import _Hash\n\n    from pip._vendor.requests.models import Request, Response\n\n    from pip._internal.metadata import BaseDistribution\n    from pip._internal.models.link import Link\n    from pip._internal.req.req_install import InstallRequirement\n\nlogger = logging.getLogger(__name__)\n\n\n#\n# Scaffolding\n#\ndef _is_kebab_case(s: str) -> bool:\n    return re.match(r\"^[a-z]+(-[a-z]+)*$\", s) is not None\n\n\ndef _prefix_with_indent(\n    s: Union[Text, str],\n    console: Console,\n    *,\n    prefix: str,\n    indent: str,\n) -> Text:\n    if isinstance(s, Text):\n        text = s\n    else:\n        text = console.render_str(s)\n\n    return console.render_str(prefix, overflow=\"ignore\") + console.render_str(\n        f\"\\n{indent}\", overflow=\"ignore\"\n    ).join(text.split(allow_blank=True))\n\n\nclass PipError(Exception):\n    \"\"\"The base pip error.\"\"\"\n\n\nclass DiagnosticPipError(PipError):\n    \"\"\"An error, that presents diagnostic information to the user.\n\n    This contains a bunch of logic, to enable pretty presentation of our error\n    messages. Each error gets a unique reference. Each error can also include\n    additional context, a hint and/or a note -- which are presented with the\n    main error message in a consistent style.\n\n    This is adapted from the error output styling in `sphinx-theme-builder`.\n    \"\"\"\n\n    reference: str\n\n    def __init__(\n        self,\n        *,\n        kind: 'Literal[\"error\", \"warning\"]' = \"error\",\n        reference: Optional[str] = None,\n        message: Union[str, Text],\n        context: Optional[Union[str, Text]],\n        hint_stmt: Optional[Union[str, Text]],\n        note_stmt: Optional[Union[str, Text]] = None,\n        link: Optional[str] = None,\n    ) -> None:\n        # Ensure a proper reference is provided.\n        if reference is None:\n            assert hasattr(self, \"reference\"), \"error reference not provided!\"\n            reference = self.reference\n        assert _is_kebab_case(reference), \"error reference must be kebab-case!\"\n\n        self.kind = kind\n        self.reference = reference\n\n        self.message = message\n        self.context = context\n\n        self.note_stmt = note_stmt\n        self.hint_stmt = hint_stmt\n\n        self.link = link\n\n        super().__init__(f\"<{self.__class__.__name__}: {self.reference}>\")\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__}(\"\n            f\"reference={self.reference!r}, \"\n            f\"message={self.message!r}, \"\n            f\"context={self.context!r}, \"\n            f\"note_stmt={self.note_stmt!r}, \"\n            f\"hint_stmt={self.hint_stmt!r}\"\n            \")>\"\n        )\n\n    def __rich_console__(\n        self,\n        console: Console,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\main.py": {
      "sha": "442943cd1fa0",
      "lines": 12,
      "head": "from typing import List, Optional\n\n\ndef main(args: Optional[List[str]] = None) -> int:\n    \"\"\"This is preserved for old console scripts that may still be referencing\n    it.\n\n    For additional details, see https://github.com/pypa/pip/issues/7498.\n    \"\"\"\n    from pip._internal.utils.entrypoints import _wrapper\n\n    return _wrapper(args)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\pyproject.py": {
      "sha": "e4b375c5ef19",
      "lines": 185,
      "head": "import importlib.util\nimport os\nimport sys\nfrom collections import namedtuple\nfrom typing import Any, List, Optional\n\nif sys.version_info >= (3, 11):\n    import tomllib\nelse:\n    from pip._vendor import tomli as tomllib\n\nfrom pip._vendor.packaging.requirements import InvalidRequirement\n\nfrom pip._internal.exceptions import (\n    InstallationError,\n    InvalidPyProjectBuildRequires,\n    MissingPyProjectBuildRequires,\n)\nfrom pip._internal.utils.packaging import get_requirement\n\n\ndef _is_list_of_str(obj: Any) -> bool:\n    return isinstance(obj, list) and all(isinstance(item, str) for item in obj)\n\n\ndef make_pyproject_path(unpacked_source_directory: str) -> str:\n    return os.path.join(unpacked_source_directory, \"pyproject.toml\")\n\n\nBuildSystemDetails = namedtuple(\n    \"BuildSystemDetails\", [\"requires\", \"backend\", \"check\", \"backend_path\"]\n)\n\n\ndef load_pyproject_toml(\n    use_pep517: Optional[bool], pyproject_toml: str, setup_py: str, req_name: str\n) -> Optional[BuildSystemDetails]:\n    \"\"\"Load the pyproject.toml file.\n\n    Parameters:\n        use_pep517 - Has the user requested PEP 517 processing? None\n                     means the user hasn't explicitly specified.\n        pyproject_toml - Location of the project's pyproject.toml file\n        setup_py - Location of the project's setup.py file\n        req_name - The name of the requirement we're processing (for\n                   error reporting)\n\n    Returns:\n        None if we should use the legacy code path, otherwise a tuple\n        (\n            requirements from pyproject.toml,\n            name of PEP 517 backend,\n            requirements we should check are installed after setting\n                up the build environment\n            directory paths to import the backend from (backend-path),\n                relative to the project root.\n        )\n    \"\"\"\n    has_pyproject = os.path.isfile(pyproject_toml)\n    has_setup = os.path.isfile(setup_py)\n\n    if not has_pyproject and not has_setup:\n        raise InstallationError(\n            f\"{req_name} does not appear to be a Python project: \"\n            f\"neither 'setup.py' nor 'pyproject.toml' found.\"\n        )\n\n    if has_pyproject:\n        with open(pyproject_toml, encoding=\"utf-8\") as f:\n            pp_toml = tomllib.loads(f.read())\n        build_system = pp_toml.get(\"build-system\")\n    else:\n        build_system = None\n\n    # The following cases must use PEP 517\n    # We check for use_pep517 being non-None and falsy because that means\n    # the user explicitly requested --no-use-pep517.  The value 0 as\n    # opposed to False can occur when the value is provided via an\n    # environment variable or config file option (due to the quirk of\n    # strtobool() returning an integer in pip's configuration code).\n    if has_pyproject and not has_setup:\n        if use_pep517 is not None and not use_pep517:\n            raise InstallationError(\n                \"Disabling PEP 517 processing is invalid: \"\n                \"project does not have a setup.py\"\n            )\n        use_pep517 = True\n    elif build_system and \"build-backend\" in build_system:\n        if use_pep517 is not None and not use_pep517:\n            raise InstallationError(\n                \"Disabling PEP 517 processing is invalid: \"\n                \"project specifies a build backend of {} \"\n                \"in pyproject.toml\".format(build_system[\"build-backend\"])\n            )\n        use_pep517 = True\n\n    # If we haven't worked out whether to use PEP 517 yet,\n    # and the user hasn't explicitly stated a preference,\n    # we do so if the project has a pyproject.toml file\n    # or if we cannot import setuptools or wheels.\n\n    # We fallback to PEP 517 when without setuptools or without the wheel package,\n    # so setuptools can be installed as a default build backend.\n    # For more info see:\n    # https://discuss.python.org/t/pip-without-setuptools-could-the-experience-be-improved/11810/9\n    # https://github.com/pypa/pip/issues/8559\n    elif use_pep517 is None:\n        use_pep517 = (\n            has_pyproject\n            or not importlib.util.find_spec(\"setuptools\")\n            or not importlib.util.find_spec(\"wheel\")\n        )\n\n    # At this point, we know whether we're going to use PEP 517.\n    assert use_pep517 is not None\n\n    # If we're using the legacy code path, there is nothing further\n    # for us to do here.\n    if not use_pep517:\n        return None\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\self_outdated_check.py": {
      "sha": "7d3a637d66bc",
      "lines": 252,
      "head": "import datetime\nimport functools\nimport hashlib\nimport json\nimport logging\nimport optparse\nimport os.path\nimport sys\nfrom dataclasses import dataclass\nfrom typing import Any, Callable, Dict, Optional\n\nfrom pip._vendor.packaging.version import Version\nfrom pip._vendor.packaging.version import parse as parse_version\nfrom pip._vendor.rich.console import Group\nfrom pip._vendor.rich.markup import escape\nfrom pip._vendor.rich.text import Text\n\nfrom pip._internal.index.collector import LinkCollector\nfrom pip._internal.index.package_finder import PackageFinder\nfrom pip._internal.metadata import get_default_environment\nfrom pip._internal.models.selection_prefs import SelectionPreferences\nfrom pip._internal.network.session import PipSession\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.entrypoints import (\n    get_best_invocation_for_this_pip,\n    get_best_invocation_for_this_python,\n)\nfrom pip._internal.utils.filesystem import adjacent_tmp_file, check_path_owner, replace\nfrom pip._internal.utils.misc import (\n    ExternallyManagedEnvironment,\n    check_externally_managed,\n    ensure_dir,\n)\n\n_WEEK = datetime.timedelta(days=7)\n\nlogger = logging.getLogger(__name__)\n\n\ndef _get_statefile_name(key: str) -> str:\n    key_bytes = key.encode()\n    name = hashlib.sha224(key_bytes).hexdigest()\n    return name\n\n\ndef _convert_date(isodate: str) -> datetime.datetime:\n    \"\"\"Convert an ISO format string to a date.\n\n    Handles the format 2020-01-22T14:24:01Z (trailing Z)\n    which is not supported by older versions of fromisoformat.\n    \"\"\"\n    return datetime.datetime.fromisoformat(isodate.replace(\"Z\", \"+00:00\"))\n\n\nclass SelfCheckState:\n    def __init__(self, cache_dir: str) -> None:\n        self._state: Dict[str, Any] = {}\n        self._statefile_path = None\n\n        # Try to load the existing state\n        if cache_dir:\n            self._statefile_path = os.path.join(\n                cache_dir, \"selfcheck\", _get_statefile_name(self.key)\n            )\n            try:\n                with open(self._statefile_path, encoding=\"utf-8\") as statefile:\n                    self._state = json.load(statefile)\n            except (OSError, ValueError, KeyError):\n                # Explicitly suppressing exceptions, since we don't want to\n                # error out if the cache file is invalid.\n                pass\n\n    @property\n    def key(self) -> str:\n        return sys.prefix\n\n    def get(self, current_time: datetime.datetime) -> Optional[str]:\n        \"\"\"Check if we have a not-outdated version loaded already.\"\"\"\n        if not self._state:\n            return None\n\n        if \"last_check\" not in self._state:\n            return None\n\n        if \"pypi_version\" not in self._state:\n            return None\n\n        # Determine if we need to refresh the state\n        last_check = _convert_date(self._state[\"last_check\"])\n        time_since_last_check = current_time - last_check\n        if time_since_last_check > _WEEK:\n            return None\n\n        return self._state[\"pypi_version\"]\n\n    def set(self, pypi_version: str, current_time: datetime.datetime) -> None:\n        # If we do not have a path to cache in, don't bother saving.\n        if not self._statefile_path:\n            return\n\n        # Check to make sure that we own the directory\n        if not check_path_owner(os.path.dirname(self._statefile_path)):\n            return\n\n        # Now that we've ensured the directory is owned by this user, we'll go\n        # ahead and make sure that all our directories are created.\n        ensure_dir(os.path.dirname(self._statefile_path))\n\n        state = {\n            # Include the key so it's easy to tell which pip wrote the\n            # file.\n            \"key\": self.key,\n            \"last_check\": current_time.isoformat(),\n            \"pypi_version\": pypi_version,\n        }\n\n        text = json.dumps(state, sort_keys=True, separators=(\",\", \":\"))\n\n        with adjacent_tmp_file(self._statefile_path) as f:\n            f.write(text.encode())\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\wheel_builder.py": {
      "sha": "01623191358d",
      "lines": 332,
      "head": "\"\"\"Orchestrator for building wheels from InstallRequirements.\"\"\"\n\nimport logging\nimport os.path\nimport re\nimport shutil\nfrom typing import Iterable, List, Optional, Tuple\n\nfrom pip._vendor.packaging.utils import canonicalize_name, canonicalize_version\nfrom pip._vendor.packaging.version import InvalidVersion, Version\n\nfrom pip._internal.cache import WheelCache\nfrom pip._internal.exceptions import InvalidWheelFilename, UnsupportedWheel\nfrom pip._internal.metadata import FilesystemWheel, get_wheel_distribution\nfrom pip._internal.models.link import Link\nfrom pip._internal.models.wheel import Wheel\nfrom pip._internal.operations.build.wheel import build_wheel_pep517\nfrom pip._internal.operations.build.wheel_editable import build_wheel_editable\nfrom pip._internal.operations.build.wheel_legacy import build_wheel_legacy\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.utils.logging import indent_log\nfrom pip._internal.utils.misc import ensure_dir, hash_file\nfrom pip._internal.utils.setuptools_build import make_setuptools_clean_args\nfrom pip._internal.utils.subprocess import call_subprocess\nfrom pip._internal.utils.temp_dir import TempDirectory\nfrom pip._internal.utils.urls import path_to_url\nfrom pip._internal.vcs import vcs\n\nlogger = logging.getLogger(__name__)\n\n_egg_info_re = re.compile(r\"([a-z0-9_.]+)-([a-z0-9_.!+-]+)\", re.IGNORECASE)\n\nBuildResult = Tuple[List[InstallRequirement], List[InstallRequirement]]\n\n\ndef _contains_egg_info(s: str) -> bool:\n    \"\"\"Determine whether the string looks like an egg_info.\n\n    :param s: The string to parse. E.g. foo-2.1\n    \"\"\"\n    return bool(_egg_info_re.search(s))\n\n\ndef _should_build(\n    req: InstallRequirement,\n) -> bool:\n    \"\"\"Return whether an InstallRequirement should be built into a wheel.\"\"\"\n    assert not req.constraint\n\n    if req.is_wheel:\n        return False\n\n    assert req.source_dir\n\n    if req.editable:\n        # we only build PEP 660 editable requirements\n        return req.supports_pyproject_editable\n\n    return True\n\n\ndef should_build_for_install_command(\n    req: InstallRequirement,\n) -> bool:\n    return _should_build(req)\n\n\ndef _should_cache(\n    req: InstallRequirement,\n) -> Optional[bool]:\n    \"\"\"\n    Return whether a built InstallRequirement can be stored in the persistent\n    wheel cache, assuming the wheel cache is available, and _should_build()\n    has determined a wheel needs to be built.\n    \"\"\"\n    if req.editable or not req.source_dir:\n        # never cache editable requirements\n        return False\n\n    if req.link and req.link.is_vcs:\n        # VCS checkout. Do not cache\n        # unless it points to an immutable commit hash.\n        assert not req.editable\n        assert req.source_dir\n        vcs_backend = vcs.get_backend_for_scheme(req.link.scheme)\n        assert vcs_backend\n        if vcs_backend.is_immutable_rev_checkout(req.link.url, req.source_dir):\n            return True\n        return False\n\n    assert req.link\n    base, ext = req.link.splitext()\n    if _contains_egg_info(base):\n        return True\n\n    # Otherwise, do not cache.\n    return False\n\n\ndef _get_cache_dir(\n    req: InstallRequirement,\n    wheel_cache: WheelCache,\n) -> str:\n    \"\"\"Return the persistent or temporary cache directory where the built\n    wheel need to be stored.\n    \"\"\"\n    cache_available = bool(wheel_cache.cache_dir)\n    assert req.link\n    if cache_available and _should_cache(req):\n        cache_dir = wheel_cache.get_path_for_link(req.link)\n    else:\n        cache_dir = wheel_cache.get_ephem_path_for_link(req.link)\n    return cache_dir\n\n\ndef _verify_one(req: InstallRequirement, wheel_path: str) -> None:\n    canonical_name = canonicalize_name(req.name or \"\")\n    w = Wheel(os.path.basename(wheel_path))\n    if canonicalize_name(w.name) != canonical_name:\n        raise InvalidWheelFilename(\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\__init__.py": {
      "sha": "c693fd7c867f",
      "lines": 18,
      "head": "from typing import List, Optional\n\nfrom pip._internal.utils import _log\n\n# init_logging() must be called before any call to logging.getLogger()\n# which happens at import of most modules.\n_log.init_logging()\n\n\ndef main(args: Optional[List[str]] = None) -> int:\n    \"\"\"This is preserved for old console scripts that may still be referencing\n    it.\n\n    For additional details, see https://github.com/pypa/pip/issues/7498.\n    \"\"\"\n    from pip._internal.utils.entrypoints import _wrapper\n\n    return _wrapper(args)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\autocompletion.py": {
      "sha": "3ddb82c94376",
      "lines": 175,
      "head": "\"\"\"Logic that powers autocompletion installed by ``pip completion``.\"\"\"\n\nimport optparse\nimport os\nimport sys\nfrom itertools import chain\nfrom typing import Any, Iterable, List, Optional\n\nfrom pip._internal.cli.main_parser import create_main_parser\nfrom pip._internal.commands import commands_dict, create_command\nfrom pip._internal.metadata import get_default_environment\n\n\ndef autocomplete() -> None:\n    \"\"\"Entry Point for completion of main and subcommand options.\"\"\"\n    # Don't complete if user hasn't sourced bash_completion file.\n    if \"PIP_AUTO_COMPLETE\" not in os.environ:\n        return\n    # Don't complete if autocompletion environment variables\n    # are not present\n    if not os.environ.get(\"COMP_WORDS\") or not os.environ.get(\"COMP_CWORD\"):\n        return\n    cwords = os.environ[\"COMP_WORDS\"].split()[1:]\n    cword = int(os.environ[\"COMP_CWORD\"])\n    try:\n        current = cwords[cword - 1]\n    except IndexError:\n        current = \"\"\n\n    parser = create_main_parser()\n    subcommands = list(commands_dict)\n    options = []\n\n    # subcommand\n    subcommand_name: Optional[str] = None\n    for word in cwords:\n        if word in subcommands:\n            subcommand_name = word\n            break\n    # subcommand options\n    if subcommand_name is not None:\n        # special case: 'help' subcommand has no options\n        if subcommand_name == \"help\":\n            sys.exit(1)\n        # special case: list locally installed dists for show and uninstall\n        should_list_installed = not current.startswith(\"-\") and subcommand_name in [\n            \"show\",\n            \"uninstall\",\n        ]\n        if should_list_installed:\n            env = get_default_environment()\n            lc = current.lower()\n            installed = [\n                dist.canonical_name\n                for dist in env.iter_installed_distributions(local_only=True)\n                if dist.canonical_name.startswith(lc)\n                and dist.canonical_name not in cwords[1:]\n            ]\n            # if there are no dists installed, fall back to option completion\n            if installed:\n                for dist in installed:\n                    print(dist)\n                sys.exit(1)\n\n        should_list_installables = (\n            not current.startswith(\"-\") and subcommand_name == \"install\"\n        )\n        if should_list_installables:\n            for path in auto_complete_paths(current, \"path\"):\n                print(path)\n            sys.exit(1)\n\n        subcommand = create_command(subcommand_name)\n\n        for opt in subcommand.parser.option_list_all:\n            if opt.help != optparse.SUPPRESS_HELP:\n                options += [\n                    (opt_str, opt.nargs) for opt_str in opt._long_opts + opt._short_opts\n                ]\n\n        # filter out previously specified options from available options\n        prev_opts = [x.split(\"=\")[0] for x in cwords[1 : cword - 1]]\n        options = [(x, v) for (x, v) in options if x not in prev_opts]\n        # filter options by current input\n        options = [(k, v) for k, v in options if k.startswith(current)]\n        # get completion type given cwords and available subcommand options\n        completion_type = get_path_completion_type(\n            cwords,\n            cword,\n            subcommand.parser.option_list_all,\n        )\n        # get completion files and directories if ``completion_type`` is\n        # ``<file>``, ``<dir>`` or ``<path>``\n        if completion_type:\n            paths = auto_complete_paths(current, completion_type)\n            options = [(path, 0) for path in paths]\n        for option in options:\n            opt_label = option[0]\n            # append '=' to options which require args\n            if option[1] and option[0][:2] == \"--\":\n                opt_label += \"=\"\n            print(opt_label)\n    else:\n        # show main parser options only when necessary\n\n        opts = [i.option_list for i in parser.option_groups]\n        opts.append(parser.option_list)\n        flattened_opts = chain.from_iterable(opts)\n        if current.startswith(\"-\"):\n            for opt in flattened_opts:\n                if opt.help != optparse.SUPPRESS_HELP:\n                    subcommands += opt._long_opts + opt._short_opts\n        else:\n            # get completion type given cwords and all available options\n            completion_type = get_path_completion_type(cwords, cword, flattened_opts)\n            if completion_type:\n                subcommands = list(auto_complete_paths(current, completion_type))\n\n        print(\" \".join([x for x in subcommands if x.startswith(current)]))\n    sys.exit(1)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py": {
      "sha": "3f60b47587cb",
      "lines": 233,
      "head": "\"\"\"Base Command class, and related routines\"\"\"\n\nimport logging\nimport logging.config\nimport optparse\nimport os\nimport sys\nimport traceback\nfrom optparse import Values\nfrom typing import List, Optional, Tuple\n\nfrom pip._vendor.rich import reconfigure\nfrom pip._vendor.rich import traceback as rich_traceback\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.command_context import CommandContextMixIn\nfrom pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter\nfrom pip._internal.cli.status_codes import (\n    ERROR,\n    PREVIOUS_BUILD_DIR_ERROR,\n    UNKNOWN_ERROR,\n    VIRTUALENV_NOT_FOUND,\n)\nfrom pip._internal.exceptions import (\n    BadCommand,\n    CommandError,\n    DiagnosticPipError,\n    InstallationError,\n    NetworkConnectionError,\n    PreviousBuildDirError,\n)\nfrom pip._internal.utils.filesystem import check_path_owner\nfrom pip._internal.utils.logging import BrokenStdoutLoggingError, setup_logging\nfrom pip._internal.utils.misc import get_prog, normalize_path\nfrom pip._internal.utils.temp_dir import TempDirectoryTypeRegistry as TempDirRegistry\nfrom pip._internal.utils.temp_dir import global_tempdir_manager, tempdir_registry\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\n\n__all__ = [\"Command\"]\n\nlogger = logging.getLogger(__name__)\n\n\nclass Command(CommandContextMixIn):\n    usage: str = \"\"\n    ignore_require_venv: bool = False\n\n    def __init__(self, name: str, summary: str, isolated: bool = False) -> None:\n        super().__init__()\n\n        self.name = name\n        self.summary = summary\n        self.parser = ConfigOptionParser(\n            usage=self.usage,\n            prog=f\"{get_prog()} {name}\",\n            formatter=UpdatingDefaultsHelpFormatter(),\n            add_help_option=False,\n            name=name,\n            description=self.__doc__,\n            isolated=isolated,\n        )\n\n        self.tempdir_registry: Optional[TempDirRegistry] = None\n\n        # Commands should add options to this option group\n        optgroup_name = f\"{self.name.capitalize()} Options\"\n        self.cmd_opts = optparse.OptionGroup(self.parser, optgroup_name)\n\n        # Add the general options\n        gen_opts = cmdoptions.make_option_group(\n            cmdoptions.general_group,\n            self.parser,\n        )\n        self.parser.add_option_group(gen_opts)\n\n        self.add_options()\n\n    def add_options(self) -> None:\n        pass\n\n    def handle_pip_version_check(self, options: Values) -> None:\n        \"\"\"\n        This is a no-op so that commands by default do not do the pip version\n        check.\n        \"\"\"\n        # Make sure we do the pip version check if the index_group options\n        # are present.\n        assert not hasattr(options, \"no_index\")\n\n    def run(self, options: Values, args: List[str]) -> int:\n        raise NotImplementedError\n\n    def _run_wrapper(self, level_number: int, options: Values, args: List[str]) -> int:\n        def _inner_run() -> int:\n            try:\n                return self.run(options, args)\n            finally:\n                self.handle_pip_version_check(options)\n\n        if options.debug_mode:\n            rich_traceback.install(show_locals=True)\n            return _inner_run()\n\n        try:\n            status = _inner_run()\n            assert isinstance(status, int)\n            return status\n        except DiagnosticPipError as exc:\n            logger.error(\"%s\", exc, extra={\"rich\": True})\n            logger.debug(\"Exception information:\", exc_info=True)\n\n            return ERROR\n        except PreviousBuildDirError as exc:\n            logger.critical(str(exc))\n            logger.debug(\"Exception information:\", exc_info=True)\n\n            return PREVIOUS_BUILD_DIR_ERROR\n        except (\n            InstallationError,\n            BadCommand,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\cmdoptions.py": {
      "sha": "b258644977c1",
      "lines": 1133,
      "head": "\"\"\"\nshared options and groups\n\nThe principle here is to define options once, but *not* instantiate them\nglobally. One reason being that options with action='append' can carry state\nbetween parses. pip parses general options twice internally, and shouldn't\npass on state. To be consistent, all options will follow this design.\n\"\"\"\n\n# The following comment should be removed at some point in the future.\n# mypy: strict-optional=False\n\nimport importlib.util\nimport logging\nimport os\nimport pathlib\nimport textwrap\nfrom functools import partial\nfrom optparse import SUPPRESS_HELP, Option, OptionGroup, OptionParser, Values\nfrom textwrap import dedent\nfrom typing import Any, Callable, Dict, Optional, Tuple\n\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.cli.parser import ConfigOptionParser\nfrom pip._internal.exceptions import CommandError\nfrom pip._internal.locations import USER_CACHE_DIR, get_src_prefix\nfrom pip._internal.models.format_control import FormatControl\nfrom pip._internal.models.index import PyPI\nfrom pip._internal.models.target_python import TargetPython\nfrom pip._internal.utils.hashes import STRONG_HASHES\nfrom pip._internal.utils.misc import strtobool\n\nlogger = logging.getLogger(__name__)\n\n\ndef raise_option_error(parser: OptionParser, option: Option, msg: str) -> None:\n    \"\"\"\n    Raise an option parsing error using parser.error().\n\n    Args:\n      parser: an OptionParser instance.\n      option: an Option instance.\n      msg: the error text.\n    \"\"\"\n    msg = f\"{option} error: {msg}\"\n    msg = textwrap.fill(\" \".join(msg.split()))\n    parser.error(msg)\n\n\ndef make_option_group(group: Dict[str, Any], parser: ConfigOptionParser) -> OptionGroup:\n    \"\"\"\n    Return an OptionGroup object\n    group  -- assumed to be dict with 'name' and 'options' keys\n    parser -- an optparse Parser\n    \"\"\"\n    option_group = OptionGroup(parser, group[\"name\"])\n    for option in group[\"options\"]:\n        option_group.add_option(option())\n    return option_group\n\n\ndef check_dist_restriction(options: Values, check_target: bool = False) -> None:\n    \"\"\"Function for determining if custom platform options are allowed.\n\n    :param options: The OptionParser options.\n    :param check_target: Whether or not to check if --target is being used.\n    \"\"\"\n    dist_restriction_set = any(\n        [\n            options.python_version,\n            options.platforms,\n            options.abis,\n            options.implementation,\n        ]\n    )\n\n    binary_only = FormatControl(set(), {\":all:\"})\n    sdist_dependencies_allowed = (\n        options.format_control != binary_only and not options.ignore_dependencies\n    )\n\n    # Installations or downloads using dist restrictions must not combine\n    # source distributions and dist-specific wheels, as they are not\n    # guaranteed to be locally compatible.\n    if dist_restriction_set and sdist_dependencies_allowed:\n        raise CommandError(\n            \"When restricting platform and interpreter constraints using \"\n            \"--python-version, --platform, --abi, or --implementation, \"\n            \"either --no-deps must be set, or --only-binary=:all: must be \"\n            \"set and --no-binary must not be set (or must be set to \"\n            \":none:).\"\n        )\n\n    if check_target:\n        if not options.dry_run and dist_restriction_set and not options.target_dir:\n            raise CommandError(\n                \"Can not use any platform or abi specific options unless \"\n                \"installing via '--target' or using '--dry-run'\"\n            )\n\n\ndef _path_option_check(option: Option, opt: str, value: str) -> str:\n    return os.path.expanduser(value)\n\n\ndef _package_name_option_check(option: Option, opt: str, value: str) -> str:\n    return canonicalize_name(value)\n\n\nclass PipOption(Option):\n    TYPES = Option.TYPES + (\"path\", \"package_name\")\n    TYPE_CHECKER = Option.TYPE_CHECKER.copy()\n    TYPE_CHECKER[\"package_name\"] = _package_name_option_check\n    TYPE_CHECKER[\"path\"] = _path_option_check\n\n\n###########\n# options #\n###########\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\command_context.py": {
      "sha": "07cfd732dc65",
      "lines": 27,
      "head": "from contextlib import ExitStack, contextmanager\nfrom typing import ContextManager, Generator, TypeVar\n\n_T = TypeVar(\"_T\", covariant=True)\n\n\nclass CommandContextMixIn:\n    def __init__(self) -> None:\n        super().__init__()\n        self._in_main_context = False\n        self._main_context = ExitStack()\n\n    @contextmanager\n    def main_context(self) -> Generator[None, None, None]:\n        assert not self._in_main_context\n\n        self._in_main_context = True\n        try:\n            with self._main_context:\n                yield\n        finally:\n            self._in_main_context = False\n\n    def enter_context(self, context_provider: ContextManager[_T]) -> _T:\n        assert self._in_main_context\n\n        return self._main_context.enter_context(context_provider)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\index_command.py": {
      "sha": "77dac446b663",
      "lines": 173,
      "head": "\"\"\"\nContains command classes which may interact with an index / the network.\n\nUnlike its sister module, req_command, this module still uses lazy imports\nso commands which don't always hit the network (e.g. list w/o --outdated or\n--uptodate) don't need waste time importing PipSession and friends.\n\"\"\"\n\nimport logging\nimport os\nimport sys\nfrom functools import lru_cache\nfrom optparse import Values\nfrom typing import TYPE_CHECKING, List, Optional\n\nfrom pip._vendor import certifi\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.command_context import CommandContextMixIn\n\nif TYPE_CHECKING:\n    from ssl import SSLContext\n\n    from pip._internal.network.session import PipSession\n\nlogger = logging.getLogger(__name__)\n\n\n@lru_cache\ndef _create_truststore_ssl_context() -> Optional[\"SSLContext\"]:\n    if sys.version_info < (3, 10):\n        logger.debug(\"Disabling truststore because Python version isn't 3.10+\")\n        return None\n\n    try:\n        import ssl\n    except ImportError:\n        logger.warning(\"Disabling truststore since ssl support is missing\")\n        return None\n\n    try:\n        from pip._vendor import truststore\n    except ImportError:\n        logger.warning(\"Disabling truststore because platform isn't supported\")\n        return None\n\n    ctx = truststore.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n    ctx.load_verify_locations(certifi.where())\n    return ctx\n\n\nclass SessionCommandMixin(CommandContextMixIn):\n    \"\"\"\n    A class mixin for command classes needing _build_session().\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self._session: Optional[PipSession] = None\n\n    @classmethod\n    def _get_index_urls(cls, options: Values) -> Optional[List[str]]:\n        \"\"\"Return a list of index urls from user-provided options.\"\"\"\n        index_urls = []\n        if not getattr(options, \"no_index\", False):\n            url = getattr(options, \"index_url\", None)\n            if url:\n                index_urls.append(url)\n        urls = getattr(options, \"extra_index_urls\", None)\n        if urls:\n            index_urls.extend(urls)\n        # Return None rather than an empty list\n        return index_urls or None\n\n    def get_default_session(self, options: Values) -> \"PipSession\":\n        \"\"\"Get a default-managed session.\"\"\"\n        if self._session is None:\n            self._session = self.enter_context(self._build_session(options))\n            # there's no type annotation on requests.Session, so it's\n            # automatically ContextManager[Any] and self._session becomes Any,\n            # then https://github.com/python/mypy/issues/7696 kicks in\n            assert self._session is not None\n        return self._session\n\n    def _build_session(\n        self,\n        options: Values,\n        retries: Optional[int] = None,\n        timeout: Optional[int] = None,\n    ) -> \"PipSession\":\n        from pip._internal.network.session import PipSession\n\n        cache_dir = options.cache_dir\n        assert not cache_dir or os.path.isabs(cache_dir)\n\n        if \"legacy-certs\" not in options.deprecated_features_enabled:\n            ssl_context = _create_truststore_ssl_context()\n        else:\n            ssl_context = None\n\n        session = PipSession(\n            cache=os.path.join(cache_dir, \"http-v2\") if cache_dir else None,\n            retries=retries if retries is not None else options.retries,\n            trusted_hosts=options.trusted_hosts,\n            index_urls=self._get_index_urls(options),\n            ssl_context=ssl_context,\n        )\n\n        # Handle custom ca-bundles from the user\n        if options.cert:\n            session.verify = options.cert\n\n        # Handle SSL client certificate\n        if options.client_cert:\n            session.cert = options.client_cert\n\n        # Handle timeouts\n        if options.timeout or timeout:\n            session.timeout = timeout if timeout is not None else options.timeout\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\main.py": {
      "sha": "4c9327d795bf",
      "lines": 79,
      "head": "\"\"\"Primary application entrypoint.\"\"\"\n\nimport locale\nimport logging\nimport os\nimport sys\nimport warnings\nfrom typing import List, Optional\n\nfrom pip._internal.cli.autocompletion import autocomplete\nfrom pip._internal.cli.main_parser import parse_command\nfrom pip._internal.commands import create_command\nfrom pip._internal.exceptions import PipError\nfrom pip._internal.utils import deprecation\n\nlogger = logging.getLogger(__name__)\n\n\n# Do not import and use main() directly! Using it directly is actively\n# discouraged by pip's maintainers. The name, location and behavior of\n# this function is subject to change, so calling it directly is not\n# portable across different pip versions.\n\n# In addition, running pip in-process is unsupported and unsafe. This is\n# elaborated in detail at\n# https://pip.pypa.io/en/stable/user_guide/#using-pip-from-your-program.\n# That document also provides suggestions that should work for nearly\n# all users that are considering importing and using main() directly.\n\n# However, we know that certain users will still want to invoke pip\n# in-process. If you understand and accept the implications of using pip\n# in an unsupported manner, the best approach is to use runpy to avoid\n# depending on the exact location of this entry point.\n\n# The following example shows how to use runpy to invoke pip in that\n# case:\n#\n#     sys.argv = [\"pip\", your, args, here]\n#     runpy.run_module(\"pip\", run_name=\"__main__\")\n#\n# Note that this will exit the process after running, unlike a direct\n# call to main. As it is not safe to do any processing after calling\n# main, this should not be an issue in practice.\n\n\ndef main(args: Optional[List[str]] = None) -> int:\n    if args is None:\n        args = sys.argv[1:]\n\n    # Suppress the pkg_resources deprecation warning\n    # Note - we use a module of .*pkg_resources to cover\n    # the normal case (pip._vendor.pkg_resources) and the\n    # devendored case (a bare pkg_resources)\n    warnings.filterwarnings(\n        action=\"ignore\", category=DeprecationWarning, module=\".*pkg_resources\"\n    )\n\n    # Configure our deprecation warnings to be sent through loggers\n    deprecation.install_warning_logger()\n\n    autocomplete()\n\n    try:\n        cmd_name, cmd_args = parse_command(args)\n    except PipError as exc:\n        sys.stderr.write(f\"ERROR: {exc}\")\n        sys.stderr.write(os.linesep)\n        sys.exit(1)\n\n    # Needed for locale.getpreferredencoding(False) to work\n    # in pip._internal.utils.encoding.auto_decode\n    try:\n        locale.setlocale(locale.LC_ALL, \"\")\n    except locale.Error as e:\n        # setlocale can apparently crash if locale are uninitialized\n        logger.debug(\"Ignoring error %s when setting locale\", e)\n    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n\n    return command.main(cmd_args)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\main_parser.py": {
      "sha": "54386af91241",
      "lines": 133,
      "head": "\"\"\"A single place for constructing and exposing the main parser\"\"\"\n\nimport os\nimport subprocess\nimport sys\nfrom typing import List, Optional, Tuple\n\nfrom pip._internal.build_env import get_runnable_pip\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter\nfrom pip._internal.commands import commands_dict, get_similar_commands\nfrom pip._internal.exceptions import CommandError\nfrom pip._internal.utils.misc import get_pip_version, get_prog\n\n__all__ = [\"create_main_parser\", \"parse_command\"]\n\n\ndef create_main_parser() -> ConfigOptionParser:\n    \"\"\"Creates and returns the main parser for pip's CLI\"\"\"\n\n    parser = ConfigOptionParser(\n        usage=\"\\n%prog <command> [options]\",\n        add_help_option=False,\n        formatter=UpdatingDefaultsHelpFormatter(),\n        name=\"global\",\n        prog=get_prog(),\n    )\n    parser.disable_interspersed_args()\n\n    parser.version = get_pip_version()\n\n    # add the general options\n    gen_opts = cmdoptions.make_option_group(cmdoptions.general_group, parser)\n    parser.add_option_group(gen_opts)\n\n    # so the help formatter knows\n    parser.main = True  # type: ignore\n\n    # create command listing for description\n    description = [\"\"] + [\n        f\"{name:27} {command_info.summary}\"\n        for name, command_info in commands_dict.items()\n    ]\n    parser.description = \"\\n\".join(description)\n\n    return parser\n\n\ndef identify_python_interpreter(python: str) -> Optional[str]:\n    # If the named file exists, use it.\n    # If it's a directory, assume it's a virtual environment and\n    # look for the environment's Python executable.\n    if os.path.exists(python):\n        if os.path.isdir(python):\n            # bin/python for Unix, Scripts/python.exe for Windows\n            # Try both in case of odd cases like cygwin.\n            for exe in (\"bin/python\", \"Scripts/python.exe\"):\n                py = os.path.join(python, exe)\n                if os.path.exists(py):\n                    return py\n        else:\n            return python\n\n    # Could not find the interpreter specified\n    return None\n\n\ndef parse_command(args: List[str]) -> Tuple[str, List[str]]:\n    parser = create_main_parser()\n\n    # Note: parser calls disable_interspersed_args(), so the result of this\n    # call is to split the initial args into the general options before the\n    # subcommand and everything else.\n    # For example:\n    #  args: ['--timeout=5', 'install', '--user', 'INITools']\n    #  general_options: ['--timeout==5']\n    #  args_else: ['install', '--user', 'INITools']\n    general_options, args_else = parser.parse_args(args)\n\n    # --python\n    if general_options.python and \"_PIP_RUNNING_IN_SUBPROCESS\" not in os.environ:\n        # Re-invoke pip using the specified Python interpreter\n        interpreter = identify_python_interpreter(general_options.python)\n        if interpreter is None:\n            raise CommandError(\n                f\"Could not locate Python interpreter {general_options.python}\"\n            )\n\n        pip_cmd = [\n            interpreter,\n            get_runnable_pip(),\n        ]\n        pip_cmd.extend(args)\n\n        # Set a flag so the child doesn't re-invoke itself, causing\n        # an infinite loop.\n        os.environ[\"_PIP_RUNNING_IN_SUBPROCESS\"] = \"1\"\n        returncode = 0\n        try:\n            proc = subprocess.run(pip_cmd)\n            returncode = proc.returncode\n        except (subprocess.SubprocessError, OSError) as exc:\n            raise CommandError(f\"Failed to run pip under {interpreter}: {exc}\")\n        sys.exit(returncode)\n\n    # --version\n    if general_options.version:\n        sys.stdout.write(parser.version)\n        sys.stdout.write(os.linesep)\n        sys.exit()\n\n    # pip || pip help -> print_help()\n    if not args_else or (args_else[0] == \"help\" and len(args_else) == 1):\n        parser.print_help()\n        sys.exit()\n\n    # the subcommand name\n    cmd_name = args_else[0]\n\n    if cmd_name not in commands_dict:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\parser.py": {
      "sha": "30f8dc09ad52",
      "lines": 294,
      "head": "\"\"\"Base option parser setup\"\"\"\n\nimport logging\nimport optparse\nimport shutil\nimport sys\nimport textwrap\nfrom contextlib import suppress\nfrom typing import Any, Dict, Generator, List, NoReturn, Optional, Tuple\n\nfrom pip._internal.cli.status_codes import UNKNOWN_ERROR\nfrom pip._internal.configuration import Configuration, ConfigurationError\nfrom pip._internal.utils.misc import redact_auth_from_url, strtobool\n\nlogger = logging.getLogger(__name__)\n\n\nclass PrettyHelpFormatter(optparse.IndentedHelpFormatter):\n    \"\"\"A prettier/less verbose help formatter for optparse.\"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        # help position must be aligned with __init__.parseopts.description\n        kwargs[\"max_help_position\"] = 30\n        kwargs[\"indent_increment\"] = 1\n        kwargs[\"width\"] = shutil.get_terminal_size()[0] - 2\n        super().__init__(*args, **kwargs)\n\n    def format_option_strings(self, option: optparse.Option) -> str:\n        return self._format_option_strings(option)\n\n    def _format_option_strings(\n        self, option: optparse.Option, mvarfmt: str = \" <{}>\", optsep: str = \", \"\n    ) -> str:\n        \"\"\"\n        Return a comma-separated list of option strings and metavars.\n\n        :param option:  tuple of (short opt, long opt), e.g: ('-f', '--format')\n        :param mvarfmt: metavar format string\n        :param optsep:  separator\n        \"\"\"\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, optsep)\n\n        if option.takes_value():\n            assert option.dest is not None\n            metavar = option.metavar or option.dest.lower()\n            opts.append(mvarfmt.format(metavar.lower()))\n\n        return \"\".join(opts)\n\n    def format_heading(self, heading: str) -> str:\n        if heading == \"Options\":\n            return \"\"\n        return heading + \":\\n\"\n\n    def format_usage(self, usage: str) -> str:\n        \"\"\"\n        Ensure there is only one newline between usage and the first heading\n        if there is no description.\n        \"\"\"\n        msg = \"\\nUsage: {}\\n\".format(self.indent_lines(textwrap.dedent(usage), \"  \"))\n        return msg\n\n    def format_description(self, description: Optional[str]) -> str:\n        # leave full control over description to us\n        if description:\n            if hasattr(self.parser, \"main\"):\n                label = \"Commands\"\n            else:\n                label = \"Description\"\n            # some doc strings have initial newlines, some don't\n            description = description.lstrip(\"\\n\")\n            # some doc strings have final newlines and spaces, some don't\n            description = description.rstrip()\n            # dedent, then reindent\n            description = self.indent_lines(textwrap.dedent(description), \"  \")\n            description = f\"{label}:\\n{description}\\n\"\n            return description\n        else:\n            return \"\"\n\n    def format_epilog(self, epilog: Optional[str]) -> str:\n        # leave full control over epilog to us\n        if epilog:\n            return epilog\n        else:\n            return \"\"\n\n    def indent_lines(self, text: str, indent: str) -> str:\n        new_lines = [indent + line for line in text.split(\"\\n\")]\n        return \"\\n\".join(new_lines)\n\n\nclass UpdatingDefaultsHelpFormatter(PrettyHelpFormatter):\n    \"\"\"Custom help formatter for use in ConfigOptionParser.\n\n    This is updates the defaults before expanding them, allowing\n    them to show up correctly in the help listing.\n\n    Also redact auth from url type options\n    \"\"\"\n\n    def expand_default(self, option: optparse.Option) -> str:\n        default_values = None\n        if self.parser is not None:\n            assert isinstance(self.parser, ConfigOptionParser)\n            self.parser._update_defaults(self.parser.defaults)\n            assert option.dest is not None\n            default_values = self.parser.defaults.get(option.dest)\n        help_text = super().expand_default(option)\n\n        if default_values and option.metavar == \"URL\":\n            if isinstance(default_values, str):\n                default_values = [default_values]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py": {
      "sha": "97a6496f41ba",
      "lines": 144,
      "head": "import functools\nimport sys\nfrom typing import Callable, Generator, Iterable, Iterator, Optional, Tuple, TypeVar\n\nfrom pip._vendor.rich.progress import (\n    BarColumn,\n    DownloadColumn,\n    FileSizeColumn,\n    MofNCompleteColumn,\n    Progress,\n    ProgressColumn,\n    SpinnerColumn,\n    TextColumn,\n    TimeElapsedColumn,\n    TimeRemainingColumn,\n    TransferSpeedColumn,\n)\n\nfrom pip._internal.cli.spinners import RateLimiter\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.utils.logging import get_console, get_indentation\n\nT = TypeVar(\"T\")\nProgressRenderer = Callable[[Iterable[T]], Iterator[T]]\n\n\ndef _rich_download_progress_bar(\n    iterable: Iterable[bytes],\n    *,\n    bar_type: str,\n    size: Optional[int],\n    initial_progress: Optional[int] = None,\n) -> Generator[bytes, None, None]:\n    assert bar_type == \"on\", \"This should only be used in the default mode.\"\n\n    if not size:\n        total = float(\"inf\")\n        columns: Tuple[ProgressColumn, ...] = (\n            TextColumn(\"[progress.description]{task.description}\"),\n            SpinnerColumn(\"line\", speed=1.5),\n            FileSizeColumn(),\n            TransferSpeedColumn(),\n            TimeElapsedColumn(),\n        )\n    else:\n        total = size\n        columns = (\n            TextColumn(\"[progress.description]{task.description}\"),\n            BarColumn(),\n            DownloadColumn(),\n            TransferSpeedColumn(),\n            TextColumn(\"eta\"),\n            TimeRemainingColumn(),\n        )\n\n    progress = Progress(*columns, refresh_per_second=5)\n    task_id = progress.add_task(\" \" * (get_indentation() + 2), total=total)\n    if initial_progress is not None:\n        progress.update(task_id, advance=initial_progress)\n    with progress:\n        for chunk in iterable:\n            yield chunk\n            progress.update(task_id, advance=len(chunk))\n\n\ndef _rich_install_progress_bar(\n    iterable: Iterable[InstallRequirement], *, total: int\n) -> Iterator[InstallRequirement]:\n    columns = (\n        TextColumn(\"{task.fields[indent]}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n        TextColumn(\"{task.description}\"),\n    )\n    console = get_console()\n\n    bar = Progress(*columns, refresh_per_second=6, console=console, transient=True)\n    # Hiding the progress bar at initialization forces a refresh cycle to occur\n    # until the bar appears, avoiding very short flashes.\n    task = bar.add_task(\"\", total=total, indent=\" \" * get_indentation(), visible=False)\n    with bar:\n        for req in iterable:\n            bar.update(task, description=rf\"\\[{req.name}]\", visible=True)\n            yield req\n            bar.advance(task)\n\n\ndef _raw_progress_bar(\n    iterable: Iterable[bytes],\n    *,\n    size: Optional[int],\n    initial_progress: Optional[int] = None,\n) -> Generator[bytes, None, None]:\n    def write_progress(current: int, total: int) -> None:\n        sys.stdout.write(f\"Progress {current} of {total}\\n\")\n        sys.stdout.flush()\n\n    current = initial_progress or 0\n    total = size or 0\n    rate_limiter = RateLimiter(0.25)\n\n    write_progress(current, total)\n    for chunk in iterable:\n        current += len(chunk)\n        if rate_limiter.ready() or current == total:\n            write_progress(current, total)\n            rate_limiter.reset()\n        yield chunk\n\n\ndef get_download_progress_renderer(\n    *, bar_type: str, size: Optional[int] = None, initial_progress: Optional[int] = None\n) -> ProgressRenderer[bytes]:\n    \"\"\"Get an object that can be used to render the download progress.\n\n    Returns a callable, that takes an iterable to \"wrap\".\n    \"\"\"\n    if bar_type == \"on\":\n        return functools.partial(\n            _rich_download_progress_bar,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py": {
      "sha": "fe9e371a5b13",
      "lines": 347,
      "head": "\"\"\"Contains the RequirementCommand base class.\n\nThis class is in a separate module so the commands that do not always\nneed PackageFinder capability don't unnecessarily import the\nPackageFinder machinery and all its vendored dependencies, etc.\n\"\"\"\n\nimport logging\nfrom functools import partial\nfrom optparse import Values\nfrom typing import Any, List, Optional, Tuple\n\nfrom pip._internal.cache import WheelCache\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.index_command import IndexGroupCommand\nfrom pip._internal.cli.index_command import SessionCommandMixin as SessionCommandMixin\nfrom pip._internal.exceptions import CommandError, PreviousBuildDirError\nfrom pip._internal.index.collector import LinkCollector\nfrom pip._internal.index.package_finder import PackageFinder\nfrom pip._internal.models.selection_prefs import SelectionPreferences\nfrom pip._internal.models.target_python import TargetPython\nfrom pip._internal.network.session import PipSession\nfrom pip._internal.operations.build.build_tracker import BuildTracker\nfrom pip._internal.operations.prepare import RequirementPreparer\nfrom pip._internal.req.constructors import (\n    install_req_from_editable,\n    install_req_from_line,\n    install_req_from_parsed_requirement,\n    install_req_from_req_string,\n)\nfrom pip._internal.req.req_dependency_group import parse_dependency_groups\nfrom pip._internal.req.req_file import parse_requirements\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.resolution.base import BaseResolver\nfrom pip._internal.utils.temp_dir import (\n    TempDirectory,\n    TempDirectoryTypeRegistry,\n    tempdir_kinds,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nKEEPABLE_TEMPDIR_TYPES = [\n    tempdir_kinds.BUILD_ENV,\n    tempdir_kinds.EPHEM_WHEEL_CACHE,\n    tempdir_kinds.REQ_BUILD,\n]\n\n\ndef with_cleanup(func: Any) -> Any:\n    \"\"\"Decorator for common logic related to managing temporary\n    directories.\n    \"\"\"\n\n    def configure_tempdir_registry(registry: TempDirectoryTypeRegistry) -> None:\n        for t in KEEPABLE_TEMPDIR_TYPES:\n            registry.set_delete(t, False)\n\n    def wrapper(\n        self: RequirementCommand, options: Values, args: List[Any]\n    ) -> Optional[int]:\n        assert self.tempdir_registry is not None\n        if options.no_clean:\n            configure_tempdir_registry(self.tempdir_registry)\n\n        try:\n            return func(self, options, args)\n        except PreviousBuildDirError:\n            # This kind of conflict can occur when the user passes an explicit\n            # build directory with a pre-existing folder. In that case we do\n            # not want to accidentally remove it.\n            configure_tempdir_registry(self.tempdir_registry)\n            raise\n\n    return wrapper\n\n\nclass RequirementCommand(IndexGroupCommand):\n    def __init__(self, *args: Any, **kw: Any) -> None:\n        super().__init__(*args, **kw)\n\n        self.cmd_opts.add_option(cmdoptions.dependency_groups())\n        self.cmd_opts.add_option(cmdoptions.no_clean())\n\n    @staticmethod\n    def determine_resolver_variant(options: Values) -> str:\n        \"\"\"Determines which resolver should be used, based on the given options.\"\"\"\n        if \"legacy-resolver\" in options.deprecated_features_enabled:\n            return \"legacy\"\n\n        return \"resolvelib\"\n\n    @classmethod\n    def make_requirement_preparer(\n        cls,\n        temp_build_dir: TempDirectory,\n        options: Values,\n        build_tracker: BuildTracker,\n        session: PipSession,\n        finder: PackageFinder,\n        use_user_site: bool,\n        download_dir: Optional[str] = None,\n        verbosity: int = 0,\n    ) -> RequirementPreparer:\n        \"\"\"\n        Create a RequirementPreparer instance for the given parameters.\n        \"\"\"\n        temp_build_dir_path = temp_build_dir.path\n        assert temp_build_dir_path is not None\n        legacy_resolver = False\n\n        resolver_variant = cls.determine_resolver_variant(options)\n        if resolver_variant == \"resolvelib\":\n            lazy_wheel = \"fast-deps\" in options.features_enabled\n            if lazy_wheel:\n                logger.warning(\n                    \"pip is using lazily downloaded wheels using HTTP \"\n                    \"range requests to obtain dependency information. \"\n                    \"This experimental feature is enabled through \"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\spinners.py": {
      "sha": "ecfe25bb7fde",
      "lines": 159,
      "head": "import contextlib\nimport itertools\nimport logging\nimport sys\nimport time\nfrom typing import IO, Generator, Optional\n\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.logging import get_indentation\n\nlogger = logging.getLogger(__name__)\n\n\nclass SpinnerInterface:\n    def spin(self) -> None:\n        raise NotImplementedError()\n\n    def finish(self, final_status: str) -> None:\n        raise NotImplementedError()\n\n\nclass InteractiveSpinner(SpinnerInterface):\n    def __init__(\n        self,\n        message: str,\n        file: Optional[IO[str]] = None,\n        spin_chars: str = \"-\\\\|/\",\n        # Empirically, 8 updates/second looks nice\n        min_update_interval_seconds: float = 0.125,\n    ):\n        self._message = message\n        if file is None:\n            file = sys.stdout\n        self._file = file\n        self._rate_limiter = RateLimiter(min_update_interval_seconds)\n        self._finished = False\n\n        self._spin_cycle = itertools.cycle(spin_chars)\n\n        self._file.write(\" \" * get_indentation() + self._message + \" ... \")\n        self._width = 0\n\n    def _write(self, status: str) -> None:\n        assert not self._finished\n        # Erase what we wrote before by backspacing to the beginning, writing\n        # spaces to overwrite the old text, and then backspacing again\n        backup = \"\\b\" * self._width\n        self._file.write(backup + \" \" * self._width + backup)\n        # Now we have a blank slate to add our status\n        self._file.write(status)\n        self._width = len(status)\n        self._file.flush()\n        self._rate_limiter.reset()\n\n    def spin(self) -> None:\n        if self._finished:\n            return\n        if not self._rate_limiter.ready():\n            return\n        self._write(next(self._spin_cycle))\n\n    def finish(self, final_status: str) -> None:\n        if self._finished:\n            return\n        self._write(final_status)\n        self._file.write(\"\\n\")\n        self._file.flush()\n        self._finished = True\n\n\n# Used for dumb terminals, non-interactive installs (no tty), etc.\n# We still print updates occasionally (once every 60 seconds by default) to\n# act as a keep-alive for systems like Travis-CI that take lack-of-output as\n# an indication that a task has frozen.\nclass NonInteractiveSpinner(SpinnerInterface):\n    def __init__(self, message: str, min_update_interval_seconds: float = 60.0) -> None:\n        self._message = message\n        self._finished = False\n        self._rate_limiter = RateLimiter(min_update_interval_seconds)\n        self._update(\"started\")\n\n    def _update(self, status: str) -> None:\n        assert not self._finished\n        self._rate_limiter.reset()\n        logger.info(\"%s: %s\", self._message, status)\n\n    def spin(self) -> None:\n        if self._finished:\n            return\n        if not self._rate_limiter.ready():\n            return\n        self._update(\"still running...\")\n\n    def finish(self, final_status: str) -> None:\n        if self._finished:\n            return\n        self._update(f\"finished with status '{final_status}'\")\n        self._finished = True\n\n\nclass RateLimiter:\n    def __init__(self, min_update_interval_seconds: float) -> None:\n        self._min_update_interval_seconds = min_update_interval_seconds\n        self._last_update: float = 0\n\n    def ready(self) -> bool:\n        now = time.time()\n        delta = now - self._last_update\n        return delta >= self._min_update_interval_seconds\n\n    def reset(self) -> None:\n        self._last_update = time.time()\n\n\n@contextlib.contextmanager\ndef open_spinner(message: str) -> Generator[SpinnerInterface, None, None]:\n    # Interactive spinner goes directly to sys.stdout rather than being routed\n    # through the logging system, but it acts like it has level INFO,\n    # i.e. it's only displayed if we're at level INFO or better.\n    # Non-interactive spinner goes through the logging system, so it is always\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\status_codes.py": {
      "sha": "0f5af7b27d1a",
      "lines": 6,
      "head": "SUCCESS = 0\nERROR = 1\nUNKNOWN_ERROR = 2\nVIRTUALENV_NOT_FOUND = 3\nPREVIOUS_BUILD_DIR_ERROR = 4\nNO_MATCHES_FOUND = 23\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\cli\\__init__.py": {
      "sha": "b9915226c5c8",
      "lines": 3,
      "head": "\"\"\"Subpackage containing all of pip's command line interface related code\"\"\"\n\n# This file intentionally does not import submodules\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\cache.py": {
      "sha": "27fee02bbb6a",
      "lines": 228,
      "head": "import os\nimport textwrap\nfrom optparse import Values\nfrom typing import Any, List\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import ERROR, SUCCESS\nfrom pip._internal.exceptions import CommandError, PipError\nfrom pip._internal.utils import filesystem\nfrom pip._internal.utils.logging import getLogger\nfrom pip._internal.utils.misc import format_size\n\nlogger = getLogger(__name__)\n\n\nclass CacheCommand(Command):\n    \"\"\"\n    Inspect and manage pip's wheel cache.\n\n    Subcommands:\n\n    - dir: Show the cache directory.\n    - info: Show information about the cache.\n    - list: List filenames of packages stored in the cache.\n    - remove: Remove one or more package from the cache.\n    - purge: Remove all items from the cache.\n\n    ``<pattern>`` can be a glob expression or a package name.\n    \"\"\"\n\n    ignore_require_venv = True\n    usage = \"\"\"\n        %prog dir\n        %prog info\n        %prog list [<pattern>] [--format=[human, abspath]]\n        %prog remove <pattern>\n        %prog purge\n    \"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"--format\",\n            action=\"store\",\n            dest=\"list_format\",\n            default=\"human\",\n            choices=(\"human\", \"abspath\"),\n            help=\"Select the output format among: human (default) or abspath\",\n        )\n\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        handlers = {\n            \"dir\": self.get_cache_dir,\n            \"info\": self.get_cache_info,\n            \"list\": self.list_cache_items,\n            \"remove\": self.remove_cache_items,\n            \"purge\": self.purge_cache,\n        }\n\n        if not options.cache_dir:\n            logger.error(\"pip cache commands can not function since cache is disabled.\")\n            return ERROR\n\n        # Determine action\n        if not args or args[0] not in handlers:\n            logger.error(\n                \"Need an action (%s) to perform.\",\n                \", \".join(sorted(handlers)),\n            )\n            return ERROR\n\n        action = args[0]\n\n        # Error handling happens here, not in the action-handlers.\n        try:\n            handlers[action](options, args[1:])\n        except PipError as e:\n            logger.error(e.args[0])\n            return ERROR\n\n        return SUCCESS\n\n    def get_cache_dir(self, options: Values, args: List[Any]) -> None:\n        if args:\n            raise CommandError(\"Too many arguments\")\n\n        logger.info(options.cache_dir)\n\n    def get_cache_info(self, options: Values, args: List[Any]) -> None:\n        if args:\n            raise CommandError(\"Too many arguments\")\n\n        num_http_files = len(self._find_http_files(options))\n        num_packages = len(self._find_wheels(options, \"*\"))\n\n        http_cache_location = self._cache_dir(options, \"http-v2\")\n        old_http_cache_location = self._cache_dir(options, \"http\")\n        wheels_cache_location = self._cache_dir(options, \"wheels\")\n        http_cache_size = filesystem.format_size(\n            filesystem.directory_size(http_cache_location)\n            + filesystem.directory_size(old_http_cache_location)\n        )\n        wheels_cache_size = filesystem.format_directory_size(wheels_cache_location)\n\n        message = (\n            textwrap.dedent(\n                \"\"\"\n                    Package index page cache location (pip v23.3+): {http_cache_location}\n                    Package index page cache location (older pips): {old_http_cache_location}\n                    Package index page cache size: {http_cache_size}\n                    Number of HTTP files: {num_http_files}\n                    Locally built wheels location: {wheels_cache_location}\n                    Locally built wheels size: {wheels_cache_size}\n                    Number of locally built wheels: {package_count}\n                \"\"\"  # noqa: E501\n            )\n            .format(\n                http_cache_location=http_cache_location,\n                old_http_cache_location=old_http_cache_location,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\check.py": {
      "sha": "719d91213d80",
      "lines": 67,
      "head": "import logging\nfrom optparse import Values\nfrom typing import List\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import ERROR, SUCCESS\nfrom pip._internal.metadata import get_default_environment\nfrom pip._internal.operations.check import (\n    check_package_set,\n    check_unsupported,\n    create_package_set_from_installed,\n)\nfrom pip._internal.utils.compatibility_tags import get_supported\nfrom pip._internal.utils.misc import write_output\n\nlogger = logging.getLogger(__name__)\n\n\nclass CheckCommand(Command):\n    \"\"\"Verify installed packages have compatible dependencies.\"\"\"\n\n    ignore_require_venv = True\n    usage = \"\"\"\n      %prog [options]\"\"\"\n\n    def run(self, options: Values, args: List[str]) -> int:\n        package_set, parsing_probs = create_package_set_from_installed()\n        missing, conflicting = check_package_set(package_set)\n        unsupported = list(\n            check_unsupported(\n                get_default_environment().iter_installed_distributions(),\n                get_supported(),\n            )\n        )\n\n        for project_name in missing:\n            version = package_set[project_name].version\n            for dependency in missing[project_name]:\n                write_output(\n                    \"%s %s requires %s, which is not installed.\",\n                    project_name,\n                    version,\n                    dependency[0],\n                )\n\n        for project_name in conflicting:\n            version = package_set[project_name].version\n            for dep_name, dep_version, req in conflicting[project_name]:\n                write_output(\n                    \"%s %s has requirement %s, but you have %s %s.\",\n                    project_name,\n                    version,\n                    req,\n                    dep_name,\n                    dep_version,\n                )\n        for package in unsupported:\n            write_output(\n                \"%s %s is not supported on this platform\",\n                package.raw_name,\n                package.version,\n            )\n        if missing or conflicting or parsing_probs or unsupported:\n            return ERROR\n        else:\n            write_output(\"No broken requirements found.\")\n            return SUCCESS\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\completion.py": {
      "sha": "9cf6c7dc8d8f",
      "lines": 136,
      "head": "import sys\nimport textwrap\nfrom optparse import Values\nfrom typing import List\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.utils.misc import get_prog\n\nBASE_COMPLETION = \"\"\"\n# pip {shell} completion start{script}# pip {shell} completion end\n\"\"\"\n\nCOMPLETION_SCRIPTS = {\n    \"bash\": \"\"\"\n        _pip_completion()\n        {{\n            COMPREPLY=( $( COMP_WORDS=\"${{COMP_WORDS[*]}}\" \\\\\n                           COMP_CWORD=$COMP_CWORD \\\\\n                           PIP_AUTO_COMPLETE=1 $1 2>/dev/null ) )\n        }}\n        complete -o default -F _pip_completion {prog}\n    \"\"\",\n    \"zsh\": \"\"\"\n        #compdef -P pip[0-9.]#\n        __pip() {{\n          compadd $( COMP_WORDS=\"$words[*]\" \\\\\n                     COMP_CWORD=$((CURRENT-1)) \\\\\n                     PIP_AUTO_COMPLETE=1 $words[1] 2>/dev/null )\n        }}\n        if [[ $zsh_eval_context[-1] == loadautofunc ]]; then\n          # autoload from fpath, call function directly\n          __pip \"$@\"\n        else\n          # eval/source/. command, register function for later\n          compdef __pip -P 'pip[0-9.]#'\n        fi\n    \"\"\",\n    \"fish\": \"\"\"\n        function __fish_complete_pip\n            set -lx COMP_WORDS \\\\\n                (commandline --current-process --tokenize --cut-at-cursor) \\\\\n                (commandline --current-token --cut-at-cursor)\n            set -lx COMP_CWORD (math (count $COMP_WORDS) - 1)\n            set -lx PIP_AUTO_COMPLETE 1\n            set -l completions\n            if string match -q '2.*' $version\n                set completions (eval $COMP_WORDS[1])\n            else\n                set completions ($COMP_WORDS[1])\n            end\n            string split \\\\  -- $completions\n        end\n        complete -fa \"(__fish_complete_pip)\" -c {prog}\n    \"\"\",\n    \"powershell\": \"\"\"\n        if ((Test-Path Function:\\\\TabExpansion) -and -not `\n            (Test-Path Function:\\\\_pip_completeBackup)) {{\n            Rename-Item Function:\\\\TabExpansion _pip_completeBackup\n        }}\n        function TabExpansion($line, $lastWord) {{\n            $lastBlock = [regex]::Split($line, '[|;]')[-1].TrimStart()\n            if ($lastBlock.StartsWith(\"{prog} \")) {{\n                $Env:COMP_WORDS=$lastBlock\n                $Env:COMP_CWORD=$lastBlock.Split().Length - 1\n                $Env:PIP_AUTO_COMPLETE=1\n                (& {prog}).Split()\n                Remove-Item Env:COMP_WORDS\n                Remove-Item Env:COMP_CWORD\n                Remove-Item Env:PIP_AUTO_COMPLETE\n            }}\n            elseif (Test-Path Function:\\\\_pip_completeBackup) {{\n                # Fall back on existing tab expansion\n                _pip_completeBackup $line $lastWord\n            }}\n        }}\n    \"\"\",\n}\n\n\nclass CompletionCommand(Command):\n    \"\"\"A helper command to be used for command completion.\"\"\"\n\n    ignore_require_venv = True\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"--bash\",\n            \"-b\",\n            action=\"store_const\",\n            const=\"bash\",\n            dest=\"shell\",\n            help=\"Emit completion code for bash\",\n        )\n        self.cmd_opts.add_option(\n            \"--zsh\",\n            \"-z\",\n            action=\"store_const\",\n            const=\"zsh\",\n            dest=\"shell\",\n            help=\"Emit completion code for zsh\",\n        )\n        self.cmd_opts.add_option(\n            \"--fish\",\n            \"-f\",\n            action=\"store_const\",\n            const=\"fish\",\n            dest=\"shell\",\n            help=\"Emit completion code for fish\",\n        )\n        self.cmd_opts.add_option(\n            \"--powershell\",\n            \"-p\",\n            action=\"store_const\",\n            const=\"powershell\",\n            dest=\"shell\",\n            help=\"Emit completion code for powershell\",\n        )\n\n        self.parser.insert_option_group(0, self.cmd_opts)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\configuration.py": {
      "sha": "4bfaf98054bb",
      "lines": 280,
      "head": "import logging\nimport os\nimport subprocess\nfrom optparse import Values\nfrom typing import Any, List, Optional\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import ERROR, SUCCESS\nfrom pip._internal.configuration import (\n    Configuration,\n    Kind,\n    get_configuration_files,\n    kinds,\n)\nfrom pip._internal.exceptions import PipError\nfrom pip._internal.utils.logging import indent_log\nfrom pip._internal.utils.misc import get_prog, write_output\n\nlogger = logging.getLogger(__name__)\n\n\nclass ConfigurationCommand(Command):\n    \"\"\"\n    Manage local and global configuration.\n\n    Subcommands:\n\n    - list: List the active configuration (or from the file specified)\n    - edit: Edit the configuration file in an editor\n    - get: Get the value associated with command.option\n    - set: Set the command.option=value\n    - unset: Unset the value associated with command.option\n    - debug: List the configuration files and values defined under them\n\n    Configuration keys should be dot separated command and option name,\n    with the special prefix \"global\" affecting any command. For example,\n    \"pip config set global.index-url https://example.org/\" would configure\n    the index url for all commands, but \"pip config set download.timeout 10\"\n    would configure a 10 second timeout only for \"pip download\" commands.\n\n    If none of --user, --global and --site are passed, a virtual\n    environment configuration file is used if one is active and the file\n    exists. Otherwise, all modifications happen to the user file by\n    default.\n    \"\"\"\n\n    ignore_require_venv = True\n    usage = \"\"\"\n        %prog [<file-option>] list\n        %prog [<file-option>] [--editor <editor-path>] edit\n\n        %prog [<file-option>] get command.option\n        %prog [<file-option>] set command.option value\n        %prog [<file-option>] unset command.option\n        %prog [<file-option>] debug\n    \"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"--editor\",\n            dest=\"editor\",\n            action=\"store\",\n            default=None,\n            help=(\n                \"Editor to use to edit the file. Uses VISUAL or EDITOR \"\n                \"environment variables if not provided.\"\n            ),\n        )\n\n        self.cmd_opts.add_option(\n            \"--global\",\n            dest=\"global_file\",\n            action=\"store_true\",\n            default=False,\n            help=\"Use the system-wide configuration file only\",\n        )\n\n        self.cmd_opts.add_option(\n            \"--user\",\n            dest=\"user_file\",\n            action=\"store_true\",\n            default=False,\n            help=\"Use the user configuration file only\",\n        )\n\n        self.cmd_opts.add_option(\n            \"--site\",\n            dest=\"site_file\",\n            action=\"store_true\",\n            default=False,\n            help=\"Use the current environment configuration file only\",\n        )\n\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        handlers = {\n            \"list\": self.list_values,\n            \"edit\": self.open_in_editor,\n            \"get\": self.get_name,\n            \"set\": self.set_name_value,\n            \"unset\": self.unset_name,\n            \"debug\": self.list_config_values,\n        }\n\n        # Determine action\n        if not args or args[0] not in handlers:\n            logger.error(\n                \"Need an action (%s) to perform.\",\n                \", \".join(sorted(handlers)),\n            )\n            return ERROR\n\n        action = args[0]\n\n        # Determine which configuration files are to be loaded\n        #    Depends on whether the command is modifying.\n        try:\n            load_only = self._determine_file(\n                options, need_value=(action in [\"get\", \"set\", \"unset\", \"edit\"])\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\debug.py": {
      "sha": "84a1c542a832",
      "lines": 201,
      "head": "import locale\nimport logging\nimport os\nimport sys\nfrom optparse import Values\nfrom types import ModuleType\nfrom typing import Any, Dict, List, Optional\n\nimport pip._vendor\nfrom pip._vendor.certifi import where\nfrom pip._vendor.packaging.version import parse as parse_version\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.cmdoptions import make_target_python\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.configuration import Configuration\nfrom pip._internal.metadata import get_environment\nfrom pip._internal.utils.compat import open_text_resource\nfrom pip._internal.utils.logging import indent_log\nfrom pip._internal.utils.misc import get_pip_version\n\nlogger = logging.getLogger(__name__)\n\n\ndef show_value(name: str, value: Any) -> None:\n    logger.info(\"%s: %s\", name, value)\n\n\ndef show_sys_implementation() -> None:\n    logger.info(\"sys.implementation:\")\n    implementation_name = sys.implementation.name\n    with indent_log():\n        show_value(\"name\", implementation_name)\n\n\ndef create_vendor_txt_map() -> Dict[str, str]:\n    with open_text_resource(\"pip._vendor\", \"vendor.txt\") as f:\n        # Purge non version specifying lines.\n        # Also, remove any space prefix or suffixes (including comments).\n        lines = [\n            line.strip().split(\" \", 1)[0] for line in f.readlines() if \"==\" in line\n        ]\n\n    # Transform into \"module\" -> version dict.\n    return dict(line.split(\"==\", 1) for line in lines)\n\n\ndef get_module_from_module_name(module_name: str) -> Optional[ModuleType]:\n    # Module name can be uppercase in vendor.txt for some reason...\n    module_name = module_name.lower().replace(\"-\", \"_\")\n    # PATCH: setuptools is actually only pkg_resources.\n    if module_name == \"setuptools\":\n        module_name = \"pkg_resources\"\n\n    try:\n        __import__(f\"pip._vendor.{module_name}\", globals(), locals(), level=0)\n        return getattr(pip._vendor, module_name)\n    except ImportError:\n        # We allow 'truststore' to fail to import due\n        # to being unavailable on Python 3.9 and earlier.\n        if module_name == \"truststore\" and sys.version_info < (3, 10):\n            return None\n        raise\n\n\ndef get_vendor_version_from_module(module_name: str) -> Optional[str]:\n    module = get_module_from_module_name(module_name)\n    version = getattr(module, \"__version__\", None)\n\n    if module and not version:\n        # Try to find version in debundled module info.\n        assert module.__file__ is not None\n        env = get_environment([os.path.dirname(module.__file__)])\n        dist = env.get_distribution(module_name)\n        if dist:\n            version = str(dist.version)\n\n    return version\n\n\ndef show_actual_vendor_versions(vendor_txt_versions: Dict[str, str]) -> None:\n    \"\"\"Log the actual version and print extra info if there is\n    a conflict or if the actual version could not be imported.\n    \"\"\"\n    for module_name, expected_version in vendor_txt_versions.items():\n        extra_message = \"\"\n        actual_version = get_vendor_version_from_module(module_name)\n        if not actual_version:\n            extra_message = (\n                \" (Unable to locate actual module version, using\"\n                \" vendor.txt specified version)\"\n            )\n            actual_version = expected_version\n        elif parse_version(actual_version) != parse_version(expected_version):\n            extra_message = (\n                \" (CONFLICT: vendor.txt suggests version should\"\n                f\" be {expected_version})\"\n            )\n        logger.info(\"%s==%s%s\", module_name, actual_version, extra_message)\n\n\ndef show_vendor_versions() -> None:\n    logger.info(\"vendored library versions:\")\n\n    vendor_txt_versions = create_vendor_txt_map()\n    with indent_log():\n        show_actual_vendor_versions(vendor_txt_versions)\n\n\ndef show_tags(options: Values) -> None:\n    tag_limit = 10\n\n    target_python = make_target_python(options)\n    tags = target_python.get_sorted_tags()\n\n    # Display the target options that were explicitly provided.\n    formatted_target = target_python.format_given()\n    suffix = \"\"\n    if formatted_target:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\download.py": {
      "sha": "aaa2e2e35bcc",
      "lines": 146,
      "head": "import logging\nimport os\nfrom optparse import Values\nfrom typing import List\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.cmdoptions import make_target_python\nfrom pip._internal.cli.req_command import RequirementCommand, with_cleanup\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.operations.build.build_tracker import get_build_tracker\nfrom pip._internal.req.req_install import check_legacy_setup_py_options\nfrom pip._internal.utils.misc import ensure_dir, normalize_path, write_output\nfrom pip._internal.utils.temp_dir import TempDirectory\n\nlogger = logging.getLogger(__name__)\n\n\nclass DownloadCommand(RequirementCommand):\n    \"\"\"\n    Download packages from:\n\n    - PyPI (and other indexes) using requirement specifiers.\n    - VCS project urls.\n    - Local project directories.\n    - Local or remote source archives.\n\n    pip also supports downloading from \"requirements files\", which provide\n    an easy way to specify a whole environment to be downloaded.\n    \"\"\"\n\n    usage = \"\"\"\n      %prog [options] <requirement specifier> [package-index-options] ...\n      %prog [options] -r <requirements file> [package-index-options] ...\n      %prog [options] <vcs project url> ...\n      %prog [options] <local project path> ...\n      %prog [options] <archive url/path> ...\"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(cmdoptions.constraints())\n        self.cmd_opts.add_option(cmdoptions.requirements())\n        self.cmd_opts.add_option(cmdoptions.no_deps())\n        self.cmd_opts.add_option(cmdoptions.global_options())\n        self.cmd_opts.add_option(cmdoptions.no_binary())\n        self.cmd_opts.add_option(cmdoptions.only_binary())\n        self.cmd_opts.add_option(cmdoptions.prefer_binary())\n        self.cmd_opts.add_option(cmdoptions.src())\n        self.cmd_opts.add_option(cmdoptions.pre())\n        self.cmd_opts.add_option(cmdoptions.require_hashes())\n        self.cmd_opts.add_option(cmdoptions.progress_bar())\n        self.cmd_opts.add_option(cmdoptions.no_build_isolation())\n        self.cmd_opts.add_option(cmdoptions.use_pep517())\n        self.cmd_opts.add_option(cmdoptions.no_use_pep517())\n        self.cmd_opts.add_option(cmdoptions.check_build_deps())\n        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())\n\n        self.cmd_opts.add_option(\n            \"-d\",\n            \"--dest\",\n            \"--destination-dir\",\n            \"--destination-directory\",\n            dest=\"download_dir\",\n            metavar=\"dir\",\n            default=os.curdir,\n            help=\"Download packages into <dir>.\",\n        )\n\n        cmdoptions.add_target_python_options(self.cmd_opts)\n\n        index_opts = cmdoptions.make_option_group(\n            cmdoptions.index_group,\n            self.parser,\n        )\n\n        self.parser.insert_option_group(0, index_opts)\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    @with_cleanup\n    def run(self, options: Values, args: List[str]) -> int:\n        options.ignore_installed = True\n        # editable doesn't really make sense for `pip download`, but the bowels\n        # of the RequirementSet code require that property.\n        options.editables = []\n\n        cmdoptions.check_dist_restriction(options)\n\n        options.download_dir = normalize_path(options.download_dir)\n        ensure_dir(options.download_dir)\n\n        session = self.get_default_session(options)\n\n        target_python = make_target_python(options)\n        finder = self._build_package_finder(\n            options=options,\n            session=session,\n            target_python=target_python,\n            ignore_requires_python=options.ignore_requires_python,\n        )\n\n        build_tracker = self.enter_context(get_build_tracker())\n\n        directory = TempDirectory(\n            delete=not options.no_clean,\n            kind=\"download\",\n            globally_managed=True,\n        )\n\n        reqs = self.get_requirements(args, options, finder, session)\n        check_legacy_setup_py_options(options, reqs)\n\n        preparer = self.make_requirement_preparer(\n            temp_build_dir=directory,\n            options=options,\n            build_tracker=build_tracker,\n            session=session,\n            finder=finder,\n            download_dir=options.download_dir,\n            use_user_site=False,\n            verbosity=self.verbosity,\n        )\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\freeze.py": {
      "sha": "4a54a14db71c",
      "lines": 108,
      "head": "import sys\nfrom optparse import Values\nfrom typing import AbstractSet, List\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.operations.freeze import freeze\nfrom pip._internal.utils.compat import stdlib_pkgs\n\n\ndef _should_suppress_build_backends() -> bool:\n    return sys.version_info < (3, 12)\n\n\ndef _dev_pkgs() -> AbstractSet[str]:\n    pkgs = {\"pip\"}\n\n    if _should_suppress_build_backends():\n        pkgs |= {\"setuptools\", \"distribute\", \"wheel\"}\n\n    return pkgs\n\n\nclass FreezeCommand(Command):\n    \"\"\"\n    Output installed packages in requirements format.\n\n    packages are listed in a case-insensitive sorted order.\n    \"\"\"\n\n    ignore_require_venv = True\n    usage = \"\"\"\n      %prog [options]\"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"-r\",\n            \"--requirement\",\n            dest=\"requirements\",\n            action=\"append\",\n            default=[],\n            metavar=\"file\",\n            help=(\n                \"Use the order in the given requirements file and its \"\n                \"comments when generating output. This option can be \"\n                \"used multiple times.\"\n            ),\n        )\n        self.cmd_opts.add_option(\n            \"-l\",\n            \"--local\",\n            dest=\"local\",\n            action=\"store_true\",\n            default=False,\n            help=(\n                \"If in a virtualenv that has global access, do not output \"\n                \"globally-installed packages.\"\n            ),\n        )\n        self.cmd_opts.add_option(\n            \"--user\",\n            dest=\"user\",\n            action=\"store_true\",\n            default=False,\n            help=\"Only output packages installed in user-site.\",\n        )\n        self.cmd_opts.add_option(cmdoptions.list_path())\n        self.cmd_opts.add_option(\n            \"--all\",\n            dest=\"freeze_all\",\n            action=\"store_true\",\n            help=(\n                \"Do not skip these packages in the output:\"\n                \" {}\".format(\", \".join(_dev_pkgs()))\n            ),\n        )\n        self.cmd_opts.add_option(\n            \"--exclude-editable\",\n            dest=\"exclude_editable\",\n            action=\"store_true\",\n            help=\"Exclude editable package from output.\",\n        )\n        self.cmd_opts.add_option(cmdoptions.list_exclude())\n\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        skip = set(stdlib_pkgs)\n        if not options.freeze_all:\n            skip.update(_dev_pkgs())\n\n        if options.excludes:\n            skip.update(options.excludes)\n\n        cmdoptions.check_list_path_option(options)\n\n        for line in freeze(\n            requirement=options.requirements,\n            local_only=options.local,\n            user_only=options.user,\n            paths=options.path,\n            isolated=options.isolated_mode,\n            skip=skip,\n            exclude_editable=options.exclude_editable,\n        ):\n            sys.stdout.write(line + \"\\n\")\n        return SUCCESS\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\hash.py": {
      "sha": "3ff85f8d8bee",
      "lines": 59,
      "head": "import hashlib\nimport logging\nimport sys\nfrom optparse import Values\nfrom typing import List\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import ERROR, SUCCESS\nfrom pip._internal.utils.hashes import FAVORITE_HASH, STRONG_HASHES\nfrom pip._internal.utils.misc import read_chunks, write_output\n\nlogger = logging.getLogger(__name__)\n\n\nclass HashCommand(Command):\n    \"\"\"\n    Compute a hash of a local package archive.\n\n    These can be used with --hash in a requirements file to do repeatable\n    installs.\n    \"\"\"\n\n    usage = \"%prog [options] <file> ...\"\n    ignore_require_venv = True\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"-a\",\n            \"--algorithm\",\n            dest=\"algorithm\",\n            choices=STRONG_HASHES,\n            action=\"store\",\n            default=FAVORITE_HASH,\n            help=\"The hash algorithm to use: one of {}\".format(\n                \", \".join(STRONG_HASHES)\n            ),\n        )\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        if not args:\n            self.parser.print_usage(sys.stderr)\n            return ERROR\n\n        algorithm = options.algorithm\n        for path in args:\n            write_output(\n                \"%s:\\n--hash=%s:%s\", path, algorithm, _hash_of_file(path, algorithm)\n            )\n        return SUCCESS\n\n\ndef _hash_of_file(path: str, algorithm: str) -> str:\n    \"\"\"Return the hash digest of a file.\"\"\"\n    with open(path, \"rb\") as archive:\n        hash = hashlib.new(algorithm)\n        for chunk in read_chunks(archive):\n            hash.update(chunk)\n    return hash.hexdigest()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\help.py": {
      "sha": "9dbfb87d39f0",
      "lines": 41,
      "head": "from optparse import Values\nfrom typing import List\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.exceptions import CommandError\n\n\nclass HelpCommand(Command):\n    \"\"\"Show help for commands\"\"\"\n\n    usage = \"\"\"\n      %prog <command>\"\"\"\n    ignore_require_venv = True\n\n    def run(self, options: Values, args: List[str]) -> int:\n        from pip._internal.commands import (\n            commands_dict,\n            create_command,\n            get_similar_commands,\n        )\n\n        try:\n            # 'pip help' with no args is handled by pip.__init__.parseopt()\n            cmd_name = args[0]  # the command we need help for\n        except IndexError:\n            return SUCCESS\n\n        if cmd_name not in commands_dict:\n            guess = get_similar_commands(cmd_name)\n\n            msg = [f'unknown command \"{cmd_name}\"']\n            if guess:\n                msg.append(f'maybe you meant \"{guess}\"')\n\n            raise CommandError(\" - \".join(msg))\n\n        command = create_command(cmd_name)\n        command.parser.print_help()\n\n        return SUCCESS\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\index.py": {
      "sha": "494c8e0fe12c",
      "lines": 153,
      "head": "import json\nimport logging\nfrom optparse import Values\nfrom typing import Any, Iterable, List, Optional\n\nfrom pip._vendor.packaging.version import Version\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.req_command import IndexGroupCommand\nfrom pip._internal.cli.status_codes import ERROR, SUCCESS\nfrom pip._internal.commands.search import (\n    get_installed_distribution,\n    print_dist_installation_info,\n)\nfrom pip._internal.exceptions import CommandError, DistributionNotFound, PipError\nfrom pip._internal.index.collector import LinkCollector\nfrom pip._internal.index.package_finder import PackageFinder\nfrom pip._internal.models.selection_prefs import SelectionPreferences\nfrom pip._internal.models.target_python import TargetPython\nfrom pip._internal.network.session import PipSession\nfrom pip._internal.utils.misc import write_output\n\nlogger = logging.getLogger(__name__)\n\n\nclass IndexCommand(IndexGroupCommand):\n    \"\"\"\n    Inspect information available from package indexes.\n    \"\"\"\n\n    ignore_require_venv = True\n    usage = \"\"\"\n        %prog versions <package>\n    \"\"\"\n\n    def add_options(self) -> None:\n        cmdoptions.add_target_python_options(self.cmd_opts)\n\n        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())\n        self.cmd_opts.add_option(cmdoptions.pre())\n        self.cmd_opts.add_option(cmdoptions.json())\n        self.cmd_opts.add_option(cmdoptions.no_binary())\n        self.cmd_opts.add_option(cmdoptions.only_binary())\n\n        index_opts = cmdoptions.make_option_group(\n            cmdoptions.index_group,\n            self.parser,\n        )\n\n        self.parser.insert_option_group(0, index_opts)\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        handlers = {\n            \"versions\": self.get_available_package_versions,\n        }\n\n        # Determine action\n        if not args or args[0] not in handlers:\n            logger.error(\n                \"Need an action (%s) to perform.\",\n                \", \".join(sorted(handlers)),\n            )\n            return ERROR\n\n        action = args[0]\n\n        # Error handling happens here, not in the action-handlers.\n        try:\n            handlers[action](options, args[1:])\n        except PipError as e:\n            logger.error(e.args[0])\n            return ERROR\n\n        return SUCCESS\n\n    def _build_package_finder(\n        self,\n        options: Values,\n        session: PipSession,\n        target_python: Optional[TargetPython] = None,\n        ignore_requires_python: Optional[bool] = None,\n    ) -> PackageFinder:\n        \"\"\"\n        Create a package finder appropriate to the index command.\n        \"\"\"\n        link_collector = LinkCollector.create(session, options=options)\n\n        # Pass allow_yanked=False to ignore yanked versions.\n        selection_prefs = SelectionPreferences(\n            allow_yanked=False,\n            allow_all_prereleases=options.pre,\n            ignore_requires_python=ignore_requires_python,\n        )\n\n        return PackageFinder.create(\n            link_collector=link_collector,\n            selection_prefs=selection_prefs,\n            target_python=target_python,\n        )\n\n    def get_available_package_versions(self, options: Values, args: List[Any]) -> None:\n        if len(args) != 1:\n            raise CommandError(\"You need to specify exactly one argument\")\n\n        target_python = cmdoptions.make_target_python(options)\n        query = args[0]\n\n        with self._build_session(options) as session:\n            finder = self._build_package_finder(\n                options=options,\n                session=session,\n                target_python=target_python,\n                ignore_requires_python=options.ignore_requires_python,\n            )\n\n            versions: Iterable[Version] = (\n                candidate.version for candidate in finder.find_all_candidates(query)\n            )\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\inspect.py": {
      "sha": "3091daf91c0b",
      "lines": 92,
      "head": "import logging\nfrom optparse import Values\nfrom typing import Any, Dict, List\n\nfrom pip._vendor.packaging.markers import default_environment\nfrom pip._vendor.rich import print_json\n\nfrom pip import __version__\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.metadata import BaseDistribution, get_environment\nfrom pip._internal.utils.compat import stdlib_pkgs\nfrom pip._internal.utils.urls import path_to_url\n\nlogger = logging.getLogger(__name__)\n\n\nclass InspectCommand(Command):\n    \"\"\"\n    Inspect the content of a Python environment and produce a report in JSON format.\n    \"\"\"\n\n    ignore_require_venv = True\n    usage = \"\"\"\n      %prog [options]\"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"--local\",\n            action=\"store_true\",\n            default=False,\n            help=(\n                \"If in a virtualenv that has global access, do not list \"\n                \"globally-installed packages.\"\n            ),\n        )\n        self.cmd_opts.add_option(\n            \"--user\",\n            dest=\"user\",\n            action=\"store_true\",\n            default=False,\n            help=\"Only output packages installed in user-site.\",\n        )\n        self.cmd_opts.add_option(cmdoptions.list_path())\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        cmdoptions.check_list_path_option(options)\n        dists = get_environment(options.path).iter_installed_distributions(\n            local_only=options.local,\n            user_only=options.user,\n            skip=set(stdlib_pkgs),\n        )\n        output = {\n            \"version\": \"1\",\n            \"pip_version\": __version__,\n            \"installed\": [self._dist_to_dict(dist) for dist in dists],\n            \"environment\": default_environment(),\n            # TODO tags? scheme?\n        }\n        print_json(data=output)\n        return SUCCESS\n\n    def _dist_to_dict(self, dist: BaseDistribution) -> Dict[str, Any]:\n        res: Dict[str, Any] = {\n            \"metadata\": dist.metadata_dict,\n            \"metadata_location\": dist.info_location,\n        }\n        # direct_url. Note that we don't have download_info (as in the installation\n        # report) since it is not recorded in installed metadata.\n        direct_url = dist.direct_url\n        if direct_url is not None:\n            res[\"direct_url\"] = direct_url.to_dict()\n        else:\n            # Emulate direct_url for legacy editable installs.\n            editable_project_location = dist.editable_project_location\n            if editable_project_location is not None:\n                res[\"direct_url\"] = {\n                    \"url\": path_to_url(editable_project_location),\n                    \"dir_info\": {\n                        \"editable\": True,\n                    },\n                }\n        # installer\n        installer = dist.installer\n        if dist.installer:\n            res[\"installer\"] = installer\n        # requested\n        if dist.installed_with_dist_info:\n            res[\"requested\"] = dist.requested\n        return res\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\install.py": {
      "sha": "a4599da7ea16",
      "lines": 793,
      "head": "import errno\nimport json\nimport operator\nimport os\nimport shutil\nimport site\nfrom optparse import SUPPRESS_HELP, Values\nfrom typing import List, Optional\n\nfrom pip._vendor.packaging.utils import canonicalize_name\nfrom pip._vendor.requests.exceptions import InvalidProxyURL\nfrom pip._vendor.rich import print_json\n\n# Eagerly import self_outdated_check to avoid crashes. Otherwise,\n# this module would be imported *after* pip was replaced, resulting\n# in crashes if the new self_outdated_check module was incompatible\n# with the rest of pip that's already imported, or allowing a\n# wheel to execute arbitrary code on install by replacing\n# self_outdated_check.\nimport pip._internal.self_outdated_check  # noqa: F401\nfrom pip._internal.cache import WheelCache\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.cmdoptions import make_target_python\nfrom pip._internal.cli.req_command import (\n    RequirementCommand,\n    with_cleanup,\n)\nfrom pip._internal.cli.status_codes import ERROR, SUCCESS\nfrom pip._internal.exceptions import CommandError, InstallationError\nfrom pip._internal.locations import get_scheme\nfrom pip._internal.metadata import get_environment\nfrom pip._internal.models.installation_report import InstallationReport\nfrom pip._internal.operations.build.build_tracker import get_build_tracker\nfrom pip._internal.operations.check import ConflictDetails, check_install_conflicts\nfrom pip._internal.req import install_given_reqs\nfrom pip._internal.req.req_install import (\n    InstallRequirement,\n    check_legacy_setup_py_options,\n)\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.filesystem import test_writable_dir\nfrom pip._internal.utils.logging import getLogger\nfrom pip._internal.utils.misc import (\n    check_externally_managed,\n    ensure_dir,\n    get_pip_version,\n    protect_pip_from_modification_on_windows,\n    warn_if_run_as_root,\n    write_output,\n)\nfrom pip._internal.utils.temp_dir import TempDirectory\nfrom pip._internal.utils.virtualenv import (\n    running_under_virtualenv,\n    virtualenv_no_global,\n)\nfrom pip._internal.wheel_builder import build, should_build_for_install_command\n\nlogger = getLogger(__name__)\n\n\nclass InstallCommand(RequirementCommand):\n    \"\"\"\n    Install packages from:\n\n    - PyPI (and other indexes) using requirement specifiers.\n    - VCS project urls.\n    - Local project directories.\n    - Local or remote source archives.\n\n    pip also supports installing from \"requirements files\", which provide\n    an easy way to specify a whole environment to be installed.\n    \"\"\"\n\n    usage = \"\"\"\n      %prog [options] <requirement specifier> [package-index-options] ...\n      %prog [options] -r <requirements file> [package-index-options] ...\n      %prog [options] [-e] <vcs project url> ...\n      %prog [options] [-e] <local project path> ...\n      %prog [options] <archive url/path> ...\"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(cmdoptions.requirements())\n        self.cmd_opts.add_option(cmdoptions.constraints())\n        self.cmd_opts.add_option(cmdoptions.no_deps())\n        self.cmd_opts.add_option(cmdoptions.pre())\n\n        self.cmd_opts.add_option(cmdoptions.editable())\n        self.cmd_opts.add_option(\n            \"--dry-run\",\n            action=\"store_true\",\n            dest=\"dry_run\",\n            default=False,\n            help=(\n                \"Don't actually install anything, just print what would be. \"\n                \"Can be used in combination with --ignore-installed \"\n                \"to 'resolve' the requirements.\"\n            ),\n        )\n        self.cmd_opts.add_option(\n            \"-t\",\n            \"--target\",\n            dest=\"target_dir\",\n            metavar=\"dir\",\n            default=None,\n            help=(\n                \"Install packages into <dir>. \"\n                \"By default this will not replace existing files/folders in \"\n                \"<dir>. Use --upgrade to replace existing packages in <dir> \"\n                \"with new versions.\"\n            ),\n        )\n        cmdoptions.add_target_python_options(self.cmd_opts)\n\n        self.cmd_opts.add_option(\n            \"--user\",\n            dest=\"use_user_site\",\n            action=\"store_true\",\n            help=(\n                \"Install to the Python user install directory for your \"\n                \"platform. Typically ~/.local/, or %APPDATA%\\\\Python on \"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\list.py": {
      "sha": "300bbeb41eec",
      "lines": 391,
      "head": "import json\nimport logging\nfrom email.parser import Parser\nfrom optparse import Values\nfrom typing import TYPE_CHECKING, Generator, List, Optional, Sequence, Tuple, cast\n\nfrom pip._vendor.packaging.utils import canonicalize_name\nfrom pip._vendor.packaging.version import Version\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.index_command import IndexGroupCommand\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.exceptions import CommandError\nfrom pip._internal.metadata import BaseDistribution, get_environment\nfrom pip._internal.models.selection_prefs import SelectionPreferences\nfrom pip._internal.utils.compat import stdlib_pkgs\nfrom pip._internal.utils.misc import tabulate, write_output\n\nif TYPE_CHECKING:\n    from pip._internal.index.package_finder import PackageFinder\n    from pip._internal.network.session import PipSession\n\n    class _DistWithLatestInfo(BaseDistribution):\n        \"\"\"Give the distribution object a couple of extra fields.\n\n        These will be populated during ``get_outdated()``. This is dirty but\n        makes the rest of the code much cleaner.\n        \"\"\"\n\n        latest_version: Version\n        latest_filetype: str\n\n    _ProcessedDists = Sequence[_DistWithLatestInfo]\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass ListCommand(IndexGroupCommand):\n    \"\"\"\n    List installed packages, including editables.\n\n    Packages are listed in a case-insensitive sorted order.\n    \"\"\"\n\n    ignore_require_venv = True\n    usage = \"\"\"\n      %prog [options]\"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"-o\",\n            \"--outdated\",\n            action=\"store_true\",\n            default=False,\n            help=\"List outdated packages\",\n        )\n        self.cmd_opts.add_option(\n            \"-u\",\n            \"--uptodate\",\n            action=\"store_true\",\n            default=False,\n            help=\"List uptodate packages\",\n        )\n        self.cmd_opts.add_option(\n            \"-e\",\n            \"--editable\",\n            action=\"store_true\",\n            default=False,\n            help=\"List editable projects.\",\n        )\n        self.cmd_opts.add_option(\n            \"-l\",\n            \"--local\",\n            action=\"store_true\",\n            default=False,\n            help=(\n                \"If in a virtualenv that has global access, do not list \"\n                \"globally-installed packages.\"\n            ),\n        )\n        self.cmd_opts.add_option(\n            \"--user\",\n            dest=\"user\",\n            action=\"store_true\",\n            default=False,\n            help=\"Only output packages installed in user-site.\",\n        )\n        self.cmd_opts.add_option(cmdoptions.list_path())\n        self.cmd_opts.add_option(\n            \"--pre\",\n            action=\"store_true\",\n            default=False,\n            help=(\n                \"Include pre-release and development versions. By default, \"\n                \"pip only finds stable versions.\"\n            ),\n        )\n\n        self.cmd_opts.add_option(\n            \"--format\",\n            action=\"store\",\n            dest=\"list_format\",\n            default=\"columns\",\n            choices=(\"columns\", \"freeze\", \"json\"),\n            help=(\n                \"Select the output format among: columns (default), freeze, or json. \"\n                \"The 'freeze' format cannot be used with the --outdated option.\"\n            ),\n        )\n\n        self.cmd_opts.add_option(\n            \"--not-required\",\n            action=\"store_true\",\n            dest=\"not_required\",\n            help=\"List packages that are not dependencies of installed packages.\",\n        )\n\n        self.cmd_opts.add_option(\n            \"--exclude-editable\",\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\lock.py": {
      "sha": "b8927d7c54ee",
      "lines": 171,
      "head": "import sys\nfrom optparse import Values\nfrom pathlib import Path\nfrom typing import List\n\nfrom pip._internal.cache import WheelCache\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.req_command import (\n    RequirementCommand,\n    with_cleanup,\n)\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.models.pylock import Pylock, is_valid_pylock_file_name\nfrom pip._internal.operations.build.build_tracker import get_build_tracker\nfrom pip._internal.req.req_install import (\n    check_legacy_setup_py_options,\n)\nfrom pip._internal.utils.logging import getLogger\nfrom pip._internal.utils.misc import (\n    get_pip_version,\n)\nfrom pip._internal.utils.temp_dir import TempDirectory\n\nlogger = getLogger(__name__)\n\n\nclass LockCommand(RequirementCommand):\n    \"\"\"\n    EXPERIMENTAL - Lock packages and their dependencies from:\n\n    - PyPI (and other indexes) using requirement specifiers.\n    - VCS project urls.\n    - Local project directories.\n    - Local or remote source archives.\n\n    pip also supports locking from \"requirements files\", which provide an easy\n    way to specify a whole environment to be installed.\n\n    The generated lock file is only guaranteed to be valid for the current\n    python version and platform.\n    \"\"\"\n\n    usage = \"\"\"\n      %prog [options] [-e] <local project path> ...\n      %prog [options] <requirement specifier> [package-index-options] ...\n      %prog [options] -r <requirements file> [package-index-options] ...\n      %prog [options] <archive url/path> ...\"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            cmdoptions.PipOption(\n                \"--output\",\n                \"-o\",\n                dest=\"output_file\",\n                metavar=\"path\",\n                type=\"path\",\n                default=\"pylock.toml\",\n                help=\"Lock file name (default=pylock.toml). Use - for stdout.\",\n            )\n        )\n        self.cmd_opts.add_option(cmdoptions.requirements())\n        self.cmd_opts.add_option(cmdoptions.constraints())\n        self.cmd_opts.add_option(cmdoptions.no_deps())\n        self.cmd_opts.add_option(cmdoptions.pre())\n\n        self.cmd_opts.add_option(cmdoptions.editable())\n\n        self.cmd_opts.add_option(cmdoptions.src())\n\n        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())\n        self.cmd_opts.add_option(cmdoptions.no_build_isolation())\n        self.cmd_opts.add_option(cmdoptions.use_pep517())\n        self.cmd_opts.add_option(cmdoptions.no_use_pep517())\n        self.cmd_opts.add_option(cmdoptions.check_build_deps())\n\n        self.cmd_opts.add_option(cmdoptions.config_settings())\n\n        self.cmd_opts.add_option(cmdoptions.no_binary())\n        self.cmd_opts.add_option(cmdoptions.only_binary())\n        self.cmd_opts.add_option(cmdoptions.prefer_binary())\n        self.cmd_opts.add_option(cmdoptions.require_hashes())\n        self.cmd_opts.add_option(cmdoptions.progress_bar())\n\n        index_opts = cmdoptions.make_option_group(\n            cmdoptions.index_group,\n            self.parser,\n        )\n\n        self.parser.insert_option_group(0, index_opts)\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    @with_cleanup\n    def run(self, options: Values, args: List[str]) -> int:\n        logger.verbose(\"Using %s\", get_pip_version())\n\n        logger.warning(\n            \"pip lock is currently an experimental command. \"\n            \"It may be removed/changed in a future release \"\n            \"without prior warning.\"\n        )\n\n        session = self.get_default_session(options)\n\n        finder = self._build_package_finder(\n            options=options,\n            session=session,\n            ignore_requires_python=options.ignore_requires_python,\n        )\n        build_tracker = self.enter_context(get_build_tracker())\n\n        directory = TempDirectory(\n            delete=not options.no_clean,\n            kind=\"install\",\n            globally_managed=True,\n        )\n\n        reqs = self.get_requirements(args, options, finder, session)\n        check_legacy_setup_py_options(options, reqs)\n\n        wheel_cache = WheelCache(options.cache_dir)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\search.py": {
      "sha": "c967b7ed7e0c",
      "lines": 176,
      "head": "import logging\nimport shutil\nimport sys\nimport textwrap\nimport xmlrpc.client\nfrom collections import OrderedDict\nfrom optparse import Values\nfrom typing import Dict, List, Optional, TypedDict\n\nfrom pip._vendor.packaging.version import parse as parse_version\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.req_command import SessionCommandMixin\nfrom pip._internal.cli.status_codes import NO_MATCHES_FOUND, SUCCESS\nfrom pip._internal.exceptions import CommandError\nfrom pip._internal.metadata import get_default_environment\nfrom pip._internal.metadata.base import BaseDistribution\nfrom pip._internal.models.index import PyPI\nfrom pip._internal.network.xmlrpc import PipXmlrpcTransport\nfrom pip._internal.utils.logging import indent_log\nfrom pip._internal.utils.misc import write_output\n\n\nclass TransformedHit(TypedDict):\n    name: str\n    summary: str\n    versions: List[str]\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass SearchCommand(Command, SessionCommandMixin):\n    \"\"\"Search for PyPI packages whose name or summary contains <query>.\"\"\"\n\n    usage = \"\"\"\n      %prog [options] <query>\"\"\"\n    ignore_require_venv = True\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"-i\",\n            \"--index\",\n            dest=\"index\",\n            metavar=\"URL\",\n            default=PyPI.pypi_url,\n            help=\"Base URL of Python Package Index (default %default)\",\n        )\n\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        if not args:\n            raise CommandError(\"Missing required argument (search query).\")\n        query = args\n        pypi_hits = self.search(query, options)\n        hits = transform_hits(pypi_hits)\n\n        terminal_width = None\n        if sys.stdout.isatty():\n            terminal_width = shutil.get_terminal_size()[0]\n\n        print_results(hits, terminal_width=terminal_width)\n        if pypi_hits:\n            return SUCCESS\n        return NO_MATCHES_FOUND\n\n    def search(self, query: List[str], options: Values) -> List[Dict[str, str]]:\n        index_url = options.index\n\n        session = self.get_default_session(options)\n\n        transport = PipXmlrpcTransport(index_url, session)\n        pypi = xmlrpc.client.ServerProxy(index_url, transport)\n        try:\n            hits = pypi.search({\"name\": query, \"summary\": query}, \"or\")\n        except xmlrpc.client.Fault as fault:\n            message = (\n                f\"XMLRPC request failed [code: {fault.faultCode}]\\n{fault.faultString}\"\n            )\n            raise CommandError(message)\n        assert isinstance(hits, list)\n        return hits\n\n\ndef transform_hits(hits: List[Dict[str, str]]) -> List[\"TransformedHit\"]:\n    \"\"\"\n    The list from pypi is really a list of versions. We want a list of\n    packages with the list of versions stored inline. This converts the\n    list from pypi into one we can use.\n    \"\"\"\n    packages: Dict[str, TransformedHit] = OrderedDict()\n    for hit in hits:\n        name = hit[\"name\"]\n        summary = hit[\"summary\"]\n        version = hit[\"version\"]\n\n        if name not in packages.keys():\n            packages[name] = {\n                \"name\": name,\n                \"summary\": summary,\n                \"versions\": [version],\n            }\n        else:\n            packages[name][\"versions\"].append(version)\n\n            # if this is the highest version, replace summary and score\n            if version == highest_version(packages[name][\"versions\"]):\n                packages[name][\"summary\"] = summary\n\n    return list(packages.values())\n\n\ndef print_dist_installation_info(latest: str, dist: Optional[BaseDistribution]) -> None:\n    if dist is not None:\n        with indent_log():\n            if dist.version == latest:\n                write_output(\"INSTALLED: %s (latest)\", dist.version)\n            else:\n                write_output(\"INSTALLED: %s\", dist.version)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\show.py": {
      "sha": "9a80bfd2c960",
      "lines": 228,
      "head": "import logging\nimport string\nfrom optparse import Values\nfrom typing import Generator, Iterable, Iterator, List, NamedTuple, Optional\n\nfrom pip._vendor.packaging.requirements import InvalidRequirement\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import ERROR, SUCCESS\nfrom pip._internal.metadata import BaseDistribution, get_default_environment\nfrom pip._internal.utils.misc import write_output\n\nlogger = logging.getLogger(__name__)\n\n\ndef normalize_project_url_label(label: str) -> str:\n    # This logic is from PEP 753 (Well-known Project URLs in Metadata).\n    chars_to_remove = string.punctuation + string.whitespace\n    removal_map = str.maketrans(\"\", \"\", chars_to_remove)\n    return label.translate(removal_map).lower()\n\n\nclass ShowCommand(Command):\n    \"\"\"\n    Show information about one or more installed packages.\n\n    The output is in RFC-compliant mail header format.\n    \"\"\"\n\n    usage = \"\"\"\n      %prog [options] <package> ...\"\"\"\n    ignore_require_venv = True\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"-f\",\n            \"--files\",\n            dest=\"files\",\n            action=\"store_true\",\n            default=False,\n            help=\"Show the full list of installed files for each package.\",\n        )\n\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        if not args:\n            logger.warning(\"ERROR: Please provide a package name or names.\")\n            return ERROR\n        query = args\n\n        results = search_packages_info(query)\n        if not print_results(\n            results, list_files=options.files, verbose=options.verbose\n        ):\n            return ERROR\n        return SUCCESS\n\n\nclass _PackageInfo(NamedTuple):\n    name: str\n    version: str\n    location: str\n    editable_project_location: Optional[str]\n    requires: List[str]\n    required_by: List[str]\n    installer: str\n    metadata_version: str\n    classifiers: List[str]\n    summary: str\n    homepage: str\n    project_urls: List[str]\n    author: str\n    author_email: str\n    license: str\n    license_expression: str\n    entry_points: List[str]\n    files: Optional[List[str]]\n\n\ndef search_packages_info(query: List[str]) -> Generator[_PackageInfo, None, None]:\n    \"\"\"\n    Gather details from installed distributions. Print distribution name,\n    version, location, and installed files. Installed files requires a\n    pip generated 'installed-files.txt' in the distributions '.egg-info'\n    directory.\n    \"\"\"\n    env = get_default_environment()\n\n    installed = {dist.canonical_name: dist for dist in env.iter_all_distributions()}\n    query_names = [canonicalize_name(name) for name in query]\n    missing = sorted(\n        [name for name, pkg in zip(query, query_names) if pkg not in installed]\n    )\n    if missing:\n        logger.warning(\"Package(s) not found: %s\", \", \".join(missing))\n\n    def _get_requiring_packages(current_dist: BaseDistribution) -> Iterator[str]:\n        return (\n            dist.metadata[\"Name\"] or \"UNKNOWN\"\n            for dist in installed.values()\n            if current_dist.canonical_name\n            in {canonicalize_name(d.name) for d in dist.iter_dependencies()}\n        )\n\n    for query_name in query_names:\n        try:\n            dist = installed[query_name]\n        except KeyError:\n            continue\n\n        try:\n            requires = sorted(\n                # Avoid duplicates in requirements (e.g. due to environment markers).\n                {req.name for req in dist.iter_dependencies()},\n                key=str.lower,\n            )\n        except InvalidRequirement:\n            requires = sorted(dist.iter_raw_dependencies(), key=str.lower)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\uninstall.py": {
      "sha": "0e7b34f7cb0f",
      "lines": 114,
      "head": "import logging\nfrom optparse import Values\nfrom typing import List\n\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.index_command import SessionCommandMixin\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.exceptions import InstallationError\nfrom pip._internal.req import parse_requirements\nfrom pip._internal.req.constructors import (\n    install_req_from_line,\n    install_req_from_parsed_requirement,\n)\nfrom pip._internal.utils.misc import (\n    check_externally_managed,\n    protect_pip_from_modification_on_windows,\n    warn_if_run_as_root,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nclass UninstallCommand(Command, SessionCommandMixin):\n    \"\"\"\n    Uninstall packages.\n\n    pip is able to uninstall most installed packages. Known exceptions are:\n\n    - Pure distutils packages installed with ``python setup.py install``, which\n      leave behind no metadata to determine what files were installed.\n    - Script wrappers installed by ``python setup.py develop``.\n    \"\"\"\n\n    usage = \"\"\"\n      %prog [options] <package> ...\n      %prog [options] -r <requirements file> ...\"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"-r\",\n            \"--requirement\",\n            dest=\"requirements\",\n            action=\"append\",\n            default=[],\n            metavar=\"file\",\n            help=(\n                \"Uninstall all the packages listed in the given requirements \"\n                \"file.  This option can be used multiple times.\"\n            ),\n        )\n        self.cmd_opts.add_option(\n            \"-y\",\n            \"--yes\",\n            dest=\"yes\",\n            action=\"store_true\",\n            help=\"Don't ask for confirmation of uninstall deletions.\",\n        )\n        self.cmd_opts.add_option(cmdoptions.root_user_action())\n        self.cmd_opts.add_option(cmdoptions.override_externally_managed())\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        session = self.get_default_session(options)\n\n        reqs_to_uninstall = {}\n        for name in args:\n            req = install_req_from_line(\n                name,\n                isolated=options.isolated_mode,\n            )\n            if req.name:\n                reqs_to_uninstall[canonicalize_name(req.name)] = req\n            else:\n                logger.warning(\n                    \"Invalid requirement: %r ignored -\"\n                    \" the uninstall command expects named\"\n                    \" requirements.\",\n                    name,\n                )\n        for filename in options.requirements:\n            for parsed_req in parse_requirements(\n                filename, options=options, session=session\n            ):\n                req = install_req_from_parsed_requirement(\n                    parsed_req, isolated=options.isolated_mode\n                )\n                if req.name:\n                    reqs_to_uninstall[canonicalize_name(req.name)] = req\n        if not reqs_to_uninstall:\n            raise InstallationError(\n                f\"You must give at least one requirement to {self.name} (see \"\n                f'\"pip help {self.name}\")'\n            )\n\n        if not options.override_externally_managed:\n            check_externally_managed()\n\n        protect_pip_from_modification_on_windows(\n            modifying_pip=\"pip\" in reqs_to_uninstall\n        )\n\n        for req in reqs_to_uninstall.values():\n            uninstall_pathset = req.uninstall(\n                auto_confirm=options.yes,\n                verbose=self.verbosity > 0,\n            )\n            if uninstall_pathset:\n                uninstall_pathset.commit()\n        if options.root_user_action == \"warn\":\n            warn_if_run_as_root()\n        return SUCCESS\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\wheel.py": {
      "sha": "cd89427184a5",
      "lines": 182,
      "head": "import logging\nimport os\nimport shutil\nfrom optparse import Values\nfrom typing import List\n\nfrom pip._internal.cache import WheelCache\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.req_command import RequirementCommand, with_cleanup\nfrom pip._internal.cli.status_codes import SUCCESS\nfrom pip._internal.exceptions import CommandError\nfrom pip._internal.operations.build.build_tracker import get_build_tracker\nfrom pip._internal.req.req_install import (\n    InstallRequirement,\n    check_legacy_setup_py_options,\n)\nfrom pip._internal.utils.misc import ensure_dir, normalize_path\nfrom pip._internal.utils.temp_dir import TempDirectory\nfrom pip._internal.wheel_builder import build\n\nlogger = logging.getLogger(__name__)\n\n\nclass WheelCommand(RequirementCommand):\n    \"\"\"\n    Build Wheel archives for your requirements and dependencies.\n\n    Wheel is a built-package format, and offers the advantage of not\n    recompiling your software during every install. For more details, see the\n    wheel docs: https://wheel.readthedocs.io/en/latest/\n\n    'pip wheel' uses the build system interface as described here:\n    https://pip.pypa.io/en/stable/reference/build-system/\n\n    \"\"\"\n\n    usage = \"\"\"\n      %prog [options] <requirement specifier> ...\n      %prog [options] -r <requirements file> ...\n      %prog [options] [-e] <vcs project url> ...\n      %prog [options] [-e] <local project path> ...\n      %prog [options] <archive url/path> ...\"\"\"\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"-w\",\n            \"--wheel-dir\",\n            dest=\"wheel_dir\",\n            metavar=\"dir\",\n            default=os.curdir,\n            help=(\n                \"Build wheels into <dir>, where the default is the \"\n                \"current working directory.\"\n            ),\n        )\n        self.cmd_opts.add_option(cmdoptions.no_binary())\n        self.cmd_opts.add_option(cmdoptions.only_binary())\n        self.cmd_opts.add_option(cmdoptions.prefer_binary())\n        self.cmd_opts.add_option(cmdoptions.no_build_isolation())\n        self.cmd_opts.add_option(cmdoptions.use_pep517())\n        self.cmd_opts.add_option(cmdoptions.no_use_pep517())\n        self.cmd_opts.add_option(cmdoptions.check_build_deps())\n        self.cmd_opts.add_option(cmdoptions.constraints())\n        self.cmd_opts.add_option(cmdoptions.editable())\n        self.cmd_opts.add_option(cmdoptions.requirements())\n        self.cmd_opts.add_option(cmdoptions.src())\n        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())\n        self.cmd_opts.add_option(cmdoptions.no_deps())\n        self.cmd_opts.add_option(cmdoptions.progress_bar())\n\n        self.cmd_opts.add_option(\n            \"--no-verify\",\n            dest=\"no_verify\",\n            action=\"store_true\",\n            default=False,\n            help=\"Don't verify if built wheel is valid.\",\n        )\n\n        self.cmd_opts.add_option(cmdoptions.config_settings())\n        self.cmd_opts.add_option(cmdoptions.build_options())\n        self.cmd_opts.add_option(cmdoptions.global_options())\n\n        self.cmd_opts.add_option(\n            \"--pre\",\n            action=\"store_true\",\n            default=False,\n            help=(\n                \"Include pre-release and development versions. By default, \"\n                \"pip only finds stable versions.\"\n            ),\n        )\n\n        self.cmd_opts.add_option(cmdoptions.require_hashes())\n\n        index_opts = cmdoptions.make_option_group(\n            cmdoptions.index_group,\n            self.parser,\n        )\n\n        self.parser.insert_option_group(0, index_opts)\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    @with_cleanup\n    def run(self, options: Values, args: List[str]) -> int:\n        session = self.get_default_session(options)\n\n        finder = self._build_package_finder(options, session)\n\n        options.wheel_dir = normalize_path(options.wheel_dir)\n        ensure_dir(options.wheel_dir)\n\n        build_tracker = self.enter_context(get_build_tracker())\n\n        directory = TempDirectory(\n            delete=not options.no_clean,\n            kind=\"wheel\",\n            globally_managed=True,\n        )\n\n        reqs = self.get_requirements(args, options, finder, session)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\commands\\__init__.py": {
      "sha": "ca7db98f1c0b",
      "lines": 137,
      "head": "\"\"\"\nPackage containing all pip commands\n\"\"\"\n\nimport importlib\nfrom collections import namedtuple\nfrom typing import Any, Dict, Optional\n\nfrom pip._internal.cli.base_command import Command\n\nCommandInfo = namedtuple(\"CommandInfo\", \"module_path, class_name, summary\")\n\n# This dictionary does a bunch of heavy lifting for help output:\n# - Enables avoiding additional (costly) imports for presenting `--help`.\n# - The ordering matters for help display.\n#\n# Even though the module path starts with the same \"pip._internal.commands\"\n# prefix, the full path makes testing easier (specifically when modifying\n# `commands_dict` in test setup / teardown).\ncommands_dict: Dict[str, CommandInfo] = {\n    \"install\": CommandInfo(\n        \"pip._internal.commands.install\",\n        \"InstallCommand\",\n        \"Install packages.\",\n    ),\n    \"lock\": CommandInfo(\n        \"pip._internal.commands.lock\",\n        \"LockCommand\",\n        \"Generate a lock file.\",\n    ),\n    \"download\": CommandInfo(\n        \"pip._internal.commands.download\",\n        \"DownloadCommand\",\n        \"Download packages.\",\n    ),\n    \"uninstall\": CommandInfo(\n        \"pip._internal.commands.uninstall\",\n        \"UninstallCommand\",\n        \"Uninstall packages.\",\n    ),\n    \"freeze\": CommandInfo(\n        \"pip._internal.commands.freeze\",\n        \"FreezeCommand\",\n        \"Output installed packages in requirements format.\",\n    ),\n    \"inspect\": CommandInfo(\n        \"pip._internal.commands.inspect\",\n        \"InspectCommand\",\n        \"Inspect the python environment.\",\n    ),\n    \"list\": CommandInfo(\n        \"pip._internal.commands.list\",\n        \"ListCommand\",\n        \"List installed packages.\",\n    ),\n    \"show\": CommandInfo(\n        \"pip._internal.commands.show\",\n        \"ShowCommand\",\n        \"Show information about installed packages.\",\n    ),\n    \"check\": CommandInfo(\n        \"pip._internal.commands.check\",\n        \"CheckCommand\",\n        \"Verify installed packages have compatible dependencies.\",\n    ),\n    \"config\": CommandInfo(\n        \"pip._internal.commands.configuration\",\n        \"ConfigurationCommand\",\n        \"Manage local and global configuration.\",\n    ),\n    \"search\": CommandInfo(\n        \"pip._internal.commands.search\",\n        \"SearchCommand\",\n        \"Search PyPI for packages.\",\n    ),\n    \"cache\": CommandInfo(\n        \"pip._internal.commands.cache\",\n        \"CacheCommand\",\n        \"Inspect and manage pip's wheel cache.\",\n    ),\n    \"index\": CommandInfo(\n        \"pip._internal.commands.index\",\n        \"IndexCommand\",\n        \"Inspect information available from package indexes.\",\n    ),\n    \"wheel\": CommandInfo(\n        \"pip._internal.commands.wheel\",\n        \"WheelCommand\",\n        \"Build wheels from your requirements.\",\n    ),\n    \"hash\": CommandInfo(\n        \"pip._internal.commands.hash\",\n        \"HashCommand\",\n        \"Compute hashes of package archives.\",\n    ),\n    \"completion\": CommandInfo(\n        \"pip._internal.commands.completion\",\n        \"CompletionCommand\",\n        \"A helper command used for command completion.\",\n    ),\n    \"debug\": CommandInfo(\n        \"pip._internal.commands.debug\",\n        \"DebugCommand\",\n        \"Show information useful for debugging.\",\n    ),\n    \"help\": CommandInfo(\n        \"pip._internal.commands.help\",\n        \"HelpCommand\",\n        \"Show help for commands.\",\n    ),\n}\n\n\ndef create_command(name: str, **kwargs: Any) -> Command:\n    \"\"\"\n    Create an instance of the Command class with the given name.\n    \"\"\"\n    module_path, class_name, summary = commands_dict[name]\n    module = importlib.import_module(module_path)\n    command_class = getattr(module, class_name)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\base.py": {
      "sha": "8d155b14c993",
      "lines": 53,
      "head": "import abc\nfrom typing import TYPE_CHECKING, Optional\n\nfrom pip._internal.metadata.base import BaseDistribution\nfrom pip._internal.req import InstallRequirement\n\nif TYPE_CHECKING:\n    from pip._internal.index.package_finder import PackageFinder\n\n\nclass AbstractDistribution(metaclass=abc.ABCMeta):\n    \"\"\"A base class for handling installable artifacts.\n\n    The requirements for anything installable are as follows:\n\n     - we must be able to determine the requirement name\n       (or we can't correctly handle the non-upgrade case).\n\n     - for packages with setup requirements, we must also be able\n       to determine their requirements without installing additional\n       packages (for the same reason as run-time dependencies)\n\n     - we must be able to create a Distribution object exposing the\n       above metadata.\n\n     - if we need to do work in the build tracker, we must be able to generate a unique\n       string to identify the requirement in the build tracker.\n    \"\"\"\n\n    def __init__(self, req: InstallRequirement) -> None:\n        super().__init__()\n        self.req = req\n\n    @abc.abstractproperty\n    def build_tracker_id(self) -> Optional[str]:\n        \"\"\"A string that uniquely identifies this requirement to the build tracker.\n\n        If None, then this dist has no work to do in the build tracker, and\n        ``.prepare_distribution_metadata()`` will not be called.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def get_metadata_distribution(self) -> BaseDistribution:\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def prepare_distribution_metadata(\n        self,\n        finder: \"PackageFinder\",\n        build_isolation: bool,\n        check_build_deps: bool,\n    ) -> None:\n        raise NotImplementedError()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\installed.py": {
      "sha": "d324a8c68f8a",
      "lines": 29,
      "head": "from typing import Optional\n\nfrom pip._internal.distributions.base import AbstractDistribution\nfrom pip._internal.index.package_finder import PackageFinder\nfrom pip._internal.metadata import BaseDistribution\n\n\nclass InstalledDistribution(AbstractDistribution):\n    \"\"\"Represents an installed package.\n\n    This does not need any preparation as the required information has already\n    been computed.\n    \"\"\"\n\n    @property\n    def build_tracker_id(self) -> Optional[str]:\n        return None\n\n    def get_metadata_distribution(self) -> BaseDistribution:\n        assert self.req.satisfied_by is not None, \"not actually installed\"\n        return self.req.satisfied_by\n\n    def prepare_distribution_metadata(\n        self,\n        finder: PackageFinder,\n        build_isolation: bool,\n        check_build_deps: bool,\n    ) -> None:\n        pass\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py": {
      "sha": "77e02a0ac12b",
      "lines": 158,
      "head": "import logging\nfrom typing import TYPE_CHECKING, Iterable, Optional, Set, Tuple\n\nfrom pip._internal.build_env import BuildEnvironment\nfrom pip._internal.distributions.base import AbstractDistribution\nfrom pip._internal.exceptions import InstallationError\nfrom pip._internal.metadata import BaseDistribution\nfrom pip._internal.utils.subprocess import runner_with_spinner_message\n\nif TYPE_CHECKING:\n    from pip._internal.index.package_finder import PackageFinder\n\nlogger = logging.getLogger(__name__)\n\n\nclass SourceDistribution(AbstractDistribution):\n    \"\"\"Represents a source distribution.\n\n    The preparation step for these needs metadata for the packages to be\n    generated, either using PEP 517 or using the legacy `setup.py egg_info`.\n    \"\"\"\n\n    @property\n    def build_tracker_id(self) -> Optional[str]:\n        \"\"\"Identify this requirement uniquely by its link.\"\"\"\n        assert self.req.link\n        return self.req.link.url_without_fragment\n\n    def get_metadata_distribution(self) -> BaseDistribution:\n        return self.req.get_dist()\n\n    def prepare_distribution_metadata(\n        self,\n        finder: \"PackageFinder\",\n        build_isolation: bool,\n        check_build_deps: bool,\n    ) -> None:\n        # Load pyproject.toml, to determine whether PEP 517 is to be used\n        self.req.load_pyproject_toml()\n\n        # Set up the build isolation, if this requirement should be isolated\n        should_isolate = self.req.use_pep517 and build_isolation\n        if should_isolate:\n            # Setup an isolated environment and install the build backend static\n            # requirements in it.\n            self._prepare_build_backend(finder)\n            # Check that if the requirement is editable, it either supports PEP 660 or\n            # has a setup.py or a setup.cfg. This cannot be done earlier because we need\n            # to setup the build backend to verify it supports build_editable, nor can\n            # it be done later, because we want to avoid installing build requirements\n            # needlessly. Doing it here also works around setuptools generating\n            # UNKNOWN.egg-info when running get_requires_for_build_wheel on a directory\n            # without setup.py nor setup.cfg.\n            self.req.isolated_editable_sanity_check()\n            # Install the dynamic build requirements.\n            self._install_build_reqs(finder)\n        # Check if the current environment provides build dependencies\n        should_check_deps = self.req.use_pep517 and check_build_deps\n        if should_check_deps:\n            pyproject_requires = self.req.pyproject_requires\n            assert pyproject_requires is not None\n            conflicting, missing = self.req.build_env.check_requirements(\n                pyproject_requires\n            )\n            if conflicting:\n                self._raise_conflicts(\"the backend dependencies\", conflicting)\n            if missing:\n                self._raise_missing_reqs(missing)\n        self.req.prepare_metadata()\n\n    def _prepare_build_backend(self, finder: \"PackageFinder\") -> None:\n        # Isolate in a BuildEnvironment and install the build-time\n        # requirements.\n        pyproject_requires = self.req.pyproject_requires\n        assert pyproject_requires is not None\n\n        self.req.build_env = BuildEnvironment()\n        self.req.build_env.install_requirements(\n            finder, pyproject_requires, \"overlay\", kind=\"build dependencies\"\n        )\n        conflicting, missing = self.req.build_env.check_requirements(\n            self.req.requirements_to_check\n        )\n        if conflicting:\n            self._raise_conflicts(\"PEP 517/518 supported requirements\", conflicting)\n        if missing:\n            logger.warning(\n                \"Missing build requirements in pyproject.toml for %s.\",\n                self.req,\n            )\n            logger.warning(\n                \"The project does not specify a build backend, and \"\n                \"pip cannot fall back to setuptools without %s.\",\n                \" and \".join(map(repr, sorted(missing))),\n            )\n\n    def _get_build_requires_wheel(self) -> Iterable[str]:\n        with self.req.build_env:\n            runner = runner_with_spinner_message(\"Getting requirements to build wheel\")\n            backend = self.req.pep517_backend\n            assert backend is not None\n            with backend.subprocess_runner(runner):\n                return backend.get_requires_for_build_wheel()\n\n    def _get_build_requires_editable(self) -> Iterable[str]:\n        with self.req.build_env:\n            runner = runner_with_spinner_message(\n                \"Getting requirements to build editable\"\n            )\n            backend = self.req.pep517_backend\n            assert backend is not None\n            with backend.subprocess_runner(runner):\n                return backend.get_requires_for_build_editable()\n\n    def _install_build_reqs(self, finder: \"PackageFinder\") -> None:\n        # Install any extra build dependencies that the backend requests.\n        # This must be done in a second pass, as the pyproject.toml\n        # dependencies must be installed before we can call the backend.\n        if (\n            self.req.editable\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\wheel.py": {
      "sha": "4b434ee9ebae",
      "lines": 42,
      "head": "from typing import TYPE_CHECKING, Optional\n\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.distributions.base import AbstractDistribution\nfrom pip._internal.metadata import (\n    BaseDistribution,\n    FilesystemWheel,\n    get_wheel_distribution,\n)\n\nif TYPE_CHECKING:\n    from pip._internal.index.package_finder import PackageFinder\n\n\nclass WheelDistribution(AbstractDistribution):\n    \"\"\"Represents a wheel distribution.\n\n    This does not need any preparation as wheels can be directly unpacked.\n    \"\"\"\n\n    @property\n    def build_tracker_id(self) -> Optional[str]:\n        return None\n\n    def get_metadata_distribution(self) -> BaseDistribution:\n        \"\"\"Loads the metadata from the wheel file into memory and returns a\n        Distribution that uses it, not relying on the wheel file or\n        requirement.\n        \"\"\"\n        assert self.req.local_file_path, \"Set as part of preparation during download\"\n        assert self.req.name, \"Wheels are never unnamed\"\n        wheel = FilesystemWheel(self.req.local_file_path)\n        return get_wheel_distribution(wheel, canonicalize_name(self.req.name))\n\n    def prepare_distribution_metadata(\n        self,\n        finder: \"PackageFinder\",\n        build_isolation: bool,\n        check_build_deps: bool,\n    ) -> None:\n        pass\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\distributions\\__init__.py": {
      "sha": "cda4ca594b1a",
      "lines": 21,
      "head": "from pip._internal.distributions.base import AbstractDistribution\nfrom pip._internal.distributions.sdist import SourceDistribution\nfrom pip._internal.distributions.wheel import WheelDistribution\nfrom pip._internal.req.req_install import InstallRequirement\n\n\ndef make_distribution_for_install_requirement(\n    install_req: InstallRequirement,\n) -> AbstractDistribution:\n    \"\"\"Returns a Distribution for the given InstallRequirement\"\"\"\n    # Editable requirements will always be source distributions. They use the\n    # legacy logic until we create a modern standard for them.\n    if install_req.editable:\n        return SourceDistribution(install_req)\n\n    # If it's a wheel, it's a WheelDistribution\n    if install_req.is_wheel:\n        return WheelDistribution(install_req)\n\n    # Otherwise, a SourceDistribution\n    return SourceDistribution(install_req)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\index\\collector.py": {
      "sha": "d5809b7e772c",
      "lines": 494,
      "head": "\"\"\"\nThe main purpose of this module is to expose LinkCollector.collect_sources().\n\"\"\"\n\nimport collections\nimport email.message\nimport functools\nimport itertools\nimport json\nimport logging\nimport os\nimport urllib.parse\nimport urllib.request\nfrom dataclasses import dataclass\nfrom html.parser import HTMLParser\nfrom optparse import Values\nfrom typing import (\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    MutableMapping,\n    NamedTuple,\n    Optional,\n    Protocol,\n    Sequence,\n    Tuple,\n    Union,\n)\n\nfrom pip._vendor import requests\nfrom pip._vendor.requests import Response\nfrom pip._vendor.requests.exceptions import RetryError, SSLError\n\nfrom pip._internal.exceptions import NetworkConnectionError\nfrom pip._internal.models.link import Link\nfrom pip._internal.models.search_scope import SearchScope\nfrom pip._internal.network.session import PipSession\nfrom pip._internal.network.utils import raise_for_status\nfrom pip._internal.utils.filetypes import is_archive_file\nfrom pip._internal.utils.misc import redact_auth_from_url\nfrom pip._internal.vcs import vcs\n\nfrom .sources import CandidatesFromPage, LinkSource, build_source\n\nlogger = logging.getLogger(__name__)\n\nResponseHeaders = MutableMapping[str, str]\n\n\ndef _match_vcs_scheme(url: str) -> Optional[str]:\n    \"\"\"Look for VCS schemes in the URL.\n\n    Returns the matched VCS scheme, or None if there's no match.\n    \"\"\"\n    for scheme in vcs.schemes:\n        if url.lower().startswith(scheme) and url[len(scheme)] in \"+:\":\n            return scheme\n    return None\n\n\nclass _NotAPIContent(Exception):\n    def __init__(self, content_type: str, request_desc: str) -> None:\n        super().__init__(content_type, request_desc)\n        self.content_type = content_type\n        self.request_desc = request_desc\n\n\ndef _ensure_api_header(response: Response) -> None:\n    \"\"\"\n    Check the Content-Type header to ensure the response contains a Simple\n    API Response.\n\n    Raises `_NotAPIContent` if the content type is not a valid content-type.\n    \"\"\"\n    content_type = response.headers.get(\"Content-Type\", \"Unknown\")\n\n    content_type_l = content_type.lower()\n    if content_type_l.startswith(\n        (\n            \"text/html\",\n            \"application/vnd.pypi.simple.v1+html\",\n            \"application/vnd.pypi.simple.v1+json\",\n        )\n    ):\n        return\n\n    raise _NotAPIContent(content_type, response.request.method)\n\n\nclass _NotHTTP(Exception):\n    pass\n\n\ndef _ensure_api_response(url: str, session: PipSession) -> None:\n    \"\"\"\n    Send a HEAD request to the URL, and ensure the response contains a simple\n    API Response.\n\n    Raises `_NotHTTP` if the URL is not available for a HEAD request, or\n    `_NotAPIContent` if the content type is not a valid content type.\n    \"\"\"\n    scheme, netloc, path, query, fragment = urllib.parse.urlsplit(url)\n    if scheme not in {\"http\", \"https\"}:\n        raise _NotHTTP()\n\n    resp = session.head(url, allow_redirects=True)\n    raise_for_status(resp)\n\n    _ensure_api_header(resp)\n\n\ndef _get_simple_response(url: str, session: PipSession) -> Response:\n    \"\"\"Access an Simple API response with GET, and return the response.\n\n    This consists of three parts:\n\n    1. If the URL looks suspiciously like an archive, send a HEAD first to\n       check the Content-Type is HTML or Simple API, to avoid downloading a\n       large file. Raise `_NotHTTP` if the content type cannot be determined, or\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\index\\package_finder.py": {
      "sha": "ad4078f6a59e",
      "lines": 1050,
      "head": "\"\"\"Routines related to PyPI, indexes\"\"\"\n\nimport enum\nimport functools\nimport itertools\nimport logging\nimport re\nfrom dataclasses import dataclass\nfrom typing import (\n    TYPE_CHECKING,\n    Dict,\n    FrozenSet,\n    Iterable,\n    List,\n    Optional,\n    Set,\n    Tuple,\n    Union,\n)\n\nfrom pip._vendor.packaging import specifiers\nfrom pip._vendor.packaging.tags import Tag\nfrom pip._vendor.packaging.utils import canonicalize_name\nfrom pip._vendor.packaging.version import InvalidVersion, _BaseVersion\nfrom pip._vendor.packaging.version import parse as parse_version\n\nfrom pip._internal.exceptions import (\n    BestVersionAlreadyInstalled,\n    DistributionNotFound,\n    InvalidWheelFilename,\n    UnsupportedWheel,\n)\nfrom pip._internal.index.collector import LinkCollector, parse_links\nfrom pip._internal.models.candidate import InstallationCandidate\nfrom pip._internal.models.format_control import FormatControl\nfrom pip._internal.models.link import Link\nfrom pip._internal.models.search_scope import SearchScope\nfrom pip._internal.models.selection_prefs import SelectionPreferences\nfrom pip._internal.models.target_python import TargetPython\nfrom pip._internal.models.wheel import Wheel\nfrom pip._internal.req import InstallRequirement\nfrom pip._internal.utils._log import getLogger\nfrom pip._internal.utils.filetypes import WHEEL_EXTENSION\nfrom pip._internal.utils.hashes import Hashes\nfrom pip._internal.utils.logging import indent_log\nfrom pip._internal.utils.misc import build_netloc\nfrom pip._internal.utils.packaging import check_requires_python\nfrom pip._internal.utils.unpacking import SUPPORTED_EXTENSIONS\n\nif TYPE_CHECKING:\n    from pip._vendor.typing_extensions import TypeGuard\n\n__all__ = [\"FormatControl\", \"BestCandidateResult\", \"PackageFinder\"]\n\n\nlogger = getLogger(__name__)\n\nBuildTag = Union[Tuple[()], Tuple[int, str]]\nCandidateSortingKey = Tuple[int, int, int, _BaseVersion, Optional[int], BuildTag]\n\n\ndef _check_link_requires_python(\n    link: Link,\n    version_info: Tuple[int, int, int],\n    ignore_requires_python: bool = False,\n) -> bool:\n    \"\"\"\n    Return whether the given Python version is compatible with a link's\n    \"Requires-Python\" value.\n\n    :param version_info: A 3-tuple of ints representing the Python\n        major-minor-micro version to check.\n    :param ignore_requires_python: Whether to ignore the \"Requires-Python\"\n        value if the given Python version isn't compatible.\n    \"\"\"\n    try:\n        is_compatible = check_requires_python(\n            link.requires_python,\n            version_info=version_info,\n        )\n    except specifiers.InvalidSpecifier:\n        logger.debug(\n            \"Ignoring invalid Requires-Python (%r) for link: %s\",\n            link.requires_python,\n            link,\n        )\n    else:\n        if not is_compatible:\n            version = \".\".join(map(str, version_info))\n            if not ignore_requires_python:\n                logger.verbose(\n                    \"Link requires a different Python (%s not in: %r): %s\",\n                    version,\n                    link.requires_python,\n                    link,\n                )\n                return False\n\n            logger.debug(\n                \"Ignoring failed Requires-Python check (%s not in: %r) for link: %s\",\n                version,\n                link.requires_python,\n                link,\n            )\n\n    return True\n\n\nclass LinkType(enum.Enum):\n    candidate = enum.auto()\n    different_project = enum.auto()\n    yanked = enum.auto()\n    format_unsupported = enum.auto()\n    format_invalid = enum.auto()\n    platform_mismatch = enum.auto()\n    requires_python_mismatch = enum.auto()\n\n\nclass LinkEvaluator:\n    \"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\index\\sources.py": {
      "sha": "5889a7db3081",
      "lines": 284,
      "head": "import logging\nimport mimetypes\nimport os\nfrom collections import defaultdict\nfrom typing import Callable, Dict, Iterable, List, Optional, Tuple\n\nfrom pip._vendor.packaging.utils import (\n    InvalidSdistFilename,\n    InvalidWheelFilename,\n    canonicalize_name,\n    parse_sdist_filename,\n    parse_wheel_filename,\n)\n\nfrom pip._internal.models.candidate import InstallationCandidate\nfrom pip._internal.models.link import Link\nfrom pip._internal.utils.urls import path_to_url, url_to_path\nfrom pip._internal.vcs import is_url\n\nlogger = logging.getLogger(__name__)\n\nFoundCandidates = Iterable[InstallationCandidate]\nFoundLinks = Iterable[Link]\nCandidatesFromPage = Callable[[Link], Iterable[InstallationCandidate]]\nPageValidator = Callable[[Link], bool]\n\n\nclass LinkSource:\n    @property\n    def link(self) -> Optional[Link]:\n        \"\"\"Returns the underlying link, if there's one.\"\"\"\n        raise NotImplementedError()\n\n    def page_candidates(self) -> FoundCandidates:\n        \"\"\"Candidates found by parsing an archive listing HTML file.\"\"\"\n        raise NotImplementedError()\n\n    def file_links(self) -> FoundLinks:\n        \"\"\"Links found by specifying archives directly.\"\"\"\n        raise NotImplementedError()\n\n\ndef _is_html_file(file_url: str) -> bool:\n    return mimetypes.guess_type(file_url, strict=False)[0] == \"text/html\"\n\n\nclass _FlatDirectoryToUrls:\n    \"\"\"Scans directory and caches results\"\"\"\n\n    def __init__(self, path: str) -> None:\n        self._path = path\n        self._page_candidates: List[str] = []\n        self._project_name_to_urls: Dict[str, List[str]] = defaultdict(list)\n        self._scanned_directory = False\n\n    def _scan_directory(self) -> None:\n        \"\"\"Scans directory once and populates both page_candidates\n        and project_name_to_urls at the same time\n        \"\"\"\n        for entry in os.scandir(self._path):\n            url = path_to_url(entry.path)\n            if _is_html_file(url):\n                self._page_candidates.append(url)\n                continue\n\n            # File must have a valid wheel or sdist name,\n            # otherwise not worth considering as a package\n            try:\n                project_filename = parse_wheel_filename(entry.name)[0]\n            except InvalidWheelFilename:\n                try:\n                    project_filename = parse_sdist_filename(entry.name)[0]\n                except InvalidSdistFilename:\n                    continue\n\n            self._project_name_to_urls[project_filename].append(url)\n        self._scanned_directory = True\n\n    @property\n    def page_candidates(self) -> List[str]:\n        if not self._scanned_directory:\n            self._scan_directory()\n\n        return self._page_candidates\n\n    @property\n    def project_name_to_urls(self) -> Dict[str, List[str]]:\n        if not self._scanned_directory:\n            self._scan_directory()\n\n        return self._project_name_to_urls\n\n\nclass _FlatDirectorySource(LinkSource):\n    \"\"\"Link source specified by ``--find-links=<path-to-dir>``.\n\n    This looks the content of the directory, and returns:\n\n    * ``page_candidates``: Links listed on each HTML file in the directory.\n    * ``file_candidates``: Archives in the directory.\n    \"\"\"\n\n    _paths_to_urls: Dict[str, _FlatDirectoryToUrls] = {}\n\n    def __init__(\n        self,\n        candidates_from_page: CandidatesFromPage,\n        path: str,\n        project_name: str,\n    ) -> None:\n        self._candidates_from_page = candidates_from_page\n        self._project_name = canonicalize_name(project_name)\n\n        # Get existing instance of _FlatDirectoryToUrls if it exists\n        if path in self._paths_to_urls:\n            self._path_to_urls = self._paths_to_urls[path]\n        else:\n            self._path_to_urls = _FlatDirectoryToUrls(path=path)\n            self._paths_to_urls[path] = self._path_to_urls\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\index\\__init__.py": {
      "sha": "714fd0cf401b",
      "lines": 1,
      "head": "\"\"\"Index interaction code\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\locations\\base.py": {
      "sha": "b8e2670e0688",
      "lines": 81,
      "head": "import functools\nimport os\nimport site\nimport sys\nimport sysconfig\nimport typing\n\nfrom pip._internal.exceptions import InstallationError\nfrom pip._internal.utils import appdirs\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\n\n# Application Directories\nUSER_CACHE_DIR = appdirs.user_cache_dir(\"pip\")\n\n# FIXME doesn't account for venv linked to global site-packages\nsite_packages: str = sysconfig.get_path(\"purelib\")\n\n\ndef get_major_minor_version() -> str:\n    \"\"\"\n    Return the major-minor version of the current Python as a string, e.g.\n    \"3.7\" or \"3.10\".\n    \"\"\"\n    return \"{}.{}\".format(*sys.version_info)\n\n\ndef change_root(new_root: str, pathname: str) -> str:\n    \"\"\"Return 'pathname' with 'new_root' prepended.\n\n    If 'pathname' is relative, this is equivalent to os.path.join(new_root, pathname).\n    Otherwise, it requires making 'pathname' relative and then joining the\n    two, which is tricky on DOS/Windows and Mac OS.\n\n    This is borrowed from Python's standard library's distutils module.\n    \"\"\"\n    if os.name == \"posix\":\n        if not os.path.isabs(pathname):\n            return os.path.join(new_root, pathname)\n        else:\n            return os.path.join(new_root, pathname[1:])\n\n    elif os.name == \"nt\":\n        (drive, path) = os.path.splitdrive(pathname)\n        if path[0] == \"\\\\\":\n            path = path[1:]\n        return os.path.join(new_root, path)\n\n    else:\n        raise InstallationError(\n            f\"Unknown platform: {os.name}\\n\"\n            \"Can not change root path prefix on unknown platform.\"\n        )\n\n\ndef get_src_prefix() -> str:\n    if running_under_virtualenv():\n        src_prefix = os.path.join(sys.prefix, \"src\")\n    else:\n        # FIXME: keep src in cwd for now (it is not a temporary folder)\n        try:\n            src_prefix = os.path.join(os.getcwd(), \"src\")\n        except OSError:\n            # In case the current working directory has been renamed or deleted\n            sys.exit(\"The folder you are executing pip from can no longer be found.\")\n\n    # under macOS + virtualenv sys.prefix is not properly resolved\n    # it is something like /path/to/python/bin/..\n    return os.path.abspath(src_prefix)\n\n\ntry:\n    # Use getusersitepackages if this is present, as it ensures that the\n    # value is initialised properly.\n    user_site: typing.Optional[str] = site.getusersitepackages()\nexcept AttributeError:\n    user_site = site.USER_SITE\n\n\n@functools.lru_cache(maxsize=None)\ndef is_osx_framework() -> bool:\n    return bool(sysconfig.get_config_var(\"PYTHONFRAMEWORK\"))\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\locations\\_distutils.py": {
      "sha": "78733a97f47e",
      "lines": 172,
      "head": "\"\"\"Locations where we look for configs, install stuff, etc\"\"\"\n\n# The following comment should be removed at some point in the future.\n# mypy: strict-optional=False\n\n# If pip's going to use distutils, it should not be using the copy that setuptools\n# might have injected into the environment. This is done by removing the injected\n# shim, if it's injected.\n#\n# See https://github.com/pypa/pip/issues/8761 for the original discussion and\n# rationale for why this is done within pip.\ntry:\n    __import__(\"_distutils_hack\").remove_shim()\nexcept (ImportError, AttributeError):\n    pass\n\nimport logging\nimport os\nimport sys\nfrom distutils.cmd import Command as DistutilsCommand\nfrom distutils.command.install import SCHEME_KEYS\nfrom distutils.command.install import install as distutils_install_command\nfrom distutils.sysconfig import get_python_lib\nfrom typing import Dict, List, Optional, Union\n\nfrom pip._internal.models.scheme import Scheme\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\n\nfrom .base import get_major_minor_version\n\nlogger = logging.getLogger(__name__)\n\n\ndef distutils_scheme(\n    dist_name: str,\n    user: bool = False,\n    home: Optional[str] = None,\n    root: Optional[str] = None,\n    isolated: bool = False,\n    prefix: Optional[str] = None,\n    *,\n    ignore_config_files: bool = False,\n) -> Dict[str, str]:\n    \"\"\"\n    Return a distutils install scheme\n    \"\"\"\n    from distutils.dist import Distribution\n\n    dist_args: Dict[str, Union[str, List[str]]] = {\"name\": dist_name}\n    if isolated:\n        dist_args[\"script_args\"] = [\"--no-user-cfg\"]\n\n    d = Distribution(dist_args)\n    if not ignore_config_files:\n        try:\n            d.parse_config_files()\n        except UnicodeDecodeError:\n            paths = d.find_config_files()\n            logger.warning(\n                \"Ignore distutils configs in %s due to encoding errors.\",\n                \", \".join(os.path.basename(p) for p in paths),\n            )\n    obj: Optional[DistutilsCommand] = None\n    obj = d.get_command_obj(\"install\", create=True)\n    assert obj is not None\n    i: distutils_install_command = obj\n    # NOTE: setting user or home has the side-effect of creating the home dir\n    # or user base for installations during finalize_options()\n    # ideally, we'd prefer a scheme class that has no side-effects.\n    assert not (user and prefix), f\"user={user} prefix={prefix}\"\n    assert not (home and prefix), f\"home={home} prefix={prefix}\"\n    i.user = user or i.user\n    if user or home:\n        i.prefix = \"\"\n    i.prefix = prefix or i.prefix\n    i.home = home or i.home\n    i.root = root or i.root\n    i.finalize_options()\n\n    scheme: Dict[str, str] = {}\n    for key in SCHEME_KEYS:\n        scheme[key] = getattr(i, \"install_\" + key)\n\n    # install_lib specified in setup.cfg should install *everything*\n    # into there (i.e. it takes precedence over both purelib and\n    # platlib).  Note, i.install_lib is *always* set after\n    # finalize_options(); we only want to override here if the user\n    # has explicitly requested it hence going back to the config\n    if \"install_lib\" in d.get_option_dict(\"install\"):\n        scheme.update({\"purelib\": i.install_lib, \"platlib\": i.install_lib})\n\n    if running_under_virtualenv():\n        if home:\n            prefix = home\n        elif user:\n            prefix = i.install_userbase\n        else:\n            prefix = i.prefix\n        scheme[\"headers\"] = os.path.join(\n            prefix,\n            \"include\",\n            \"site\",\n            f\"python{get_major_minor_version()}\",\n            dist_name,\n        )\n\n        if root is not None:\n            path_no_drive = os.path.splitdrive(os.path.abspath(scheme[\"headers\"]))[1]\n            scheme[\"headers\"] = os.path.join(root, path_no_drive[1:])\n\n    return scheme\n\n\ndef get_scheme(\n    dist_name: str,\n    user: bool = False,\n    home: Optional[str] = None,\n    root: Optional[str] = None,\n    isolated: bool = False,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\locations\\_sysconfig.py": {
      "sha": "49c9f1bd1563",
      "lines": 214,
      "head": "import logging\nimport os\nimport sys\nimport sysconfig\nimport typing\n\nfrom pip._internal.exceptions import InvalidSchemeCombination, UserInstallationInvalid\nfrom pip._internal.models.scheme import SCHEME_KEYS, Scheme\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\n\nfrom .base import change_root, get_major_minor_version, is_osx_framework\n\nlogger = logging.getLogger(__name__)\n\n\n# Notes on _infer_* functions.\n# Unfortunately ``get_default_scheme()`` didn't exist before 3.10, so there's no\n# way to ask things like \"what is the '_prefix' scheme on this platform\". These\n# functions try to answer that with some heuristics while accounting for ad-hoc\n# platforms not covered by CPython's default sysconfig implementation. If the\n# ad-hoc implementation does not fully implement sysconfig, we'll fall back to\n# a POSIX scheme.\n\n_AVAILABLE_SCHEMES = set(sysconfig.get_scheme_names())\n\n_PREFERRED_SCHEME_API = getattr(sysconfig, \"get_preferred_scheme\", None)\n\n\ndef _should_use_osx_framework_prefix() -> bool:\n    \"\"\"Check for Apple's ``osx_framework_library`` scheme.\n\n    Python distributed by Apple's Command Line Tools has this special scheme\n    that's used when:\n\n    * This is a framework build.\n    * We are installing into the system prefix.\n\n    This does not account for ``pip install --prefix`` (also means we're not\n    installing to the system prefix), which should use ``posix_prefix``, but\n    logic here means ``_infer_prefix()`` outputs ``osx_framework_library``. But\n    since ``prefix`` is not available for ``sysconfig.get_default_scheme()``,\n    which is the stdlib replacement for ``_infer_prefix()``, presumably Apple\n    wouldn't be able to magically switch between ``osx_framework_library`` and\n    ``posix_prefix``. ``_infer_prefix()`` returning ``osx_framework_library``\n    means its behavior is consistent whether we use the stdlib implementation\n    or our own, and we deal with this special case in ``get_scheme()`` instead.\n    \"\"\"\n    return (\n        \"osx_framework_library\" in _AVAILABLE_SCHEMES\n        and not running_under_virtualenv()\n        and is_osx_framework()\n    )\n\n\ndef _infer_prefix() -> str:\n    \"\"\"Try to find a prefix scheme for the current platform.\n\n    This tries:\n\n    * A special ``osx_framework_library`` for Python distributed by Apple's\n      Command Line Tools, when not running in a virtual environment.\n    * Implementation + OS, used by PyPy on Windows (``pypy_nt``).\n    * Implementation without OS, used by PyPy on POSIX (``pypy``).\n    * OS + \"prefix\", used by CPython on POSIX (``posix_prefix``).\n    * Just the OS name, used by CPython on Windows (``nt``).\n\n    If none of the above works, fall back to ``posix_prefix``.\n    \"\"\"\n    if _PREFERRED_SCHEME_API:\n        return _PREFERRED_SCHEME_API(\"prefix\")\n    if _should_use_osx_framework_prefix():\n        return \"osx_framework_library\"\n    implementation_suffixed = f\"{sys.implementation.name}_{os.name}\"\n    if implementation_suffixed in _AVAILABLE_SCHEMES:\n        return implementation_suffixed\n    if sys.implementation.name in _AVAILABLE_SCHEMES:\n        return sys.implementation.name\n    suffixed = f\"{os.name}_prefix\"\n    if suffixed in _AVAILABLE_SCHEMES:\n        return suffixed\n    if os.name in _AVAILABLE_SCHEMES:  # On Windows, prefx is just called \"nt\".\n        return os.name\n    return \"posix_prefix\"\n\n\ndef _infer_user() -> str:\n    \"\"\"Try to find a user scheme for the current platform.\"\"\"\n    if _PREFERRED_SCHEME_API:\n        return _PREFERRED_SCHEME_API(\"user\")\n    if is_osx_framework() and not running_under_virtualenv():\n        suffixed = \"osx_framework_user\"\n    else:\n        suffixed = f\"{os.name}_user\"\n    if suffixed in _AVAILABLE_SCHEMES:\n        return suffixed\n    if \"posix_user\" not in _AVAILABLE_SCHEMES:  # User scheme unavailable.\n        raise UserInstallationInvalid()\n    return \"posix_user\"\n\n\ndef _infer_home() -> str:\n    \"\"\"Try to find a home for the current platform.\"\"\"\n    if _PREFERRED_SCHEME_API:\n        return _PREFERRED_SCHEME_API(\"home\")\n    suffixed = f\"{os.name}_home\"\n    if suffixed in _AVAILABLE_SCHEMES:\n        return suffixed\n    return \"posix_home\"\n\n\n# Update these keys if the user sets a custom home.\n_HOME_KEYS = [\n    \"installed_base\",\n    \"base\",\n    \"installed_platbase\",\n    \"platbase\",\n    \"prefix\",\n    \"exec_prefix\",\n]\nif sysconfig.get_config_var(\"userbase\") is not None:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\locations\\__init__.py": {
      "sha": "f713043b65bf",
      "lines": 439,
      "head": "import functools\nimport logging\nimport os\nimport pathlib\nimport sys\nimport sysconfig\nfrom typing import Any, Dict, Optional\n\nfrom pip._internal.models.scheme import SCHEME_KEYS, Scheme\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.deprecation import deprecated\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\n\nfrom . import _sysconfig\nfrom .base import (\n    USER_CACHE_DIR,\n    get_major_minor_version,\n    get_src_prefix,\n    is_osx_framework,\n    site_packages,\n    user_site,\n)\n\n__all__ = [\n    \"USER_CACHE_DIR\",\n    \"get_bin_prefix\",\n    \"get_bin_user\",\n    \"get_major_minor_version\",\n    \"get_platlib\",\n    \"get_purelib\",\n    \"get_scheme\",\n    \"get_src_prefix\",\n    \"site_packages\",\n    \"user_site\",\n]\n\n\nlogger = logging.getLogger(__name__)\n\n\n_PLATLIBDIR: str = getattr(sys, \"platlibdir\", \"lib\")\n\n_USE_SYSCONFIG_DEFAULT = sys.version_info >= (3, 10)\n\n\ndef _should_use_sysconfig() -> bool:\n    \"\"\"This function determines the value of _USE_SYSCONFIG.\n\n    By default, pip uses sysconfig on Python 3.10+.\n    But Python distributors can override this decision by setting:\n        sysconfig._PIP_USE_SYSCONFIG = True / False\n    Rationale in https://github.com/pypa/pip/issues/10647\n\n    This is a function for testability, but should be constant during any one\n    run.\n    \"\"\"\n    return bool(getattr(sysconfig, \"_PIP_USE_SYSCONFIG\", _USE_SYSCONFIG_DEFAULT))\n\n\n_USE_SYSCONFIG = _should_use_sysconfig()\n\nif not _USE_SYSCONFIG:\n    # Import distutils lazily to avoid deprecation warnings,\n    # but import it soon enough that it is in memory and available during\n    # a pip reinstall.\n    from . import _distutils\n\n# Be noisy about incompatibilities if this platforms \"should\" be using\n# sysconfig, but is explicitly opting out and using distutils instead.\nif _USE_SYSCONFIG_DEFAULT and not _USE_SYSCONFIG:\n    _MISMATCH_LEVEL = logging.WARNING\nelse:\n    _MISMATCH_LEVEL = logging.DEBUG\n\n\ndef _looks_like_bpo_44860() -> bool:\n    \"\"\"The resolution to bpo-44860 will change this incorrect platlib.\n\n    See <https://bugs.python.org/issue44860>.\n    \"\"\"\n    from distutils.command.install import INSTALL_SCHEMES\n\n    try:\n        unix_user_platlib = INSTALL_SCHEMES[\"unix_user\"][\"platlib\"]\n    except KeyError:\n        return False\n    return unix_user_platlib == \"$usersite\"\n\n\ndef _looks_like_red_hat_patched_platlib_purelib(scheme: Dict[str, str]) -> bool:\n    platlib = scheme[\"platlib\"]\n    if \"/$platlibdir/\" in platlib:\n        platlib = platlib.replace(\"/$platlibdir/\", f\"/{_PLATLIBDIR}/\")\n    if \"/lib64/\" not in platlib:\n        return False\n    unpatched = platlib.replace(\"/lib64/\", \"/lib/\")\n    return unpatched.replace(\"$platbase/\", \"$base/\") == scheme[\"purelib\"]\n\n\n@functools.lru_cache(maxsize=None)\ndef _looks_like_red_hat_lib() -> bool:\n    \"\"\"Red Hat patches platlib in unix_prefix and unix_home, but not purelib.\n\n    This is the only way I can see to tell a Red Hat-patched Python.\n    \"\"\"\n    from distutils.command.install import INSTALL_SCHEMES\n\n    return all(\n        k in INSTALL_SCHEMES\n        and _looks_like_red_hat_patched_platlib_purelib(INSTALL_SCHEMES[k])\n        for k in (\"unix_prefix\", \"unix_home\")\n    )\n\n\n@functools.lru_cache(maxsize=None)\ndef _looks_like_debian_scheme() -> bool:\n    \"\"\"Debian adds two additional schemes.\"\"\"\n    from distutils.command.install import INSTALL_SCHEMES\n\n    return \"deb_system\" in INSTALL_SCHEMES and \"unix_local\" in INSTALL_SCHEMES\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\base.py": {
      "sha": "22dc3943317d",
      "lines": 690,
      "head": "import csv\nimport email.message\nimport functools\nimport json\nimport logging\nimport pathlib\nimport re\nimport zipfile\nfrom typing import (\n    IO,\n    Any,\n    Collection,\n    Container,\n    Dict,\n    Iterable,\n    Iterator,\n    List,\n    NamedTuple,\n    Optional,\n    Protocol,\n    Tuple,\n    Union,\n)\n\nfrom pip._vendor.packaging.requirements import Requirement\nfrom pip._vendor.packaging.specifiers import InvalidSpecifier, SpecifierSet\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\nfrom pip._vendor.packaging.version import Version\n\nfrom pip._internal.exceptions import NoneMetadataError\nfrom pip._internal.locations import site_packages, user_site\nfrom pip._internal.models.direct_url import (\n    DIRECT_URL_METADATA_NAME,\n    DirectUrl,\n    DirectUrlValidationError,\n)\nfrom pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.\nfrom pip._internal.utils.egg_link import egg_link_path_from_sys_path\nfrom pip._internal.utils.misc import is_local, normalize_path\nfrom pip._internal.utils.urls import url_to_path\n\nfrom ._json import msg_to_json\n\nInfoPath = Union[str, pathlib.PurePath]\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseEntryPoint(Protocol):\n    @property\n    def name(self) -> str:\n        raise NotImplementedError()\n\n    @property\n    def value(self) -> str:\n        raise NotImplementedError()\n\n    @property\n    def group(self) -> str:\n        raise NotImplementedError()\n\n\ndef _convert_installed_files_path(\n    entry: Tuple[str, ...],\n    info: Tuple[str, ...],\n) -> str:\n    \"\"\"Convert a legacy installed-files.txt path into modern RECORD path.\n\n    The legacy format stores paths relative to the info directory, while the\n    modern format stores paths relative to the package root, e.g. the\n    site-packages directory.\n\n    :param entry: Path parts of the installed-files.txt entry.\n    :param info: Path parts of the egg-info directory relative to package root.\n    :returns: The converted entry.\n\n    For best compatibility with symlinks, this does not use ``abspath()`` or\n    ``Path.resolve()``, but tries to work with path parts:\n\n    1. While ``entry`` starts with ``..``, remove the equal amounts of parts\n       from ``info``; if ``info`` is empty, start appending ``..`` instead.\n    2. Join the two directly.\n    \"\"\"\n    while entry and entry[0] == \"..\":\n        if not info or info[-1] == \"..\":\n            info += (\"..\",)\n        else:\n            info = info[:-1]\n        entry = entry[1:]\n    return str(pathlib.Path(*info, *entry))\n\n\nclass RequiresEntry(NamedTuple):\n    requirement: str\n    extra: str\n    marker: str\n\n\nclass BaseDistribution(Protocol):\n    @classmethod\n    def from_directory(cls, directory: str) -> \"BaseDistribution\":\n        \"\"\"Load the distribution from a metadata directory.\n\n        :param directory: Path to a metadata directory, e.g. ``.dist-info``.\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def from_metadata_file_contents(\n        cls,\n        metadata_contents: bytes,\n        filename: str,\n        project_name: str,\n    ) -> \"BaseDistribution\":\n        \"\"\"Load the distribution from the contents of a METADATA file.\n\n        This is used to implement PEP 658 by generating a \"shallow\" dist object that can\n        be used for resolution without downloading or building the actual dist yet.\n\n        :param metadata_contents: The contents of a METADATA file.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py": {
      "sha": "4d42374ffb06",
      "lines": 301,
      "head": "import email.message\nimport email.parser\nimport logging\nimport os\nimport zipfile\nfrom typing import (\n    Collection,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    NamedTuple,\n    Optional,\n)\n\nfrom pip._vendor import pkg_resources\nfrom pip._vendor.packaging.requirements import Requirement\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\nfrom pip._vendor.packaging.version import Version\nfrom pip._vendor.packaging.version import parse as parse_version\n\nfrom pip._internal.exceptions import InvalidWheel, NoneMetadataError, UnsupportedWheel\nfrom pip._internal.utils.egg_link import egg_link_path_from_location\nfrom pip._internal.utils.misc import display_path, normalize_path\nfrom pip._internal.utils.wheel import parse_wheel, read_wheel_metadata_file\n\nfrom .base import (\n    BaseDistribution,\n    BaseEntryPoint,\n    BaseEnvironment,\n    InfoPath,\n    Wheel,\n)\n\n__all__ = [\"NAME\", \"Distribution\", \"Environment\"]\n\nlogger = logging.getLogger(__name__)\n\nNAME = \"pkg_resources\"\n\n\nclass EntryPoint(NamedTuple):\n    name: str\n    value: str\n    group: str\n\n\nclass InMemoryMetadata:\n    \"\"\"IMetadataProvider that reads metadata files from a dictionary.\n\n    This also maps metadata decoding exceptions to our internal exception type.\n    \"\"\"\n\n    def __init__(self, metadata: Mapping[str, bytes], wheel_name: str) -> None:\n        self._metadata = metadata\n        self._wheel_name = wheel_name\n\n    def has_metadata(self, name: str) -> bool:\n        return name in self._metadata\n\n    def get_metadata(self, name: str) -> str:\n        try:\n            return self._metadata[name].decode()\n        except UnicodeDecodeError as e:\n            # Augment the default error with the origin of the file.\n            raise UnsupportedWheel(\n                f\"Error decoding metadata for {self._wheel_name}: {e} in {name} file\"\n            )\n\n    def get_metadata_lines(self, name: str) -> Iterable[str]:\n        return pkg_resources.yield_lines(self.get_metadata(name))\n\n    def metadata_isdir(self, name: str) -> bool:\n        return False\n\n    def metadata_listdir(self, name: str) -> List[str]:\n        return []\n\n    def run_script(self, script_name: str, namespace: str) -> None:\n        pass\n\n\nclass Distribution(BaseDistribution):\n    def __init__(self, dist: pkg_resources.Distribution) -> None:\n        self._dist = dist\n        # This is populated lazily, to avoid loading metadata for all possible\n        # distributions eagerly.\n        self.__extra_mapping: Optional[Mapping[NormalizedName, str]] = None\n\n    @property\n    def _extra_mapping(self) -> Mapping[NormalizedName, str]:\n        if self.__extra_mapping is None:\n            self.__extra_mapping = {\n                canonicalize_name(extra): extra for extra in self._dist.extras\n            }\n\n        return self.__extra_mapping\n\n    @classmethod\n    def from_directory(cls, directory: str) -> BaseDistribution:\n        dist_dir = directory.rstrip(os.sep)\n\n        # Build a PathMetadata object, from path to metadata. :wink:\n        base_dir, dist_dir_name = os.path.split(dist_dir)\n        metadata = pkg_resources.PathMetadata(base_dir, dist_dir)\n\n        # Determine the correct Distribution object type.\n        if dist_dir.endswith(\".egg-info\"):\n            dist_cls = pkg_resources.Distribution\n            dist_name = os.path.splitext(dist_dir_name)[0]\n        else:\n            assert dist_dir.endswith(\".dist-info\")\n            dist_cls = pkg_resources.DistInfoDistribution\n            dist_name = os.path.splitext(dist_dir_name)[0].split(\"-\")[0]\n\n        dist = dist_cls(base_dir, project_name=dist_name, metadata=metadata)\n        return cls(dist)\n\n    @classmethod\n    def from_metadata_file_contents(\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\_json.py": {
      "sha": "8f93b64e79fd",
      "lines": 86,
      "head": "# Extracted from https://github.com/pfmoore/pkg_metadata\n\nfrom email.header import Header, decode_header, make_header\nfrom email.message import Message\nfrom typing import Any, Dict, List, Union, cast\n\nMETADATA_FIELDS = [\n    # Name, Multiple-Use\n    (\"Metadata-Version\", False),\n    (\"Name\", False),\n    (\"Version\", False),\n    (\"Dynamic\", True),\n    (\"Platform\", True),\n    (\"Supported-Platform\", True),\n    (\"Summary\", False),\n    (\"Description\", False),\n    (\"Description-Content-Type\", False),\n    (\"Keywords\", False),\n    (\"Home-page\", False),\n    (\"Download-URL\", False),\n    (\"Author\", False),\n    (\"Author-email\", False),\n    (\"Maintainer\", False),\n    (\"Maintainer-email\", False),\n    (\"License\", False),\n    (\"License-Expression\", False),\n    (\"License-File\", True),\n    (\"Classifier\", True),\n    (\"Requires-Dist\", True),\n    (\"Requires-Python\", False),\n    (\"Requires-External\", True),\n    (\"Project-URL\", True),\n    (\"Provides-Extra\", True),\n    (\"Provides-Dist\", True),\n    (\"Obsoletes-Dist\", True),\n]\n\n\ndef json_name(field: str) -> str:\n    return field.lower().replace(\"-\", \"_\")\n\n\ndef msg_to_json(msg: Message) -> Dict[str, Any]:\n    \"\"\"Convert a Message object into a JSON-compatible dictionary.\"\"\"\n\n    def sanitise_header(h: Union[Header, str]) -> str:\n        if isinstance(h, Header):\n            chunks = []\n            for bytes, encoding in decode_header(h):\n                if encoding == \"unknown-8bit\":\n                    try:\n                        # See if UTF-8 works\n                        bytes.decode(\"utf-8\")\n                        encoding = \"utf-8\"\n                    except UnicodeDecodeError:\n                        # If not, latin1 at least won't fail\n                        encoding = \"latin1\"\n                chunks.append((bytes, encoding))\n            return str(make_header(chunks))\n        return str(h)\n\n    result = {}\n    for field, multi in METADATA_FIELDS:\n        if field not in msg:\n            continue\n        key = json_name(field)\n        if multi:\n            value: Union[str, List[str]] = [\n                sanitise_header(v) for v in msg.get_all(field)  # type: ignore\n            ]\n        else:\n            value = sanitise_header(msg.get(field))  # type: ignore\n            if key == \"keywords\":\n                # Accept both comma-separated and space-separated\n                # forms, for better compatibility with old data.\n                if \",\" in value:\n                    value = [v.strip() for v in value.split(\",\")]\n                else:\n                    value = value.split()\n        result[key] = value\n\n    payload = cast(str, msg.get_payload())\n    if payload:\n        result[\"description\"] = payload\n\n    return result\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\__init__.py": {
      "sha": "64dfb1c2ff2d",
      "lines": 162,
      "head": "import contextlib\nimport functools\nimport os\nimport sys\nfrom typing import List, Literal, Optional, Protocol, Type, cast\n\nfrom pip._internal.utils.deprecation import deprecated\nfrom pip._internal.utils.misc import strtobool\n\nfrom .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel\n\n__all__ = [\n    \"BaseDistribution\",\n    \"BaseEnvironment\",\n    \"FilesystemWheel\",\n    \"MemoryWheel\",\n    \"Wheel\",\n    \"get_default_environment\",\n    \"get_environment\",\n    \"get_wheel_distribution\",\n    \"select_backend\",\n]\n\n\ndef _should_use_importlib_metadata() -> bool:\n    \"\"\"Whether to use the ``importlib.metadata`` or ``pkg_resources`` backend.\n\n    By default, pip uses ``importlib.metadata`` on Python 3.11+, and\n    ``pkg_resources`` otherwise. Up to Python 3.13, This can be\n    overridden by a couple of ways:\n\n    * If environment variable ``_PIP_USE_IMPORTLIB_METADATA`` is set, it\n      dictates whether ``importlib.metadata`` is used, for Python <3.14.\n    * On Python 3.11, 3.12 and 3.13, Python distributors can patch\n      ``importlib.metadata`` to add a global constant\n      ``_PIP_USE_IMPORTLIB_METADATA = False``. This makes pip use\n      ``pkg_resources`` (unless the user set the aforementioned environment\n      variable to *True*).\n\n    On Python 3.14+, the ``pkg_resources`` backend cannot be used.\n    \"\"\"\n    if sys.version_info >= (3, 14):\n        # On Python >=3.14 we only support importlib.metadata.\n        return True\n    with contextlib.suppress(KeyError, ValueError):\n        # On Python <3.14, if the environment variable is set, we obey what it says.\n        return bool(strtobool(os.environ[\"_PIP_USE_IMPORTLIB_METADATA\"]))\n    if sys.version_info < (3, 11):\n        # On Python <3.11, we always use pkg_resources, unless the environment\n        # variable was set.\n        return False\n    # On Python 3.11, 3.12 and 3.13, we check if the global constant is set.\n    import importlib.metadata\n\n    return bool(getattr(importlib.metadata, \"_PIP_USE_IMPORTLIB_METADATA\", True))\n\n\ndef _emit_pkg_resources_deprecation_if_needed() -> None:\n    if sys.version_info < (3, 11):\n        # All pip versions supporting Python<=3.11 will support pkg_resources,\n        # and pkg_resources is the default for these, so let's not bother users.\n        return\n\n    import importlib.metadata\n\n    if hasattr(importlib.metadata, \"_PIP_USE_IMPORTLIB_METADATA\"):\n        # The Python distributor has set the global constant, so we don't\n        # warn, since it is not a user decision.\n        return\n\n    # The user has decided to use pkg_resources, so we warn.\n    deprecated(\n        reason=\"Using the pkg_resources metadata backend is deprecated.\",\n        replacement=(\n            \"to use the default importlib.metadata backend, \"\n            \"by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable\"\n        ),\n        gone_in=\"26.3\",\n        issue=13317,\n    )\n\n\nclass Backend(Protocol):\n    NAME: 'Literal[\"importlib\", \"pkg_resources\"]'\n    Distribution: Type[BaseDistribution]\n    Environment: Type[BaseEnvironment]\n\n\n@functools.lru_cache(maxsize=None)\ndef select_backend() -> Backend:\n    if _should_use_importlib_metadata():\n        from . import importlib\n\n        return cast(Backend, importlib)\n\n    _emit_pkg_resources_deprecation_if_needed()\n\n    from . import pkg_resources\n\n    return cast(Backend, pkg_resources)\n\n\ndef get_default_environment() -> BaseEnvironment:\n    \"\"\"Get the default representation for the current environment.\n\n    This returns an Environment instance from the chosen backend. The default\n    Environment instance should be built from ``sys.path`` and may use caching\n    to share instance state across calls.\n    \"\"\"\n    return select_backend().Environment.default()\n\n\ndef get_environment(paths: Optional[List[str]]) -> BaseEnvironment:\n    \"\"\"Get a representation of the environment specified by ``paths``.\n\n    This returns an Environment instance from the chosen backend based on the\n    given import paths. The backend must build a fresh instance representing\n    the state of installed distributions when this function is called.\n    \"\"\"\n    return select_backend().Environment.from_paths(paths)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_compat.py": {
      "sha": "d440a9db1801",
      "lines": 85,
      "head": "import importlib.metadata\nimport os\nfrom typing import Any, Optional, Protocol, Tuple, cast\n\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\n\n\nclass BadMetadata(ValueError):\n    def __init__(self, dist: importlib.metadata.Distribution, *, reason: str) -> None:\n        self.dist = dist\n        self.reason = reason\n\n    def __str__(self) -> str:\n        return f\"Bad metadata in {self.dist} ({self.reason})\"\n\n\nclass BasePath(Protocol):\n    \"\"\"A protocol that various path objects conform.\n\n    This exists because importlib.metadata uses both ``pathlib.Path`` and\n    ``zipfile.Path``, and we need a common base for type hints (Union does not\n    work well since ``zipfile.Path`` is too new for our linter setup).\n\n    This does not mean to be exhaustive, but only contains things that present\n    in both classes *that we need*.\n    \"\"\"\n\n    @property\n    def name(self) -> str:\n        raise NotImplementedError()\n\n    @property\n    def parent(self) -> \"BasePath\":\n        raise NotImplementedError()\n\n\ndef get_info_location(d: importlib.metadata.Distribution) -> Optional[BasePath]:\n    \"\"\"Find the path to the distribution's metadata directory.\n\n    HACK: This relies on importlib.metadata's private ``_path`` attribute. Not\n    all distributions exist on disk, so importlib.metadata is correct to not\n    expose the attribute as public. But pip's code base is old and not as clean,\n    so we do this to avoid having to rewrite too many things. Hopefully we can\n    eliminate this some day.\n    \"\"\"\n    return getattr(d, \"_path\", None)\n\n\ndef parse_name_and_version_from_info_directory(\n    dist: importlib.metadata.Distribution,\n) -> Tuple[Optional[str], Optional[str]]:\n    \"\"\"Get a name and version from the metadata directory name.\n\n    This is much faster than reading distribution metadata.\n    \"\"\"\n    info_location = get_info_location(dist)\n    if info_location is None:\n        return None, None\n\n    stem, suffix = os.path.splitext(info_location.name)\n    if suffix == \".dist-info\":\n        name, sep, version = stem.partition(\"-\")\n        if sep:\n            return name, version\n\n    if suffix == \".egg-info\":\n        name = stem.split(\"-\", 1)[0]\n        return name, None\n\n    return None, None\n\n\ndef get_dist_canonical_name(dist: importlib.metadata.Distribution) -> NormalizedName:\n    \"\"\"Get the distribution's normalized name.\n\n    The ``name`` attribute is only available in Python 3.10 or later. We are\n    targeting exactly that, but Mypy does not know this.\n    \"\"\"\n    if name := parse_name_and_version_from_info_directory(dist)[0]:\n        return canonicalize_name(name)\n\n    name = cast(Any, dist).name\n    if not isinstance(name, str):\n        raise BadMetadata(dist, reason=\"invalid metadata entry 'name'\")\n    return canonicalize_name(name)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_dists.py": {
      "sha": "b092529645c6",
      "lines": 228,
      "head": "import email.message\nimport importlib.metadata\nimport pathlib\nimport zipfile\nfrom os import PathLike\nfrom typing import (\n    Collection,\n    Dict,\n    Iterable,\n    Iterator,\n    Mapping,\n    Optional,\n    Sequence,\n    Union,\n    cast,\n)\n\nfrom pip._vendor.packaging.requirements import Requirement\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\nfrom pip._vendor.packaging.version import Version\nfrom pip._vendor.packaging.version import parse as parse_version\n\nfrom pip._internal.exceptions import InvalidWheel, UnsupportedWheel\nfrom pip._internal.metadata.base import (\n    BaseDistribution,\n    BaseEntryPoint,\n    InfoPath,\n    Wheel,\n)\nfrom pip._internal.utils.misc import normalize_path\nfrom pip._internal.utils.packaging import get_requirement\nfrom pip._internal.utils.temp_dir import TempDirectory\nfrom pip._internal.utils.wheel import parse_wheel, read_wheel_metadata_file\n\nfrom ._compat import (\n    BasePath,\n    get_dist_canonical_name,\n    parse_name_and_version_from_info_directory,\n)\n\n\nclass WheelDistribution(importlib.metadata.Distribution):\n    \"\"\"An ``importlib.metadata.Distribution`` read from a wheel.\n\n    Although ``importlib.metadata.PathDistribution`` accepts ``zipfile.Path``,\n    its implementation is too \"lazy\" for pip's needs (we can't keep the ZipFile\n    handle open for the entire lifetime of the distribution object).\n\n    This implementation eagerly reads the entire metadata directory into the\n    memory instead, and operates from that.\n    \"\"\"\n\n    def __init__(\n        self,\n        files: Mapping[pathlib.PurePosixPath, bytes],\n        info_location: pathlib.PurePosixPath,\n    ) -> None:\n        self._files = files\n        self.info_location = info_location\n\n    @classmethod\n    def from_zipfile(\n        cls,\n        zf: zipfile.ZipFile,\n        name: str,\n        location: str,\n    ) -> \"WheelDistribution\":\n        info_dir, _ = parse_wheel(zf, name)\n        paths = (\n            (name, pathlib.PurePosixPath(name.split(\"/\", 1)[-1]))\n            for name in zf.namelist()\n            if name.startswith(f\"{info_dir}/\")\n        )\n        files = {\n            relpath: read_wheel_metadata_file(zf, fullpath)\n            for fullpath, relpath in paths\n        }\n        info_location = pathlib.PurePosixPath(location, info_dir)\n        return cls(files, info_location)\n\n    def iterdir(self, path: InfoPath) -> Iterator[pathlib.PurePosixPath]:\n        # Only allow iterating through the metadata directory.\n        if pathlib.PurePosixPath(str(path)) in self._files:\n            return iter(self._files)\n        raise FileNotFoundError(path)\n\n    def read_text(self, filename: str) -> Optional[str]:\n        try:\n            data = self._files[pathlib.PurePosixPath(filename)]\n        except KeyError:\n            return None\n        try:\n            text = data.decode(\"utf-8\")\n        except UnicodeDecodeError as e:\n            wheel = self.info_location.parent\n            error = f\"Error decoding metadata for {wheel}: {e} in {filename} file\"\n            raise UnsupportedWheel(error)\n        return text\n\n    def locate_file(self, path: Union[str, \"PathLike[str]\"]) -> pathlib.Path:\n        # This method doesn't make sense for our in-memory wheel, but the API\n        # requires us to define it.\n        raise NotImplementedError\n\n\nclass Distribution(BaseDistribution):\n    def __init__(\n        self,\n        dist: importlib.metadata.Distribution,\n        info_location: Optional[BasePath],\n        installed_location: Optional[BasePath],\n    ) -> None:\n        self._dist = dist\n        self._info_location = info_location\n        self._installed_location = installed_location\n\n    @classmethod\n    def from_directory(cls, directory: str) -> BaseDistribution:\n        info_location = pathlib.Path(directory)\n        dist = importlib.metadata.Distribution.at(info_location)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_envs.py": {
      "sha": "a225e824dc93",
      "lines": 140,
      "head": "import importlib.metadata\nimport logging\nimport os\nimport pathlib\nimport sys\nimport zipfile\nfrom typing import Iterator, List, Optional, Sequence, Set, Tuple\n\nfrom pip._vendor.packaging.utils import (\n    InvalidWheelFilename,\n    NormalizedName,\n    canonicalize_name,\n    parse_wheel_filename,\n)\n\nfrom pip._internal.metadata.base import BaseDistribution, BaseEnvironment\nfrom pip._internal.utils.filetypes import WHEEL_EXTENSION\n\nfrom ._compat import BadMetadata, BasePath, get_dist_canonical_name, get_info_location\nfrom ._dists import Distribution\n\nlogger = logging.getLogger(__name__)\n\n\ndef _looks_like_wheel(location: str) -> bool:\n    if not location.endswith(WHEEL_EXTENSION):\n        return False\n    if not os.path.isfile(location):\n        return False\n    try:\n        parse_wheel_filename(os.path.basename(location))\n    except InvalidWheelFilename:\n        return False\n    return zipfile.is_zipfile(location)\n\n\nclass _DistributionFinder:\n    \"\"\"Finder to locate distributions.\n\n    The main purpose of this class is to memoize found distributions' names, so\n    only one distribution is returned for each package name. At lot of pip code\n    assumes this (because it is setuptools's behavior), and not doing the same\n    can potentially cause a distribution in lower precedence path to override a\n    higher precedence one if the caller is not careful.\n\n    Eventually we probably want to make it possible to see lower precedence\n    installations as well. It's useful feature, after all.\n    \"\"\"\n\n    FoundResult = Tuple[importlib.metadata.Distribution, Optional[BasePath]]\n\n    def __init__(self) -> None:\n        self._found_names: Set[NormalizedName] = set()\n\n    def _find_impl(self, location: str) -> Iterator[FoundResult]:\n        \"\"\"Find distributions in a location.\"\"\"\n        # Skip looking inside a wheel. Since a package inside a wheel is not\n        # always valid (due to .data directories etc.), its .dist-info entry\n        # should not be considered an installed distribution.\n        if _looks_like_wheel(location):\n            return\n        # To know exactly where we find a distribution, we have to feed in the\n        # paths one by one, instead of dumping the list to importlib.metadata.\n        for dist in importlib.metadata.distributions(path=[location]):\n            info_location = get_info_location(dist)\n            try:\n                name = get_dist_canonical_name(dist)\n            except BadMetadata as e:\n                logger.warning(\"Skipping %s due to %s\", info_location, e.reason)\n                continue\n            if name in self._found_names:\n                continue\n            self._found_names.add(name)\n            yield dist, info_location\n\n    def find(self, location: str) -> Iterator[BaseDistribution]:\n        \"\"\"Find distributions in a location.\n\n        The path can be either a directory, or a ZIP archive.\n        \"\"\"\n        for dist, info_location in self._find_impl(location):\n            if info_location is None:\n                installed_location: Optional[BasePath] = None\n            else:\n                installed_location = info_location.parent\n            yield Distribution(dist, info_location, installed_location)\n\n    def find_legacy_editables(self, location: str) -> Iterator[BaseDistribution]:\n        \"\"\"Read location in egg-link files and return distributions in there.\n\n        The path should be a directory; otherwise this returns nothing. This\n        follows how setuptools does this for compatibility. The first non-empty\n        line in the egg-link is read as a path (resolved against the egg-link's\n        containing directory if relative). Distributions found at that linked\n        location are returned.\n        \"\"\"\n        path = pathlib.Path(location)\n        if not path.is_dir():\n            return\n        for child in path.iterdir():\n            if child.suffix != \".egg-link\":\n                continue\n            with child.open() as f:\n                lines = (line.strip() for line in f)\n                target_rel = next((line for line in lines if line), \"\")\n            if not target_rel:\n                continue\n            target_location = str(path.joinpath(target_rel))\n            for dist, info_location in self._find_impl(target_location):\n                yield Distribution(dist, info_location, path)\n\n\nclass Environment(BaseEnvironment):\n    def __init__(self, paths: Sequence[str]) -> None:\n        self._paths = paths\n\n    @classmethod\n    def default(cls) -> BaseEnvironment:\n        return cls(sys.path)\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\__init__.py": {
      "sha": "e7447ed9c17d",
      "lines": 6,
      "head": "from ._dists import Distribution\nfrom ._envs import Environment\n\n__all__ = [\"NAME\", \"Distribution\", \"Environment\"]\n\nNAME = \"importlib\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\candidate.py": {
      "sha": "afbf60b94e62",
      "lines": 25,
      "head": "from dataclasses import dataclass\n\nfrom pip._vendor.packaging.version import Version\nfrom pip._vendor.packaging.version import parse as parse_version\n\nfrom pip._internal.models.link import Link\n\n\n@dataclass(frozen=True)\nclass InstallationCandidate:\n    \"\"\"Represents a potential \"candidate\" for installation.\"\"\"\n\n    __slots__ = [\"name\", \"version\", \"link\"]\n\n    name: str\n    version: Version\n    link: Link\n\n    def __init__(self, name: str, version: str, link: Link) -> None:\n        object.__setattr__(self, \"name\", name)\n        object.__setattr__(self, \"version\", parse_version(version))\n        object.__setattr__(self, \"link\", link)\n\n    def __str__(self) -> str:\n        return f\"{self.name!r} candidate (version {self.version} at {self.link})\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\direct_url.py": {
      "sha": "225496c20ace",
      "lines": 224,
      "head": "\"\"\"PEP 610\"\"\"\n\nimport json\nimport re\nimport urllib.parse\nfrom dataclasses import dataclass\nfrom typing import Any, ClassVar, Dict, Iterable, Optional, Type, TypeVar, Union\n\n__all__ = [\n    \"DirectUrl\",\n    \"DirectUrlValidationError\",\n    \"DirInfo\",\n    \"ArchiveInfo\",\n    \"VcsInfo\",\n]\n\nT = TypeVar(\"T\")\n\nDIRECT_URL_METADATA_NAME = \"direct_url.json\"\nENV_VAR_RE = re.compile(r\"^\\$\\{[A-Za-z0-9-_]+\\}(:\\$\\{[A-Za-z0-9-_]+\\})?$\")\n\n\nclass DirectUrlValidationError(Exception):\n    pass\n\n\ndef _get(\n    d: Dict[str, Any], expected_type: Type[T], key: str, default: Optional[T] = None\n) -> Optional[T]:\n    \"\"\"Get value from dictionary and verify expected type.\"\"\"\n    if key not in d:\n        return default\n    value = d[key]\n    if not isinstance(value, expected_type):\n        raise DirectUrlValidationError(\n            f\"{value!r} has unexpected type for {key} (expected {expected_type})\"\n        )\n    return value\n\n\ndef _get_required(\n    d: Dict[str, Any], expected_type: Type[T], key: str, default: Optional[T] = None\n) -> T:\n    value = _get(d, expected_type, key, default)\n    if value is None:\n        raise DirectUrlValidationError(f\"{key} must have a value\")\n    return value\n\n\ndef _exactly_one_of(infos: Iterable[Optional[\"InfoType\"]]) -> \"InfoType\":\n    infos = [info for info in infos if info is not None]\n    if not infos:\n        raise DirectUrlValidationError(\n            \"missing one of archive_info, dir_info, vcs_info\"\n        )\n    if len(infos) > 1:\n        raise DirectUrlValidationError(\n            \"more than one of archive_info, dir_info, vcs_info\"\n        )\n    assert infos[0] is not None\n    return infos[0]\n\n\ndef _filter_none(**kwargs: Any) -> Dict[str, Any]:\n    \"\"\"Make dict excluding None values.\"\"\"\n    return {k: v for k, v in kwargs.items() if v is not None}\n\n\n@dataclass\nclass VcsInfo:\n    name: ClassVar = \"vcs_info\"\n\n    vcs: str\n    commit_id: str\n    requested_revision: Optional[str] = None\n\n    @classmethod\n    def _from_dict(cls, d: Optional[Dict[str, Any]]) -> Optional[\"VcsInfo\"]:\n        if d is None:\n            return None\n        return cls(\n            vcs=_get_required(d, str, \"vcs\"),\n            commit_id=_get_required(d, str, \"commit_id\"),\n            requested_revision=_get(d, str, \"requested_revision\"),\n        )\n\n    def _to_dict(self) -> Dict[str, Any]:\n        return _filter_none(\n            vcs=self.vcs,\n            requested_revision=self.requested_revision,\n            commit_id=self.commit_id,\n        )\n\n\nclass ArchiveInfo:\n    name = \"archive_info\"\n\n    def __init__(\n        self,\n        hash: Optional[str] = None,\n        hashes: Optional[Dict[str, str]] = None,\n    ) -> None:\n        # set hashes before hash, since the hash setter will further populate hashes\n        self.hashes = hashes\n        self.hash = hash\n\n    @property\n    def hash(self) -> Optional[str]:\n        return self._hash\n\n    @hash.setter\n    def hash(self, value: Optional[str]) -> None:\n        if value is not None:\n            # Auto-populate the hashes key to upgrade to the new format automatically.\n            # We don't back-populate the legacy hash key from hashes.\n            try:\n                hash_name, hash_value = value.split(\"=\", 1)\n            except ValueError:\n                raise DirectUrlValidationError(\n                    f\"invalid archive_info.hash format: {value!r}\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\format_control.py": {
      "sha": "22cb3e5d1d2d",
      "lines": 78,
      "head": "from typing import FrozenSet, Optional, Set\n\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.exceptions import CommandError\n\n\nclass FormatControl:\n    \"\"\"Helper for managing formats from which a package can be installed.\"\"\"\n\n    __slots__ = [\"no_binary\", \"only_binary\"]\n\n    def __init__(\n        self,\n        no_binary: Optional[Set[str]] = None,\n        only_binary: Optional[Set[str]] = None,\n    ) -> None:\n        if no_binary is None:\n            no_binary = set()\n        if only_binary is None:\n            only_binary = set()\n\n        self.no_binary = no_binary\n        self.only_binary = only_binary\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n\n        if self.__slots__ != other.__slots__:\n            return False\n\n        return all(getattr(self, k) == getattr(other, k) for k in self.__slots__)\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({self.no_binary}, {self.only_binary})\"\n\n    @staticmethod\n    def handle_mutual_excludes(value: str, target: Set[str], other: Set[str]) -> None:\n        if value.startswith(\"-\"):\n            raise CommandError(\n                \"--no-binary / --only-binary option requires 1 argument.\"\n            )\n        new = value.split(\",\")\n        while \":all:\" in new:\n            other.clear()\n            target.clear()\n            target.add(\":all:\")\n            del new[: new.index(\":all:\") + 1]\n            # Without a none, we want to discard everything as :all: covers it\n            if \":none:\" not in new:\n                return\n        for name in new:\n            if name == \":none:\":\n                target.clear()\n                continue\n            name = canonicalize_name(name)\n            other.discard(name)\n            target.add(name)\n\n    def get_allowed_formats(self, canonical_name: str) -> FrozenSet[str]:\n        result = {\"binary\", \"source\"}\n        if canonical_name in self.only_binary:\n            result.discard(\"source\")\n        elif canonical_name in self.no_binary:\n            result.discard(\"binary\")\n        elif \":all:\" in self.only_binary:\n            result.discard(\"source\")\n        elif \":all:\" in self.no_binary:\n            result.discard(\"binary\")\n        return frozenset(result)\n\n    def disallow_binaries(self) -> None:\n        self.handle_mutual_excludes(\n            \":all:\",\n            self.no_binary,\n            self.only_binary,\n        )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\index.py": {
      "sha": "26707b880bf1",
      "lines": 28,
      "head": "import urllib.parse\n\n\nclass PackageIndex:\n    \"\"\"Represents a Package Index and provides easier access to endpoints\"\"\"\n\n    __slots__ = [\"url\", \"netloc\", \"simple_url\", \"pypi_url\", \"file_storage_domain\"]\n\n    def __init__(self, url: str, file_storage_domain: str) -> None:\n        super().__init__()\n        self.url = url\n        self.netloc = urllib.parse.urlsplit(url).netloc\n        self.simple_url = self._url_for_path(\"simple\")\n        self.pypi_url = self._url_for_path(\"pypi\")\n\n        # This is part of a temporary hack used to block installs of PyPI\n        # packages which depend on external urls only necessary until PyPI can\n        # block such packages themselves\n        self.file_storage_domain = file_storage_domain\n\n    def _url_for_path(self, path: str) -> str:\n        return urllib.parse.urljoin(self.url, path)\n\n\nPyPI = PackageIndex(\"https://pypi.org/\", file_storage_domain=\"files.pythonhosted.org\")\nTestPyPI = PackageIndex(\n    \"https://test.pypi.org/\", file_storage_domain=\"test-files.pythonhosted.org\"\n)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\installation_report.py": {
      "sha": "8e0e2f7c9ae3",
      "lines": 56,
      "head": "from typing import Any, Dict, Sequence\n\nfrom pip._vendor.packaging.markers import default_environment\n\nfrom pip import __version__\nfrom pip._internal.req.req_install import InstallRequirement\n\n\nclass InstallationReport:\n    def __init__(self, install_requirements: Sequence[InstallRequirement]):\n        self._install_requirements = install_requirements\n\n    @classmethod\n    def _install_req_to_dict(cls, ireq: InstallRequirement) -> Dict[str, Any]:\n        assert ireq.download_info, f\"No download_info for {ireq}\"\n        res = {\n            # PEP 610 json for the download URL. download_info.archive_info.hashes may\n            # be absent when the requirement was installed from the wheel cache\n            # and the cache entry was populated by an older pip version that did not\n            # record origin.json.\n            \"download_info\": ireq.download_info.to_dict(),\n            # is_direct is true if the requirement was a direct URL reference (which\n            # includes editable requirements), and false if the requirement was\n            # downloaded from a PEP 503 index or --find-links.\n            \"is_direct\": ireq.is_direct,\n            # is_yanked is true if the requirement was yanked from the index, but\n            # was still selected by pip to conform to PEP 592.\n            \"is_yanked\": ireq.link.is_yanked if ireq.link else False,\n            # requested is true if the requirement was specified by the user (aka\n            # top level requirement), and false if it was installed as a dependency of a\n            # requirement. https://peps.python.org/pep-0376/#requested\n            \"requested\": ireq.user_supplied,\n            # PEP 566 json encoding for metadata\n            # https://www.python.org/dev/peps/pep-0566/#json-compatible-metadata\n            \"metadata\": ireq.get_dist().metadata_dict,\n        }\n        if ireq.user_supplied and ireq.extras:\n            # For top level requirements, the list of requested extras, if any.\n            res[\"requested_extras\"] = sorted(ireq.extras)\n        return res\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"version\": \"1\",\n            \"pip_version\": __version__,\n            \"install\": [\n                self._install_req_to_dict(ireq) for ireq in self._install_requirements\n            ],\n            # https://peps.python.org/pep-0508/#environment-markers\n            # TODO: currently, the resolver uses the default environment to evaluate\n            # environment markers, so that is what we report here. In the future, it\n            # should also take into account options such as --python-version or\n            # --platform, perhaps under the form of an environment_override field?\n            # https://github.com/pypa/pip/issues/11198\n            \"environment\": default_environment(),\n        }\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\link.py": {
      "sha": "9a6d7e4e9ddb",
      "lines": 608,
      "head": "import functools\nimport itertools\nimport logging\nimport os\nimport posixpath\nimport re\nimport urllib.parse\nfrom dataclasses import dataclass\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Dict,\n    List,\n    Mapping,\n    NamedTuple,\n    Optional,\n    Tuple,\n    Union,\n)\n\nfrom pip._internal.utils.deprecation import deprecated\nfrom pip._internal.utils.filetypes import WHEEL_EXTENSION\nfrom pip._internal.utils.hashes import Hashes\nfrom pip._internal.utils.misc import (\n    pairwise,\n    redact_auth_from_url,\n    split_auth_from_netloc,\n    splitext,\n)\nfrom pip._internal.utils.urls import path_to_url, url_to_path\n\nif TYPE_CHECKING:\n    from pip._internal.index.collector import IndexContent\n\nlogger = logging.getLogger(__name__)\n\n\n# Order matters, earlier hashes have a precedence over later hashes for what\n# we will pick to use.\n_SUPPORTED_HASHES = (\"sha512\", \"sha384\", \"sha256\", \"sha224\", \"sha1\", \"md5\")\n\n\n@dataclass(frozen=True)\nclass LinkHash:\n    \"\"\"Links to content may have embedded hash values. This class parses those.\n\n    `name` must be any member of `_SUPPORTED_HASHES`.\n\n    This class can be converted to and from `ArchiveInfo`. While ArchiveInfo intends to\n    be JSON-serializable to conform to PEP 610, this class contains the logic for\n    parsing a hash name and value for correctness, and then checking whether that hash\n    conforms to a schema with `.is_hash_allowed()`.\"\"\"\n\n    name: str\n    value: str\n\n    _hash_url_fragment_re = re.compile(\n        # NB: we do not validate that the second group (.*) is a valid hex\n        # digest. Instead, we simply keep that string in this class, and then check it\n        # against Hashes when hash-checking is needed. This is easier to debug than\n        # proactively discarding an invalid hex digest, as we handle incorrect hashes\n        # and malformed hashes in the same place.\n        r\"[#&]({choices})=([^&]*)\".format(\n            choices=\"|\".join(re.escape(hash_name) for hash_name in _SUPPORTED_HASHES)\n        ),\n    )\n\n    def __post_init__(self) -> None:\n        assert self.name in _SUPPORTED_HASHES\n\n    @classmethod\n    @functools.lru_cache(maxsize=None)\n    def find_hash_url_fragment(cls, url: str) -> Optional[\"LinkHash\"]:\n        \"\"\"Search a string for a checksum algorithm name and encoded output value.\"\"\"\n        match = cls._hash_url_fragment_re.search(url)\n        if match is None:\n            return None\n        name, value = match.groups()\n        return cls(name=name, value=value)\n\n    def as_dict(self) -> Dict[str, str]:\n        return {self.name: self.value}\n\n    def as_hashes(self) -> Hashes:\n        \"\"\"Return a Hashes instance which checks only for the current hash.\"\"\"\n        return Hashes({self.name: [self.value]})\n\n    def is_hash_allowed(self, hashes: Optional[Hashes]) -> bool:\n        \"\"\"\n        Return True if the current hash is allowed by `hashes`.\n        \"\"\"\n        if hashes is None:\n            return False\n        return hashes.is_hash_allowed(self.name, hex_digest=self.value)\n\n\n@dataclass(frozen=True)\nclass MetadataFile:\n    \"\"\"Information about a core metadata file associated with a distribution.\"\"\"\n\n    hashes: Optional[Dict[str, str]]\n\n    def __post_init__(self) -> None:\n        if self.hashes is not None:\n            assert all(name in _SUPPORTED_HASHES for name in self.hashes)\n\n\ndef supported_hashes(hashes: Optional[Dict[str, str]]) -> Optional[Dict[str, str]]:\n    # Remove any unsupported hash types from the mapping. If this leaves no\n    # supported hashes, return None\n    if hashes is None:\n        return None\n    hashes = {n: v for n, v in hashes.items() if n in _SUPPORTED_HASHES}\n    if not hashes:\n        return None\n    return hashes\n\n\ndef _clean_url_path_part(part: str) -> str:\n    \"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\pylock.py": {
      "sha": "90200ed0162c",
      "lines": 183,
      "head": "import dataclasses\nimport re\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Any, Dict, Iterable, List, Optional, Tuple\n\nfrom pip._vendor import tomli_w\nfrom pip._vendor.typing_extensions import Self\n\nfrom pip._internal.models.direct_url import ArchiveInfo, DirInfo, VcsInfo\nfrom pip._internal.models.link import Link\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.utils.urls import url_to_path\n\nPYLOCK_FILE_NAME_RE = re.compile(r\"^pylock\\.([^.]+)\\.toml$\")\n\n\ndef is_valid_pylock_file_name(path: Path) -> bool:\n    return path.name == \"pylock.toml\" or bool(re.match(PYLOCK_FILE_NAME_RE, path.name))\n\n\ndef _toml_dict_factory(data: List[Tuple[str, Any]]) -> Dict[str, Any]:\n    return {key.replace(\"_\", \"-\"): value for key, value in data if value is not None}\n\n\n@dataclass\nclass PackageVcs:\n    type: str\n    url: Optional[str]\n    # (not supported) path: Optional[str]\n    requested_revision: Optional[str]\n    commit_id: str\n    subdirectory: Optional[str]\n\n\n@dataclass\nclass PackageDirectory:\n    path: str\n    editable: Optional[bool]\n    subdirectory: Optional[str]\n\n\n@dataclass\nclass PackageArchive:\n    url: Optional[str]\n    # (not supported) path: Optional[str]\n    # (not supported) size: Optional[int]\n    # (not supported) upload_time: Optional[datetime]\n    hashes: Dict[str, str]\n    subdirectory: Optional[str]\n\n\n@dataclass\nclass PackageSdist:\n    name: str\n    # (not supported) upload_time: Optional[datetime]\n    url: Optional[str]\n    # (not supported) path: Optional[str]\n    # (not supported) size: Optional[int]\n    hashes: Dict[str, str]\n\n\n@dataclass\nclass PackageWheel:\n    name: str\n    # (not supported) upload_time: Optional[datetime]\n    url: Optional[str]\n    # (not supported) path: Optional[str]\n    # (not supported) size: Optional[int]\n    hashes: Dict[str, str]\n\n\n@dataclass\nclass Package:\n    name: str\n    version: Optional[str] = None\n    # (not supported) marker: Optional[str]\n    # (not supported) requires_python: Optional[str]\n    # (not supported) dependencies\n    vcs: Optional[PackageVcs] = None\n    directory: Optional[PackageDirectory] = None\n    archive: Optional[PackageArchive] = None\n    # (not supported) index: Optional[str]\n    sdist: Optional[PackageSdist] = None\n    wheels: Optional[List[PackageWheel]] = None\n    # (not supported) attestation_identities: Optional[List[Dict[str, Any]]]\n    # (not supported) tool: Optional[Dict[str, Any]]\n\n    @classmethod\n    def from_install_requirement(cls, ireq: InstallRequirement, base_dir: Path) -> Self:\n        base_dir = base_dir.resolve()\n        dist = ireq.get_dist()\n        download_info = ireq.download_info\n        assert download_info\n        package = cls(name=dist.canonical_name)\n        if ireq.is_direct:\n            if isinstance(download_info.info, VcsInfo):\n                package.vcs = PackageVcs(\n                    type=download_info.info.vcs,\n                    url=download_info.url,\n                    requested_revision=download_info.info.requested_revision,\n                    commit_id=download_info.info.commit_id,\n                    subdirectory=download_info.subdirectory,\n                )\n            elif isinstance(download_info.info, DirInfo):\n                package.directory = PackageDirectory(\n                    path=(\n                        Path(url_to_path(download_info.url))\n                        .resolve()\n                        .relative_to(base_dir)\n                        .as_posix()\n                    ),\n                    editable=(\n                        download_info.info.editable\n                        if download_info.info.editable\n                        else None\n                    ),\n                    subdirectory=download_info.subdirectory,\n                )\n            elif isinstance(download_info.info, ArchiveInfo):\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\scheme.py": {
      "sha": "0dfcfe35e057",
      "lines": 25,
      "head": "\"\"\"\nFor types associated with installation schemes.\n\nFor a general overview of available schemes and their context, see\nhttps://docs.python.org/3/install/index.html#alternate-installation.\n\"\"\"\n\nfrom dataclasses import dataclass\n\nSCHEME_KEYS = [\"platlib\", \"purelib\", \"headers\", \"scripts\", \"data\"]\n\n\n@dataclass(frozen=True)\nclass Scheme:\n    \"\"\"A Scheme holds paths which are used as the base directories for\n    artifacts associated with a Python package.\n    \"\"\"\n\n    __slots__ = SCHEME_KEYS\n\n    platlib: str\n    purelib: str\n    headers: str\n    scripts: str\n    data: str\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\search_scope.py": {
      "sha": "0f72e06bd7b6",
      "lines": 127,
      "head": "import itertools\nimport logging\nimport os\nimport posixpath\nimport urllib.parse\nfrom dataclasses import dataclass\nfrom typing import List\n\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.models.index import PyPI\nfrom pip._internal.utils.compat import has_tls\nfrom pip._internal.utils.misc import normalize_path, redact_auth_from_url\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass(frozen=True)\nclass SearchScope:\n    \"\"\"\n    Encapsulates the locations that pip is configured to search.\n    \"\"\"\n\n    __slots__ = [\"find_links\", \"index_urls\", \"no_index\"]\n\n    find_links: List[str]\n    index_urls: List[str]\n    no_index: bool\n\n    @classmethod\n    def create(\n        cls,\n        find_links: List[str],\n        index_urls: List[str],\n        no_index: bool,\n    ) -> \"SearchScope\":\n        \"\"\"\n        Create a SearchScope object after normalizing the `find_links`.\n        \"\"\"\n        # Build find_links. If an argument starts with ~, it may be\n        # a local file relative to a home directory. So try normalizing\n        # it and if it exists, use the normalized version.\n        # This is deliberately conservative - it might be fine just to\n        # blindly normalize anything starting with a ~...\n        built_find_links: List[str] = []\n        for link in find_links:\n            if link.startswith(\"~\"):\n                new_link = normalize_path(link)\n                if os.path.exists(new_link):\n                    link = new_link\n            built_find_links.append(link)\n\n        # If we don't have TLS enabled, then WARN if anyplace we're looking\n        # relies on TLS.\n        if not has_tls():\n            for link in itertools.chain(index_urls, built_find_links):\n                parsed = urllib.parse.urlparse(link)\n                if parsed.scheme == \"https\":\n                    logger.warning(\n                        \"pip is configured with locations that require \"\n                        \"TLS/SSL, however the ssl module in Python is not \"\n                        \"available.\"\n                    )\n                    break\n\n        return cls(\n            find_links=built_find_links,\n            index_urls=index_urls,\n            no_index=no_index,\n        )\n\n    def get_formatted_locations(self) -> str:\n        lines = []\n        redacted_index_urls = []\n        if self.index_urls and self.index_urls != [PyPI.simple_url]:\n            for url in self.index_urls:\n                redacted_index_url = redact_auth_from_url(url)\n\n                # Parse the URL\n                purl = urllib.parse.urlsplit(redacted_index_url)\n\n                # URL is generally invalid if scheme and netloc is missing\n                # there are issues with Python and URL parsing, so this test\n                # is a bit crude. See bpo-20271, bpo-23505. Python doesn't\n                # always parse invalid URLs correctly - it should raise\n                # exceptions for malformed URLs\n                if not purl.scheme and not purl.netloc:\n                    logger.warning(\n                        'The index url \"%s\" seems invalid, please provide a scheme.',\n                        redacted_index_url,\n                    )\n\n                redacted_index_urls.append(redacted_index_url)\n\n            lines.append(\n                \"Looking in indexes: {}\".format(\", \".join(redacted_index_urls))\n            )\n\n        if self.find_links:\n            lines.append(\n                \"Looking in links: {}\".format(\n                    \", \".join(redact_auth_from_url(url) for url in self.find_links)\n                )\n            )\n        return \"\\n\".join(lines)\n\n    def get_index_urls_locations(self, project_name: str) -> List[str]:\n        \"\"\"Returns the locations found via self.index_urls\n\n        Checks the url_name on the main (first in the list) index and\n        use this url_name to produce all locations\n        \"\"\"\n\n        def mkurl_pypi_url(url: str) -> str:\n            loc = posixpath.join(\n                url, urllib.parse.quote(canonicalize_name(project_name))\n            )\n            # For maximum compatibility with easy_install, ensure the path\n            # ends in a trailing slash.  Although this isn't in the spec\n            # (and PyPI can handle it without the slash) some other index\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\selection_prefs.py": {
      "sha": "df4ee02f80ae",
      "lines": 53,
      "head": "from typing import Optional\n\nfrom pip._internal.models.format_control import FormatControl\n\n\n# TODO: This needs Python 3.10's improved slots support for dataclasses\n# to be converted into a dataclass.\nclass SelectionPreferences:\n    \"\"\"\n    Encapsulates the candidate selection preferences for downloading\n    and installing files.\n    \"\"\"\n\n    __slots__ = [\n        \"allow_yanked\",\n        \"allow_all_prereleases\",\n        \"format_control\",\n        \"prefer_binary\",\n        \"ignore_requires_python\",\n    ]\n\n    # Don't include an allow_yanked default value to make sure each call\n    # site considers whether yanked releases are allowed. This also causes\n    # that decision to be made explicit in the calling code, which helps\n    # people when reading the code.\n    def __init__(\n        self,\n        allow_yanked: bool,\n        allow_all_prereleases: bool = False,\n        format_control: Optional[FormatControl] = None,\n        prefer_binary: bool = False,\n        ignore_requires_python: Optional[bool] = None,\n    ) -> None:\n        \"\"\"Create a SelectionPreferences object.\n\n        :param allow_yanked: Whether files marked as yanked (in the sense\n            of PEP 592) are permitted to be candidates for install.\n        :param format_control: A FormatControl object or None. Used to control\n            the selection of source packages / binary packages when consulting\n            the index and links.\n        :param prefer_binary: Whether to prefer an old, but valid, binary\n            dist over a new source dist.\n        :param ignore_requires_python: Whether to ignore incompatible\n            \"Requires-Python\" values in links. Defaults to False.\n        \"\"\"\n        if ignore_requires_python is None:\n            ignore_requires_python = False\n\n        self.allow_yanked = allow_yanked\n        self.allow_all_prereleases = allow_all_prereleases\n        self.format_control = format_control\n        self.prefer_binary = prefer_binary\n        self.ignore_requires_python = ignore_requires_python\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\target_python.py": {
      "sha": "66180881c576",
      "lines": 121,
      "head": "import sys\nfrom typing import List, Optional, Set, Tuple\n\nfrom pip._vendor.packaging.tags import Tag\n\nfrom pip._internal.utils.compatibility_tags import get_supported, version_info_to_nodot\nfrom pip._internal.utils.misc import normalize_version_info\n\n\nclass TargetPython:\n    \"\"\"\n    Encapsulates the properties of a Python interpreter one is targeting\n    for a package install, download, etc.\n    \"\"\"\n\n    __slots__ = [\n        \"_given_py_version_info\",\n        \"abis\",\n        \"implementation\",\n        \"platforms\",\n        \"py_version\",\n        \"py_version_info\",\n        \"_valid_tags\",\n        \"_valid_tags_set\",\n    ]\n\n    def __init__(\n        self,\n        platforms: Optional[List[str]] = None,\n        py_version_info: Optional[Tuple[int, ...]] = None,\n        abis: Optional[List[str]] = None,\n        implementation: Optional[str] = None,\n    ) -> None:\n        \"\"\"\n        :param platforms: A list of strings or None. If None, searches for\n            packages that are supported by the current system. Otherwise, will\n            find packages that can be built on the platforms passed in. These\n            packages will only be downloaded for distribution: they will\n            not be built locally.\n        :param py_version_info: An optional tuple of ints representing the\n            Python version information to use (e.g. `sys.version_info[:3]`).\n            This can have length 1, 2, or 3 when provided.\n        :param abis: A list of strings or None. This is passed to\n            compatibility_tags.py's get_supported() function as is.\n        :param implementation: A string or None. This is passed to\n            compatibility_tags.py's get_supported() function as is.\n        \"\"\"\n        # Store the given py_version_info for when we call get_supported().\n        self._given_py_version_info = py_version_info\n\n        if py_version_info is None:\n            py_version_info = sys.version_info[:3]\n        else:\n            py_version_info = normalize_version_info(py_version_info)\n\n        py_version = \".\".join(map(str, py_version_info[:2]))\n\n        self.abis = abis\n        self.implementation = implementation\n        self.platforms = platforms\n        self.py_version = py_version\n        self.py_version_info = py_version_info\n\n        # This is used to cache the return value of get_(un)sorted_tags.\n        self._valid_tags: Optional[List[Tag]] = None\n        self._valid_tags_set: Optional[Set[Tag]] = None\n\n    def format_given(self) -> str:\n        \"\"\"\n        Format the given, non-None attributes for display.\n        \"\"\"\n        display_version = None\n        if self._given_py_version_info is not None:\n            display_version = \".\".join(\n                str(part) for part in self._given_py_version_info\n            )\n\n        key_values = [\n            (\"platforms\", self.platforms),\n            (\"version_info\", display_version),\n            (\"abis\", self.abis),\n            (\"implementation\", self.implementation),\n        ]\n        return \" \".join(\n            f\"{key}={value!r}\" for key, value in key_values if value is not None\n        )\n\n    def get_sorted_tags(self) -> List[Tag]:\n        \"\"\"\n        Return the supported PEP 425 tags to check wheel candidates against.\n\n        The tags are returned in order of preference (most preferred first).\n        \"\"\"\n        if self._valid_tags is None:\n            # Pass versions=None if no py_version_info was given since\n            # versions=None uses special default logic.\n            py_version_info = self._given_py_version_info\n            if py_version_info is None:\n                version = None\n            else:\n                version = version_info_to_nodot(py_version_info)\n\n            tags = get_supported(\n                version=version,\n                platforms=self.platforms,\n                abis=self.abis,\n                impl=self.implementation,\n            )\n            self._valid_tags = tags\n\n        return self._valid_tags\n\n    def get_unsorted_tags(self) -> Set[Tag]:\n        \"\"\"Exactly the same as get_sorted_tags, but returns a set.\n\n        This is important for performance.\n        \"\"\"\n        if self._valid_tags_set is None:\n            self._valid_tags_set = set(self.get_sorted_tags())\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\wheel.py": {
      "sha": "c117ba395780",
      "lines": 139,
      "head": "\"\"\"Represents a wheel file and provides access to the various parts of the\nname that have meaning.\n\"\"\"\n\nimport re\nfrom typing import Dict, Iterable, List, Optional\n\nfrom pip._vendor.packaging.tags import Tag\nfrom pip._vendor.packaging.utils import BuildTag, parse_wheel_filename\nfrom pip._vendor.packaging.utils import (\n    InvalidWheelFilename as _PackagingInvalidWheelFilename,\n)\n\nfrom pip._internal.exceptions import InvalidWheelFilename\nfrom pip._internal.utils.deprecation import deprecated\n\n\nclass Wheel:\n    \"\"\"A wheel file\"\"\"\n\n    legacy_wheel_file_re = re.compile(\n        r\"\"\"^(?P<namever>(?P<name>[^\\s-]+?)-(?P<ver>[^\\s-]*?))\n        ((-(?P<build>\\d[^-]*?))?-(?P<pyver>[^\\s-]+?)-(?P<abi>[^\\s-]+?)-(?P<plat>[^\\s-]+?)\n        \\.whl|\\.dist-info)$\"\"\",\n        re.VERBOSE,\n    )\n\n    def __init__(self, filename: str) -> None:\n        self.filename = filename\n\n        # To make mypy happy specify type hints that can come from either\n        # parse_wheel_filename or the legacy_wheel_file_re match.\n        self.name: str\n        self._build_tag: Optional[BuildTag] = None\n\n        try:\n            wheel_info = parse_wheel_filename(filename)\n            self.name, _version, self._build_tag, self.file_tags = wheel_info\n            self.version = str(_version)\n        except _PackagingInvalidWheelFilename as e:\n            # Check if the wheel filename is in the legacy format\n            legacy_wheel_info = self.legacy_wheel_file_re.match(filename)\n            if not legacy_wheel_info:\n                raise InvalidWheelFilename(e.args[0]) from None\n\n            deprecated(\n                reason=(\n                    f\"Wheel filename {filename!r} is not correctly normalised. \"\n                    \"Future versions of pip will raise the following error:\\n\"\n                    f\"{e.args[0]}\\n\\n\"\n                ),\n                replacement=(\n                    \"to rename the wheel to use a correctly normalised \"\n                    \"name (this may require updating the version in \"\n                    \"the project metadata)\"\n                ),\n                gone_in=\"25.3\",\n                issue=12938,\n            )\n\n            self.name = legacy_wheel_info.group(\"name\").replace(\"_\", \"-\")\n            self.version = legacy_wheel_info.group(\"ver\").replace(\"_\", \"-\")\n\n            # Generate the file tags from the legacy wheel filename\n            pyversions = legacy_wheel_info.group(\"pyver\").split(\".\")\n            abis = legacy_wheel_info.group(\"abi\").split(\".\")\n            plats = legacy_wheel_info.group(\"plat\").split(\".\")\n            self.file_tags = frozenset(\n                Tag(interpreter=py, abi=abi, platform=plat)\n                for py in pyversions\n                for abi in abis\n                for plat in plats\n            )\n\n    @property\n    def build_tag(self) -> BuildTag:\n        if self._build_tag is not None:\n            return self._build_tag\n\n        # Parse the build tag from the legacy wheel filename\n        legacy_wheel_info = self.legacy_wheel_file_re.match(self.filename)\n        assert legacy_wheel_info is not None, \"guaranteed by filename validation\"\n        build_tag = legacy_wheel_info.group(\"build\")\n        match = re.match(r\"^(\\d+)(.*)$\", build_tag)\n        assert match is not None, \"guaranteed by filename validation\"\n        build_tag_groups = match.groups()\n        self._build_tag = (int(build_tag_groups[0]), build_tag_groups[1])\n\n        return self._build_tag\n\n    def get_formatted_file_tags(self) -> List[str]:\n        \"\"\"Return the wheel's tags as a sorted list of strings.\"\"\"\n        return sorted(str(tag) for tag in self.file_tags)\n\n    def support_index_min(self, tags: List[Tag]) -> int:\n        \"\"\"Return the lowest index that one of the wheel's file_tag combinations\n        achieves in the given list of supported tags.\n\n        For example, if there are 8 supported tags and one of the file tags\n        is first in the list, then return 0.\n\n        :param tags: the PEP 425 tags to check the wheel against, in order\n            with most preferred first.\n\n        :raises ValueError: If none of the wheel's file tags match one of\n            the supported tags.\n        \"\"\"\n        try:\n            return next(i for i, t in enumerate(tags) if t in self.file_tags)\n        except StopIteration:\n            raise ValueError()\n\n    def find_most_preferred_tag(\n        self, tags: List[Tag], tag_to_priority: Dict[Tag, int]\n    ) -> int:\n        \"\"\"Return the priority of the most preferred tag that one of the wheel's file\n        tag combinations achieves in the given list of supported tags using the given\n        tag_to_priority mapping, where lower priorities are more-preferred.\n\n        This is used in place of support_index_min in some cases in order to avoid\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\models\\__init__.py": {
      "sha": "1e20a4d1d269",
      "lines": 1,
      "head": "\"\"\"A package that contains models that represent entities.\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\auth.py": {
      "sha": "f9652bbef1a3",
      "lines": 566,
      "head": "\"\"\"Network Authentication Helpers\n\nContains interface (MultiDomainBasicAuth) and associated glue code for\nproviding credentials in the context of network requests.\n\"\"\"\n\nimport logging\nimport os\nimport shutil\nimport subprocess\nimport sysconfig\nimport typing\nimport urllib.parse\nfrom abc import ABC, abstractmethod\nfrom functools import lru_cache\nfrom os.path import commonprefix\nfrom pathlib import Path\nfrom typing import Any, Dict, List, NamedTuple, Optional, Tuple\n\nfrom pip._vendor.requests.auth import AuthBase, HTTPBasicAuth\nfrom pip._vendor.requests.models import Request, Response\nfrom pip._vendor.requests.utils import get_netrc_auth\n\nfrom pip._internal.utils.logging import getLogger\nfrom pip._internal.utils.misc import (\n    ask,\n    ask_input,\n    ask_password,\n    remove_auth_from_url,\n    split_auth_netloc_from_url,\n)\nfrom pip._internal.vcs.versioncontrol import AuthInfo\n\nlogger = getLogger(__name__)\n\nKEYRING_DISABLED = False\n\n\nclass Credentials(NamedTuple):\n    url: str\n    username: str\n    password: str\n\n\nclass KeyRingBaseProvider(ABC):\n    \"\"\"Keyring base provider interface\"\"\"\n\n    has_keyring: bool\n\n    @abstractmethod\n    def get_auth_info(\n        self, url: str, username: Optional[str]\n    ) -> Optional[AuthInfo]: ...\n\n    @abstractmethod\n    def save_auth_info(self, url: str, username: str, password: str) -> None: ...\n\n\nclass KeyRingNullProvider(KeyRingBaseProvider):\n    \"\"\"Keyring null provider\"\"\"\n\n    has_keyring = False\n\n    def get_auth_info(self, url: str, username: Optional[str]) -> Optional[AuthInfo]:\n        return None\n\n    def save_auth_info(self, url: str, username: str, password: str) -> None:\n        return None\n\n\nclass KeyRingPythonProvider(KeyRingBaseProvider):\n    \"\"\"Keyring interface which uses locally imported `keyring`\"\"\"\n\n    has_keyring = True\n\n    def __init__(self) -> None:\n        import keyring\n\n        self.keyring = keyring\n\n    def get_auth_info(self, url: str, username: Optional[str]) -> Optional[AuthInfo]:\n        # Support keyring's get_credential interface which supports getting\n        # credentials without a username. This is only available for\n        # keyring>=15.2.0.\n        if hasattr(self.keyring, \"get_credential\"):\n            logger.debug(\"Getting credentials from keyring for %s\", url)\n            cred = self.keyring.get_credential(url, username)\n            if cred is not None:\n                return cred.username, cred.password\n            return None\n\n        if username is not None:\n            logger.debug(\"Getting password from keyring for %s\", url)\n            password = self.keyring.get_password(url, username)\n            if password:\n                return username, password\n        return None\n\n    def save_auth_info(self, url: str, username: str, password: str) -> None:\n        self.keyring.set_password(url, username, password)\n\n\nclass KeyRingCliProvider(KeyRingBaseProvider):\n    \"\"\"Provider which uses `keyring` cli\n\n    Instead of calling the keyring package installed alongside pip\n    we call keyring on the command line which will enable pip to\n    use which ever installation of keyring is available first in\n    PATH.\n    \"\"\"\n\n    has_keyring = True\n\n    def __init__(self, cmd: str) -> None:\n        self.keyring = cmd\n\n    def get_auth_info(self, url: str, username: Optional[str]) -> Optional[AuthInfo]:\n        # This is the default implementation of keyring.get_credential\n        # https://github.com/jaraco/keyring/blob/97689324abcf01bd1793d49063e7ca01e03d7d07/keyring/backend.py#L134-L139\n        if username is not None:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\cache.py": {
      "sha": "a44561751122",
      "lines": 117,
      "head": "\"\"\"HTTP cache implementation.\"\"\"\n\nimport os\nfrom contextlib import contextmanager\nfrom datetime import datetime\nfrom typing import BinaryIO, Generator, Optional, Union\n\nfrom pip._vendor.cachecontrol.cache import SeparateBodyBaseCache\nfrom pip._vendor.cachecontrol.caches import SeparateBodyFileCache\nfrom pip._vendor.requests.models import Response\n\nfrom pip._internal.utils.filesystem import adjacent_tmp_file, replace\nfrom pip._internal.utils.misc import ensure_dir\n\n\ndef is_from_cache(response: Response) -> bool:\n    return getattr(response, \"from_cache\", False)\n\n\n@contextmanager\ndef suppressed_cache_errors() -> Generator[None, None, None]:\n    \"\"\"If we can't access the cache then we can just skip caching and process\n    requests as if caching wasn't enabled.\n    \"\"\"\n    try:\n        yield\n    except OSError:\n        pass\n\n\nclass SafeFileCache(SeparateBodyBaseCache):\n    \"\"\"\n    A file based cache which is safe to use even when the target directory may\n    not be accessible or writable.\n\n    There is a race condition when two processes try to write and/or read the\n    same entry at the same time, since each entry consists of two separate\n    files (https://github.com/psf/cachecontrol/issues/324).  We therefore have\n    additional logic that makes sure that both files to be present before\n    returning an entry; this fixes the read side of the race condition.\n\n    For the write side, we assume that the server will only ever return the\n    same data for the same URL, which ought to be the case for files pip is\n    downloading.  PyPI does not have a mechanism to swap out a wheel for\n    another wheel, for example.  If this assumption is not true, the\n    CacheControl issue will need to be fixed.\n    \"\"\"\n\n    def __init__(self, directory: str) -> None:\n        assert directory is not None, \"Cache directory must not be None.\"\n        super().__init__()\n        self.directory = directory\n\n    def _get_cache_path(self, name: str) -> str:\n        # From cachecontrol.caches.file_cache.FileCache._fn, brought into our\n        # class for backwards-compatibility and to avoid using a non-public\n        # method.\n        hashed = SeparateBodyFileCache.encode(name)\n        parts = list(hashed[:5]) + [hashed]\n        return os.path.join(self.directory, *parts)\n\n    def get(self, key: str) -> Optional[bytes]:\n        # The cache entry is only valid if both metadata and body exist.\n        metadata_path = self._get_cache_path(key)\n        body_path = metadata_path + \".body\"\n        if not (os.path.exists(metadata_path) and os.path.exists(body_path)):\n            return None\n        with suppressed_cache_errors():\n            with open(metadata_path, \"rb\") as f:\n                return f.read()\n\n    def _write(self, path: str, data: bytes) -> None:\n        with suppressed_cache_errors():\n            ensure_dir(os.path.dirname(path))\n\n            with adjacent_tmp_file(path) as f:\n                f.write(data)\n                # Inherit the read/write permissions of the cache directory\n                # to enable multi-user cache use-cases.\n                mode = (\n                    os.stat(self.directory).st_mode\n                    & 0o666  # select read/write permissions of cache directory\n                    | 0o600  # set owner read/write permissions\n                )\n                # Change permissions only if there is no risk of following a symlink.\n                if os.chmod in os.supports_fd:\n                    os.chmod(f.fileno(), mode)\n                elif os.chmod in os.supports_follow_symlinks:\n                    os.chmod(f.name, mode, follow_symlinks=False)\n\n            replace(f.name, path)\n\n    def set(\n        self, key: str, value: bytes, expires: Union[int, datetime, None] = None\n    ) -> None:\n        path = self._get_cache_path(key)\n        self._write(path, value)\n\n    def delete(self, key: str) -> None:\n        path = self._get_cache_path(key)\n        with suppressed_cache_errors():\n            os.remove(path)\n        with suppressed_cache_errors():\n            os.remove(path + \".body\")\n\n    def get_body(self, key: str) -> Optional[BinaryIO]:\n        # The cache entry is only valid if both metadata and body exist.\n        metadata_path = self._get_cache_path(key)\n        body_path = metadata_path + \".body\"\n        if not (os.path.exists(metadata_path) and os.path.exists(body_path)):\n            return None\n        with suppressed_cache_errors():\n            return open(body_path, \"rb\")\n\n    def set_body(self, key: str, body: bytes) -> None:\n        path = self._get_cache_path(key) + \".body\"\n        self._write(path, body)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\download.py": {
      "sha": "701dbfd7cbb6",
      "lines": 314,
      "head": "\"\"\"Download files with progress indicators.\"\"\"\n\nimport email.message\nimport logging\nimport mimetypes\nimport os\nfrom http import HTTPStatus\nfrom typing import BinaryIO, Iterable, Optional, Tuple\n\nfrom pip._vendor.requests.models import Response\nfrom pip._vendor.urllib3.exceptions import ReadTimeoutError\n\nfrom pip._internal.cli.progress_bars import get_download_progress_renderer\nfrom pip._internal.exceptions import IncompleteDownloadError, NetworkConnectionError\nfrom pip._internal.models.index import PyPI\nfrom pip._internal.models.link import Link\nfrom pip._internal.network.cache import is_from_cache\nfrom pip._internal.network.session import PipSession\nfrom pip._internal.network.utils import HEADERS, raise_for_status, response_chunks\nfrom pip._internal.utils.misc import format_size, redact_auth_from_url, splitext\n\nlogger = logging.getLogger(__name__)\n\n\ndef _get_http_response_size(resp: Response) -> Optional[int]:\n    try:\n        return int(resp.headers[\"content-length\"])\n    except (ValueError, KeyError, TypeError):\n        return None\n\n\ndef _get_http_response_etag_or_last_modified(resp: Response) -> Optional[str]:\n    \"\"\"\n    Return either the ETag or Last-Modified header (or None if neither exists).\n    The return value can be used in an If-Range header.\n    \"\"\"\n    return resp.headers.get(\"etag\", resp.headers.get(\"last-modified\"))\n\n\ndef _prepare_download(\n    resp: Response,\n    link: Link,\n    progress_bar: str,\n    total_length: Optional[int],\n    range_start: Optional[int] = 0,\n) -> Iterable[bytes]:\n    if link.netloc == PyPI.file_storage_domain:\n        url = link.show_url\n    else:\n        url = link.url_without_fragment\n\n    logged_url = redact_auth_from_url(url)\n\n    if total_length:\n        if range_start:\n            logged_url = (\n                f\"{logged_url} ({format_size(range_start)}/{format_size(total_length)})\"\n            )\n        else:\n            logged_url = f\"{logged_url} ({format_size(total_length)})\"\n\n    if is_from_cache(resp):\n        logger.info(\"Using cached %s\", logged_url)\n    elif range_start:\n        logger.info(\"Resuming download %s\", logged_url)\n    else:\n        logger.info(\"Downloading %s\", logged_url)\n\n    if logger.getEffectiveLevel() > logging.INFO:\n        show_progress = False\n    elif is_from_cache(resp):\n        show_progress = False\n    elif not total_length:\n        show_progress = True\n    elif total_length > (512 * 1024):\n        show_progress = True\n    else:\n        show_progress = False\n\n    chunks = response_chunks(resp)\n\n    if not show_progress:\n        return chunks\n\n    renderer = get_download_progress_renderer(\n        bar_type=progress_bar, size=total_length, initial_progress=range_start\n    )\n    return renderer(chunks)\n\n\ndef sanitize_content_filename(filename: str) -> str:\n    \"\"\"\n    Sanitize the \"filename\" value from a Content-Disposition header.\n    \"\"\"\n    return os.path.basename(filename)\n\n\ndef parse_content_disposition(content_disposition: str, default_filename: str) -> str:\n    \"\"\"\n    Parse the \"filename\" value from a Content-Disposition header, and\n    return the default filename if the result is empty.\n    \"\"\"\n    m = email.message.Message()\n    m[\"content-type\"] = content_disposition\n    filename = m.get_param(\"filename\")\n    if filename:\n        # We need to sanitize the filename to prevent directory traversal\n        # in case the filename contains \"..\" path parts.\n        filename = sanitize_content_filename(str(filename))\n    return filename or default_filename\n\n\ndef _get_http_response_filename(resp: Response, link: Link) -> str:\n    \"\"\"Get an ideal filename from the given HTTP response, falling back to\n    the link filename if not provided.\n    \"\"\"\n    filename = link.filename  # fallback\n    # Have a look at the Content-Disposition header for a better guess\n    content_disposition = resp.headers.get(\"content-disposition\")\n    if content_disposition:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\lazy_wheel.py": {
      "sha": "7cf373f9a337",
      "lines": 210,
      "head": "\"\"\"Lazy ZIP over HTTP\"\"\"\n\n__all__ = [\"HTTPRangeRequestUnsupported\", \"dist_from_wheel_url\"]\n\nfrom bisect import bisect_left, bisect_right\nfrom contextlib import contextmanager\nfrom tempfile import NamedTemporaryFile\nfrom typing import Any, Dict, Generator, List, Optional, Tuple\nfrom zipfile import BadZipFile, ZipFile\n\nfrom pip._vendor.packaging.utils import canonicalize_name\nfrom pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response\n\nfrom pip._internal.metadata import BaseDistribution, MemoryWheel, get_wheel_distribution\nfrom pip._internal.network.session import PipSession\nfrom pip._internal.network.utils import HEADERS, raise_for_status, response_chunks\n\n\nclass HTTPRangeRequestUnsupported(Exception):\n    pass\n\n\ndef dist_from_wheel_url(name: str, url: str, session: PipSession) -> BaseDistribution:\n    \"\"\"Return a distribution object from the given wheel URL.\n\n    This uses HTTP range requests to only fetch the portion of the wheel\n    containing metadata, just enough for the object to be constructed.\n    If such requests are not supported, HTTPRangeRequestUnsupported\n    is raised.\n    \"\"\"\n    with LazyZipOverHTTP(url, session) as zf:\n        # For read-only ZIP files, ZipFile only needs methods read,\n        # seek, seekable and tell, not the whole IO protocol.\n        wheel = MemoryWheel(zf.name, zf)  # type: ignore\n        # After context manager exit, wheel.name\n        # is an invalid file by intention.\n        return get_wheel_distribution(wheel, canonicalize_name(name))\n\n\nclass LazyZipOverHTTP:\n    \"\"\"File-like object mapped to a ZIP file over HTTP.\n\n    This uses HTTP range requests to lazily fetch the file's content,\n    which is supposed to be fed to ZipFile.  If such requests are not\n    supported by the server, raise HTTPRangeRequestUnsupported\n    during initialization.\n    \"\"\"\n\n    def __init__(\n        self, url: str, session: PipSession, chunk_size: int = CONTENT_CHUNK_SIZE\n    ) -> None:\n        head = session.head(url, headers=HEADERS)\n        raise_for_status(head)\n        assert head.status_code == 200\n        self._session, self._url, self._chunk_size = session, url, chunk_size\n        self._length = int(head.headers[\"Content-Length\"])\n        self._file = NamedTemporaryFile()\n        self.truncate(self._length)\n        self._left: List[int] = []\n        self._right: List[int] = []\n        if \"bytes\" not in head.headers.get(\"Accept-Ranges\", \"none\"):\n            raise HTTPRangeRequestUnsupported(\"range request is not supported\")\n        self._check_zip()\n\n    @property\n    def mode(self) -> str:\n        \"\"\"Opening mode, which is always rb.\"\"\"\n        return \"rb\"\n\n    @property\n    def name(self) -> str:\n        \"\"\"Path to the underlying file.\"\"\"\n        return self._file.name\n\n    def seekable(self) -> bool:\n        \"\"\"Return whether random access is supported, which is True.\"\"\"\n        return True\n\n    def close(self) -> None:\n        \"\"\"Close the file.\"\"\"\n        self._file.close()\n\n    @property\n    def closed(self) -> bool:\n        \"\"\"Whether the file is closed.\"\"\"\n        return self._file.closed\n\n    def read(self, size: int = -1) -> bytes:\n        \"\"\"Read up to size bytes from the object and return them.\n\n        As a convenience, if size is unspecified or -1,\n        all bytes until EOF are returned.  Fewer than\n        size bytes may be returned if EOF is reached.\n        \"\"\"\n        download_size = max(size, self._chunk_size)\n        start, length = self.tell(), self._length\n        stop = length if size < 0 else min(start + download_size, length)\n        start = max(0, stop - download_size)\n        self._download(start, stop - 1)\n        return self._file.read(size)\n\n    def readable(self) -> bool:\n        \"\"\"Return whether the file is readable, which is True.\"\"\"\n        return True\n\n    def seek(self, offset: int, whence: int = 0) -> int:\n        \"\"\"Change stream position and return the new absolute position.\n\n        Seek to offset relative position indicated by whence:\n        * 0: Start of stream (the default).  pos should be >= 0;\n        * 1: Current position - pos may be negative;\n        * 2: End of stream - pos usually negative.\n        \"\"\"\n        return self._file.seek(offset, whence)\n\n    def tell(self) -> int:\n        \"\"\"Return the current position.\"\"\"\n        return self._file.tell()\n\n    def truncate(self, size: Optional[int] = None) -> int:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\session.py": {
      "sha": "6a35b172cd79",
      "lines": 523,
      "head": "\"\"\"PipSession and supporting code, containing all pip-specific\nnetwork request configuration and behavior.\n\"\"\"\n\nimport email.utils\nimport functools\nimport io\nimport ipaddress\nimport json\nimport logging\nimport mimetypes\nimport os\nimport platform\nimport shutil\nimport subprocess\nimport sys\nimport urllib.parse\nimport warnings\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Dict,\n    Generator,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    Union,\n)\n\nfrom pip._vendor import requests, urllib3\nfrom pip._vendor.cachecontrol import CacheControlAdapter as _BaseCacheControlAdapter\nfrom pip._vendor.requests.adapters import DEFAULT_POOLBLOCK, BaseAdapter\nfrom pip._vendor.requests.adapters import HTTPAdapter as _BaseHTTPAdapter\nfrom pip._vendor.requests.models import PreparedRequest, Response\nfrom pip._vendor.requests.structures import CaseInsensitiveDict\nfrom pip._vendor.urllib3.connectionpool import ConnectionPool\nfrom pip._vendor.urllib3.exceptions import InsecureRequestWarning\n\nfrom pip import __version__\nfrom pip._internal.metadata import get_default_environment\nfrom pip._internal.models.link import Link\nfrom pip._internal.network.auth import MultiDomainBasicAuth\nfrom pip._internal.network.cache import SafeFileCache\n\n# Import ssl from compat so the initial import occurs in only one place.\nfrom pip._internal.utils.compat import has_tls\nfrom pip._internal.utils.glibc import libc_ver\nfrom pip._internal.utils.misc import build_url_from_netloc, parse_netloc\nfrom pip._internal.utils.urls import url_to_path\n\nif TYPE_CHECKING:\n    from ssl import SSLContext\n\n    from pip._vendor.urllib3.poolmanager import PoolManager\n\n\nlogger = logging.getLogger(__name__)\n\nSecureOrigin = Tuple[str, str, Optional[Union[int, str]]]\n\n\n# Ignore warning raised when using --trusted-host.\nwarnings.filterwarnings(\"ignore\", category=InsecureRequestWarning)\n\n\nSECURE_ORIGINS: List[SecureOrigin] = [\n    # protocol, hostname, port\n    # Taken from Chrome's list of secure origins (See: http://bit.ly/1qrySKC)\n    (\"https\", \"*\", \"*\"),\n    (\"*\", \"localhost\", \"*\"),\n    (\"*\", \"127.0.0.0/8\", \"*\"),\n    (\"*\", \"::1/128\", \"*\"),\n    (\"file\", \"*\", None),\n    # ssh is always secure.\n    (\"ssh\", \"*\", \"*\"),\n]\n\n\n# These are environment variables present when running under various\n# CI systems.  For each variable, some CI systems that use the variable\n# are indicated.  The collection was chosen so that for each of a number\n# of popular systems, at least one of the environment variables is used.\n# This list is used to provide some indication of and lower bound for\n# CI traffic to PyPI.  Thus, it is okay if the list is not comprehensive.\n# For more background, see: https://github.com/pypa/pip/issues/5499\nCI_ENVIRONMENT_VARIABLES = (\n    # Azure Pipelines\n    \"BUILD_BUILDID\",\n    # Jenkins\n    \"BUILD_ID\",\n    # AppVeyor, CircleCI, Codeship, Gitlab CI, Shippable, Travis CI\n    \"CI\",\n    # Explicit environment variable.\n    \"PIP_IS_CI\",\n)\n\n\ndef looks_like_ci() -> bool:\n    \"\"\"\n    Return whether it looks like pip is running under CI.\n    \"\"\"\n    # We don't use the method of checking for a tty (e.g. using isatty())\n    # because some CI systems mimic a tty (e.g. Travis CI).  Thus that\n    # method doesn't provide definitive information in either direction.\n    return any(name in os.environ for name in CI_ENVIRONMENT_VARIABLES)\n\n\n@functools.lru_cache(maxsize=1)\ndef user_agent() -> str:\n    \"\"\"\n    Return a string representing the user agent.\n    \"\"\"\n    data: Dict[str, Any] = {\n        \"installer\": {\"name\": \"pip\", \"version\": __version__},\n        \"python\": platform.python_version(),\n        \"implementation\": {\n            \"name\": platform.python_implementation(),\n        },\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\utils.py": {
      "sha": "bb62c8293bb1",
      "lines": 98,
      "head": "from typing import Dict, Generator\n\nfrom pip._vendor.requests.models import Response\n\nfrom pip._internal.exceptions import NetworkConnectionError\n\n# The following comments and HTTP headers were originally added by\n# Donald Stufft in git commit 22c562429a61bb77172039e480873fb239dd8c03.\n#\n# We use Accept-Encoding: identity here because requests defaults to\n# accepting compressed responses. This breaks in a variety of ways\n# depending on how the server is configured.\n# - Some servers will notice that the file isn't a compressible file\n#   and will leave the file alone and with an empty Content-Encoding\n# - Some servers will notice that the file is already compressed and\n#   will leave the file alone, adding a Content-Encoding: gzip header\n# - Some servers won't notice anything at all and will take a file\n#   that's already been compressed and compress it again, and set\n#   the Content-Encoding: gzip header\n# By setting this to request only the identity encoding we're hoping\n# to eliminate the third case.  Hopefully there does not exist a server\n# which when given a file will notice it is already compressed and that\n# you're not asking for a compressed file and will then decompress it\n# before sending because if that's the case I don't think it'll ever be\n# possible to make this work.\nHEADERS: Dict[str, str] = {\"Accept-Encoding\": \"identity\"}\n\nDOWNLOAD_CHUNK_SIZE = 256 * 1024\n\n\ndef raise_for_status(resp: Response) -> None:\n    http_error_msg = \"\"\n    if isinstance(resp.reason, bytes):\n        # We attempt to decode utf-8 first because some servers\n        # choose to localize their reason strings. If the string\n        # isn't utf-8, we fall back to iso-8859-1 for all other\n        # encodings.\n        try:\n            reason = resp.reason.decode(\"utf-8\")\n        except UnicodeDecodeError:\n            reason = resp.reason.decode(\"iso-8859-1\")\n    else:\n        reason = resp.reason\n\n    if 400 <= resp.status_code < 500:\n        http_error_msg = (\n            f\"{resp.status_code} Client Error: {reason} for url: {resp.url}\"\n        )\n\n    elif 500 <= resp.status_code < 600:\n        http_error_msg = (\n            f\"{resp.status_code} Server Error: {reason} for url: {resp.url}\"\n        )\n\n    if http_error_msg:\n        raise NetworkConnectionError(http_error_msg, response=resp)\n\n\ndef response_chunks(\n    response: Response, chunk_size: int = DOWNLOAD_CHUNK_SIZE\n) -> Generator[bytes, None, None]:\n    \"\"\"Given a requests Response, provide the data chunks.\"\"\"\n    try:\n        # Special case for urllib3.\n        for chunk in response.raw.stream(\n            chunk_size,\n            # We use decode_content=False here because we don't\n            # want urllib3 to mess with the raw bytes we get\n            # from the server. If we decompress inside of\n            # urllib3 then we cannot verify the checksum\n            # because the checksum will be of the compressed\n            # file. This breakage will only occur if the\n            # server adds a Content-Encoding header, which\n            # depends on how the server was configured:\n            # - Some servers will notice that the file isn't a\n            #   compressible file and will leave the file alone\n            #   and with an empty Content-Encoding\n            # - Some servers will notice that the file is\n            #   already compressed and will leave the file\n            #   alone and will add a Content-Encoding: gzip\n            #   header\n            # - Some servers won't notice anything at all and\n            #   will take a file that's already been compressed\n            #   and compress it again and set the\n            #   Content-Encoding: gzip header\n            #\n            # By setting this not to decode automatically we\n            # hope to eliminate problems with the second case.\n            decode_content=False,\n        ):\n            yield chunk\n    except AttributeError:\n        # Standard file-like object.\n        while True:\n            chunk = response.raw.read(chunk_size)\n            if not chunk:\n                break\n            yield chunk\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\xmlrpc.py": {
      "sha": "29bb170a732e",
      "lines": 61,
      "head": "\"\"\"xmlrpclib.Transport implementation\"\"\"\n\nimport logging\nimport urllib.parse\nimport xmlrpc.client\nfrom typing import TYPE_CHECKING, Tuple\n\nfrom pip._internal.exceptions import NetworkConnectionError\nfrom pip._internal.network.session import PipSession\nfrom pip._internal.network.utils import raise_for_status\n\nif TYPE_CHECKING:\n    from xmlrpc.client import _HostType, _Marshallable\n\n    from _typeshed import SizedBuffer\n\nlogger = logging.getLogger(__name__)\n\n\nclass PipXmlrpcTransport(xmlrpc.client.Transport):\n    \"\"\"Provide a `xmlrpclib.Transport` implementation via a `PipSession`\n    object.\n    \"\"\"\n\n    def __init__(\n        self, index_url: str, session: PipSession, use_datetime: bool = False\n    ) -> None:\n        super().__init__(use_datetime)\n        index_parts = urllib.parse.urlparse(index_url)\n        self._scheme = index_parts.scheme\n        self._session = session\n\n    def request(\n        self,\n        host: \"_HostType\",\n        handler: str,\n        request_body: \"SizedBuffer\",\n        verbose: bool = False,\n    ) -> Tuple[\"_Marshallable\", ...]:\n        assert isinstance(host, str)\n        parts = (self._scheme, host, handler, None, None, None)\n        url = urllib.parse.urlunparse(parts)\n        try:\n            headers = {\"Content-Type\": \"text/xml\"}\n            response = self._session.post(\n                url,\n                data=request_body,\n                headers=headers,\n                stream=True,\n            )\n            raise_for_status(response)\n            self.verbose = verbose\n            return self.parse_response(response.raw)\n        except NetworkConnectionError as exc:\n            assert exc.response\n            logger.critical(\n                \"HTTP error %s while getting %s\",\n                exc.response.status_code,\n                url,\n            )\n            raise\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\network\\__init__.py": {
      "sha": "73831e878838",
      "lines": 1,
      "head": "\"\"\"Contains purely network-related utilities.\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\check.py": {
      "sha": "7b7426431e42",
      "lines": 180,
      "head": "\"\"\"Validation of dependencies of packages\"\"\"\n\nimport logging\nfrom contextlib import suppress\nfrom email.parser import Parser\nfrom functools import reduce\nfrom typing import (\n    Callable,\n    Dict,\n    FrozenSet,\n    Generator,\n    Iterable,\n    List,\n    NamedTuple,\n    Optional,\n    Set,\n    Tuple,\n)\n\nfrom pip._vendor.packaging.requirements import Requirement\nfrom pip._vendor.packaging.tags import Tag, parse_tag\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\nfrom pip._vendor.packaging.version import Version\n\nfrom pip._internal.distributions import make_distribution_for_install_requirement\nfrom pip._internal.metadata import get_default_environment\nfrom pip._internal.metadata.base import BaseDistribution\nfrom pip._internal.req.req_install import InstallRequirement\n\nlogger = logging.getLogger(__name__)\n\n\nclass PackageDetails(NamedTuple):\n    version: Version\n    dependencies: List[Requirement]\n\n\n# Shorthands\nPackageSet = Dict[NormalizedName, PackageDetails]\nMissing = Tuple[NormalizedName, Requirement]\nConflicting = Tuple[NormalizedName, Version, Requirement]\n\nMissingDict = Dict[NormalizedName, List[Missing]]\nConflictingDict = Dict[NormalizedName, List[Conflicting]]\nCheckResult = Tuple[MissingDict, ConflictingDict]\nConflictDetails = Tuple[PackageSet, CheckResult]\n\n\ndef create_package_set_from_installed() -> Tuple[PackageSet, bool]:\n    \"\"\"Converts a list of distributions into a PackageSet.\"\"\"\n    package_set = {}\n    problems = False\n    env = get_default_environment()\n    for dist in env.iter_installed_distributions(local_only=False, skip=()):\n        name = dist.canonical_name\n        try:\n            dependencies = list(dist.iter_dependencies())\n            package_set[name] = PackageDetails(dist.version, dependencies)\n        except (OSError, ValueError) as e:\n            # Don't crash on unreadable or broken metadata.\n            logger.warning(\"Error parsing dependencies of %s: %s\", name, e)\n            problems = True\n    return package_set, problems\n\n\ndef check_package_set(\n    package_set: PackageSet, should_ignore: Optional[Callable[[str], bool]] = None\n) -> CheckResult:\n    \"\"\"Check if a package set is consistent\n\n    If should_ignore is passed, it should be a callable that takes a\n    package name and returns a boolean.\n    \"\"\"\n\n    missing = {}\n    conflicting = {}\n\n    for package_name, package_detail in package_set.items():\n        # Info about dependencies of package_name\n        missing_deps: Set[Missing] = set()\n        conflicting_deps: Set[Conflicting] = set()\n\n        if should_ignore and should_ignore(package_name):\n            continue\n\n        for req in package_detail.dependencies:\n            name = canonicalize_name(req.name)\n\n            # Check if it's missing\n            if name not in package_set:\n                missed = True\n                if req.marker is not None:\n                    missed = req.marker.evaluate({\"extra\": \"\"})\n                if missed:\n                    missing_deps.add((name, req))\n                continue\n\n            # Check if there's a conflict\n            version = package_set[name].version\n            if not req.specifier.contains(version, prereleases=True):\n                conflicting_deps.add((name, version, req))\n\n        if missing_deps:\n            missing[package_name] = sorted(missing_deps, key=str)\n        if conflicting_deps:\n            conflicting[package_name] = sorted(conflicting_deps, key=str)\n\n    return missing, conflicting\n\n\ndef check_install_conflicts(to_install: List[InstallRequirement]) -> ConflictDetails:\n    \"\"\"For checking if the dependency graph would be consistent after \\\n    installing given requirements\n    \"\"\"\n    # Start from the current state\n    package_set, _ = create_package_set_from_installed()\n    # Install packages\n    would_be_installed = _simulate_installation_of(to_install, package_set)\n\n    # Only warn about directly-dependent packages; create a whitelist of them\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\freeze.py": {
      "sha": "47df3e86b316",
      "lines": 256,
      "head": "import collections\nimport logging\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Container, Dict, Generator, Iterable, List, NamedTuple, Optional, Set\n\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\nfrom pip._vendor.packaging.version import InvalidVersion\n\nfrom pip._internal.exceptions import BadCommand, InstallationError\nfrom pip._internal.metadata import BaseDistribution, get_environment\nfrom pip._internal.req.constructors import (\n    install_req_from_editable,\n    install_req_from_line,\n)\nfrom pip._internal.req.req_file import COMMENT_RE\nfrom pip._internal.utils.direct_url_helpers import direct_url_as_pep440_direct_reference\n\nlogger = logging.getLogger(__name__)\n\n\nclass _EditableInfo(NamedTuple):\n    requirement: str\n    comments: List[str]\n\n\ndef freeze(\n    requirement: Optional[List[str]] = None,\n    local_only: bool = False,\n    user_only: bool = False,\n    paths: Optional[List[str]] = None,\n    isolated: bool = False,\n    exclude_editable: bool = False,\n    skip: Container[str] = (),\n) -> Generator[str, None, None]:\n    installations: Dict[str, FrozenRequirement] = {}\n\n    dists = get_environment(paths).iter_installed_distributions(\n        local_only=local_only,\n        skip=(),\n        user_only=user_only,\n    )\n    for dist in dists:\n        req = FrozenRequirement.from_dist(dist)\n        if exclude_editable and req.editable:\n            continue\n        installations[req.canonical_name] = req\n\n    if requirement:\n        # the options that don't get turned into an InstallRequirement\n        # should only be emitted once, even if the same option is in multiple\n        # requirements files, so we need to keep track of what has been emitted\n        # so that we don't emit it again if it's seen again\n        emitted_options: Set[str] = set()\n        # keep track of which files a requirement is in so that we can\n        # give an accurate warning if a requirement appears multiple times.\n        req_files: Dict[str, List[str]] = collections.defaultdict(list)\n        for req_file_path in requirement:\n            with open(req_file_path) as req_file:\n                for line in req_file:\n                    if (\n                        not line.strip()\n                        or line.strip().startswith(\"#\")\n                        or line.startswith(\n                            (\n                                \"-r\",\n                                \"--requirement\",\n                                \"-f\",\n                                \"--find-links\",\n                                \"-i\",\n                                \"--index-url\",\n                                \"--pre\",\n                                \"--trusted-host\",\n                                \"--process-dependency-links\",\n                                \"--extra-index-url\",\n                                \"--use-feature\",\n                            )\n                        )\n                    ):\n                        line = line.rstrip()\n                        if line not in emitted_options:\n                            emitted_options.add(line)\n                            yield line\n                        continue\n\n                    if line.startswith(\"-e\") or line.startswith(\"--editable\"):\n                        if line.startswith(\"-e\"):\n                            line = line[2:].strip()\n                        else:\n                            line = line[len(\"--editable\") :].strip().lstrip(\"=\")\n                        line_req = install_req_from_editable(\n                            line,\n                            isolated=isolated,\n                        )\n                    else:\n                        line_req = install_req_from_line(\n                            COMMENT_RE.sub(\"\", line).strip(),\n                            isolated=isolated,\n                        )\n\n                    if not line_req.name:\n                        logger.info(\n                            \"Skipping line in requirement file [%s] because \"\n                            \"it's not clear what it would install: %s\",\n                            req_file_path,\n                            line.strip(),\n                        )\n                        logger.info(\n                            \"  (add #egg=PackageName to the URL to avoid\"\n                            \" this warning)\"\n                        )\n                    else:\n                        line_req_canonical_name = canonicalize_name(line_req.name)\n                        if line_req_canonical_name not in installations:\n                            # either it's not installed, or it is installed\n                            # but has been processed already\n                            if not req_files[line_req.name]:\n                                logger.warning(\n                                    \"Requirement file [%s] contains %s, but \"\n                                    \"package %r is not installed\",\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py": {
      "sha": "441c5b117b55",
      "lines": 737,
      "head": "\"\"\"Prepares a distribution for installation\"\"\"\n\n# The following comment should be removed at some point in the future.\n# mypy: strict-optional=False\n\nimport mimetypes\nimport os\nimport shutil\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Optional\n\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.distributions import make_distribution_for_install_requirement\nfrom pip._internal.distributions.installed import InstalledDistribution\nfrom pip._internal.exceptions import (\n    DirectoryUrlHashUnsupported,\n    HashMismatch,\n    HashUnpinned,\n    InstallationError,\n    MetadataInconsistent,\n    NetworkConnectionError,\n    VcsHashUnsupported,\n)\nfrom pip._internal.index.package_finder import PackageFinder\nfrom pip._internal.metadata import BaseDistribution, get_metadata_distribution\nfrom pip._internal.models.direct_url import ArchiveInfo\nfrom pip._internal.models.link import Link\nfrom pip._internal.models.wheel import Wheel\nfrom pip._internal.network.download import BatchDownloader, Downloader\nfrom pip._internal.network.lazy_wheel import (\n    HTTPRangeRequestUnsupported,\n    dist_from_wheel_url,\n)\nfrom pip._internal.network.session import PipSession\nfrom pip._internal.operations.build.build_tracker import BuildTracker\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.utils._log import getLogger\nfrom pip._internal.utils.direct_url_helpers import (\n    direct_url_for_editable,\n    direct_url_from_link,\n)\nfrom pip._internal.utils.hashes import Hashes, MissingHashes\nfrom pip._internal.utils.logging import indent_log\nfrom pip._internal.utils.misc import (\n    display_path,\n    hash_file,\n    hide_url,\n    redact_auth_from_requirement,\n)\nfrom pip._internal.utils.temp_dir import TempDirectory\nfrom pip._internal.utils.unpacking import unpack_file\nfrom pip._internal.vcs import vcs\n\nlogger = getLogger(__name__)\n\n\ndef _get_prepared_distribution(\n    req: InstallRequirement,\n    build_tracker: BuildTracker,\n    finder: PackageFinder,\n    build_isolation: bool,\n    check_build_deps: bool,\n) -> BaseDistribution:\n    \"\"\"Prepare a distribution for installation.\"\"\"\n    abstract_dist = make_distribution_for_install_requirement(req)\n    tracker_id = abstract_dist.build_tracker_id\n    if tracker_id is not None:\n        with build_tracker.track(req, tracker_id):\n            abstract_dist.prepare_distribution_metadata(\n                finder, build_isolation, check_build_deps\n            )\n    return abstract_dist.get_metadata_distribution()\n\n\ndef unpack_vcs_link(link: Link, location: str, verbosity: int) -> None:\n    vcs_backend = vcs.get_backend_for_scheme(link.scheme)\n    assert vcs_backend is not None\n    vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)\n\n\n@dataclass\nclass File:\n    path: str\n    content_type: Optional[str] = None\n\n    def __post_init__(self) -> None:\n        if self.content_type is None:\n            # Try to guess the file's MIME type. If the system MIME tables\n            # can't be loaded, give up.\n            try:\n                self.content_type = mimetypes.guess_type(self.path)[0]\n            except OSError:\n                pass\n\n\ndef get_http_url(\n    link: Link,\n    download: Downloader,\n    download_dir: Optional[str] = None,\n    hashes: Optional[Hashes] = None,\n) -> File:\n    temp_dir = TempDirectory(kind=\"unpack\", globally_managed=True)\n    # If a download dir is specified, is the file already downloaded there?\n    already_downloaded_path = None\n    if download_dir:\n        already_downloaded_path = _check_download_dir(link, download_dir, hashes)\n\n    if already_downloaded_path:\n        from_path = already_downloaded_path\n        content_type = None\n    else:\n        # let's download to a tmp dir\n        from_path, content_type = download(link, temp_dir.path)\n        if hashes:\n            hashes.check_against_path(from_path)\n\n    return File(from_path, content_type)\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\build_tracker.py": {
      "sha": "3ce919ff6b35",
      "lines": 138,
      "head": "import contextlib\nimport hashlib\nimport logging\nimport os\nfrom types import TracebackType\nfrom typing import Dict, Generator, Optional, Type, Union\n\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.utils.temp_dir import TempDirectory\n\nlogger = logging.getLogger(__name__)\n\n\n@contextlib.contextmanager\ndef update_env_context_manager(**changes: str) -> Generator[None, None, None]:\n    target = os.environ\n\n    # Save values from the target and change them.\n    non_existent_marker = object()\n    saved_values: Dict[str, Union[object, str]] = {}\n    for name, new_value in changes.items():\n        try:\n            saved_values[name] = target[name]\n        except KeyError:\n            saved_values[name] = non_existent_marker\n        target[name] = new_value\n\n    try:\n        yield\n    finally:\n        # Restore original values in the target.\n        for name, original_value in saved_values.items():\n            if original_value is non_existent_marker:\n                del target[name]\n            else:\n                assert isinstance(original_value, str)  # for mypy\n                target[name] = original_value\n\n\n@contextlib.contextmanager\ndef get_build_tracker() -> Generator[\"BuildTracker\", None, None]:\n    root = os.environ.get(\"PIP_BUILD_TRACKER\")\n    with contextlib.ExitStack() as ctx:\n        if root is None:\n            root = ctx.enter_context(TempDirectory(kind=\"build-tracker\")).path\n            ctx.enter_context(update_env_context_manager(PIP_BUILD_TRACKER=root))\n            logger.debug(\"Initialized build tracking at %s\", root)\n\n        with BuildTracker(root) as tracker:\n            yield tracker\n\n\nclass TrackerId(str):\n    \"\"\"Uniquely identifying string provided to the build tracker.\"\"\"\n\n\nclass BuildTracker:\n    \"\"\"Ensure that an sdist cannot request itself as a setup requirement.\n\n    When an sdist is prepared, it identifies its setup requirements in the\n    context of ``BuildTracker.track()``. If a requirement shows up recursively, this\n    raises an exception.\n\n    This stops fork bombs embedded in malicious packages.\"\"\"\n\n    def __init__(self, root: str) -> None:\n        self._root = root\n        self._entries: Dict[TrackerId, InstallRequirement] = {}\n        logger.debug(\"Created build tracker: %s\", self._root)\n\n    def __enter__(self) -> \"BuildTracker\":\n        logger.debug(\"Entered build tracker: %s\", self._root)\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        self.cleanup()\n\n    def _entry_path(self, key: TrackerId) -> str:\n        hashed = hashlib.sha224(key.encode()).hexdigest()\n        return os.path.join(self._root, hashed)\n\n    def add(self, req: InstallRequirement, key: TrackerId) -> None:\n        \"\"\"Add an InstallRequirement to build tracking.\"\"\"\n\n        # Get the file to write information about this requirement.\n        entry_path = self._entry_path(key)\n\n        # Try reading from the file. If it exists and can be read from, a build\n        # is already in progress, so a LookupError is raised.\n        try:\n            with open(entry_path) as fp:\n                contents = fp.read()\n        except FileNotFoundError:\n            pass\n        else:\n            message = f\"{req.link} is already being built: {contents}\"\n            raise LookupError(message)\n\n        # If we're here, req should really not be building already.\n        assert key not in self._entries\n\n        # Start tracking this requirement.\n        with open(entry_path, \"w\", encoding=\"utf-8\") as fp:\n            fp.write(str(req))\n        self._entries[key] = req\n\n        logger.debug(\"Added %s to build tracker %r\", req, self._root)\n\n    def remove(self, req: InstallRequirement, key: TrackerId) -> None:\n        \"\"\"Remove an InstallRequirement from build tracking.\"\"\"\n\n        # Delete the created file and the corresponding entry.\n        os.unlink(self._entry_path(key))\n        del self._entries[key]\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata.py": {
      "sha": "021d8109c828",
      "lines": 38,
      "head": "\"\"\"Metadata generation logic for source distributions.\"\"\"\n\nimport os\n\nfrom pip._vendor.pyproject_hooks import BuildBackendHookCaller\n\nfrom pip._internal.build_env import BuildEnvironment\nfrom pip._internal.exceptions import (\n    InstallationSubprocessError,\n    MetadataGenerationFailed,\n)\nfrom pip._internal.utils.subprocess import runner_with_spinner_message\nfrom pip._internal.utils.temp_dir import TempDirectory\n\n\ndef generate_metadata(\n    build_env: BuildEnvironment, backend: BuildBackendHookCaller, details: str\n) -> str:\n    \"\"\"Generate metadata using mechanisms described in PEP 517.\n\n    Returns the generated metadata directory.\n    \"\"\"\n    metadata_tmpdir = TempDirectory(kind=\"modern-metadata\", globally_managed=True)\n\n    metadata_dir = metadata_tmpdir.path\n\n    with build_env:\n        # Note that BuildBackendHookCaller implements a fallback for\n        # prepare_metadata_for_build_wheel, so we don't have to\n        # consider the possibility that this hook doesn't exist.\n        runner = runner_with_spinner_message(\"Preparing metadata (pyproject.toml)\")\n        with backend.subprocess_runner(runner):\n            try:\n                distinfo_dir = backend.prepare_metadata_for_build_wheel(metadata_dir)\n            except InstallationSubprocessError as error:\n                raise MetadataGenerationFailed(package_details=details) from error\n\n    return os.path.join(metadata_dir, distinfo_dir)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata_editable.py": {
      "sha": "a44c10569c6b",
      "lines": 41,
      "head": "\"\"\"Metadata generation logic for source distributions.\"\"\"\n\nimport os\n\nfrom pip._vendor.pyproject_hooks import BuildBackendHookCaller\n\nfrom pip._internal.build_env import BuildEnvironment\nfrom pip._internal.exceptions import (\n    InstallationSubprocessError,\n    MetadataGenerationFailed,\n)\nfrom pip._internal.utils.subprocess import runner_with_spinner_message\nfrom pip._internal.utils.temp_dir import TempDirectory\n\n\ndef generate_editable_metadata(\n    build_env: BuildEnvironment, backend: BuildBackendHookCaller, details: str\n) -> str:\n    \"\"\"Generate metadata using mechanisms described in PEP 660.\n\n    Returns the generated metadata directory.\n    \"\"\"\n    metadata_tmpdir = TempDirectory(kind=\"modern-metadata\", globally_managed=True)\n\n    metadata_dir = metadata_tmpdir.path\n\n    with build_env:\n        # Note that BuildBackendHookCaller implements a fallback for\n        # prepare_metadata_for_build_wheel/editable, so we don't have to\n        # consider the possibility that this hook doesn't exist.\n        runner = runner_with_spinner_message(\n            \"Preparing editable metadata (pyproject.toml)\"\n        )\n        with backend.subprocess_runner(runner):\n            try:\n                distinfo_dir = backend.prepare_metadata_for_build_editable(metadata_dir)\n            except InstallationSubprocessError as error:\n                raise MetadataGenerationFailed(package_details=details) from error\n\n    assert distinfo_dir is not None\n    return os.path.join(metadata_dir, distinfo_dir)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\metadata_legacy.py": {
      "sha": "5259b685ae68",
      "lines": 73,
      "head": "\"\"\"Metadata generation logic for legacy source distributions.\"\"\"\n\nimport logging\nimport os\n\nfrom pip._internal.build_env import BuildEnvironment\nfrom pip._internal.cli.spinners import open_spinner\nfrom pip._internal.exceptions import (\n    InstallationError,\n    InstallationSubprocessError,\n    MetadataGenerationFailed,\n)\nfrom pip._internal.utils.setuptools_build import make_setuptools_egg_info_args\nfrom pip._internal.utils.subprocess import call_subprocess\nfrom pip._internal.utils.temp_dir import TempDirectory\n\nlogger = logging.getLogger(__name__)\n\n\ndef _find_egg_info(directory: str) -> str:\n    \"\"\"Find an .egg-info subdirectory in `directory`.\"\"\"\n    filenames = [f for f in os.listdir(directory) if f.endswith(\".egg-info\")]\n\n    if not filenames:\n        raise InstallationError(f\"No .egg-info directory found in {directory}\")\n\n    if len(filenames) > 1:\n        raise InstallationError(\n            f\"More than one .egg-info directory found in {directory}\"\n        )\n\n    return os.path.join(directory, filenames[0])\n\n\ndef generate_metadata(\n    build_env: BuildEnvironment,\n    setup_py_path: str,\n    source_dir: str,\n    isolated: bool,\n    details: str,\n) -> str:\n    \"\"\"Generate metadata using setup.py-based defacto mechanisms.\n\n    Returns the generated metadata directory.\n    \"\"\"\n    logger.debug(\n        \"Running setup.py (path:%s) egg_info for package %s\",\n        setup_py_path,\n        details,\n    )\n\n    egg_info_dir = TempDirectory(kind=\"pip-egg-info\", globally_managed=True).path\n\n    args = make_setuptools_egg_info_args(\n        setup_py_path,\n        egg_info_dir=egg_info_dir,\n        no_user_config=isolated,\n    )\n\n    with build_env:\n        with open_spinner(\"Preparing metadata (setup.py)\") as spinner:\n            try:\n                call_subprocess(\n                    args,\n                    cwd=source_dir,\n                    command_desc=\"python setup.py egg_info\",\n                    spinner=spinner,\n                )\n            except InstallationSubprocessError as error:\n                raise MetadataGenerationFailed(package_details=details) from error\n\n    # Return the .egg-info directory.\n    return _find_egg_info(egg_info_dir)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel.py": {
      "sha": "dcd764c358f2",
      "lines": 37,
      "head": "import logging\nimport os\nfrom typing import Optional\n\nfrom pip._vendor.pyproject_hooks import BuildBackendHookCaller\n\nfrom pip._internal.utils.subprocess import runner_with_spinner_message\n\nlogger = logging.getLogger(__name__)\n\n\ndef build_wheel_pep517(\n    name: str,\n    backend: BuildBackendHookCaller,\n    metadata_directory: str,\n    tempd: str,\n) -> Optional[str]:\n    \"\"\"Build one InstallRequirement using the PEP 517 build process.\n\n    Returns path to wheel if successfully built. Otherwise, returns None.\n    \"\"\"\n    assert metadata_directory is not None\n    try:\n        logger.debug(\"Destination directory: %s\", tempd)\n\n        runner = runner_with_spinner_message(\n            f\"Building wheel for {name} (pyproject.toml)\"\n        )\n        with backend.subprocess_runner(runner):\n            wheel_name = backend.build_wheel(\n                tempd,\n                metadata_directory=metadata_directory,\n            )\n    except Exception:\n        logger.error(\"Failed building wheel for %s\", name)\n        return None\n    return os.path.join(tempd, wheel_name)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel_editable.py": {
      "sha": "1d8e256134a5",
      "lines": 46,
      "head": "import logging\nimport os\nfrom typing import Optional\n\nfrom pip._vendor.pyproject_hooks import BuildBackendHookCaller, HookMissing\n\nfrom pip._internal.utils.subprocess import runner_with_spinner_message\n\nlogger = logging.getLogger(__name__)\n\n\ndef build_wheel_editable(\n    name: str,\n    backend: BuildBackendHookCaller,\n    metadata_directory: str,\n    tempd: str,\n) -> Optional[str]:\n    \"\"\"Build one InstallRequirement using the PEP 660 build process.\n\n    Returns path to wheel if successfully built. Otherwise, returns None.\n    \"\"\"\n    assert metadata_directory is not None\n    try:\n        logger.debug(\"Destination directory: %s\", tempd)\n\n        runner = runner_with_spinner_message(\n            f\"Building editable for {name} (pyproject.toml)\"\n        )\n        with backend.subprocess_runner(runner):\n            try:\n                wheel_name = backend.build_editable(\n                    tempd,\n                    metadata_directory=metadata_directory,\n                )\n            except HookMissing as e:\n                logger.error(\n                    \"Cannot build editable %s because the build \"\n                    \"backend does not have the %s hook\",\n                    name,\n                    e,\n                )\n                return None\n    except Exception:\n        logger.error(\"Failed building editable for %s\", name)\n        return None\n    return os.path.join(tempd, wheel_name)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\wheel_legacy.py": {
      "sha": "befcf9882a76",
      "lines": 118,
      "head": "import logging\nimport os.path\nfrom typing import List, Optional\n\nfrom pip._internal.cli.spinners import open_spinner\nfrom pip._internal.utils.deprecation import deprecated\nfrom pip._internal.utils.setuptools_build import make_setuptools_bdist_wheel_args\nfrom pip._internal.utils.subprocess import call_subprocess, format_command_args\n\nlogger = logging.getLogger(__name__)\n\n\ndef format_command_result(\n    command_args: List[str],\n    command_output: str,\n) -> str:\n    \"\"\"Format command information for logging.\"\"\"\n    command_desc = format_command_args(command_args)\n    text = f\"Command arguments: {command_desc}\\n\"\n\n    if not command_output:\n        text += \"Command output: None\"\n    elif logger.getEffectiveLevel() > logging.DEBUG:\n        text += \"Command output: [use --verbose to show]\"\n    else:\n        if not command_output.endswith(\"\\n\"):\n            command_output += \"\\n\"\n        text += f\"Command output:\\n{command_output}\"\n\n    return text\n\n\ndef get_legacy_build_wheel_path(\n    names: List[str],\n    temp_dir: str,\n    name: str,\n    command_args: List[str],\n    command_output: str,\n) -> Optional[str]:\n    \"\"\"Return the path to the wheel in the temporary build directory.\"\"\"\n    # Sort for determinism.\n    names = sorted(names)\n    if not names:\n        msg = f\"Legacy build of wheel for {name!r} created no files.\\n\"\n        msg += format_command_result(command_args, command_output)\n        logger.warning(msg)\n        return None\n\n    if len(names) > 1:\n        msg = (\n            f\"Legacy build of wheel for {name!r} created more than one file.\\n\"\n            f\"Filenames (choosing first): {names}\\n\"\n        )\n        msg += format_command_result(command_args, command_output)\n        logger.warning(msg)\n\n    return os.path.join(temp_dir, names[0])\n\n\ndef build_wheel_legacy(\n    name: str,\n    setup_py_path: str,\n    source_dir: str,\n    global_options: List[str],\n    build_options: List[str],\n    tempd: str,\n) -> Optional[str]:\n    \"\"\"Build one unpacked package using the \"legacy\" build process.\n\n    Returns path to wheel if successfully built. Otherwise, returns None.\n    \"\"\"\n    deprecated(\n        reason=(\n            f\"Building {name!r} using the legacy setup.py bdist_wheel mechanism, \"\n            \"which will be removed in a future version.\"\n        ),\n        replacement=(\n            \"to use the standardized build interface by \"\n            \"setting the `--use-pep517` option, \"\n            \"(possibly combined with `--no-build-isolation`), \"\n            f\"or adding a `pyproject.toml` file to the source tree of {name!r}\"\n        ),\n        gone_in=\"25.3\",\n        issue=6334,\n    )\n\n    wheel_args = make_setuptools_bdist_wheel_args(\n        setup_py_path,\n        global_options=global_options,\n        build_options=build_options,\n        destination_dir=tempd,\n    )\n\n    spin_message = f\"Building wheel for {name} (setup.py)\"\n    with open_spinner(spin_message) as spinner:\n        logger.debug(\"Destination directory: %s\", tempd)\n\n        try:\n            output = call_subprocess(\n                wheel_args,\n                command_desc=\"python setup.py bdist_wheel\",\n                cwd=source_dir,\n                spinner=spinner,\n            )\n        except Exception:\n            spinner.finish(\"error\")\n            logger.error(\"Failed building wheel for %s\", name)\n            return None\n\n        names = os.listdir(tempd)\n        wheel_path = get_legacy_build_wheel_path(\n            names=names,\n            temp_dir=tempd,\n            name=name,\n            command_args=wheel_args,\n            command_output=output,\n        )\n        return wheel_path\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\build\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\install\\editable_legacy.py": {
      "sha": "fa759c72452f",
      "lines": 46,
      "head": "\"\"\"Legacy editable installation process, i.e. `setup.py develop`.\"\"\"\n\nimport logging\nfrom typing import Optional, Sequence\n\nfrom pip._internal.build_env import BuildEnvironment\nfrom pip._internal.utils.logging import indent_log\nfrom pip._internal.utils.setuptools_build import make_setuptools_develop_args\nfrom pip._internal.utils.subprocess import call_subprocess\n\nlogger = logging.getLogger(__name__)\n\n\ndef install_editable(\n    *,\n    global_options: Sequence[str],\n    prefix: Optional[str],\n    home: Optional[str],\n    use_user_site: bool,\n    name: str,\n    setup_py_path: str,\n    isolated: bool,\n    build_env: BuildEnvironment,\n    unpacked_source_directory: str,\n) -> None:\n    \"\"\"Install a package in editable mode. Most arguments are pass-through\n    to setuptools.\n    \"\"\"\n    logger.info(\"Running setup.py develop for %s\", name)\n\n    args = make_setuptools_develop_args(\n        setup_py_path,\n        global_options=global_options,\n        no_user_config=isolated,\n        prefix=prefix,\n        home=home,\n        use_user_site=use_user_site,\n    )\n\n    with indent_log():\n        with build_env:\n            call_subprocess(\n                args,\n                command_desc=\"python setup.py develop\",\n                cwd=unpacked_source_directory,\n            )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\install\\wheel.py": {
      "sha": "39e594091f6d",
      "lines": 738,
      "head": "\"\"\"Support for installing and building the \"wheel\" binary package format.\"\"\"\n\nimport collections\nimport compileall\nimport contextlib\nimport csv\nimport importlib\nimport logging\nimport os.path\nimport re\nimport shutil\nimport sys\nimport warnings\nfrom base64 import urlsafe_b64encode\nfrom email.message import Message\nfrom itertools import chain, filterfalse, starmap\nfrom typing import (\n    IO,\n    Any,\n    BinaryIO,\n    Callable,\n    Dict,\n    Generator,\n    Iterable,\n    Iterator,\n    List,\n    NewType,\n    Optional,\n    Protocol,\n    Sequence,\n    Set,\n    Tuple,\n    Union,\n    cast,\n)\nfrom zipfile import ZipFile, ZipInfo\n\nfrom pip._vendor.distlib.scripts import ScriptMaker\nfrom pip._vendor.distlib.util import get_export_entry\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.exceptions import InstallationError\nfrom pip._internal.locations import get_major_minor_version\nfrom pip._internal.metadata import (\n    BaseDistribution,\n    FilesystemWheel,\n    get_wheel_distribution,\n)\nfrom pip._internal.models.direct_url import DIRECT_URL_METADATA_NAME, DirectUrl\nfrom pip._internal.models.scheme import SCHEME_KEYS, Scheme\nfrom pip._internal.utils.filesystem import adjacent_tmp_file, replace\nfrom pip._internal.utils.misc import StreamWrapper, ensure_dir, hash_file, partition\nfrom pip._internal.utils.unpacking import (\n    current_umask,\n    is_within_directory,\n    set_extracted_file_to_default_mode_plus_executable,\n    zip_item_is_executable,\n)\nfrom pip._internal.utils.wheel import parse_wheel\n\n\nclass File(Protocol):\n    src_record_path: \"RecordPath\"\n    dest_path: str\n    changed: bool\n\n    def save(self) -> None:\n        pass\n\n\nlogger = logging.getLogger(__name__)\n\nRecordPath = NewType(\"RecordPath\", str)\nInstalledCSVRow = Tuple[RecordPath, str, Union[int, str]]\n\n\ndef rehash(path: str, blocksize: int = 1 << 20) -> Tuple[str, str]:\n    \"\"\"Return (encoded_digest, length) for path using hashlib.sha256()\"\"\"\n    h, length = hash_file(path, blocksize)\n    digest = \"sha256=\" + urlsafe_b64encode(h.digest()).decode(\"latin1\").rstrip(\"=\")\n    return (digest, str(length))\n\n\ndef csv_io_kwargs(mode: str) -> Dict[str, Any]:\n    \"\"\"Return keyword arguments to properly open a CSV file\n    in the given mode.\n    \"\"\"\n    return {\"mode\": mode, \"newline\": \"\", \"encoding\": \"utf-8\"}\n\n\ndef fix_script(path: str) -> bool:\n    \"\"\"Replace #!python with #!/path/to/python\n    Return True if file was changed.\n    \"\"\"\n    # XXX RECORD hashes will need to be updated\n    assert os.path.isfile(path)\n\n    with open(path, \"rb\") as script:\n        firstline = script.readline()\n        if not firstline.startswith(b\"#!python\"):\n            return False\n        exename = sys.executable.encode(sys.getfilesystemencoding())\n        firstline = b\"#!\" + exename + os.linesep.encode(\"ascii\")\n        rest = script.read()\n    with open(path, \"wb\") as script:\n        script.write(firstline)\n        script.write(rest)\n    return True\n\n\ndef wheel_root_is_purelib(metadata: Message) -> bool:\n    return metadata.get(\"Root-Is-Purelib\", \"\").lower() == \"true\"\n\n\ndef get_entrypoints(dist: BaseDistribution) -> Tuple[Dict[str, str], Dict[str, str]]:\n    console_scripts = {}\n    gui_scripts = {}\n    for entry_point in dist.iter_entry_points():\n        if entry_point.group == \"console_scripts\":\n            console_scripts[entry_point.name] = entry_point.value\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\operations\\install\\__init__.py": {
      "sha": "3e2f1b68dff6",
      "lines": 1,
      "head": "\"\"\"For modules related to installing packages.\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\constructors.py": {
      "sha": "481b2fed7cbc",
      "lines": 560,
      "head": "\"\"\"Backing implementation for InstallRequirement's various constructors\n\nThe idea here is that these formed a major chunk of InstallRequirement's size\nso, moving them and support code dedicated to them outside of that class\nhelps creates for better understandability for the rest of the code.\n\nThese are meant to be used elsewhere within pip to create instances of\nInstallRequirement.\n\"\"\"\n\nimport copy\nimport logging\nimport os\nimport re\nfrom dataclasses import dataclass\nfrom typing import Collection, Dict, List, Optional, Set, Tuple, Union\n\nfrom pip._vendor.packaging.markers import Marker\nfrom pip._vendor.packaging.requirements import InvalidRequirement, Requirement\nfrom pip._vendor.packaging.specifiers import Specifier\n\nfrom pip._internal.exceptions import InstallationError\nfrom pip._internal.models.index import PyPI, TestPyPI\nfrom pip._internal.models.link import Link\nfrom pip._internal.models.wheel import Wheel\nfrom pip._internal.req.req_file import ParsedRequirement\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.utils.filetypes import is_archive_file\nfrom pip._internal.utils.misc import is_installable_dir\nfrom pip._internal.utils.packaging import get_requirement\nfrom pip._internal.utils.urls import path_to_url\nfrom pip._internal.vcs import is_url, vcs\n\n__all__ = [\n    \"install_req_from_editable\",\n    \"install_req_from_line\",\n    \"parse_editable\",\n]\n\nlogger = logging.getLogger(__name__)\noperators = Specifier._operators.keys()\n\n\ndef _strip_extras(path: str) -> Tuple[str, Optional[str]]:\n    m = re.match(r\"^(.+)(\\[[^\\]]+\\])$\", path)\n    extras = None\n    if m:\n        path_no_extras = m.group(1)\n        extras = m.group(2)\n    else:\n        path_no_extras = path\n\n    return path_no_extras, extras\n\n\ndef convert_extras(extras: Optional[str]) -> Set[str]:\n    if not extras:\n        return set()\n    return get_requirement(\"placeholder\" + extras.lower()).extras\n\n\ndef _set_requirement_extras(req: Requirement, new_extras: Set[str]) -> Requirement:\n    \"\"\"\n    Returns a new requirement based on the given one, with the supplied extras. If the\n    given requirement already has extras those are replaced (or dropped if no new extras\n    are given).\n    \"\"\"\n    match: Optional[re.Match[str]] = re.fullmatch(\n        # see https://peps.python.org/pep-0508/#complete-grammar\n        r\"([\\w\\t .-]+)(\\[[^\\]]*\\])?(.*)\",\n        str(req),\n        flags=re.ASCII,\n    )\n    # ireq.req is a valid requirement so the regex should always match\n    assert (\n        match is not None\n    ), f\"regex match on requirement {req} failed, this should never happen\"\n    pre: Optional[str] = match.group(1)\n    post: Optional[str] = match.group(3)\n    assert (\n        pre is not None and post is not None\n    ), f\"regex group selection for requirement {req} failed, this should never happen\"\n    extras: str = \"[{}]\".format(\",\".join(sorted(new_extras)) if new_extras else \"\")\n    return get_requirement(f\"{pre}{extras}{post}\")\n\n\ndef parse_editable(editable_req: str) -> Tuple[Optional[str], str, Set[str]]:\n    \"\"\"Parses an editable requirement into:\n        - a requirement name\n        - an URL\n        - extras\n        - editable options\n    Accepted requirements:\n        svn+http://blahblah@rev#egg=Foobar[baz]&subdirectory=version_subdir\n        .[some_extra]\n    \"\"\"\n\n    url = editable_req\n\n    # If a file path is specified with extras, strip off the extras.\n    url_no_extras, extras = _strip_extras(url)\n\n    if os.path.isdir(url_no_extras):\n        # Treating it as code that has already been checked out\n        url_no_extras = path_to_url(url_no_extras)\n\n    if url_no_extras.lower().startswith(\"file:\"):\n        package_name = Link(url_no_extras).egg_fragment\n        if extras:\n            return (\n                package_name,\n                url_no_extras,\n                get_requirement(\"placeholder\" + extras.lower()).extras,\n            )\n        else:\n            return package_name, url_no_extras, set()\n\n    for version_control in vcs:\n        if url.lower().startswith(f\"{version_control}:\"):\n            url = f\"{version_control}+{url}\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_dependency_group.py": {
      "sha": "a6fb278bfa9e",
      "lines": 79,
      "head": "import sys\nfrom typing import Any, Dict, Iterable, Iterator, List, Tuple\n\nif sys.version_info >= (3, 11):\n    import tomllib\nelse:\n    from pip._vendor import tomli as tomllib\n\nfrom pip._vendor.dependency_groups import DependencyGroupResolver\n\nfrom pip._internal.exceptions import InstallationError\n\n\ndef parse_dependency_groups(groups: List[Tuple[str, str]]) -> List[str]:\n    \"\"\"\n    Parse dependency groups data as provided via the CLI, in a `[path:]group` syntax.\n\n    Raises InstallationErrors if anything goes wrong.\n    \"\"\"\n    resolvers = _build_resolvers(path for (path, _) in groups)\n    return list(_resolve_all_groups(resolvers, groups))\n\n\ndef _resolve_all_groups(\n    resolvers: Dict[str, DependencyGroupResolver], groups: List[Tuple[str, str]]\n) -> Iterator[str]:\n    \"\"\"\n    Run all resolution, converting any error from `DependencyGroupResolver` into\n    an InstallationError.\n    \"\"\"\n    for path, groupname in groups:\n        resolver = resolvers[path]\n        try:\n            yield from (str(req) for req in resolver.resolve(groupname))\n        except (ValueError, TypeError, LookupError) as e:\n            raise InstallationError(\n                f\"[dependency-groups] resolution failed for '{groupname}' \"\n                f\"from '{path}': {e}\"\n            ) from e\n\n\ndef _build_resolvers(paths: Iterable[str]) -> Dict[str, Any]:\n    resolvers = {}\n    for path in paths:\n        if path in resolvers:\n            continue\n\n        pyproject = _load_pyproject(path)\n        if \"dependency-groups\" not in pyproject:\n            raise InstallationError(\n                f\"[dependency-groups] table was missing from '{path}'. \"\n                \"Cannot resolve '--group' option.\"\n            )\n        raw_dependency_groups = pyproject[\"dependency-groups\"]\n        if not isinstance(raw_dependency_groups, dict):\n            raise InstallationError(\n                f\"[dependency-groups] table was malformed in {path}. \"\n                \"Cannot resolve '--group' option.\"\n            )\n\n        resolvers[path] = DependencyGroupResolver(raw_dependency_groups)\n    return resolvers\n\n\ndef _load_pyproject(path: str) -> Dict[str, Any]:\n    \"\"\"\n    This helper loads a pyproject.toml as TOML.\n\n    It raises an InstallationError if the operation fails.\n    \"\"\"\n    try:\n        with open(path, \"rb\") as fp:\n            return tomllib.load(fp)\n    except FileNotFoundError:\n        raise InstallationError(f\"{path} not found. Cannot resolve '--group' option.\")\n    except tomllib.TOMLDecodeError as e:\n        raise InstallationError(f\"Error parsing {path}: {e}\") from e\n    except OSError as e:\n        raise InstallationError(f\"Error reading {path}: {e}\") from e\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_file.py": {
      "sha": "eec45e3d757d",
      "lines": 623,
      "head": "\"\"\"\nRequirements file parsing\n\"\"\"\n\nimport codecs\nimport locale\nimport logging\nimport optparse\nimport os\nimport re\nimport shlex\nimport sys\nimport urllib.parse\nfrom dataclasses import dataclass\nfrom optparse import Values\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Dict,\n    Generator,\n    Iterable,\n    List,\n    NoReturn,\n    Optional,\n    Tuple,\n)\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.exceptions import InstallationError, RequirementsFileParseError\nfrom pip._internal.models.search_scope import SearchScope\n\nif TYPE_CHECKING:\n    from pip._internal.index.package_finder import PackageFinder\n    from pip._internal.network.session import PipSession\n\n__all__ = [\"parse_requirements\"]\n\nReqFileLines = Iterable[Tuple[int, str]]\n\nLineParser = Callable[[str], Tuple[str, Values]]\n\nSCHEME_RE = re.compile(r\"^(http|https|file):\", re.I)\nCOMMENT_RE = re.compile(r\"(^|\\s+)#.*$\")\n\n# Matches environment variable-style values in '${MY_VARIABLE_1}' with the\n# variable name consisting of only uppercase letters, digits or the '_'\n# (underscore). This follows the POSIX standard defined in IEEE Std 1003.1,\n# 2013 Edition.\nENV_VAR_RE = re.compile(r\"(?P<var>\\$\\{(?P<name>[A-Z0-9_]+)\\})\")\n\nSUPPORTED_OPTIONS: List[Callable[..., optparse.Option]] = [\n    cmdoptions.index_url,\n    cmdoptions.extra_index_url,\n    cmdoptions.no_index,\n    cmdoptions.constraints,\n    cmdoptions.requirements,\n    cmdoptions.editable,\n    cmdoptions.find_links,\n    cmdoptions.no_binary,\n    cmdoptions.only_binary,\n    cmdoptions.prefer_binary,\n    cmdoptions.require_hashes,\n    cmdoptions.pre,\n    cmdoptions.trusted_host,\n    cmdoptions.use_new_feature,\n]\n\n# options to be passed to requirements\nSUPPORTED_OPTIONS_REQ: List[Callable[..., optparse.Option]] = [\n    cmdoptions.global_options,\n    cmdoptions.hash,\n    cmdoptions.config_settings,\n]\n\nSUPPORTED_OPTIONS_EDITABLE_REQ: List[Callable[..., optparse.Option]] = [\n    cmdoptions.config_settings,\n]\n\n\n# the 'dest' string values\nSUPPORTED_OPTIONS_REQ_DEST = [str(o().dest) for o in SUPPORTED_OPTIONS_REQ]\nSUPPORTED_OPTIONS_EDITABLE_REQ_DEST = [\n    str(o().dest) for o in SUPPORTED_OPTIONS_EDITABLE_REQ\n]\n\n# order of BOMS is important: codecs.BOM_UTF16_LE is a prefix of codecs.BOM_UTF32_LE\n# so data.startswith(BOM_UTF16_LE) would be true for UTF32_LE data\nBOMS: List[Tuple[bytes, str]] = [\n    (codecs.BOM_UTF8, \"utf-8\"),\n    (codecs.BOM_UTF32, \"utf-32\"),\n    (codecs.BOM_UTF32_BE, \"utf-32-be\"),\n    (codecs.BOM_UTF32_LE, \"utf-32-le\"),\n    (codecs.BOM_UTF16, \"utf-16\"),\n    (codecs.BOM_UTF16_BE, \"utf-16-be\"),\n    (codecs.BOM_UTF16_LE, \"utf-16-le\"),\n]\n\nPEP263_ENCODING_RE = re.compile(rb\"coding[:=]\\s*([-\\w.]+)\")\nDEFAULT_ENCODING = \"utf-8\"\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass(frozen=True)\nclass ParsedRequirement:\n    # TODO: replace this with slots=True when dropping Python 3.9 support.\n    __slots__ = (\n        \"requirement\",\n        \"is_editable\",\n        \"comes_from\",\n        \"constraint\",\n        \"options\",\n        \"line_source\",\n    )\n\n    requirement: str\n    is_editable: bool\n    comes_from: str\n    constraint: bool\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_install.py": {
      "sha": "0e367c164ced",
      "lines": 934,
      "head": "import functools\nimport logging\nimport os\nimport shutil\nimport sys\nimport uuid\nimport zipfile\nfrom optparse import Values\nfrom pathlib import Path\nfrom typing import Any, Collection, Dict, Iterable, List, Optional, Sequence, Union\n\nfrom pip._vendor.packaging.markers import Marker\nfrom pip._vendor.packaging.requirements import Requirement\nfrom pip._vendor.packaging.specifiers import SpecifierSet\nfrom pip._vendor.packaging.utils import canonicalize_name\nfrom pip._vendor.packaging.version import Version\nfrom pip._vendor.packaging.version import parse as parse_version\nfrom pip._vendor.pyproject_hooks import BuildBackendHookCaller\n\nfrom pip._internal.build_env import BuildEnvironment, NoOpBuildEnvironment\nfrom pip._internal.exceptions import InstallationError, PreviousBuildDirError\nfrom pip._internal.locations import get_scheme\nfrom pip._internal.metadata import (\n    BaseDistribution,\n    get_default_environment,\n    get_directory_distribution,\n    get_wheel_distribution,\n)\nfrom pip._internal.metadata.base import FilesystemWheel\nfrom pip._internal.models.direct_url import DirectUrl\nfrom pip._internal.models.link import Link\nfrom pip._internal.operations.build.metadata import generate_metadata\nfrom pip._internal.operations.build.metadata_editable import generate_editable_metadata\nfrom pip._internal.operations.build.metadata_legacy import (\n    generate_metadata as generate_metadata_legacy,\n)\nfrom pip._internal.operations.install.editable_legacy import (\n    install_editable as install_editable_legacy,\n)\nfrom pip._internal.operations.install.wheel import install_wheel\nfrom pip._internal.pyproject import load_pyproject_toml, make_pyproject_path\nfrom pip._internal.req.req_uninstall import UninstallPathSet\nfrom pip._internal.utils.deprecation import deprecated\nfrom pip._internal.utils.hashes import Hashes\nfrom pip._internal.utils.misc import (\n    ConfiguredBuildBackendHookCaller,\n    ask_path_exists,\n    backup_dir,\n    display_path,\n    hide_url,\n    is_installable_dir,\n    redact_auth_from_requirement,\n    redact_auth_from_url,\n)\nfrom pip._internal.utils.packaging import get_requirement\nfrom pip._internal.utils.subprocess import runner_with_spinner_message\nfrom pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds\nfrom pip._internal.utils.unpacking import unpack_file\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\nfrom pip._internal.vcs import vcs\n\nlogger = logging.getLogger(__name__)\n\n\nclass InstallRequirement:\n    \"\"\"\n    Represents something that may be installed later on, may have information\n    about where to fetch the relevant requirement and also contains logic for\n    installing the said requirement.\n    \"\"\"\n\n    def __init__(\n        self,\n        req: Optional[Requirement],\n        comes_from: Optional[Union[str, \"InstallRequirement\"]],\n        editable: bool = False,\n        link: Optional[Link] = None,\n        markers: Optional[Marker] = None,\n        use_pep517: Optional[bool] = None,\n        isolated: bool = False,\n        *,\n        global_options: Optional[List[str]] = None,\n        hash_options: Optional[Dict[str, List[str]]] = None,\n        config_settings: Optional[Dict[str, Union[str, List[str]]]] = None,\n        constraint: bool = False,\n        extras: Collection[str] = (),\n        user_supplied: bool = False,\n        permit_editable_wheels: bool = False,\n    ) -> None:\n        assert req is None or isinstance(req, Requirement), req\n        self.req = req\n        self.comes_from = comes_from\n        self.constraint = constraint\n        self.editable = editable\n        self.permit_editable_wheels = permit_editable_wheels\n\n        # source_dir is the local directory where the linked requirement is\n        # located, or unpacked. In case unpacking is needed, creating and\n        # populating source_dir is done by the RequirementPreparer. Note this\n        # is not necessarily the directory where pyproject.toml or setup.py is\n        # located - that one is obtained via unpacked_source_directory.\n        self.source_dir: Optional[str] = None\n        if self.editable:\n            assert link\n            if link.is_file:\n                self.source_dir = os.path.normpath(os.path.abspath(link.file_path))\n\n        # original_link is the direct URL that was provided by the user for the\n        # requirement, either directly or via a constraints file.\n        if link is None and req and req.url:\n            # PEP 508 URL requirement\n            link = Link(req.url)\n        self.link = self.original_link = link\n\n        # When this InstallRequirement is a wheel obtained from the cache of locally\n        # built wheels, this is the source link corresponding to the cache entry, which\n        # was used to download and build the cached wheel.\n        self.cached_wheel_source_link: Optional[Link] = None\n\n        # Information about the location of the artifact that was downloaded . This\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_set.py": {
      "sha": "f4e5b3a69525",
      "lines": 82,
      "head": "import logging\nfrom collections import OrderedDict\nfrom typing import Dict, List\n\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.req.req_install import InstallRequirement\n\nlogger = logging.getLogger(__name__)\n\n\nclass RequirementSet:\n    def __init__(self, check_supported_wheels: bool = True) -> None:\n        \"\"\"Create a RequirementSet.\"\"\"\n\n        self.requirements: Dict[str, InstallRequirement] = OrderedDict()\n        self.check_supported_wheels = check_supported_wheels\n\n        self.unnamed_requirements: List[InstallRequirement] = []\n\n    def __str__(self) -> str:\n        requirements = sorted(\n            (req for req in self.requirements.values() if not req.comes_from),\n            key=lambda req: canonicalize_name(req.name or \"\"),\n        )\n        return \" \".join(str(req.req) for req in requirements)\n\n    def __repr__(self) -> str:\n        requirements = sorted(\n            self.requirements.values(),\n            key=lambda req: canonicalize_name(req.name or \"\"),\n        )\n\n        format_string = \"<{classname} object; {count} requirement(s): {reqs}>\"\n        return format_string.format(\n            classname=self.__class__.__name__,\n            count=len(requirements),\n            reqs=\", \".join(str(req.req) for req in requirements),\n        )\n\n    def add_unnamed_requirement(self, install_req: InstallRequirement) -> None:\n        assert not install_req.name\n        self.unnamed_requirements.append(install_req)\n\n    def add_named_requirement(self, install_req: InstallRequirement) -> None:\n        assert install_req.name\n\n        project_name = canonicalize_name(install_req.name)\n        self.requirements[project_name] = install_req\n\n    def has_requirement(self, name: str) -> bool:\n        project_name = canonicalize_name(name)\n\n        return (\n            project_name in self.requirements\n            and not self.requirements[project_name].constraint\n        )\n\n    def get_requirement(self, name: str) -> InstallRequirement:\n        project_name = canonicalize_name(name)\n\n        if project_name in self.requirements:\n            return self.requirements[project_name]\n\n        raise KeyError(f\"No project with the name {name!r}\")\n\n    @property\n    def all_requirements(self) -> List[InstallRequirement]:\n        return self.unnamed_requirements + list(self.requirements.values())\n\n    @property\n    def requirements_to_install(self) -> List[InstallRequirement]:\n        \"\"\"Return the list of requirements that need to be installed.\n\n        TODO remove this property together with the legacy resolver, since the new\n             resolver only returns requirements that need to be installed.\n        \"\"\"\n        return [\n            install_req\n            for install_req in self.all_requirements\n            if not install_req.constraint and not install_req.satisfied_by\n        ]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py": {
      "sha": "c95b31138c81",
      "lines": 636,
      "head": "import functools\nimport os\nimport sys\nimport sysconfig\nfrom importlib.util import cache_from_source\nfrom typing import Any, Callable, Dict, Generator, Iterable, List, Optional, Set, Tuple\n\nfrom pip._internal.exceptions import LegacyDistutilsInstall, UninstallMissingRecord\nfrom pip._internal.locations import get_bin_prefix, get_bin_user\nfrom pip._internal.metadata import BaseDistribution\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.egg_link import egg_link_path_from_location\nfrom pip._internal.utils.logging import getLogger, indent_log\nfrom pip._internal.utils.misc import ask, normalize_path, renames, rmtree\nfrom pip._internal.utils.temp_dir import AdjacentTempDirectory, TempDirectory\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\n\nlogger = getLogger(__name__)\n\n\ndef _script_names(\n    bin_dir: str, script_name: str, is_gui: bool\n) -> Generator[str, None, None]:\n    \"\"\"Create the fully qualified name of the files created by\n    {console,gui}_scripts for the given ``dist``.\n    Returns the list of file names\n    \"\"\"\n    exe_name = os.path.join(bin_dir, script_name)\n    yield exe_name\n    if not WINDOWS:\n        return\n    yield f\"{exe_name}.exe\"\n    yield f\"{exe_name}.exe.manifest\"\n    if is_gui:\n        yield f\"{exe_name}-script.pyw\"\n    else:\n        yield f\"{exe_name}-script.py\"\n\n\ndef _unique(\n    fn: Callable[..., Generator[Any, None, None]],\n) -> Callable[..., Generator[Any, None, None]]:\n    @functools.wraps(fn)\n    def unique(*args: Any, **kw: Any) -> Generator[Any, None, None]:\n        seen: Set[Any] = set()\n        for item in fn(*args, **kw):\n            if item not in seen:\n                seen.add(item)\n                yield item\n\n    return unique\n\n\n@_unique\ndef uninstallation_paths(dist: BaseDistribution) -> Generator[str, None, None]:\n    \"\"\"\n    Yield all the uninstallation paths for dist based on RECORD-without-.py[co]\n\n    Yield paths to all the files in RECORD. For each .py file in RECORD, add\n    the .pyc and .pyo in the same directory.\n\n    UninstallPathSet.add() takes care of the __pycache__ .py[co].\n\n    If RECORD is not found, raises an error,\n    with possible information from the INSTALLER file.\n\n    https://packaging.python.org/specifications/recording-installed-packages/\n    \"\"\"\n    location = dist.location\n    assert location is not None, \"not installed\"\n\n    entries = dist.iter_declared_entries()\n    if entries is None:\n        raise UninstallMissingRecord(distribution=dist)\n\n    for entry in entries:\n        path = os.path.join(location, entry)\n        yield path\n        if path.endswith(\".py\"):\n            dn, fn = os.path.split(path)\n            base = fn[:-3]\n            path = os.path.join(dn, base + \".pyc\")\n            yield path\n            path = os.path.join(dn, base + \".pyo\")\n            yield path\n\n\ndef compact(paths: Iterable[str]) -> Set[str]:\n    \"\"\"Compact a path set to contain the minimal number of paths\n    necessary to contain all paths in the set. If /a/path/ and\n    /a/path/to/a/file.txt are both in the set, leave only the\n    shorter path.\"\"\"\n\n    sep = os.path.sep\n    short_paths: Set[str] = set()\n    for path in sorted(paths, key=len):\n        should_skip = any(\n            path.startswith(shortpath.rstrip(\"*\"))\n            and path[len(shortpath.rstrip(\"*\").rstrip(sep))] == sep\n            for shortpath in short_paths\n        )\n        if not should_skip:\n            short_paths.add(path)\n    return short_paths\n\n\ndef compress_for_rename(paths: Iterable[str]) -> Set[str]:\n    \"\"\"Returns a set containing the paths that need to be renamed.\n\n    This set may include directories when the original sequence of paths\n    included every file on disk.\n    \"\"\"\n    case_map = {os.path.normcase(p): p for p in paths}\n    remaining = set(case_map)\n    unchecked = sorted({os.path.split(p)[0] for p in case_map.values()}, key=len)\n    wildcards: Set[str] = set()\n\n    def norm_join(*a: str) -> str:\n        return os.path.normcase(os.path.join(*a))\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\req\\__init__.py": {
      "sha": "fc1c6f3aaa33",
      "lines": 103,
      "head": "import collections\nimport logging\nfrom dataclasses import dataclass\nfrom typing import Generator, List, Optional, Sequence, Tuple\n\nfrom pip._internal.cli.progress_bars import get_install_progress_renderer\nfrom pip._internal.utils.logging import indent_log\n\nfrom .req_file import parse_requirements\nfrom .req_install import InstallRequirement\nfrom .req_set import RequirementSet\n\n__all__ = [\n    \"RequirementSet\",\n    \"InstallRequirement\",\n    \"parse_requirements\",\n    \"install_given_reqs\",\n]\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass(frozen=True)\nclass InstallationResult:\n    name: str\n\n\ndef _validate_requirements(\n    requirements: List[InstallRequirement],\n) -> Generator[Tuple[str, InstallRequirement], None, None]:\n    for req in requirements:\n        assert req.name, f\"invalid to-be-installed requirement: {req}\"\n        yield req.name, req\n\n\ndef install_given_reqs(\n    requirements: List[InstallRequirement],\n    global_options: Sequence[str],\n    root: Optional[str],\n    home: Optional[str],\n    prefix: Optional[str],\n    warn_script_location: bool,\n    use_user_site: bool,\n    pycompile: bool,\n    progress_bar: str,\n) -> List[InstallationResult]:\n    \"\"\"\n    Install everything in the given list.\n\n    (to be called after having downloaded and unpacked the packages)\n    \"\"\"\n    to_install = collections.OrderedDict(_validate_requirements(requirements))\n\n    if to_install:\n        logger.info(\n            \"Installing collected packages: %s\",\n            \", \".join(to_install.keys()),\n        )\n\n    installed = []\n\n    show_progress = logger.isEnabledFor(logging.INFO) and len(to_install) > 1\n\n    items = iter(to_install.values())\n    if show_progress:\n        renderer = get_install_progress_renderer(\n            bar_type=progress_bar, total=len(to_install)\n        )\n        items = renderer(items)\n\n    with indent_log():\n        for requirement in items:\n            req_name = requirement.name\n            assert req_name is not None\n            if requirement.should_reinstall:\n                logger.info(\"Attempting uninstall: %s\", req_name)\n                with indent_log():\n                    uninstalled_pathset = requirement.uninstall(auto_confirm=True)\n            else:\n                uninstalled_pathset = None\n\n            try:\n                requirement.install(\n                    global_options,\n                    root=root,\n                    home=home,\n                    prefix=prefix,\n                    warn_script_location=warn_script_location,\n                    use_user_site=use_user_site,\n                    pycompile=pycompile,\n                )\n            except Exception:\n                # if install did not succeed, rollback previous uninstall\n                if uninstalled_pathset and not requirement.install_succeeded:\n                    uninstalled_pathset.rollback()\n                raise\n            else:\n                if uninstalled_pathset and requirement.install_succeeded:\n                    uninstalled_pathset.commit()\n\n            installed.append(InstallationResult(req_name))\n\n    return installed\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\base.py": {
      "sha": "bb0a50e2866d",
      "lines": 20,
      "head": "from typing import Callable, List, Optional\n\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.req.req_set import RequirementSet\n\nInstallRequirementProvider = Callable[\n    [str, Optional[InstallRequirement]], InstallRequirement\n]\n\n\nclass BaseResolver:\n    def resolve(\n        self, root_reqs: List[InstallRequirement], check_supported_wheels: bool\n    ) -> RequirementSet:\n        raise NotImplementedError()\n\n    def get_installation_order(\n        self, req_set: RequirementSet\n    ) -> List[InstallRequirement]:\n        raise NotImplementedError()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py": {
      "sha": "1dcc2a85b3c6",
      "lines": 597,
      "head": "\"\"\"Dependency Resolution\n\nThe dependency resolution in pip is performed as follows:\n\nfor top-level requirements:\n    a. only one spec allowed per project, regardless of conflicts or not.\n       otherwise a \"double requirement\" exception is raised\n    b. they override sub-dependency requirements.\nfor sub-dependencies\n    a. \"first found, wins\" (where the order is breadth first)\n\"\"\"\n\nimport logging\nimport sys\nfrom collections import defaultdict\nfrom itertools import chain\nfrom typing import DefaultDict, Iterable, List, Optional, Set, Tuple\n\nfrom pip._vendor.packaging import specifiers\nfrom pip._vendor.packaging.requirements import Requirement\n\nfrom pip._internal.cache import WheelCache\nfrom pip._internal.exceptions import (\n    BestVersionAlreadyInstalled,\n    DistributionNotFound,\n    HashError,\n    HashErrors,\n    InstallationError,\n    NoneMetadataError,\n    UnsupportedPythonVersion,\n)\nfrom pip._internal.index.package_finder import PackageFinder\nfrom pip._internal.metadata import BaseDistribution\nfrom pip._internal.models.link import Link\nfrom pip._internal.models.wheel import Wheel\nfrom pip._internal.operations.prepare import RequirementPreparer\nfrom pip._internal.req.req_install import (\n    InstallRequirement,\n    check_invalid_constraint_type,\n)\nfrom pip._internal.req.req_set import RequirementSet\nfrom pip._internal.resolution.base import BaseResolver, InstallRequirementProvider\nfrom pip._internal.utils import compatibility_tags\nfrom pip._internal.utils.compatibility_tags import get_supported\nfrom pip._internal.utils.direct_url_helpers import direct_url_from_link\nfrom pip._internal.utils.logging import indent_log\nfrom pip._internal.utils.misc import normalize_version_info\nfrom pip._internal.utils.packaging import check_requires_python\n\nlogger = logging.getLogger(__name__)\n\nDiscoveredDependencies = DefaultDict[Optional[str], List[InstallRequirement]]\n\n\ndef _check_dist_requires_python(\n    dist: BaseDistribution,\n    version_info: Tuple[int, int, int],\n    ignore_requires_python: bool = False,\n) -> None:\n    \"\"\"\n    Check whether the given Python version is compatible with a distribution's\n    \"Requires-Python\" value.\n\n    :param version_info: A 3-tuple of ints representing the Python\n        major-minor-micro version to check.\n    :param ignore_requires_python: Whether to ignore the \"Requires-Python\"\n        value if the given Python version isn't compatible.\n\n    :raises UnsupportedPythonVersion: When the given Python version isn't\n        compatible.\n    \"\"\"\n    # This idiosyncratically converts the SpecifierSet to str and let\n    # check_requires_python then parse it again into SpecifierSet. But this\n    # is the legacy resolver so I'm just not going to bother refactoring.\n    try:\n        requires_python = str(dist.requires_python)\n    except FileNotFoundError as e:\n        raise NoneMetadataError(dist, str(e))\n    try:\n        is_compatible = check_requires_python(\n            requires_python,\n            version_info=version_info,\n        )\n    except specifiers.InvalidSpecifier as exc:\n        logger.warning(\n            \"Package %r has an invalid Requires-Python: %s\", dist.raw_name, exc\n        )\n        return\n\n    if is_compatible:\n        return\n\n    version = \".\".join(map(str, version_info))\n    if ignore_requires_python:\n        logger.debug(\n            \"Ignoring failed Requires-Python check for package %r: %s not in %r\",\n            dist.raw_name,\n            version,\n            requires_python,\n        )\n        return\n\n    raise UnsupportedPythonVersion(\n        f\"Package {dist.raw_name!r} requires a different Python: \"\n        f\"{version} not in {requires_python!r}\"\n    )\n\n\nclass Resolver(BaseResolver):\n    \"\"\"Resolves which packages need to be installed/uninstalled to perform \\\n    the requested operation without breaking the requirements of any package.\n    \"\"\"\n\n    _allowed_strategies = {\"eager\", \"only-if-needed\", \"to-satisfy-only\"}\n\n    def __init__(\n        self,\n        preparer: RequirementPreparer,\n        finder: PackageFinder,\n        wheel_cache: Optional[WheelCache],\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\legacy\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\base.py": {
      "sha": "8f49b0ae40fc",
      "lines": 139,
      "head": "from dataclasses import dataclass\nfrom typing import FrozenSet, Iterable, Optional, Tuple\n\nfrom pip._vendor.packaging.specifiers import SpecifierSet\nfrom pip._vendor.packaging.utils import NormalizedName\nfrom pip._vendor.packaging.version import Version\n\nfrom pip._internal.models.link import Link, links_equivalent\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.utils.hashes import Hashes\n\nCandidateLookup = Tuple[Optional[\"Candidate\"], Optional[InstallRequirement]]\n\n\ndef format_name(project: NormalizedName, extras: FrozenSet[NormalizedName]) -> str:\n    if not extras:\n        return project\n    extras_expr = \",\".join(sorted(extras))\n    return f\"{project}[{extras_expr}]\"\n\n\n@dataclass(frozen=True)\nclass Constraint:\n    specifier: SpecifierSet\n    hashes: Hashes\n    links: FrozenSet[Link]\n\n    @classmethod\n    def empty(cls) -> \"Constraint\":\n        return Constraint(SpecifierSet(), Hashes(), frozenset())\n\n    @classmethod\n    def from_ireq(cls, ireq: InstallRequirement) -> \"Constraint\":\n        links = frozenset([ireq.link]) if ireq.link else frozenset()\n        return Constraint(ireq.specifier, ireq.hashes(trust_internet=False), links)\n\n    def __bool__(self) -> bool:\n        return bool(self.specifier) or bool(self.hashes) or bool(self.links)\n\n    def __and__(self, other: InstallRequirement) -> \"Constraint\":\n        if not isinstance(other, InstallRequirement):\n            return NotImplemented\n        specifier = self.specifier & other.specifier\n        hashes = self.hashes & other.hashes(trust_internet=False)\n        links = self.links\n        if other.link:\n            links = links.union([other.link])\n        return Constraint(specifier, hashes, links)\n\n    def is_satisfied_by(self, candidate: \"Candidate\") -> bool:\n        # Reject if there are any mismatched URL constraints on this package.\n        if self.links and not all(_match_link(link, candidate) for link in self.links):\n            return False\n        # We can safely always allow prereleases here since PackageFinder\n        # already implements the prerelease logic, and would have filtered out\n        # prerelease candidates if the user does not expect them.\n        return self.specifier.contains(candidate.version, prereleases=True)\n\n\nclass Requirement:\n    @property\n    def project_name(self) -> NormalizedName:\n        \"\"\"The \"project name\" of a requirement.\n\n        This is different from ``name`` if this requirement contains extras,\n        in which case ``name`` would contain the ``[...]`` part, while this\n        refers to the name of the project.\n        \"\"\"\n        raise NotImplementedError(\"Subclass should override\")\n\n    @property\n    def name(self) -> str:\n        \"\"\"The name identifying this requirement in the resolver.\n\n        This is different from ``project_name`` if this requirement contains\n        extras, where ``project_name`` would not contain the ``[...]`` part.\n        \"\"\"\n        raise NotImplementedError(\"Subclass should override\")\n\n    def is_satisfied_by(self, candidate: \"Candidate\") -> bool:\n        return False\n\n    def get_candidate_lookup(self) -> CandidateLookup:\n        raise NotImplementedError(\"Subclass should override\")\n\n    def format_for_error(self) -> str:\n        raise NotImplementedError(\"Subclass should override\")\n\n\ndef _match_link(link: Link, candidate: \"Candidate\") -> bool:\n    if candidate.source_link:\n        return links_equivalent(link, candidate.source_link)\n    return False\n\n\nclass Candidate:\n    @property\n    def project_name(self) -> NormalizedName:\n        \"\"\"The \"project name\" of the candidate.\n\n        This is different from ``name`` if this candidate contains extras,\n        in which case ``name`` would contain the ``[...]`` part, while this\n        refers to the name of the project.\n        \"\"\"\n        raise NotImplementedError(\"Override in subclass\")\n\n    @property\n    def name(self) -> str:\n        \"\"\"The name identifying this candidate in the resolver.\n\n        This is different from ``project_name`` if this candidate contains\n        extras, where ``project_name`` would not contain the ``[...]`` part.\n        \"\"\"\n        raise NotImplementedError(\"Override in subclass\")\n\n    @property\n    def version(self) -> Version:\n        raise NotImplementedError(\"Override in subclass\")\n\n    @property\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py": {
      "sha": "5341af968069",
      "lines": 579,
      "head": "import logging\nimport sys\nfrom typing import TYPE_CHECKING, Any, FrozenSet, Iterable, Optional, Tuple, Union, cast\n\nfrom pip._vendor.packaging.requirements import InvalidRequirement\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\nfrom pip._vendor.packaging.version import Version\n\nfrom pip._internal.exceptions import (\n    HashError,\n    InstallationSubprocessError,\n    InvalidInstalledPackage,\n    MetadataInconsistent,\n    MetadataInvalid,\n)\nfrom pip._internal.metadata import BaseDistribution\nfrom pip._internal.models.link import Link, links_equivalent\nfrom pip._internal.models.wheel import Wheel\nfrom pip._internal.req.constructors import (\n    install_req_from_editable,\n    install_req_from_line,\n)\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.utils.direct_url_helpers import direct_url_from_link\nfrom pip._internal.utils.misc import normalize_version_info\n\nfrom .base import Candidate, Requirement, format_name\n\nif TYPE_CHECKING:\n    from .factory import Factory\n\nlogger = logging.getLogger(__name__)\n\nBaseCandidate = Union[\n    \"AlreadyInstalledCandidate\",\n    \"EditableCandidate\",\n    \"LinkCandidate\",\n]\n\n# Avoid conflicting with the PyPI package \"Python\".\nREQUIRES_PYTHON_IDENTIFIER = cast(NormalizedName, \"<Python from Requires-Python>\")\n\n\ndef as_base_candidate(candidate: Candidate) -> Optional[BaseCandidate]:\n    \"\"\"The runtime version of BaseCandidate.\"\"\"\n    base_candidate_classes = (\n        AlreadyInstalledCandidate,\n        EditableCandidate,\n        LinkCandidate,\n    )\n    if isinstance(candidate, base_candidate_classes):\n        return candidate\n    return None\n\n\ndef make_install_req_from_link(\n    link: Link, template: InstallRequirement\n) -> InstallRequirement:\n    assert not template.editable, \"template is editable\"\n    if template.req:\n        line = str(template.req)\n    else:\n        line = link.url\n    ireq = install_req_from_line(\n        line,\n        user_supplied=template.user_supplied,\n        comes_from=template.comes_from,\n        use_pep517=template.use_pep517,\n        isolated=template.isolated,\n        constraint=template.constraint,\n        global_options=template.global_options,\n        hash_options=template.hash_options,\n        config_settings=template.config_settings,\n    )\n    ireq.original_link = template.original_link\n    ireq.link = link\n    ireq.extras = template.extras\n    return ireq\n\n\ndef make_install_req_from_editable(\n    link: Link, template: InstallRequirement\n) -> InstallRequirement:\n    assert template.editable, \"template not editable\"\n    ireq = install_req_from_editable(\n        link.url,\n        user_supplied=template.user_supplied,\n        comes_from=template.comes_from,\n        use_pep517=template.use_pep517,\n        isolated=template.isolated,\n        constraint=template.constraint,\n        permit_editable_wheels=template.permit_editable_wheels,\n        global_options=template.global_options,\n        hash_options=template.hash_options,\n        config_settings=template.config_settings,\n    )\n    ireq.extras = template.extras\n    return ireq\n\n\ndef _make_install_req_from_dist(\n    dist: BaseDistribution, template: InstallRequirement\n) -> InstallRequirement:\n    if template.req:\n        line = str(template.req)\n    elif template.link:\n        line = f\"{dist.canonical_name} @ {template.link.url}\"\n    else:\n        line = f\"{dist.canonical_name}=={dist.version}\"\n    ireq = install_req_from_line(\n        line,\n        user_supplied=template.user_supplied,\n        comes_from=template.comes_from,\n        use_pep517=template.use_pep517,\n        isolated=template.isolated,\n        constraint=template.constraint,\n        global_options=template.global_options,\n        hash_options=template.hash_options,\n        config_settings=template.config_settings,\n    )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py": {
      "sha": "06fc68aafe28",
      "lines": 823,
      "head": "import contextlib\nimport functools\nimport logging\nfrom typing import (\n    TYPE_CHECKING,\n    Callable,\n    Dict,\n    FrozenSet,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    NamedTuple,\n    Optional,\n    Protocol,\n    Sequence,\n    Set,\n    Tuple,\n    TypeVar,\n    cast,\n)\n\nfrom pip._vendor.packaging.requirements import InvalidRequirement\nfrom pip._vendor.packaging.specifiers import SpecifierSet\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\nfrom pip._vendor.packaging.version import InvalidVersion, Version\nfrom pip._vendor.resolvelib import ResolutionImpossible\n\nfrom pip._internal.cache import CacheEntry, WheelCache\nfrom pip._internal.exceptions import (\n    DistributionNotFound,\n    InstallationError,\n    InvalidInstalledPackage,\n    MetadataInconsistent,\n    MetadataInvalid,\n    UnsupportedPythonVersion,\n    UnsupportedWheel,\n)\nfrom pip._internal.index.package_finder import PackageFinder\nfrom pip._internal.metadata import BaseDistribution, get_default_environment\nfrom pip._internal.models.link import Link\nfrom pip._internal.models.wheel import Wheel\nfrom pip._internal.operations.prepare import RequirementPreparer\nfrom pip._internal.req.constructors import (\n    install_req_drop_extras,\n    install_req_from_link_and_ireq,\n)\nfrom pip._internal.req.req_install import (\n    InstallRequirement,\n    check_invalid_constraint_type,\n)\nfrom pip._internal.resolution.base import InstallRequirementProvider\nfrom pip._internal.utils.compatibility_tags import get_supported\nfrom pip._internal.utils.hashes import Hashes\nfrom pip._internal.utils.packaging import get_requirement\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\n\nfrom .base import Candidate, Constraint, Requirement\nfrom .candidates import (\n    AlreadyInstalledCandidate,\n    BaseCandidate,\n    EditableCandidate,\n    ExtrasCandidate,\n    LinkCandidate,\n    RequiresPythonCandidate,\n    as_base_candidate,\n)\nfrom .found_candidates import FoundCandidates, IndexCandidateInfo\nfrom .requirements import (\n    ExplicitRequirement,\n    RequiresPythonRequirement,\n    SpecifierRequirement,\n    SpecifierWithoutExtrasRequirement,\n    UnsatisfiableRequirement,\n)\n\nif TYPE_CHECKING:\n\n    class ConflictCause(Protocol):\n        requirement: RequiresPythonRequirement\n        parent: Candidate\n\n\nlogger = logging.getLogger(__name__)\n\nC = TypeVar(\"C\")\nCache = Dict[Link, C]\n\n\nclass CollectedRootRequirements(NamedTuple):\n    requirements: List[Requirement]\n    constraints: Dict[str, Constraint]\n    user_requested: Dict[str, int]\n\n\nclass Factory:\n    def __init__(\n        self,\n        finder: PackageFinder,\n        preparer: RequirementPreparer,\n        make_install_req: InstallRequirementProvider,\n        wheel_cache: Optional[WheelCache],\n        use_user_site: bool,\n        force_reinstall: bool,\n        ignore_installed: bool,\n        ignore_requires_python: bool,\n        py_version_info: Optional[Tuple[int, ...]] = None,\n    ) -> None:\n        self._finder = finder\n        self.preparer = preparer\n        self._wheel_cache = wheel_cache\n        self._python_candidate = RequiresPythonCandidate(py_version_info)\n        self._make_install_req_from_spec = make_install_req\n        self._use_user_site = use_user_site\n        self._force_reinstall = force_reinstall\n        self._ignore_requires_python = ignore_requires_python\n\n        self._build_failures: Cache[InstallationError] = {}\n        self._link_candidate_cache: Cache[LinkCandidate] = {}\n        self._editable_candidate_cache: Cache[EditableCandidate] = {}\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py": {
      "sha": "1aeaf50fd571",
      "lines": 164,
      "head": "\"\"\"Utilities to lazily create and visit candidates found.\n\nCreating and visiting a candidate is a *very* costly operation. It involves\nfetching, extracting, potentially building modules from source, and verifying\ndistribution metadata. It is therefore crucial for performance to keep\neverything here lazy all the way down, so we only touch candidates that we\nabsolutely need, and not \"download the world\" when we only need one version of\nsomething.\n\"\"\"\n\nimport logging\nfrom collections.abc import Sequence\nfrom typing import Any, Callable, Iterator, Optional, Set, Tuple\n\nfrom pip._vendor.packaging.version import _BaseVersion\n\nfrom pip._internal.exceptions import MetadataInvalid\n\nfrom .base import Candidate\n\nlogger = logging.getLogger(__name__)\n\nIndexCandidateInfo = Tuple[_BaseVersion, Callable[[], Optional[Candidate]]]\n\n\ndef _iter_built(infos: Iterator[IndexCandidateInfo]) -> Iterator[Candidate]:\n    \"\"\"Iterator for ``FoundCandidates``.\n\n    This iterator is used when the package is not already installed. Candidates\n    from index come later in their normal ordering.\n    \"\"\"\n    versions_found: Set[_BaseVersion] = set()\n    for version, func in infos:\n        if version in versions_found:\n            continue\n        try:\n            candidate = func()\n        except MetadataInvalid as e:\n            logger.warning(\n                \"Ignoring version %s of %s since it has invalid metadata:\\n\"\n                \"%s\\n\"\n                \"Please use pip<24.1 if you need to use this version.\",\n                version,\n                e.ireq.name,\n                e,\n            )\n            # Mark version as found to avoid trying other candidates with the same\n            # version, since they most likely have invalid metadata as well.\n            versions_found.add(version)\n        else:\n            if candidate is None:\n                continue\n            yield candidate\n            versions_found.add(version)\n\n\ndef _iter_built_with_prepended(\n    installed: Candidate, infos: Iterator[IndexCandidateInfo]\n) -> Iterator[Candidate]:\n    \"\"\"Iterator for ``FoundCandidates``.\n\n    This iterator is used when the resolver prefers the already-installed\n    candidate and NOT to upgrade. The installed candidate is therefore\n    always yielded first, and candidates from index come later in their\n    normal ordering, except skipped when the version is already installed.\n    \"\"\"\n    yield installed\n    versions_found: Set[_BaseVersion] = {installed.version}\n    for version, func in infos:\n        if version in versions_found:\n            continue\n        candidate = func()\n        if candidate is None:\n            continue\n        yield candidate\n        versions_found.add(version)\n\n\ndef _iter_built_with_inserted(\n    installed: Candidate, infos: Iterator[IndexCandidateInfo]\n) -> Iterator[Candidate]:\n    \"\"\"Iterator for ``FoundCandidates``.\n\n    This iterator is used when the resolver prefers to upgrade an\n    already-installed package. Candidates from index are returned in their\n    normal ordering, except replaced when the version is already installed.\n\n    The implementation iterates through and yields other candidates, inserting\n    the installed candidate exactly once before we start yielding older or\n    equivalent candidates, or after all other candidates if they are all newer.\n    \"\"\"\n    versions_found: Set[_BaseVersion] = set()\n    for version, func in infos:\n        if version in versions_found:\n            continue\n        # If the installed candidate is better, yield it first.\n        if installed.version >= version:\n            yield installed\n            versions_found.add(installed.version)\n        candidate = func()\n        if candidate is None:\n            continue\n        yield candidate\n        versions_found.add(version)\n\n    # If the installed candidate is older than all other candidates.\n    if installed.version not in versions_found:\n        yield installed\n\n\nclass FoundCandidates(Sequence[Candidate]):\n    \"\"\"A lazy sequence to provide candidates to the resolver.\n\n    The intended usage is to return this from `find_matches()` so the resolver\n    can iterate through the sequence multiple times, but only access the index\n    page when remote packages are actually needed. This improve performances\n    when suitable candidates are already installed on disk.\n    \"\"\"\n\n    def __init__(\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\provider.py": {
      "sha": "0428e42d4d22",
      "lines": 281,
      "head": "import math\nfrom functools import lru_cache\nfrom typing import (\n    TYPE_CHECKING,\n    Dict,\n    Iterable,\n    Iterator,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n\nfrom pip._vendor.resolvelib.providers import AbstractProvider\n\nfrom pip._internal.req.req_install import InstallRequirement\n\nfrom .base import Candidate, Constraint, Requirement\nfrom .candidates import REQUIRES_PYTHON_IDENTIFIER\nfrom .factory import Factory\nfrom .requirements import ExplicitRequirement\n\nif TYPE_CHECKING:\n    from pip._vendor.resolvelib.providers import Preference\n    from pip._vendor.resolvelib.resolvers import RequirementInformation\n\n    PreferenceInformation = RequirementInformation[Requirement, Candidate]\n\n    _ProviderBase = AbstractProvider[Requirement, Candidate, str]\nelse:\n    _ProviderBase = AbstractProvider\n\n# Notes on the relationship between the provider, the factory, and the\n# candidate and requirement classes.\n#\n# The provider is a direct implementation of the resolvelib class. Its role\n# is to deliver the API that resolvelib expects.\n#\n# Rather than work with completely abstract \"requirement\" and \"candidate\"\n# concepts as resolvelib does, pip has concrete classes implementing these two\n# ideas. The API of Requirement and Candidate objects are defined in the base\n# classes, but essentially map fairly directly to the equivalent provider\n# methods. In particular, `find_matches` and `is_satisfied_by` are\n# requirement methods, and `get_dependencies` is a candidate method.\n#\n# The factory is the interface to pip's internal mechanisms. It is stateless,\n# and is created by the resolver and held as a property of the provider. It is\n# responsible for creating Requirement and Candidate objects, and provides\n# services to those objects (access to pip's finder and preparer).\n\n\nD = TypeVar(\"D\")\nV = TypeVar(\"V\")\n\n\ndef _get_with_identifier(\n    mapping: Mapping[str, V],\n    identifier: str,\n    default: D,\n) -> Union[D, V]:\n    \"\"\"Get item from a package name lookup mapping with a resolver identifier.\n\n    This extra logic is needed when the target mapping is keyed by package\n    name, which cannot be directly looked up with an identifier (which may\n    contain requested extras). Additional logic is added to also look up a value\n    by \"cleaning up\" the extras from the identifier.\n    \"\"\"\n    if identifier in mapping:\n        return mapping[identifier]\n    # HACK: Theoretically we should check whether this identifier is a valid\n    # \"NAME[EXTRAS]\" format, and parse out the name part with packaging or\n    # some regular expression. But since pip's resolver only spits out three\n    # kinds of identifiers: normalized PEP 503 names, normalized names plus\n    # extras, and Requires-Python, we can cheat a bit here.\n    name, open_bracket, _ = identifier.partition(\"[\")\n    if open_bracket and name in mapping:\n        return mapping[name]\n    return default\n\n\nclass PipProvider(_ProviderBase):\n    \"\"\"Pip's provider implementation for resolvelib.\n\n    :params constraints: A mapping of constraints specified by the user. Keys\n        are canonicalized project names.\n    :params ignore_dependencies: Whether the user specified ``--no-deps``.\n    :params upgrade_strategy: The user-specified upgrade strategy.\n    :params user_requested: A set of canonicalized package names that the user\n        supplied for pip to install/upgrade.\n    \"\"\"\n\n    def __init__(\n        self,\n        factory: Factory,\n        constraints: Dict[str, Constraint],\n        ignore_dependencies: bool,\n        upgrade_strategy: str,\n        user_requested: Dict[str, int],\n    ) -> None:\n        self._factory = factory\n        self._constraints = constraints\n        self._ignore_dependencies = ignore_dependencies\n        self._upgrade_strategy = upgrade_strategy\n        self._user_requested = user_requested\n\n    def identify(self, requirement_or_candidate: Union[Requirement, Candidate]) -> str:\n        return requirement_or_candidate.name\n\n    def narrow_requirement_selection(\n        self,\n        identifiers: Iterable[str],\n        resolutions: Mapping[str, Candidate],\n        candidates: Mapping[str, Iterator[Candidate]],\n        information: Mapping[str, Iterator[\"PreferenceInformation\"]],\n        backtrack_causes: Sequence[\"PreferenceInformation\"],\n    ) -> Iterable[str]:\n        \"\"\"Produce a subset of identifiers that should be considered before others.\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\reporter.py": {
      "sha": "e113792e6a62",
      "lines": 83,
      "head": "from collections import defaultdict\nfrom logging import getLogger\nfrom typing import Any, DefaultDict, Optional\n\nfrom pip._vendor.resolvelib.reporters import BaseReporter\n\nfrom .base import Candidate, Requirement\n\nlogger = getLogger(__name__)\n\n\nclass PipReporter(BaseReporter[Requirement, Candidate, str]):\n    def __init__(self) -> None:\n        self.reject_count_by_package: DefaultDict[str, int] = defaultdict(int)\n\n        self._messages_at_reject_count = {\n            1: (\n                \"pip is looking at multiple versions of {package_name} to \"\n                \"determine which version is compatible with other \"\n                \"requirements. This could take a while.\"\n            ),\n            8: (\n                \"pip is still looking at multiple versions of {package_name} to \"\n                \"determine which version is compatible with other \"\n                \"requirements. This could take a while.\"\n            ),\n            13: (\n                \"This is taking longer than usual. You might need to provide \"\n                \"the dependency resolver with stricter constraints to reduce \"\n                \"runtime. See https://pip.pypa.io/warnings/backtracking for \"\n                \"guidance. If you want to abort this run, press Ctrl + C.\"\n            ),\n        }\n\n    def rejecting_candidate(self, criterion: Any, candidate: Candidate) -> None:\n        self.reject_count_by_package[candidate.name] += 1\n\n        count = self.reject_count_by_package[candidate.name]\n        if count not in self._messages_at_reject_count:\n            return\n\n        message = self._messages_at_reject_count[count]\n        logger.info(\"INFO: %s\", message.format(package_name=candidate.name))\n\n        msg = \"Will try a different candidate, due to conflict:\"\n        for req_info in criterion.information:\n            req, parent = req_info.requirement, req_info.parent\n            # Inspired by Factory.get_installation_error\n            msg += \"\\n    \"\n            if parent:\n                msg += f\"{parent.name} {parent.version} depends on \"\n            else:\n                msg += \"The user requested \"\n            msg += req.format_for_error()\n        logger.debug(msg)\n\n\nclass PipDebuggingReporter(BaseReporter[Requirement, Candidate, str]):\n    \"\"\"A reporter that does an info log for every event it sees.\"\"\"\n\n    def starting(self) -> None:\n        logger.info(\"Reporter.starting()\")\n\n    def starting_round(self, index: int) -> None:\n        logger.info(\"Reporter.starting_round(%r)\", index)\n\n    def ending_round(self, index: int, state: Any) -> None:\n        logger.info(\"Reporter.ending_round(%r, state)\", index)\n        logger.debug(\"Reporter.ending_round(%r, %r)\", index, state)\n\n    def ending(self, state: Any) -> None:\n        logger.info(\"Reporter.ending(%r)\", state)\n\n    def adding_requirement(\n        self, requirement: Requirement, parent: Optional[Candidate]\n    ) -> None:\n        logger.info(\"Reporter.adding_requirement(%r, %r)\", requirement, parent)\n\n    def rejecting_candidate(self, criterion: Any, candidate: Candidate) -> None:\n        logger.info(\"Reporter.rejecting_candidate(%r, %r)\", criterion, candidate)\n\n    def pinning(self, candidate: Candidate) -> None:\n        logger.info(\"Reporter.pinning(%r)\", candidate)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\requirements.py": {
      "sha": "784f726b843c",
      "lines": 245,
      "head": "from typing import Any, Optional\n\nfrom pip._vendor.packaging.specifiers import SpecifierSet\nfrom pip._vendor.packaging.utils import NormalizedName, canonicalize_name\n\nfrom pip._internal.req.constructors import install_req_drop_extras\nfrom pip._internal.req.req_install import InstallRequirement\n\nfrom .base import Candidate, CandidateLookup, Requirement, format_name\n\n\nclass ExplicitRequirement(Requirement):\n    def __init__(self, candidate: Candidate) -> None:\n        self.candidate = candidate\n\n    def __str__(self) -> str:\n        return str(self.candidate)\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({self.candidate!r})\"\n\n    def __hash__(self) -> int:\n        return hash(self.candidate)\n\n    def __eq__(self, other: Any) -> bool:\n        if not isinstance(other, ExplicitRequirement):\n            return False\n        return self.candidate == other.candidate\n\n    @property\n    def project_name(self) -> NormalizedName:\n        # No need to canonicalize - the candidate did this\n        return self.candidate.project_name\n\n    @property\n    def name(self) -> str:\n        # No need to canonicalize - the candidate did this\n        return self.candidate.name\n\n    def format_for_error(self) -> str:\n        return self.candidate.format_for_error()\n\n    def get_candidate_lookup(self) -> CandidateLookup:\n        return self.candidate, None\n\n    def is_satisfied_by(self, candidate: Candidate) -> bool:\n        return candidate == self.candidate\n\n\nclass SpecifierRequirement(Requirement):\n    def __init__(self, ireq: InstallRequirement) -> None:\n        assert ireq.link is None, \"This is a link, not a specifier\"\n        self._ireq = ireq\n        self._equal_cache: Optional[str] = None\n        self._hash: Optional[int] = None\n        self._extras = frozenset(canonicalize_name(e) for e in self._ireq.extras)\n\n    @property\n    def _equal(self) -> str:\n        if self._equal_cache is not None:\n            return self._equal_cache\n\n        self._equal_cache = str(self._ireq)\n        return self._equal_cache\n\n    def __str__(self) -> str:\n        return str(self._ireq.req)\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({str(self._ireq.req)!r})\"\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, SpecifierRequirement):\n            return NotImplemented\n        return self._equal == other._equal\n\n    def __hash__(self) -> int:\n        if self._hash is not None:\n            return self._hash\n\n        self._hash = hash(self._equal)\n        return self._hash\n\n    @property\n    def project_name(self) -> NormalizedName:\n        assert self._ireq.req, \"Specifier-backed ireq is always PEP 508\"\n        return canonicalize_name(self._ireq.req.name)\n\n    @property\n    def name(self) -> str:\n        return format_name(self.project_name, self._extras)\n\n    def format_for_error(self) -> str:\n        # Convert comma-separated specifiers into \"A, B, ..., F and G\"\n        # This makes the specifier a bit more \"human readable\", without\n        # risking a change in meaning. (Hopefully! Not all edge cases have\n        # been checked)\n        parts = [s.strip() for s in str(self).split(\",\")]\n        if len(parts) == 0:\n            return \"\"\n        elif len(parts) == 1:\n            return parts[0]\n\n        return \", \".join(parts[:-1]) + \" and \" + parts[-1]\n\n    def get_candidate_lookup(self) -> CandidateLookup:\n        return None, self._ireq\n\n    def is_satisfied_by(self, candidate: Candidate) -> bool:\n        assert candidate.name == self.name, (\n            f\"Internal issue: Candidate is not for this requirement \"\n            f\"{candidate.name} vs {self.name}\"\n        )\n        # We can safely always allow prereleases here since PackageFinder\n        # already implements the prerelease logic, and would have filtered out\n        # prerelease candidates if the user does not expect them.\n        assert self._ireq.req, \"Specifier-backed ireq is always PEP 508\"\n        spec = self._ireq.req.specifier\n        return spec.contains(candidate.version, prereleases=True)\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py": {
      "sha": "90f89067e17d",
      "lines": 320,
      "head": "import contextlib\nimport functools\nimport logging\nimport os\nfrom typing import TYPE_CHECKING, Dict, List, Optional, Set, Tuple, cast\n\nfrom pip._vendor.packaging.utils import canonicalize_name\nfrom pip._vendor.resolvelib import BaseReporter, ResolutionImpossible, ResolutionTooDeep\nfrom pip._vendor.resolvelib import Resolver as RLResolver\nfrom pip._vendor.resolvelib.structs import DirectedGraph\n\nfrom pip._internal.cache import WheelCache\nfrom pip._internal.exceptions import ResolutionTooDeepError\nfrom pip._internal.index.package_finder import PackageFinder\nfrom pip._internal.operations.prepare import RequirementPreparer\nfrom pip._internal.req.constructors import install_req_extend_extras\nfrom pip._internal.req.req_install import InstallRequirement\nfrom pip._internal.req.req_set import RequirementSet\nfrom pip._internal.resolution.base import BaseResolver, InstallRequirementProvider\nfrom pip._internal.resolution.resolvelib.provider import PipProvider\nfrom pip._internal.resolution.resolvelib.reporter import (\n    PipDebuggingReporter,\n    PipReporter,\n)\nfrom pip._internal.utils.packaging import get_requirement\n\nfrom .base import Candidate, Requirement\nfrom .factory import Factory\n\nif TYPE_CHECKING:\n    from pip._vendor.resolvelib.resolvers import Result as RLResult\n\n    Result = RLResult[Requirement, Candidate, str]\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass Resolver(BaseResolver):\n    _allowed_strategies = {\"eager\", \"only-if-needed\", \"to-satisfy-only\"}\n\n    def __init__(\n        self,\n        preparer: RequirementPreparer,\n        finder: PackageFinder,\n        wheel_cache: Optional[WheelCache],\n        make_install_req: InstallRequirementProvider,\n        use_user_site: bool,\n        ignore_dependencies: bool,\n        ignore_installed: bool,\n        ignore_requires_python: bool,\n        force_reinstall: bool,\n        upgrade_strategy: str,\n        py_version_info: Optional[Tuple[int, ...]] = None,\n    ):\n        super().__init__()\n        assert upgrade_strategy in self._allowed_strategies\n\n        self.factory = Factory(\n            finder=finder,\n            preparer=preparer,\n            make_install_req=make_install_req,\n            wheel_cache=wheel_cache,\n            use_user_site=use_user_site,\n            force_reinstall=force_reinstall,\n            ignore_installed=ignore_installed,\n            ignore_requires_python=ignore_requires_python,\n            py_version_info=py_version_info,\n        )\n        self.ignore_dependencies = ignore_dependencies\n        self.upgrade_strategy = upgrade_strategy\n        self._result: Optional[Result] = None\n\n    def resolve(\n        self, root_reqs: List[InstallRequirement], check_supported_wheels: bool\n    ) -> RequirementSet:\n        collected = self.factory.collect_root_requirements(root_reqs)\n        provider = PipProvider(\n            factory=self.factory,\n            constraints=collected.constraints,\n            ignore_dependencies=self.ignore_dependencies,\n            upgrade_strategy=self.upgrade_strategy,\n            user_requested=collected.user_requested,\n        )\n        if \"PIP_RESOLVER_DEBUG\" in os.environ:\n            reporter: BaseReporter[Requirement, Candidate, str] = PipDebuggingReporter()\n        else:\n            reporter = PipReporter()\n        resolver: RLResolver[Requirement, Candidate, str] = RLResolver(\n            provider,\n            reporter,\n        )\n\n        try:\n            limit_how_complex_resolution_can_be = 200000\n            result = self._result = resolver.resolve(\n                collected.requirements, max_rounds=limit_how_complex_resolution_can_be\n            )\n\n        except ResolutionImpossible as e:\n            error = self.factory.get_installation_error(\n                cast(\"ResolutionImpossible[Requirement, Candidate]\", e),\n                collected.constraints,\n            )\n            raise error from e\n        except ResolutionTooDeep:\n            raise ResolutionTooDeepError from None\n\n        req_set = RequirementSet(check_supported_wheels=check_supported_wheels)\n        # process candidates with extras last to ensure their base equivalent is\n        # already in the req_set if appropriate.\n        # Python's sort is stable so using a binary key function keeps relative order\n        # within both subsets.\n        for candidate in sorted(\n            result.mapping.values(), key=lambda c: c.name != c.project_name\n        ):\n            ireq = candidate.get_install_requirement()\n            if ireq is None:\n                if candidate.name != candidate.project_name:\n                    # extend existing req's extras\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\appdirs.py": {
      "sha": "74682db0eaa2",
      "lines": 53,
      "head": "\"\"\"\nThis code wraps the vendored appdirs module to so the return values are\ncompatible for the current pip code base.\n\nThe intention is to rewrite current usages gradually, keeping the tests pass,\nand eventually drop this after all usages are changed.\n\"\"\"\n\nimport os\nimport sys\nfrom typing import List\n\nfrom pip._vendor import platformdirs as _appdirs\n\n\ndef user_cache_dir(appname: str) -> str:\n    return _appdirs.user_cache_dir(appname, appauthor=False)\n\n\ndef _macos_user_config_dir(appname: str, roaming: bool = True) -> str:\n    # Use ~/Application Support/pip, if the directory exists.\n    path = _appdirs.user_data_dir(appname, appauthor=False, roaming=roaming)\n    if os.path.isdir(path):\n        return path\n\n    # Use a Linux-like ~/.config/pip, by default.\n    linux_like_path = \"~/.config/\"\n    if appname:\n        linux_like_path = os.path.join(linux_like_path, appname)\n\n    return os.path.expanduser(linux_like_path)\n\n\ndef user_config_dir(appname: str, roaming: bool = True) -> str:\n    if sys.platform == \"darwin\":\n        return _macos_user_config_dir(appname, roaming)\n\n    return _appdirs.user_config_dir(appname, appauthor=False, roaming=roaming)\n\n\n# for the discussion regarding site_config_dir locations\n# see <https://github.com/pypa/pip/issues/1733>\ndef site_config_dirs(appname: str) -> List[str]:\n    if sys.platform == \"darwin\":\n        dirval = _appdirs.site_data_dir(appname, appauthor=False, multipath=True)\n        return dirval.split(os.pathsep)\n\n    dirval = _appdirs.site_config_dir(appname, appauthor=False, multipath=True)\n    if sys.platform == \"win32\":\n        return [dirval]\n\n    # Unix-y system. Look in /etc as well.\n    return dirval.split(os.pathsep) + [\"/etc\"]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\compat.py": {
      "sha": "5b96aa24f35b",
      "lines": 79,
      "head": "\"\"\"Stuff that differs in different Python versions and platform\ndistributions.\"\"\"\n\nimport importlib.resources\nimport logging\nimport os\nimport sys\nfrom typing import IO\n\n__all__ = [\"get_path_uid\", \"stdlib_pkgs\", \"WINDOWS\"]\n\n\nlogger = logging.getLogger(__name__)\n\n\ndef has_tls() -> bool:\n    try:\n        import _ssl  # noqa: F401  # ignore unused\n\n        return True\n    except ImportError:\n        pass\n\n    from pip._vendor.urllib3.util import IS_PYOPENSSL\n\n    return IS_PYOPENSSL\n\n\ndef get_path_uid(path: str) -> int:\n    \"\"\"\n    Return path's uid.\n\n    Does not follow symlinks:\n        https://github.com/pypa/pip/pull/935#discussion_r5307003\n\n    Placed this function in compat due to differences on AIX and\n    Jython, that should eventually go away.\n\n    :raises OSError: When path is a symlink or can't be read.\n    \"\"\"\n    if hasattr(os, \"O_NOFOLLOW\"):\n        fd = os.open(path, os.O_RDONLY | os.O_NOFOLLOW)\n        file_uid = os.fstat(fd).st_uid\n        os.close(fd)\n    else:  # AIX and Jython\n        # WARNING: time of check vulnerability, but best we can do w/o NOFOLLOW\n        if not os.path.islink(path):\n            # older versions of Jython don't have `os.fstat`\n            file_uid = os.stat(path).st_uid\n        else:\n            # raise OSError for parity with os.O_NOFOLLOW above\n            raise OSError(f\"{path} is a symlink; Will not return uid for symlinks\")\n    return file_uid\n\n\n# The importlib.resources.open_text function was deprecated in 3.11 with suggested\n# replacement we use below.\nif sys.version_info < (3, 11):\n    open_text_resource = importlib.resources.open_text\nelse:\n\n    def open_text_resource(\n        package: str, resource: str, encoding: str = \"utf-8\", errors: str = \"strict\"\n    ) -> IO[str]:\n        return (importlib.resources.files(package) / resource).open(\n            \"r\", encoding=encoding, errors=errors\n        )\n\n\n# packages in the stdlib that may have installation metadata, but should not be\n# considered 'installed'.  this theoretically could be determined based on\n# dist.location (py27:`sysconfig.get_paths()['stdlib']`,\n# py26:sysconfig.get_config_vars('LIBDEST')), but fear platform variation may\n# make this ineffective, so hard-coding\nstdlib_pkgs = {\"python\", \"wsgiref\", \"argparse\"}\n\n\n# windows detection, covers cpython and ironpython\nWINDOWS = sys.platform.startswith(\"win\") or (sys.platform == \"cli\" and os.name == \"nt\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\compatibility_tags.py": {
      "sha": "7b8356ae9ed1",
      "lines": 200,
      "head": "\"\"\"Generate and work with PEP 425 Compatibility Tags.\"\"\"\n\nimport re\nfrom typing import List, Optional, Tuple\n\nfrom pip._vendor.packaging.tags import (\n    PythonVersion,\n    Tag,\n    android_platforms,\n    compatible_tags,\n    cpython_tags,\n    generic_tags,\n    interpreter_name,\n    interpreter_version,\n    ios_platforms,\n    mac_platforms,\n)\n\n_apple_arch_pat = re.compile(r\"(.+)_(\\d+)_(\\d+)_(.+)\")\n\n\ndef version_info_to_nodot(version_info: Tuple[int, ...]) -> str:\n    # Only use up to the first two numbers.\n    return \"\".join(map(str, version_info[:2]))\n\n\ndef _mac_platforms(arch: str) -> List[str]:\n    match = _apple_arch_pat.match(arch)\n    if match:\n        name, major, minor, actual_arch = match.groups()\n        mac_version = (int(major), int(minor))\n        arches = [\n            # Since we have always only checked that the platform starts\n            # with \"macosx\", for backwards-compatibility we extract the\n            # actual prefix provided by the user in case they provided\n            # something like \"macosxcustom_\". It may be good to remove\n            # this as undocumented or deprecate it in the future.\n            \"{}_{}\".format(name, arch[len(\"macosx_\") :])\n            for arch in mac_platforms(mac_version, actual_arch)\n        ]\n    else:\n        # arch pattern didn't match (?!)\n        arches = [arch]\n    return arches\n\n\ndef _ios_platforms(arch: str) -> List[str]:\n    match = _apple_arch_pat.match(arch)\n    if match:\n        name, major, minor, actual_multiarch = match.groups()\n        ios_version = (int(major), int(minor))\n        arches = [\n            # Since we have always only checked that the platform starts\n            # with \"ios\", for backwards-compatibility we extract the\n            # actual prefix provided by the user in case they provided\n            # something like \"ioscustom_\". It may be good to remove\n            # this as undocumented or deprecate it in the future.\n            \"{}_{}\".format(name, arch[len(\"ios_\") :])\n            for arch in ios_platforms(ios_version, actual_multiarch)\n        ]\n    else:\n        # arch pattern didn't match (?!)\n        arches = [arch]\n    return arches\n\n\ndef _android_platforms(arch: str) -> List[str]:\n    match = re.fullmatch(r\"android_(\\d+)_(.+)\", arch)\n    if match:\n        api_level, abi = match.groups()\n        return list(android_platforms(int(api_level), abi))\n    else:\n        # arch pattern didn't match (?!)\n        return [arch]\n\n\ndef _custom_manylinux_platforms(arch: str) -> List[str]:\n    arches = [arch]\n    arch_prefix, arch_sep, arch_suffix = arch.partition(\"_\")\n    if arch_prefix == \"manylinux2014\":\n        # manylinux1/manylinux2010 wheels run on most manylinux2014 systems\n        # with the exception of wheels depending on ncurses. PEP 599 states\n        # manylinux1/manylinux2010 wheels should be considered\n        # manylinux2014 wheels:\n        # https://www.python.org/dev/peps/pep-0599/#backwards-compatibility-with-manylinux2010-wheels\n        if arch_suffix in {\"i686\", \"x86_64\"}:\n            arches.append(\"manylinux2010\" + arch_sep + arch_suffix)\n            arches.append(\"manylinux1\" + arch_sep + arch_suffix)\n    elif arch_prefix == \"manylinux2010\":\n        # manylinux1 wheels run on most manylinux2010 systems with the\n        # exception of wheels depending on ncurses. PEP 571 states\n        # manylinux1 wheels should be considered manylinux2010 wheels:\n        # https://www.python.org/dev/peps/pep-0571/#backwards-compatibility-with-manylinux1-wheels\n        arches.append(\"manylinux1\" + arch_sep + arch_suffix)\n    return arches\n\n\ndef _get_custom_platforms(arch: str) -> List[str]:\n    arch_prefix, arch_sep, arch_suffix = arch.partition(\"_\")\n    if arch.startswith(\"macosx\"):\n        arches = _mac_platforms(arch)\n    elif arch.startswith(\"ios\"):\n        arches = _ios_platforms(arch)\n    elif arch_prefix == \"android\":\n        arches = _android_platforms(arch)\n    elif arch_prefix in [\"manylinux2014\", \"manylinux2010\"]:\n        arches = _custom_manylinux_platforms(arch)\n    else:\n        arches = [arch]\n    return arches\n\n\ndef _expand_allowed_platforms(platforms: Optional[List[str]]) -> Optional[List[str]]:\n    if not platforms:\n        return None\n\n    seen = set()\n    result = []\n\n    for p in platforms:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\datetime.py": {
      "sha": "385c8adafd27",
      "lines": 10,
      "head": "\"\"\"For when pip wants to check the date or time.\"\"\"\n\nimport datetime\n\n\ndef today_is_later_than(year: int, month: int, day: int) -> bool:\n    today = datetime.date.today()\n    given = datetime.date(year, month, day)\n\n    return today > given\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\deprecation.py": {
      "sha": "9d3e78a239d0",
      "lines": 124,
      "head": "\"\"\"\nA module that implements tooling to enable easy warnings about deprecations.\n\"\"\"\n\nimport logging\nimport warnings\nfrom typing import Any, Optional, TextIO, Type, Union\n\nfrom pip._vendor.packaging.version import parse\n\nfrom pip import __version__ as current_version  # NOTE: tests patch this name.\n\nDEPRECATION_MSG_PREFIX = \"DEPRECATION: \"\n\n\nclass PipDeprecationWarning(Warning):\n    pass\n\n\n_original_showwarning: Any = None\n\n\n# Warnings <-> Logging Integration\ndef _showwarning(\n    message: Union[Warning, str],\n    category: Type[Warning],\n    filename: str,\n    lineno: int,\n    file: Optional[TextIO] = None,\n    line: Optional[str] = None,\n) -> None:\n    if file is not None:\n        if _original_showwarning is not None:\n            _original_showwarning(message, category, filename, lineno, file, line)\n    elif issubclass(category, PipDeprecationWarning):\n        # We use a specially named logger which will handle all of the\n        # deprecation messages for pip.\n        logger = logging.getLogger(\"pip._internal.deprecations\")\n        logger.warning(message)\n    else:\n        _original_showwarning(message, category, filename, lineno, file, line)\n\n\ndef install_warning_logger() -> None:\n    # Enable our Deprecation Warnings\n    warnings.simplefilter(\"default\", PipDeprecationWarning, append=True)\n\n    global _original_showwarning\n\n    if _original_showwarning is None:\n        _original_showwarning = warnings.showwarning\n        warnings.showwarning = _showwarning\n\n\ndef deprecated(\n    *,\n    reason: str,\n    replacement: Optional[str],\n    gone_in: Optional[str],\n    feature_flag: Optional[str] = None,\n    issue: Optional[int] = None,\n) -> None:\n    \"\"\"Helper to deprecate existing functionality.\n\n    reason:\n        Textual reason shown to the user about why this functionality has\n        been deprecated. Should be a complete sentence.\n    replacement:\n        Textual suggestion shown to the user about what alternative\n        functionality they can use.\n    gone_in:\n        The version of pip does this functionality should get removed in.\n        Raises an error if pip's current version is greater than or equal to\n        this.\n    feature_flag:\n        Command-line flag of the form --use-feature={feature_flag} for testing\n        upcoming functionality.\n    issue:\n        Issue number on the tracker that would serve as a useful place for\n        users to find related discussion and provide feedback.\n    \"\"\"\n\n    # Determine whether or not the feature is already gone in this version.\n    is_gone = gone_in is not None and parse(current_version) >= parse(gone_in)\n\n    message_parts = [\n        (reason, f\"{DEPRECATION_MSG_PREFIX}{{}}\"),\n        (\n            gone_in,\n            (\n                \"pip {} will enforce this behaviour change.\"\n                if not is_gone\n                else \"Since pip {}, this is no longer supported.\"\n            ),\n        ),\n        (\n            replacement,\n            \"A possible replacement is {}.\",\n        ),\n        (\n            feature_flag,\n            (\n                \"You can use the flag --use-feature={} to test the upcoming behaviour.\"\n                if not is_gone\n                else None\n            ),\n        ),\n        (\n            issue,\n            \"Discussion can be found at https://github.com/pypa/pip/issues/{}\",\n        ),\n    ]\n\n    message = \" \".join(\n        format_str.format(value)\n        for value, format_str in message_parts\n        if format_str is not None and value is not None\n    )\n\n    # Raise as an error if this behaviour is deprecated.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\direct_url_helpers.py": {
      "sha": "588197601a7e",
      "lines": 87,
      "head": "from typing import Optional\n\nfrom pip._internal.models.direct_url import ArchiveInfo, DirectUrl, DirInfo, VcsInfo\nfrom pip._internal.models.link import Link\nfrom pip._internal.utils.urls import path_to_url\nfrom pip._internal.vcs import vcs\n\n\ndef direct_url_as_pep440_direct_reference(direct_url: DirectUrl, name: str) -> str:\n    \"\"\"Convert a DirectUrl to a pip requirement string.\"\"\"\n    direct_url.validate()  # if invalid, this is a pip bug\n    requirement = name + \" @ \"\n    fragments = []\n    if isinstance(direct_url.info, VcsInfo):\n        requirement += (\n            f\"{direct_url.info.vcs}+{direct_url.url}@{direct_url.info.commit_id}\"\n        )\n    elif isinstance(direct_url.info, ArchiveInfo):\n        requirement += direct_url.url\n        if direct_url.info.hash:\n            fragments.append(direct_url.info.hash)\n    else:\n        assert isinstance(direct_url.info, DirInfo)\n        requirement += direct_url.url\n    if direct_url.subdirectory:\n        fragments.append(\"subdirectory=\" + direct_url.subdirectory)\n    if fragments:\n        requirement += \"#\" + \"&\".join(fragments)\n    return requirement\n\n\ndef direct_url_for_editable(source_dir: str) -> DirectUrl:\n    return DirectUrl(\n        url=path_to_url(source_dir),\n        info=DirInfo(editable=True),\n    )\n\n\ndef direct_url_from_link(\n    link: Link, source_dir: Optional[str] = None, link_is_in_wheel_cache: bool = False\n) -> DirectUrl:\n    if link.is_vcs:\n        vcs_backend = vcs.get_backend_for_scheme(link.scheme)\n        assert vcs_backend\n        url, requested_revision, _ = vcs_backend.get_url_rev_and_auth(\n            link.url_without_fragment\n        )\n        # For VCS links, we need to find out and add commit_id.\n        if link_is_in_wheel_cache:\n            # If the requested VCS link corresponds to a cached\n            # wheel, it means the requested revision was an\n            # immutable commit hash, otherwise it would not have\n            # been cached. In that case we don't have a source_dir\n            # with the VCS checkout.\n            assert requested_revision\n            commit_id = requested_revision\n        else:\n            # If the wheel was not in cache, it means we have\n            # had to checkout from VCS to build and we have a source_dir\n            # which we can inspect to find out the commit id.\n            assert source_dir\n            commit_id = vcs_backend.get_revision(source_dir)\n        return DirectUrl(\n            url=url,\n            info=VcsInfo(\n                vcs=vcs_backend.name,\n                commit_id=commit_id,\n                requested_revision=requested_revision,\n            ),\n            subdirectory=link.subdirectory_fragment,\n        )\n    elif link.is_existing_dir():\n        return DirectUrl(\n            url=link.url_without_fragment,\n            info=DirInfo(),\n            subdirectory=link.subdirectory_fragment,\n        )\n    else:\n        hash = None\n        hash_name = link.hash_name\n        if hash_name:\n            hash = f\"{hash_name}={link.hash}\"\n        return DirectUrl(\n            url=link.url_without_fragment,\n            info=ArchiveInfo(hash=hash),\n            subdirectory=link.subdirectory_fragment,\n        )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\egg_link.py": {
      "sha": "7f16cac0927c",
      "lines": 80,
      "head": "import os\nimport re\nimport sys\nfrom typing import List, Optional\n\nfrom pip._internal.locations import site_packages, user_site\nfrom pip._internal.utils.virtualenv import (\n    running_under_virtualenv,\n    virtualenv_no_global,\n)\n\n__all__ = [\n    \"egg_link_path_from_sys_path\",\n    \"egg_link_path_from_location\",\n]\n\n\ndef _egg_link_names(raw_name: str) -> List[str]:\n    \"\"\"\n    Convert a Name metadata value to a .egg-link name, by applying\n    the same substitution as pkg_resources's safe_name function.\n    Note: we cannot use canonicalize_name because it has a different logic.\n\n    We also look for the raw name (without normalization) as setuptools 69 changed\n    the way it names .egg-link files (https://github.com/pypa/setuptools/issues/4167).\n    \"\"\"\n    return [\n        re.sub(\"[^A-Za-z0-9.]+\", \"-\", raw_name) + \".egg-link\",\n        f\"{raw_name}.egg-link\",\n    ]\n\n\ndef egg_link_path_from_sys_path(raw_name: str) -> Optional[str]:\n    \"\"\"\n    Look for a .egg-link file for project name, by walking sys.path.\n    \"\"\"\n    egg_link_names = _egg_link_names(raw_name)\n    for path_item in sys.path:\n        for egg_link_name in egg_link_names:\n            egg_link = os.path.join(path_item, egg_link_name)\n            if os.path.isfile(egg_link):\n                return egg_link\n    return None\n\n\ndef egg_link_path_from_location(raw_name: str) -> Optional[str]:\n    \"\"\"\n    Return the path for the .egg-link file if it exists, otherwise, None.\n\n    There's 3 scenarios:\n    1) not in a virtualenv\n       try to find in site.USER_SITE, then site_packages\n    2) in a no-global virtualenv\n       try to find in site_packages\n    3) in a yes-global virtualenv\n       try to find in site_packages, then site.USER_SITE\n       (don't look in global location)\n\n    For #1 and #3, there could be odd cases, where there's an egg-link in 2\n    locations.\n\n    This method will just return the first one found.\n    \"\"\"\n    sites: List[str] = []\n    if running_under_virtualenv():\n        sites.append(site_packages)\n        if not virtualenv_no_global() and user_site:\n            sites.append(user_site)\n    else:\n        if user_site:\n            sites.append(user_site)\n        sites.append(site_packages)\n\n    egg_link_names = _egg_link_names(raw_name)\n    for site in sites:\n        for egg_link_name in egg_link_names:\n            egglink = os.path.join(site, egg_link_name)\n            if os.path.isfile(egglink):\n                return egglink\n    return None\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\entrypoints.py": {
      "sha": "db950d971586",
      "lines": 87,
      "head": "import itertools\nimport os\nimport shutil\nimport sys\nfrom typing import List, Optional\n\nfrom pip._internal.cli.main import main\nfrom pip._internal.utils.compat import WINDOWS\n\n_EXECUTABLE_NAMES = [\n    \"pip\",\n    f\"pip{sys.version_info.major}\",\n    f\"pip{sys.version_info.major}.{sys.version_info.minor}\",\n]\nif WINDOWS:\n    _allowed_extensions = {\"\", \".exe\"}\n    _EXECUTABLE_NAMES = [\n        \"\".join(parts)\n        for parts in itertools.product(_EXECUTABLE_NAMES, _allowed_extensions)\n    ]\n\n\ndef _wrapper(args: Optional[List[str]] = None) -> int:\n    \"\"\"Central wrapper for all old entrypoints.\n\n    Historically pip has had several entrypoints defined. Because of issues\n    arising from PATH, sys.path, multiple Pythons, their interactions, and most\n    of them having a pip installed, users suffer every time an entrypoint gets\n    moved.\n\n    To alleviate this pain, and provide a mechanism for warning users and\n    directing them to an appropriate place for help, we now define all of\n    our old entrypoints as wrappers for the current one.\n    \"\"\"\n    sys.stderr.write(\n        \"WARNING: pip is being invoked by an old script wrapper. This will \"\n        \"fail in a future version of pip.\\n\"\n        \"Please see https://github.com/pypa/pip/issues/5599 for advice on \"\n        \"fixing the underlying issue.\\n\"\n        \"To avoid this problem you can invoke Python with '-m pip' instead of \"\n        \"running pip directly.\\n\"\n    )\n    return main(args)\n\n\ndef get_best_invocation_for_this_pip() -> str:\n    \"\"\"Try to figure out the best way to invoke pip in the current environment.\"\"\"\n    binary_directory = \"Scripts\" if WINDOWS else \"bin\"\n    binary_prefix = os.path.join(sys.prefix, binary_directory)\n\n    # Try to use pip[X[.Y]] names, if those executables for this environment are\n    # the first on PATH with that name.\n    path_parts = os.path.normcase(os.environ.get(\"PATH\", \"\")).split(os.pathsep)\n    exe_are_in_PATH = os.path.normcase(binary_prefix) in path_parts\n    if exe_are_in_PATH:\n        for exe_name in _EXECUTABLE_NAMES:\n            found_executable = shutil.which(exe_name)\n            binary_executable = os.path.join(binary_prefix, exe_name)\n            if (\n                found_executable\n                and os.path.exists(binary_executable)\n                and os.path.samefile(\n                    found_executable,\n                    binary_executable,\n                )\n            ):\n                return exe_name\n\n    # Use the `-m` invocation, if there's no \"nice\" invocation.\n    return f\"{get_best_invocation_for_this_python()} -m pip\"\n\n\ndef get_best_invocation_for_this_python() -> str:\n    \"\"\"Try to figure out the best way to invoke the current Python.\"\"\"\n    exe = sys.executable\n    exe_name = os.path.basename(exe)\n\n    # Try to use the basename, if it's the first executable.\n    found_executable = shutil.which(exe_name)\n    # Virtual environments often symlink to their parent Python binaries, but we don't\n    # want to treat the Python binaries as equivalent when the environment's Python is\n    # not on PATH (not activated). Thus, we don't follow symlinks.\n    if found_executable and os.path.samestat(os.lstat(found_executable), os.lstat(exe)):\n        return exe_name\n\n    # Use the full executable name, because we couldn't find something simpler.\n    return exe\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\filesystem.py": {
      "sha": "2aca3a5915e7",
      "lines": 149,
      "head": "import fnmatch\nimport os\nimport os.path\nimport random\nimport sys\nfrom contextlib import contextmanager\nfrom tempfile import NamedTemporaryFile\nfrom typing import Any, BinaryIO, Generator, List, Union, cast\n\nfrom pip._internal.utils.compat import get_path_uid\nfrom pip._internal.utils.misc import format_size\nfrom pip._internal.utils.retry import retry\n\n\ndef check_path_owner(path: str) -> bool:\n    # If we don't have a way to check the effective uid of this process, then\n    # we'll just assume that we own the directory.\n    if sys.platform == \"win32\" or not hasattr(os, \"geteuid\"):\n        return True\n\n    assert os.path.isabs(path)\n\n    previous = None\n    while path != previous:\n        if os.path.lexists(path):\n            # Check if path is writable by current user.\n            if os.geteuid() == 0:\n                # Special handling for root user in order to handle properly\n                # cases where users use sudo without -H flag.\n                try:\n                    path_uid = get_path_uid(path)\n                except OSError:\n                    return False\n                return path_uid == 0\n            else:\n                return os.access(path, os.W_OK)\n        else:\n            previous, path = path, os.path.dirname(path)\n    return False  # assume we don't own the path\n\n\n@contextmanager\ndef adjacent_tmp_file(path: str, **kwargs: Any) -> Generator[BinaryIO, None, None]:\n    \"\"\"Return a file-like object pointing to a tmp file next to path.\n\n    The file is created securely and is ensured to be written to disk\n    after the context reaches its end.\n\n    kwargs will be passed to tempfile.NamedTemporaryFile to control\n    the way the temporary file will be opened.\n    \"\"\"\n    with NamedTemporaryFile(\n        delete=False,\n        dir=os.path.dirname(path),\n        prefix=os.path.basename(path),\n        suffix=\".tmp\",\n        **kwargs,\n    ) as f:\n        result = cast(BinaryIO, f)\n        try:\n            yield result\n        finally:\n            result.flush()\n            os.fsync(result.fileno())\n\n\nreplace = retry(stop_after_delay=1, wait=0.25)(os.replace)\n\n\n# test_writable_dir and _test_writable_dir_win are copied from Flit,\n# with the author's agreement to also place them under pip's license.\ndef test_writable_dir(path: str) -> bool:\n    \"\"\"Check if a directory is writable.\n\n    Uses os.access() on POSIX, tries creating files on Windows.\n    \"\"\"\n    # If the directory doesn't exist, find the closest parent that does.\n    while not os.path.isdir(path):\n        parent = os.path.dirname(path)\n        if parent == path:\n            break  # Should never get here, but infinite loops are bad\n        path = parent\n\n    if os.name == \"posix\":\n        return os.access(path, os.W_OK)\n\n    return _test_writable_dir_win(path)\n\n\ndef _test_writable_dir_win(path: str) -> bool:\n    # os.access doesn't work on Windows: http://bugs.python.org/issue2528\n    # and we can't use tempfile: http://bugs.python.org/issue22107\n    basename = \"accesstest_deleteme_fishfingers_custard_\"\n    alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n    for _ in range(10):\n        name = basename + \"\".join(random.choice(alphabet) for _ in range(6))\n        file = os.path.join(path, name)\n        try:\n            fd = os.open(file, os.O_RDWR | os.O_CREAT | os.O_EXCL)\n        except FileExistsError:\n            pass\n        except PermissionError:\n            # This could be because there's a directory with the same name.\n            # But it's highly unlikely there's a directory called that,\n            # so we'll assume it's because the parent dir is not writable.\n            # This could as well be because the parent dir is not readable,\n            # due to non-privileged user access.\n            return False\n        else:\n            os.close(fd)\n            os.unlink(file)\n            return True\n\n    # This should never be reached\n    raise OSError(\"Unexpected condition testing for writable directory\")\n\n\ndef find_files(path: str, pattern: str) -> List[str]:\n    \"\"\"Returns a list of absolute paths of files beneath path, recursively,\n    with filenames which match the UNIX-style shell glob pattern.\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\filetypes.py": {
      "sha": "fcccac070482",
      "lines": 26,
      "head": "\"\"\"Filetype information.\"\"\"\n\nfrom typing import Tuple\n\nfrom pip._internal.utils.misc import splitext\n\nWHEEL_EXTENSION = \".whl\"\nBZ2_EXTENSIONS: Tuple[str, ...] = (\".tar.bz2\", \".tbz\")\nXZ_EXTENSIONS: Tuple[str, ...] = (\n    \".tar.xz\",\n    \".txz\",\n    \".tlz\",\n    \".tar.lz\",\n    \".tar.lzma\",\n)\nZIP_EXTENSIONS: Tuple[str, ...] = (\".zip\", WHEEL_EXTENSION)\nTAR_EXTENSIONS: Tuple[str, ...] = (\".tar.gz\", \".tgz\", \".tar\")\nARCHIVE_EXTENSIONS = ZIP_EXTENSIONS + BZ2_EXTENSIONS + TAR_EXTENSIONS + XZ_EXTENSIONS\n\n\ndef is_archive_file(name: str) -> bool:\n    \"\"\"Return True if `name` is a considered as an archive file.\"\"\"\n    ext = splitext(name)[1].lower()\n    if ext in ARCHIVE_EXTENSIONS:\n        return True\n    return False\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\glibc.py": {
      "sha": "416a32119e75",
      "lines": 101,
      "head": "import os\nimport sys\nfrom typing import Optional, Tuple\n\n\ndef glibc_version_string() -> Optional[str]:\n    \"Returns glibc version string, or None if not using glibc.\"\n    return glibc_version_string_confstr() or glibc_version_string_ctypes()\n\n\ndef glibc_version_string_confstr() -> Optional[str]:\n    \"Primary implementation of glibc_version_string using os.confstr.\"\n    # os.confstr is quite a bit faster than ctypes.DLL. It's also less likely\n    # to be broken or missing. This strategy is used in the standard library\n    # platform module:\n    # https://github.com/python/cpython/blob/fcf1d003bf4f0100c9d0921ff3d70e1127ca1b71/Lib/platform.py#L175-L183\n    if sys.platform == \"win32\":\n        return None\n    try:\n        gnu_libc_version = os.confstr(\"CS_GNU_LIBC_VERSION\")\n        if gnu_libc_version is None:\n            return None\n        # os.confstr(\"CS_GNU_LIBC_VERSION\") returns a string like \"glibc 2.17\":\n        _, version = gnu_libc_version.split()\n    except (AttributeError, OSError, ValueError):\n        # os.confstr() or CS_GNU_LIBC_VERSION not available (or a bad value)...\n        return None\n    return version\n\n\ndef glibc_version_string_ctypes() -> Optional[str]:\n    \"Fallback implementation of glibc_version_string using ctypes.\"\n\n    try:\n        import ctypes\n    except ImportError:\n        return None\n\n    # ctypes.CDLL(None) internally calls dlopen(NULL), and as the dlopen\n    # manpage says, \"If filename is NULL, then the returned handle is for the\n    # main program\". This way we can let the linker do the work to figure out\n    # which libc our process is actually using.\n    #\n    # We must also handle the special case where the executable is not a\n    # dynamically linked executable. This can occur when using musl libc,\n    # for example. In this situation, dlopen() will error, leading to an\n    # OSError. Interestingly, at least in the case of musl, there is no\n    # errno set on the OSError. The single string argument used to construct\n    # OSError comes from libc itself and is therefore not portable to\n    # hard code here. In any case, failure to call dlopen() means we\n    # can't proceed, so we bail on our attempt.\n    try:\n        process_namespace = ctypes.CDLL(None)\n    except OSError:\n        return None\n\n    try:\n        gnu_get_libc_version = process_namespace.gnu_get_libc_version\n    except AttributeError:\n        # Symbol doesn't exist -> therefore, we are not linked to\n        # glibc.\n        return None\n\n    # Call gnu_get_libc_version, which returns a string like \"2.5\"\n    gnu_get_libc_version.restype = ctypes.c_char_p\n    version_str: str = gnu_get_libc_version()\n    # py2 / py3 compatibility:\n    if not isinstance(version_str, str):\n        version_str = version_str.decode(\"ascii\")\n\n    return version_str\n\n\n# platform.libc_ver regularly returns completely nonsensical glibc\n# versions. E.g. on my computer, platform says:\n#\n#   ~$ python2.7 -c 'import platform; print(platform.libc_ver())'\n#   ('glibc', '2.7')\n#   ~$ python3.5 -c 'import platform; print(platform.libc_ver())'\n#   ('glibc', '2.9')\n#\n# But the truth is:\n#\n#   ~$ ldd --version\n#   ldd (Debian GLIBC 2.22-11) 2.22\n#\n# This is unfortunate, because it means that the linehaul data on libc\n# versions that was generated by pip 8.1.2 and earlier is useless and\n# misleading. Solution: instead of using platform, use our code that actually\n# works.\ndef libc_ver() -> Tuple[str, str]:\n    \"\"\"Try to determine the glibc version\n\n    Returns a tuple of strings (lib, version) which default to empty strings\n    in case the lookup fails.\n    \"\"\"\n    glibc_version = glibc_version_string()\n    if glibc_version is None:\n        return (\"\", \"\")\n    else:\n        return (\"glibc\", glibc_version)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\hashes.py": {
      "sha": "c228365c8158",
      "lines": 147,
      "head": "import hashlib\nfrom typing import TYPE_CHECKING, BinaryIO, Dict, Iterable, List, NoReturn, Optional\n\nfrom pip._internal.exceptions import HashMismatch, HashMissing, InstallationError\nfrom pip._internal.utils.misc import read_chunks\n\nif TYPE_CHECKING:\n    from hashlib import _Hash\n\n\n# The recommended hash algo of the moment. Change this whenever the state of\n# the art changes; it won't hurt backward compatibility.\nFAVORITE_HASH = \"sha256\"\n\n\n# Names of hashlib algorithms allowed by the --hash option and ``pip hash``\n# Currently, those are the ones at least as collision-resistant as sha256.\nSTRONG_HASHES = [\"sha256\", \"sha384\", \"sha512\"]\n\n\nclass Hashes:\n    \"\"\"A wrapper that builds multiple hashes at once and checks them against\n    known-good values\n\n    \"\"\"\n\n    def __init__(self, hashes: Optional[Dict[str, List[str]]] = None) -> None:\n        \"\"\"\n        :param hashes: A dict of algorithm names pointing to lists of allowed\n            hex digests\n        \"\"\"\n        allowed = {}\n        if hashes is not None:\n            for alg, keys in hashes.items():\n                # Make sure values are always sorted (to ease equality checks)\n                allowed[alg] = [k.lower() for k in sorted(keys)]\n        self._allowed = allowed\n\n    def __and__(self, other: \"Hashes\") -> \"Hashes\":\n        if not isinstance(other, Hashes):\n            return NotImplemented\n\n        # If either of the Hashes object is entirely empty (i.e. no hash\n        # specified at all), all hashes from the other object are allowed.\n        if not other:\n            return self\n        if not self:\n            return other\n\n        # Otherwise only hashes that present in both objects are allowed.\n        new = {}\n        for alg, values in other._allowed.items():\n            if alg not in self._allowed:\n                continue\n            new[alg] = [v for v in values if v in self._allowed[alg]]\n        return Hashes(new)\n\n    @property\n    def digest_count(self) -> int:\n        return sum(len(digests) for digests in self._allowed.values())\n\n    def is_hash_allowed(self, hash_name: str, hex_digest: str) -> bool:\n        \"\"\"Return whether the given hex digest is allowed.\"\"\"\n        return hex_digest in self._allowed.get(hash_name, [])\n\n    def check_against_chunks(self, chunks: Iterable[bytes]) -> None:\n        \"\"\"Check good hashes against ones built from iterable of chunks of\n        data.\n\n        Raise HashMismatch if none match.\n\n        \"\"\"\n        gots = {}\n        for hash_name in self._allowed.keys():\n            try:\n                gots[hash_name] = hashlib.new(hash_name)\n            except (ValueError, TypeError):\n                raise InstallationError(f\"Unknown hash name: {hash_name}\")\n\n        for chunk in chunks:\n            for hash in gots.values():\n                hash.update(chunk)\n\n        for hash_name, got in gots.items():\n            if got.hexdigest() in self._allowed[hash_name]:\n                return\n        self._raise(gots)\n\n    def _raise(self, gots: Dict[str, \"_Hash\"]) -> \"NoReturn\":\n        raise HashMismatch(self._allowed, gots)\n\n    def check_against_file(self, file: BinaryIO) -> None:\n        \"\"\"Check good hashes against a file-like object\n\n        Raise HashMismatch if none match.\n\n        \"\"\"\n        return self.check_against_chunks(read_chunks(file))\n\n    def check_against_path(self, path: str) -> None:\n        with open(path, \"rb\") as file:\n            return self.check_against_file(file)\n\n    def has_one_of(self, hashes: Dict[str, str]) -> bool:\n        \"\"\"Return whether any of the given hashes are allowed.\"\"\"\n        for hash_name, hex_digest in hashes.items():\n            if self.is_hash_allowed(hash_name, hex_digest):\n                return True\n        return False\n\n    def __bool__(self) -> bool:\n        \"\"\"Return whether I know any known-good hashes.\"\"\"\n        return bool(self._allowed)\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, Hashes):\n            return NotImplemented\n        return self._allowed == other._allowed\n\n    def __hash__(self) -> int:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\logging.py": {
      "sha": "fdc1fe48a928",
      "lines": 361,
      "head": "import contextlib\nimport errno\nimport logging\nimport logging.handlers\nimport os\nimport sys\nimport threading\nfrom dataclasses import dataclass\nfrom io import TextIOWrapper\nfrom logging import Filter\nfrom typing import Any, ClassVar, Generator, List, Optional, Type\n\nfrom pip._vendor.rich.console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    RenderableType,\n    RenderResult,\n    RichCast,\n)\nfrom pip._vendor.rich.highlighter import NullHighlighter\nfrom pip._vendor.rich.logging import RichHandler\nfrom pip._vendor.rich.segment import Segment\nfrom pip._vendor.rich.style import Style\n\nfrom pip._internal.utils._log import VERBOSE, getLogger\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.deprecation import DEPRECATION_MSG_PREFIX\nfrom pip._internal.utils.misc import ensure_dir\n\n_log_state = threading.local()\n_stdout_console = None\n_stderr_console = None\nsubprocess_logger = getLogger(\"pip.subprocessor\")\n\n\nclass BrokenStdoutLoggingError(Exception):\n    \"\"\"\n    Raised if BrokenPipeError occurs for the stdout stream while logging.\n    \"\"\"\n\n\ndef _is_broken_pipe_error(exc_class: Type[BaseException], exc: BaseException) -> bool:\n    if exc_class is BrokenPipeError:\n        return True\n\n    # On Windows, a broken pipe can show up as EINVAL rather than EPIPE:\n    # https://bugs.python.org/issue19612\n    # https://bugs.python.org/issue30418\n    if not WINDOWS:\n        return False\n\n    return isinstance(exc, OSError) and exc.errno in (errno.EINVAL, errno.EPIPE)\n\n\n@contextlib.contextmanager\ndef indent_log(num: int = 2) -> Generator[None, None, None]:\n    \"\"\"\n    A context manager which will cause the log output to be indented for any\n    log messages emitted inside it.\n    \"\"\"\n    # For thread-safety\n    _log_state.indentation = get_indentation()\n    _log_state.indentation += num\n    try:\n        yield\n    finally:\n        _log_state.indentation -= num\n\n\ndef get_indentation() -> int:\n    return getattr(_log_state, \"indentation\", 0)\n\n\nclass IndentingFormatter(logging.Formatter):\n    default_time_format = \"%Y-%m-%dT%H:%M:%S\"\n\n    def __init__(\n        self,\n        *args: Any,\n        add_timestamp: bool = False,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"\n        A logging.Formatter that obeys the indent_log() context manager.\n\n        :param add_timestamp: A bool indicating output lines should be prefixed\n            with their record's timestamp.\n        \"\"\"\n        self.add_timestamp = add_timestamp\n        super().__init__(*args, **kwargs)\n\n    def get_message_start(self, formatted: str, levelno: int) -> str:\n        \"\"\"\n        Return the start of the formatted log message (not counting the\n        prefix to add to each line).\n        \"\"\"\n        if levelno < logging.WARNING:\n            return \"\"\n        if formatted.startswith(DEPRECATION_MSG_PREFIX):\n            # Then the message already has a prefix.  We don't want it to\n            # look like \"WARNING: DEPRECATION: ....\"\n            return \"\"\n        if levelno < logging.ERROR:\n            return \"WARNING: \"\n\n        return \"ERROR: \"\n\n    def format(self, record: logging.LogRecord) -> str:\n        \"\"\"\n        Calls the standard formatter, but will indent all of the log message\n        lines by our current indentation level.\n        \"\"\"\n        formatted = super().format(record)\n        message_start = self.get_message_start(formatted, record.levelno)\n        formatted = message_start + formatted\n\n        prefix = \"\"\n        if self.add_timestamp:\n            prefix = f\"{self.formatTime(record)} \"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\misc.py": {
      "sha": "8bc49854d3b0",
      "lines": 773,
      "head": "import errno\nimport getpass\nimport hashlib\nimport logging\nimport os\nimport posixpath\nimport shutil\nimport stat\nimport sys\nimport sysconfig\nimport urllib.parse\nfrom dataclasses import dataclass\nfrom functools import partial\nfrom io import StringIO\nfrom itertools import filterfalse, tee, zip_longest\nfrom pathlib import Path\nfrom types import FunctionType, TracebackType\nfrom typing import (\n    Any,\n    BinaryIO,\n    Callable,\n    Generator,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    TextIO,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    cast,\n)\n\nfrom pip._vendor.packaging.requirements import Requirement\nfrom pip._vendor.pyproject_hooks import BuildBackendHookCaller\n\nfrom pip import __version__\nfrom pip._internal.exceptions import CommandError, ExternallyManagedEnvironment\nfrom pip._internal.locations import get_major_minor_version\nfrom pip._internal.utils.compat import WINDOWS\nfrom pip._internal.utils.retry import retry\nfrom pip._internal.utils.virtualenv import running_under_virtualenv\n\n__all__ = [\n    \"rmtree\",\n    \"display_path\",\n    \"backup_dir\",\n    \"ask\",\n    \"splitext\",\n    \"format_size\",\n    \"is_installable_dir\",\n    \"normalize_path\",\n    \"renames\",\n    \"get_prog\",\n    \"ensure_dir\",\n    \"remove_auth_from_url\",\n    \"check_externally_managed\",\n    \"ConfiguredBuildBackendHookCaller\",\n]\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\nExcInfo = Tuple[Type[BaseException], BaseException, TracebackType]\nVersionInfo = Tuple[int, int, int]\nNetlocTuple = Tuple[str, Tuple[Optional[str], Optional[str]]]\nOnExc = Callable[[FunctionType, Path, BaseException], Any]\nOnErr = Callable[[FunctionType, Path, ExcInfo], Any]\n\nFILE_CHUNK_SIZE = 1024 * 1024\n\n\ndef get_pip_version() -> str:\n    pip_pkg_dir = os.path.join(os.path.dirname(__file__), \"..\", \"..\")\n    pip_pkg_dir = os.path.abspath(pip_pkg_dir)\n\n    return f\"pip {__version__} from {pip_pkg_dir} (python {get_major_minor_version()})\"\n\n\ndef normalize_version_info(py_version_info: Tuple[int, ...]) -> Tuple[int, int, int]:\n    \"\"\"\n    Convert a tuple of ints representing a Python version to one of length\n    three.\n\n    :param py_version_info: a tuple of ints representing a Python version,\n        or None to specify no version. The tuple can have any length.\n\n    :return: a tuple of length three if `py_version_info` is non-None.\n        Otherwise, return `py_version_info` unchanged (i.e. None).\n    \"\"\"\n    if len(py_version_info) < 3:\n        py_version_info += (3 - len(py_version_info)) * (0,)\n    elif len(py_version_info) > 3:\n        py_version_info = py_version_info[:3]\n\n    return cast(\"VersionInfo\", py_version_info)\n\n\ndef ensure_dir(path: str) -> None:\n    \"\"\"os.path.makedirs without EEXIST.\"\"\"\n    try:\n        os.makedirs(path)\n    except OSError as e:\n        # Windows can raise spurious ENOTEMPTY errors. See #6426.\n        if e.errno != errno.EEXIST and e.errno != errno.ENOTEMPTY:\n            raise\n\n\ndef get_prog() -> str:\n    try:\n        prog = os.path.basename(sys.argv[0])\n        if prog in (\"__main__.py\", \"-c\"):\n            return f\"{sys.executable} -m pip\"\n        else:\n            return prog\n    except (AttributeError, TypeError, IndexError):\n        pass\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\packaging.py": {
      "sha": "b487f8c36d18",
      "lines": 43,
      "head": "import functools\nimport logging\nfrom typing import Optional, Tuple\n\nfrom pip._vendor.packaging import specifiers, version\nfrom pip._vendor.packaging.requirements import Requirement\n\nlogger = logging.getLogger(__name__)\n\n\n@functools.lru_cache(maxsize=32)\ndef check_requires_python(\n    requires_python: Optional[str], version_info: Tuple[int, ...]\n) -> bool:\n    \"\"\"\n    Check if the given Python version matches a \"Requires-Python\" specifier.\n\n    :param version_info: A 3-tuple of ints representing a Python\n        major-minor-micro version to check (e.g. `sys.version_info[:3]`).\n\n    :return: `True` if the given Python version satisfies the requirement.\n        Otherwise, return `False`.\n\n    :raises InvalidSpecifier: If `requires_python` has an invalid format.\n    \"\"\"\n    if requires_python is None:\n        # The package provides no information\n        return True\n    requires_python_specifier = specifiers.SpecifierSet(requires_python)\n\n    python_version = version.parse(\".\".join(map(str, version_info)))\n    return python_version in requires_python_specifier\n\n\n@functools.lru_cache(maxsize=10000)\ndef get_requirement(req_string: str) -> Requirement:\n    \"\"\"Construct a packaging.Requirement object with caching\"\"\"\n    # Parsing requirement strings is expensive, and is also expected to happen\n    # with a low diversity of different arguments (at least relative the number\n    # constructed). This method adds a cache to requirement object creation to\n    # minimize repeated parsing of the same string to construct equivalent\n    # Requirement objects.\n    return Requirement(req_string)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\retry.py": {
      "sha": "f269c76b99b1",
      "lines": 42,
      "head": "import functools\nfrom time import perf_counter, sleep\nfrom typing import Callable, TypeVar\n\nfrom pip._vendor.typing_extensions import ParamSpec\n\nT = TypeVar(\"T\")\nP = ParamSpec(\"P\")\n\n\ndef retry(\n    wait: float, stop_after_delay: float\n) -> Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Decorator to automatically retry a function on error.\n\n    If the function raises, the function is recalled with the same arguments\n    until it returns or the time limit is reached. When the time limit is\n    surpassed, the last exception raised is reraised.\n\n    :param wait: The time to wait after an error before retrying, in seconds.\n    :param stop_after_delay: The time limit after which retries will cease,\n        in seconds.\n    \"\"\"\n\n    def wrapper(func: Callable[P, T]) -> Callable[P, T]:\n\n        @functools.wraps(func)\n        def retry_wrapped(*args: P.args, **kwargs: P.kwargs) -> T:\n            # The performance counter is monotonic on all platforms we care\n            # about and has much better resolution than time.monotonic().\n            start_time = perf_counter()\n            while True:\n                try:\n                    return func(*args, **kwargs)\n                except Exception:\n                    if perf_counter() - start_time > stop_after_delay:\n                        raise\n                    sleep(wait)\n\n        return retry_wrapped\n\n    return wrapper\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\setuptools_build.py": {
      "sha": "fc397d029628",
      "lines": 147,
      "head": "import sys\nimport textwrap\nfrom typing import List, Optional, Sequence\n\n# Shim to wrap setup.py invocation with setuptools\n# Note that __file__ is handled via two {!r} *and* %r, to ensure that paths on\n# Windows are correctly handled (it should be \"C:\\\\Users\" not \"C:\\Users\").\n_SETUPTOOLS_SHIM = textwrap.dedent(\n    \"\"\"\n    exec(compile('''\n    # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\n    #\n    # - It imports setuptools before invoking setup.py, to enable projects that directly\n    #   import from `distutils.core` to work with newer packaging standards.\n    # - It provides a clear error message when setuptools is not installed.\n    # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\n    #   setuptools doesn't think the script is `-c`. This avoids the following warning:\n    #     manifest_maker: standard file '-c' not found\".\n    # - It generates a shim setup.py, for handling setup.cfg-only projects.\n    import os, sys, tokenize, traceback\n\n    try:\n        import setuptools\n    except ImportError:\n        print(\n            \"ERROR: Can not execute `setup.py` since setuptools failed to import in \"\n            \"the build environment with exception:\",\n            file=sys.stderr,\n        )\n        traceback.print_exc()\n        sys.exit(1)\n\n    __file__ = %r\n    sys.argv[0] = __file__\n\n    if os.path.exists(__file__):\n        filename = __file__\n        with tokenize.open(__file__) as f:\n            setup_py_code = f.read()\n    else:\n        filename = \"<auto-generated setuptools caller>\"\n        setup_py_code = \"from setuptools import setup; setup()\"\n\n    exec(compile(setup_py_code, filename, \"exec\"))\n    ''' % ({!r},), \"<pip-setuptools-caller>\", \"exec\"))\n    \"\"\"\n).rstrip()\n\n\ndef make_setuptools_shim_args(\n    setup_py_path: str,\n    global_options: Optional[Sequence[str]] = None,\n    no_user_config: bool = False,\n    unbuffered_output: bool = False,\n) -> List[str]:\n    \"\"\"\n    Get setuptools command arguments with shim wrapped setup file invocation.\n\n    :param setup_py_path: The path to setup.py to be wrapped.\n    :param global_options: Additional global options.\n    :param no_user_config: If True, disables personal user configuration.\n    :param unbuffered_output: If True, adds the unbuffered switch to the\n     argument list.\n    \"\"\"\n    args = [sys.executable]\n    if unbuffered_output:\n        args += [\"-u\"]\n    args += [\"-c\", _SETUPTOOLS_SHIM.format(setup_py_path)]\n    if global_options:\n        args += global_options\n    if no_user_config:\n        args += [\"--no-user-cfg\"]\n    return args\n\n\ndef make_setuptools_bdist_wheel_args(\n    setup_py_path: str,\n    global_options: Sequence[str],\n    build_options: Sequence[str],\n    destination_dir: str,\n) -> List[str]:\n    # NOTE: Eventually, we'd want to also -S to the flags here, when we're\n    # isolating. Currently, it breaks Python in virtualenvs, because it\n    # relies on site.py to find parts of the standard library outside the\n    # virtualenv.\n    args = make_setuptools_shim_args(\n        setup_py_path, global_options=global_options, unbuffered_output=True\n    )\n    args += [\"bdist_wheel\", \"-d\", destination_dir]\n    args += build_options\n    return args\n\n\ndef make_setuptools_clean_args(\n    setup_py_path: str,\n    global_options: Sequence[str],\n) -> List[str]:\n    args = make_setuptools_shim_args(\n        setup_py_path, global_options=global_options, unbuffered_output=True\n    )\n    args += [\"clean\", \"--all\"]\n    return args\n\n\ndef make_setuptools_develop_args(\n    setup_py_path: str,\n    *,\n    global_options: Sequence[str],\n    no_user_config: bool,\n    prefix: Optional[str],\n    home: Optional[str],\n    use_user_site: bool,\n) -> List[str]:\n    assert not (use_user_site and prefix)\n\n    args = make_setuptools_shim_args(\n        setup_py_path,\n        global_options=global_options,\n        no_user_config=no_user_config,\n    )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\subprocess.py": {
      "sha": "c6578ade2da5",
      "lines": 245,
      "head": "import logging\nimport os\nimport shlex\nimport subprocess\nfrom typing import Any, Callable, Iterable, List, Literal, Mapping, Optional, Union\n\nfrom pip._vendor.rich.markup import escape\n\nfrom pip._internal.cli.spinners import SpinnerInterface, open_spinner\nfrom pip._internal.exceptions import InstallationSubprocessError\nfrom pip._internal.utils.logging import VERBOSE, subprocess_logger\nfrom pip._internal.utils.misc import HiddenText\n\nCommandArgs = List[Union[str, HiddenText]]\n\n\ndef make_command(*args: Union[str, HiddenText, CommandArgs]) -> CommandArgs:\n    \"\"\"\n    Create a CommandArgs object.\n    \"\"\"\n    command_args: CommandArgs = []\n    for arg in args:\n        # Check for list instead of CommandArgs since CommandArgs is\n        # only known during type-checking.\n        if isinstance(arg, list):\n            command_args.extend(arg)\n        else:\n            # Otherwise, arg is str or HiddenText.\n            command_args.append(arg)\n\n    return command_args\n\n\ndef format_command_args(args: Union[List[str], CommandArgs]) -> str:\n    \"\"\"\n    Format command arguments for display.\n    \"\"\"\n    # For HiddenText arguments, display the redacted form by calling str().\n    # Also, we don't apply str() to arguments that aren't HiddenText since\n    # this can trigger a UnicodeDecodeError in Python 2 if the argument\n    # has type unicode and includes a non-ascii character.  (The type\n    # checker doesn't ensure the annotations are correct in all cases.)\n    return \" \".join(\n        shlex.quote(str(arg)) if isinstance(arg, HiddenText) else shlex.quote(arg)\n        for arg in args\n    )\n\n\ndef reveal_command_args(args: Union[List[str], CommandArgs]) -> List[str]:\n    \"\"\"\n    Return the arguments in their raw, unredacted form.\n    \"\"\"\n    return [arg.secret if isinstance(arg, HiddenText) else arg for arg in args]\n\n\ndef call_subprocess(\n    cmd: Union[List[str], CommandArgs],\n    show_stdout: bool = False,\n    cwd: Optional[str] = None,\n    on_returncode: 'Literal[\"raise\", \"warn\", \"ignore\"]' = \"raise\",\n    extra_ok_returncodes: Optional[Iterable[int]] = None,\n    extra_environ: Optional[Mapping[str, Any]] = None,\n    unset_environ: Optional[Iterable[str]] = None,\n    spinner: Optional[SpinnerInterface] = None,\n    log_failed_cmd: Optional[bool] = True,\n    stdout_only: Optional[bool] = False,\n    *,\n    command_desc: str,\n) -> str:\n    \"\"\"\n    Args:\n      show_stdout: if true, use INFO to log the subprocess's stderr and\n        stdout streams.  Otherwise, use DEBUG.  Defaults to False.\n      extra_ok_returncodes: an iterable of integer return codes that are\n        acceptable, in addition to 0. Defaults to None, which means [].\n      unset_environ: an iterable of environment variable names to unset\n        prior to calling subprocess.Popen().\n      log_failed_cmd: if false, failed commands are not logged, only raised.\n      stdout_only: if true, return only stdout, else return both. When true,\n        logging of both stdout and stderr occurs when the subprocess has\n        terminated, else logging occurs as subprocess output is produced.\n    \"\"\"\n    if extra_ok_returncodes is None:\n        extra_ok_returncodes = []\n    if unset_environ is None:\n        unset_environ = []\n    # Most places in pip use show_stdout=False. What this means is--\n    #\n    # - We connect the child's output (combined stderr and stdout) to a\n    #   single pipe, which we read.\n    # - We log this output to stderr at DEBUG level as it is received.\n    # - If DEBUG logging isn't enabled (e.g. if --verbose logging wasn't\n    #   requested), then we show a spinner so the user can still see the\n    #   subprocess is in progress.\n    # - If the subprocess exits with an error, we log the output to stderr\n    #   at ERROR level if it hasn't already been displayed to the console\n    #   (e.g. if --verbose logging wasn't enabled).  This way we don't log\n    #   the output to the console twice.\n    #\n    # If show_stdout=True, then the above is still done, but with DEBUG\n    # replaced by INFO.\n    if show_stdout:\n        # Then log the subprocess output at INFO level.\n        log_subprocess: Callable[..., None] = subprocess_logger.info\n        used_level = logging.INFO\n    else:\n        # Then log the subprocess output using VERBOSE.  This also ensures\n        # it will be logged to the log file (aka user_log), if enabled.\n        log_subprocess = subprocess_logger.verbose\n        used_level = VERBOSE\n\n    # Whether the subprocess will be visible in the console.\n    showing_subprocess = subprocess_logger.getEffectiveLevel() <= used_level\n\n    # Only use the spinner if we're not showing the subprocess output\n    # and we have a spinner.\n    use_spinner = not showing_subprocess and spinner is not None\n\n    log_subprocess(\"Running command %s\", command_desc)\n    env = os.environ.copy()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py": {
      "sha": "433d2bc933f4",
      "lines": 296,
      "head": "import errno\nimport itertools\nimport logging\nimport os.path\nimport tempfile\nimport traceback\nfrom contextlib import ExitStack, contextmanager\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Generator,\n    List,\n    Optional,\n    TypeVar,\n    Union,\n)\n\nfrom pip._internal.utils.misc import enum, rmtree\n\nlogger = logging.getLogger(__name__)\n\n_T = TypeVar(\"_T\", bound=\"TempDirectory\")\n\n\n# Kinds of temporary directories. Only needed for ones that are\n# globally-managed.\ntempdir_kinds = enum(\n    BUILD_ENV=\"build-env\",\n    EPHEM_WHEEL_CACHE=\"ephem-wheel-cache\",\n    REQ_BUILD=\"req-build\",\n)\n\n\n_tempdir_manager: Optional[ExitStack] = None\n\n\n@contextmanager\ndef global_tempdir_manager() -> Generator[None, None, None]:\n    global _tempdir_manager\n    with ExitStack() as stack:\n        old_tempdir_manager, _tempdir_manager = _tempdir_manager, stack\n        try:\n            yield\n        finally:\n            _tempdir_manager = old_tempdir_manager\n\n\nclass TempDirectoryTypeRegistry:\n    \"\"\"Manages temp directory behavior\"\"\"\n\n    def __init__(self) -> None:\n        self._should_delete: Dict[str, bool] = {}\n\n    def set_delete(self, kind: str, value: bool) -> None:\n        \"\"\"Indicate whether a TempDirectory of the given kind should be\n        auto-deleted.\n        \"\"\"\n        self._should_delete[kind] = value\n\n    def get_delete(self, kind: str) -> bool:\n        \"\"\"Get configured auto-delete flag for a given TempDirectory type,\n        default True.\n        \"\"\"\n        return self._should_delete.get(kind, True)\n\n\n_tempdir_registry: Optional[TempDirectoryTypeRegistry] = None\n\n\n@contextmanager\ndef tempdir_registry() -> Generator[TempDirectoryTypeRegistry, None, None]:\n    \"\"\"Provides a scoped global tempdir registry that can be used to dictate\n    whether directories should be deleted.\n    \"\"\"\n    global _tempdir_registry\n    old_tempdir_registry = _tempdir_registry\n    _tempdir_registry = TempDirectoryTypeRegistry()\n    try:\n        yield _tempdir_registry\n    finally:\n        _tempdir_registry = old_tempdir_registry\n\n\nclass _Default:\n    pass\n\n\n_default = _Default()\n\n\nclass TempDirectory:\n    \"\"\"Helper class that owns and cleans up a temporary directory.\n\n    This class can be used as a context manager or as an OO representation of a\n    temporary directory.\n\n    Attributes:\n        path\n            Location to the created temporary directory\n        delete\n            Whether the directory should be deleted when exiting\n            (when used as a contextmanager)\n\n    Methods:\n        cleanup()\n            Deletes the temporary directory\n\n    When used as a context manager, if the delete attribute is True, on\n    exiting the context the temporary directory is deleted.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Optional[str] = None,\n        delete: Union[bool, None, _Default] = _default,\n        kind: str = \"temp\",\n        globally_managed: bool = False,\n        ignore_cleanup_errors: bool = True,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\unpacking.py": {
      "sha": "bab558e155c3",
      "lines": 335,
      "head": "\"\"\"Utilities related archives.\"\"\"\n\nimport logging\nimport os\nimport shutil\nimport stat\nimport sys\nimport tarfile\nimport zipfile\nfrom typing import Iterable, List, Optional\nfrom zipfile import ZipInfo\n\nfrom pip._internal.exceptions import InstallationError\nfrom pip._internal.utils.filetypes import (\n    BZ2_EXTENSIONS,\n    TAR_EXTENSIONS,\n    XZ_EXTENSIONS,\n    ZIP_EXTENSIONS,\n)\nfrom pip._internal.utils.misc import ensure_dir\n\nlogger = logging.getLogger(__name__)\n\n\nSUPPORTED_EXTENSIONS = ZIP_EXTENSIONS + TAR_EXTENSIONS\n\ntry:\n    import bz2  # noqa\n\n    SUPPORTED_EXTENSIONS += BZ2_EXTENSIONS\nexcept ImportError:\n    logger.debug(\"bz2 module is not available\")\n\ntry:\n    # Only for Python 3.3+\n    import lzma  # noqa\n\n    SUPPORTED_EXTENSIONS += XZ_EXTENSIONS\nexcept ImportError:\n    logger.debug(\"lzma module is not available\")\n\n\ndef current_umask() -> int:\n    \"\"\"Get the current umask which involves having to set it temporarily.\"\"\"\n    mask = os.umask(0)\n    os.umask(mask)\n    return mask\n\n\ndef split_leading_dir(path: str) -> List[str]:\n    path = path.lstrip(\"/\").lstrip(\"\\\\\")\n    if \"/\" in path and (\n        (\"\\\\\" in path and path.find(\"/\") < path.find(\"\\\\\")) or \"\\\\\" not in path\n    ):\n        return path.split(\"/\", 1)\n    elif \"\\\\\" in path:\n        return path.split(\"\\\\\", 1)\n    else:\n        return [path, \"\"]\n\n\ndef has_leading_dir(paths: Iterable[str]) -> bool:\n    \"\"\"Returns true if all the paths have the same leading path name\n    (i.e., everything is in one subdirectory in an archive)\"\"\"\n    common_prefix = None\n    for path in paths:\n        prefix, rest = split_leading_dir(path)\n        if not prefix:\n            return False\n        elif common_prefix is None:\n            common_prefix = prefix\n        elif prefix != common_prefix:\n            return False\n    return True\n\n\ndef is_within_directory(directory: str, target: str) -> bool:\n    \"\"\"\n    Return true if the absolute path of target is within the directory\n    \"\"\"\n    abs_directory = os.path.abspath(directory)\n    abs_target = os.path.abspath(target)\n\n    prefix = os.path.commonprefix([abs_directory, abs_target])\n    return prefix == abs_directory\n\n\ndef _get_default_mode_plus_executable() -> int:\n    return 0o777 & ~current_umask() | 0o111\n\n\ndef set_extracted_file_to_default_mode_plus_executable(path: str) -> None:\n    \"\"\"\n    Make file present at path have execute for user/group/world\n    (chmod +x) is no-op on windows per python docs\n    \"\"\"\n    os.chmod(path, _get_default_mode_plus_executable())\n\n\ndef zip_item_is_executable(info: ZipInfo) -> bool:\n    mode = info.external_attr >> 16\n    # if mode and regular file and any execute permissions for\n    # user/group/world?\n    return bool(mode and stat.S_ISREG(mode) and mode & 0o111)\n\n\ndef unzip_file(filename: str, location: str, flatten: bool = True) -> None:\n    \"\"\"\n    Unzip the file (with path `filename`) to the destination `location`.  All\n    files are written based on system defaults and umask (i.e. permissions are\n    not preserved), except that regular file members with any execute\n    permissions (user, group, or world) have \"chmod +x\" applied after being\n    written. Note that for windows, any execute changes using os.chmod are\n    no-ops per the python docs.\n    \"\"\"\n    ensure_dir(location)\n    zipfp = open(filename, \"rb\")\n    try:\n        zip = zipfile.ZipFile(zipfp, allowZip64=True)\n        leading = has_leading_dir(zip.namelist()) and flatten\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\urls.py": {
      "sha": "bfd9cb6ce0fd",
      "lines": 55,
      "head": "import os\nimport string\nimport urllib.parse\nimport urllib.request\n\nfrom .compat import WINDOWS\n\n\ndef path_to_url(path: str) -> str:\n    \"\"\"\n    Convert a path to a file: URL.  The path will be made absolute and have\n    quoted path parts.\n    \"\"\"\n    path = os.path.normpath(os.path.abspath(path))\n    url = urllib.parse.urljoin(\"file:\", urllib.request.pathname2url(path))\n    return url\n\n\ndef url_to_path(url: str) -> str:\n    \"\"\"\n    Convert a file: URL to a path.\n    \"\"\"\n    assert url.startswith(\n        \"file:\"\n    ), f\"You can only turn file: urls into filenames (not {url!r})\"\n\n    _, netloc, path, _, _ = urllib.parse.urlsplit(url)\n\n    if not netloc or netloc == \"localhost\":\n        # According to RFC 8089, same as empty authority.\n        netloc = \"\"\n    elif WINDOWS:\n        # If we have a UNC path, prepend UNC share notation.\n        netloc = \"\\\\\\\\\" + netloc\n    else:\n        raise ValueError(\n            f\"non-local file URIs are not supported on this platform: {url!r}\"\n        )\n\n    path = urllib.request.url2pathname(netloc + path)\n\n    # On Windows, urlsplit parses the path as something like \"/C:/Users/foo\".\n    # This creates issues for path-related functions like io.open(), so we try\n    # to detect and strip the leading slash.\n    if (\n        WINDOWS\n        and not netloc  # Not UNC.\n        and len(path) >= 3\n        and path[0] == \"/\"  # Leading slash to strip.\n        and path[1] in string.ascii_letters  # Drive letter.\n        and path[2:4] in (\":\", \":/\")  # Colon + end of string, or colon + absolute path.\n    ):\n        path = path[1:]\n\n    return path\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\virtualenv.py": {
      "sha": "14cb66aa6ea7",
      "lines": 104,
      "head": "import logging\nimport os\nimport re\nimport site\nimport sys\nfrom typing import List, Optional\n\nlogger = logging.getLogger(__name__)\n_INCLUDE_SYSTEM_SITE_PACKAGES_REGEX = re.compile(\n    r\"include-system-site-packages\\s*=\\s*(?P<value>true|false)\"\n)\n\n\ndef _running_under_venv() -> bool:\n    \"\"\"Checks if sys.base_prefix and sys.prefix match.\n\n    This handles PEP 405 compliant virtual environments.\n    \"\"\"\n    return sys.prefix != getattr(sys, \"base_prefix\", sys.prefix)\n\n\ndef _running_under_legacy_virtualenv() -> bool:\n    \"\"\"Checks if sys.real_prefix is set.\n\n    This handles virtual environments created with pypa's virtualenv.\n    \"\"\"\n    # pypa/virtualenv case\n    return hasattr(sys, \"real_prefix\")\n\n\ndef running_under_virtualenv() -> bool:\n    \"\"\"True if we're running inside a virtual environment, False otherwise.\"\"\"\n    return _running_under_venv() or _running_under_legacy_virtualenv()\n\n\ndef _get_pyvenv_cfg_lines() -> Optional[List[str]]:\n    \"\"\"Reads {sys.prefix}/pyvenv.cfg and returns its contents as list of lines\n\n    Returns None, if it could not read/access the file.\n    \"\"\"\n    pyvenv_cfg_file = os.path.join(sys.prefix, \"pyvenv.cfg\")\n    try:\n        # Although PEP 405 does not specify, the built-in venv module always\n        # writes with UTF-8. (pypa/pip#8717)\n        with open(pyvenv_cfg_file, encoding=\"utf-8\") as f:\n            return f.read().splitlines()  # avoids trailing newlines\n    except OSError:\n        return None\n\n\ndef _no_global_under_venv() -> bool:\n    \"\"\"Check `{sys.prefix}/pyvenv.cfg` for system site-packages inclusion\n\n    PEP 405 specifies that when system site-packages are not supposed to be\n    visible from a virtual environment, `pyvenv.cfg` must contain the following\n    line:\n\n        include-system-site-packages = false\n\n    Additionally, log a warning if accessing the file fails.\n    \"\"\"\n    cfg_lines = _get_pyvenv_cfg_lines()\n    if cfg_lines is None:\n        # We're not in a \"sane\" venv, so assume there is no system\n        # site-packages access (since that's PEP 405's default state).\n        logger.warning(\n            \"Could not access 'pyvenv.cfg' despite a virtual environment \"\n            \"being active. Assuming global site-packages is not accessible \"\n            \"in this environment.\"\n        )\n        return True\n\n    for line in cfg_lines:\n        match = _INCLUDE_SYSTEM_SITE_PACKAGES_REGEX.match(line)\n        if match is not None and match.group(\"value\") == \"false\":\n            return True\n    return False\n\n\ndef _no_global_under_legacy_virtualenv() -> bool:\n    \"\"\"Check if \"no-global-site-packages.txt\" exists beside site.py\n\n    This mirrors logic in pypa/virtualenv for determining whether system\n    site-packages are visible in the virtual environment.\n    \"\"\"\n    site_mod_dir = os.path.dirname(os.path.abspath(site.__file__))\n    no_global_site_packages_file = os.path.join(\n        site_mod_dir,\n        \"no-global-site-packages.txt\",\n    )\n    return os.path.exists(no_global_site_packages_file)\n\n\ndef virtualenv_no_global() -> bool:\n    \"\"\"Returns a boolean, whether running in venv with no system site-packages.\"\"\"\n    # PEP 405 compliance needs to be checked first since virtualenv >=20 would\n    # return True for both checks, but is only able to use the PEP 405 config.\n    if _running_under_venv():\n        return _no_global_under_venv()\n\n    if _running_under_legacy_virtualenv():\n        return _no_global_under_legacy_virtualenv()\n\n    return False\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\wheel.py": {
      "sha": "c44772c202c1",
      "lines": 133,
      "head": "\"\"\"Support functions for working with wheel files.\"\"\"\n\nimport logging\nfrom email.message import Message\nfrom email.parser import Parser\nfrom typing import Tuple\nfrom zipfile import BadZipFile, ZipFile\n\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.exceptions import UnsupportedWheel\n\nVERSION_COMPATIBLE = (1, 0)\n\n\nlogger = logging.getLogger(__name__)\n\n\ndef parse_wheel(wheel_zip: ZipFile, name: str) -> Tuple[str, Message]:\n    \"\"\"Extract information from the provided wheel, ensuring it meets basic\n    standards.\n\n    Returns the name of the .dist-info directory and the parsed WHEEL metadata.\n    \"\"\"\n    try:\n        info_dir = wheel_dist_info_dir(wheel_zip, name)\n        metadata = wheel_metadata(wheel_zip, info_dir)\n        version = wheel_version(metadata)\n    except UnsupportedWheel as e:\n        raise UnsupportedWheel(f\"{name} has an invalid wheel, {e}\")\n\n    check_compatibility(version, name)\n\n    return info_dir, metadata\n\n\ndef wheel_dist_info_dir(source: ZipFile, name: str) -> str:\n    \"\"\"Returns the name of the contained .dist-info directory.\n\n    Raises AssertionError or UnsupportedWheel if not found, >1 found, or\n    it doesn't match the provided name.\n    \"\"\"\n    # Zip file path separators must be /\n    subdirs = {p.split(\"/\", 1)[0] for p in source.namelist()}\n\n    info_dirs = [s for s in subdirs if s.endswith(\".dist-info\")]\n\n    if not info_dirs:\n        raise UnsupportedWheel(\".dist-info directory not found\")\n\n    if len(info_dirs) > 1:\n        raise UnsupportedWheel(\n            \"multiple .dist-info directories found: {}\".format(\", \".join(info_dirs))\n        )\n\n    info_dir = info_dirs[0]\n\n    info_dir_name = canonicalize_name(info_dir)\n    canonical_name = canonicalize_name(name)\n    if not info_dir_name.startswith(canonical_name):\n        raise UnsupportedWheel(\n            f\".dist-info directory {info_dir!r} does not start with {canonical_name!r}\"\n        )\n\n    return info_dir\n\n\ndef read_wheel_metadata_file(source: ZipFile, path: str) -> bytes:\n    try:\n        return source.read(path)\n        # BadZipFile for general corruption, KeyError for missing entry,\n        # and RuntimeError for password-protected files\n    except (BadZipFile, KeyError, RuntimeError) as e:\n        raise UnsupportedWheel(f\"could not read {path!r} file: {e!r}\")\n\n\ndef wheel_metadata(source: ZipFile, dist_info_dir: str) -> Message:\n    \"\"\"Return the WHEEL metadata of an extracted wheel, if possible.\n    Otherwise, raise UnsupportedWheel.\n    \"\"\"\n    path = f\"{dist_info_dir}/WHEEL\"\n    # Zip file path separators must be /\n    wheel_contents = read_wheel_metadata_file(source, path)\n\n    try:\n        wheel_text = wheel_contents.decode()\n    except UnicodeDecodeError as e:\n        raise UnsupportedWheel(f\"error decoding {path!r}: {e!r}\")\n\n    # FeedParser (used by Parser) does not raise any exceptions. The returned\n    # message may have .defects populated, but for backwards-compatibility we\n    # currently ignore them.\n    return Parser().parsestr(wheel_text)\n\n\ndef wheel_version(wheel_data: Message) -> Tuple[int, ...]:\n    \"\"\"Given WHEEL metadata, return the parsed Wheel-Version.\n    Otherwise, raise UnsupportedWheel.\n    \"\"\"\n    version_text = wheel_data[\"Wheel-Version\"]\n    if version_text is None:\n        raise UnsupportedWheel(\"WHEEL is missing Wheel-Version\")\n\n    version = version_text.strip()\n\n    try:\n        return tuple(map(int, version.split(\".\")))\n    except ValueError:\n        raise UnsupportedWheel(f\"invalid Wheel-Version: {version!r}\")\n\n\ndef check_compatibility(version: Tuple[int, ...], name: str) -> None:\n    \"\"\"Raises errors or warns if called with an incompatible Wheel-Version.\n\n    pip should refuse to install a Wheel-Version that's a major series\n    ahead of what it's compatible with (e.g 2.0 > 1.1); and warn when\n    installing a version only minor version ahead (e.g 1.2 > 1.1).\n\n    version: a 2-tuple representing a Wheel-Version (Major, Minor)\n    name: name of wheel or package to raise exception about\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\_jaraco_text.py": {
      "sha": "6aa20e2c27dc",
      "lines": 109,
      "head": "\"\"\"Functions brought over from jaraco.text.\n\nThese functions are not supposed to be used within `pip._internal`. These are\nhelper functions brought over from `jaraco.text` to enable vendoring newer\ncopies of `pkg_resources` without having to vendor `jaraco.text` and its entire\ndependency cone; something that our vendoring setup is not currently capable of\nhandling.\n\nLicense reproduced from original source below:\n\nCopyright Jason R. Coombs\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n\"\"\"\n\nimport functools\nimport itertools\n\n\ndef _nonblank(str):\n    return str and not str.startswith(\"#\")\n\n\n@functools.singledispatch\ndef yield_lines(iterable):\n    r\"\"\"\n    Yield valid lines of a string or iterable.\n\n    >>> list(yield_lines(''))\n    []\n    >>> list(yield_lines(['foo', 'bar']))\n    ['foo', 'bar']\n    >>> list(yield_lines('foo\\nbar'))\n    ['foo', 'bar']\n    >>> list(yield_lines('\\nfoo\\n#bar\\nbaz #comment'))\n    ['foo', 'baz #comment']\n    >>> list(yield_lines(['foo\\nbar', 'baz', 'bing\\n\\n\\n']))\n    ['foo', 'bar', 'baz', 'bing']\n    \"\"\"\n    return itertools.chain.from_iterable(map(yield_lines, iterable))\n\n\n@yield_lines.register(str)\ndef _(text):\n    return filter(_nonblank, map(str.strip, text.splitlines()))\n\n\ndef drop_comment(line):\n    \"\"\"\n    Drop comments.\n\n    >>> drop_comment('foo # bar')\n    'foo'\n\n    A hash without a space may be in a URL.\n\n    >>> drop_comment('http://example.com/foo#bar')\n    'http://example.com/foo#bar'\n    \"\"\"\n    return line.partition(\" #\")[0]\n\n\ndef join_continuation(lines):\n    r\"\"\"\n    Join lines continued by a trailing backslash.\n\n    >>> list(join_continuation(['foo \\\\', 'bar', 'baz']))\n    ['foobar', 'baz']\n    >>> list(join_continuation(['foo \\\\', 'bar', 'baz']))\n    ['foobar', 'baz']\n    >>> list(join_continuation(['foo \\\\', 'bar \\\\', 'baz']))\n    ['foobarbaz']\n\n    Not sure why, but...\n    The character preceding the backslash is also elided.\n\n    >>> list(join_continuation(['goo\\\\', 'dly']))\n    ['godly']\n\n    A terrible idea, but...\n    If no line is available to continue, suppress the lines.\n\n    >>> list(join_continuation(['foo', 'bar\\\\', 'baz\\\\']))\n    ['foo']\n    \"\"\"\n    lines = iter(lines)\n    for item in lines:\n        while item.endswith(\"\\\\\"):\n            try:\n                item = item[:-2].strip() + next(lines)\n            except StopIteration:\n                return\n        yield item\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\_log.py": {
      "sha": "2c20b7d739a3",
      "lines": 38,
      "head": "\"\"\"Customize logging\n\nDefines custom logger class for the `logger.verbose(...)` method.\n\ninit_logging() must be called before any other modules that call logging.getLogger.\n\"\"\"\n\nimport logging\nfrom typing import Any, cast\n\n# custom log level for `--verbose` output\n# between DEBUG and INFO\nVERBOSE = 15\n\n\nclass VerboseLogger(logging.Logger):\n    \"\"\"Custom Logger, defining a verbose log-level\n\n    VERBOSE is between INFO and DEBUG.\n    \"\"\"\n\n    def verbose(self, msg: str, *args: Any, **kwargs: Any) -> None:\n        return self.log(VERBOSE, msg, *args, **kwargs)\n\n\ndef getLogger(name: str) -> VerboseLogger:\n    \"\"\"logging.getLogger, but ensures our VerboseLogger class is returned\"\"\"\n    return cast(VerboseLogger, logging.getLogger(name))\n\n\ndef init_logging() -> None:\n    \"\"\"Register our VerboseLogger and VERBOSE log level.\n\n    Should be called before any calls to getLogger(),\n    i.e. in pip._internal.__init__\n    \"\"\"\n    logging.setLoggerClass(VerboseLogger)\n    logging.addLevelName(VERBOSE, \"VERBOSE\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\utils\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\bazaar.py": {
      "sha": "7de44a798522",
      "lines": 112,
      "head": "import logging\nfrom typing import List, Optional, Tuple\n\nfrom pip._internal.utils.misc import HiddenText, display_path\nfrom pip._internal.utils.subprocess import make_command\nfrom pip._internal.utils.urls import path_to_url\nfrom pip._internal.vcs.versioncontrol import (\n    AuthInfo,\n    RemoteNotFoundError,\n    RevOptions,\n    VersionControl,\n    vcs,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nclass Bazaar(VersionControl):\n    name = \"bzr\"\n    dirname = \".bzr\"\n    repo_name = \"branch\"\n    schemes = (\n        \"bzr+http\",\n        \"bzr+https\",\n        \"bzr+ssh\",\n        \"bzr+sftp\",\n        \"bzr+ftp\",\n        \"bzr+lp\",\n        \"bzr+file\",\n    )\n\n    @staticmethod\n    def get_base_rev_args(rev: str) -> List[str]:\n        return [\"-r\", rev]\n\n    def fetch_new(\n        self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int\n    ) -> None:\n        rev_display = rev_options.to_display()\n        logger.info(\n            \"Checking out %s%s to %s\",\n            url,\n            rev_display,\n            display_path(dest),\n        )\n        if verbosity <= 0:\n            flags = [\"--quiet\"]\n        elif verbosity == 1:\n            flags = []\n        else:\n            flags = [f\"-{'v'*verbosity}\"]\n        cmd_args = make_command(\n            \"checkout\", \"--lightweight\", *flags, rev_options.to_args(), url, dest\n        )\n        self.run_command(cmd_args)\n\n    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:\n        self.run_command(make_command(\"switch\", url), cwd=dest)\n\n    def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:\n        output = self.run_command(\n            make_command(\"info\"), show_stdout=False, stdout_only=True, cwd=dest\n        )\n        if output.startswith(\"Standalone \"):\n            # Older versions of pip used to create standalone branches.\n            # Convert the standalone branch to a checkout by calling \"bzr bind\".\n            cmd_args = make_command(\"bind\", \"-q\", url)\n            self.run_command(cmd_args, cwd=dest)\n\n        cmd_args = make_command(\"update\", \"-q\", rev_options.to_args())\n        self.run_command(cmd_args, cwd=dest)\n\n    @classmethod\n    def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:\n        # hotfix the URL scheme after removing bzr+ from bzr+ssh:// re-add it\n        url, rev, user_pass = super().get_url_rev_and_auth(url)\n        if url.startswith(\"ssh://\"):\n            url = \"bzr+\" + url\n        return url, rev, user_pass\n\n    @classmethod\n    def get_remote_url(cls, location: str) -> str:\n        urls = cls.run_command(\n            [\"info\"], show_stdout=False, stdout_only=True, cwd=location\n        )\n        for line in urls.splitlines():\n            line = line.strip()\n            for x in (\"checkout of branch: \", \"parent branch: \"):\n                if line.startswith(x):\n                    repo = line.split(x)[1]\n                    if cls._is_local_repository(repo):\n                        return path_to_url(repo)\n                    return repo\n        raise RemoteNotFoundError\n\n    @classmethod\n    def get_revision(cls, location: str) -> str:\n        revision = cls.run_command(\n            [\"revno\"],\n            show_stdout=False,\n            stdout_only=True,\n            cwd=location,\n        )\n        return revision.splitlines()[-1]\n\n    @classmethod\n    def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:\n        \"\"\"Always assume the versions don't match\"\"\"\n        return False\n\n\nvcs.register(Bazaar)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\git.py": {
      "sha": "a1ab7681a7d1",
      "lines": 536,
      "head": "import logging\nimport os.path\nimport pathlib\nimport re\nimport urllib.parse\nimport urllib.request\nfrom dataclasses import replace\nfrom typing import Any, List, Optional, Tuple\n\nfrom pip._internal.exceptions import BadCommand, InstallationError\nfrom pip._internal.utils.misc import HiddenText, display_path, hide_url\nfrom pip._internal.utils.subprocess import make_command\nfrom pip._internal.vcs.versioncontrol import (\n    AuthInfo,\n    RemoteNotFoundError,\n    RemoteNotValidError,\n    RevOptions,\n    VersionControl,\n    find_path_to_project_root_from_repo_root,\n    vcs,\n)\n\nurlsplit = urllib.parse.urlsplit\nurlunsplit = urllib.parse.urlunsplit\n\n\nlogger = logging.getLogger(__name__)\n\n\nGIT_VERSION_REGEX = re.compile(\n    r\"^git version \"  # Prefix.\n    r\"(\\d+)\"  # Major.\n    r\"\\.(\\d+)\"  # Dot, minor.\n    r\"(?:\\.(\\d+))?\"  # Optional dot, patch.\n    r\".*$\"  # Suffix, including any pre- and post-release segments we don't care about.\n)\n\nHASH_REGEX = re.compile(\"^[a-fA-F0-9]{40}$\")\n\n# SCP (Secure copy protocol) shorthand. e.g. 'git@example.com:foo/bar.git'\nSCP_REGEX = re.compile(\n    r\"\"\"^\n    # Optional user, e.g. 'git@'\n    (\\w+@)?\n    # Server, e.g. 'github.com'.\n    ([^/:]+):\n    # The server-side path. e.g. 'user/project.git'. Must start with an\n    # alphanumeric character so as not to be confusable with a Windows paths\n    # like 'C:/foo/bar' or 'C:\\foo\\bar'.\n    (\\w[^:]*)\n    $\"\"\",\n    re.VERBOSE,\n)\n\n\ndef looks_like_hash(sha: str) -> bool:\n    return bool(HASH_REGEX.match(sha))\n\n\nclass Git(VersionControl):\n    name = \"git\"\n    dirname = \".git\"\n    repo_name = \"clone\"\n    schemes = (\n        \"git+http\",\n        \"git+https\",\n        \"git+ssh\",\n        \"git+git\",\n        \"git+file\",\n    )\n    # Prevent the user's environment variables from interfering with pip:\n    # https://github.com/pypa/pip/issues/1130\n    unset_environ = (\"GIT_DIR\", \"GIT_WORK_TREE\")\n    default_arg_rev = \"HEAD\"\n\n    @staticmethod\n    def get_base_rev_args(rev: str) -> List[str]:\n        return [rev]\n\n    @classmethod\n    def run_command(cls, *args: Any, **kwargs: Any) -> str:\n        if os.environ.get(\"PIP_NO_INPUT\"):\n            extra_environ = kwargs.get(\"extra_environ\", {})\n            extra_environ[\"GIT_TERMINAL_PROMPT\"] = \"0\"\n            extra_environ[\"GIT_SSH_COMMAND\"] = \"ssh -oBatchMode=yes\"\n            kwargs[\"extra_environ\"] = extra_environ\n        return super().run_command(*args, **kwargs)\n\n    def is_immutable_rev_checkout(self, url: str, dest: str) -> bool:\n        _, rev_options = self.get_url_rev_options(hide_url(url))\n        if not rev_options.rev:\n            return False\n        if not self.is_commit_id_equal(dest, rev_options.rev):\n            # the current commit is different from rev,\n            # which means rev was something else than a commit hash\n            return False\n        # return False in the rare case rev is both a commit hash\n        # and a tag or a branch; we don't want to cache in that case\n        # because that branch/tag could point to something else in the future\n        is_tag_or_branch = bool(self.get_revision_sha(dest, rev_options.rev)[0])\n        return not is_tag_or_branch\n\n    def get_git_version(self) -> Tuple[int, ...]:\n        version = self.run_command(\n            [\"version\"],\n            command_desc=\"git version\",\n            show_stdout=False,\n            stdout_only=True,\n        )\n        match = GIT_VERSION_REGEX.match(version)\n        if not match:\n            logger.warning(\"Can't parse git version: %s\", version)\n            return ()\n        return (int(match.group(1)), int(match.group(2)))\n\n    @classmethod\n    def get_current_branch(cls, location: str) -> Optional[str]:\n        \"\"\"\n        Return the current branch, or None if HEAD isn't at a branch\n        (e.g. detached HEAD).\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\mercurial.py": {
      "sha": "9f7531c4ab89",
      "lines": 163,
      "head": "import configparser\nimport logging\nimport os\nfrom typing import List, Optional, Tuple\n\nfrom pip._internal.exceptions import BadCommand, InstallationError\nfrom pip._internal.utils.misc import HiddenText, display_path\nfrom pip._internal.utils.subprocess import make_command\nfrom pip._internal.utils.urls import path_to_url\nfrom pip._internal.vcs.versioncontrol import (\n    RevOptions,\n    VersionControl,\n    find_path_to_project_root_from_repo_root,\n    vcs,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nclass Mercurial(VersionControl):\n    name = \"hg\"\n    dirname = \".hg\"\n    repo_name = \"clone\"\n    schemes = (\n        \"hg+file\",\n        \"hg+http\",\n        \"hg+https\",\n        \"hg+ssh\",\n        \"hg+static-http\",\n    )\n\n    @staticmethod\n    def get_base_rev_args(rev: str) -> List[str]:\n        return [f\"--rev={rev}\"]\n\n    def fetch_new(\n        self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int\n    ) -> None:\n        rev_display = rev_options.to_display()\n        logger.info(\n            \"Cloning hg %s%s to %s\",\n            url,\n            rev_display,\n            display_path(dest),\n        )\n        if verbosity <= 0:\n            flags: Tuple[str, ...] = (\"--quiet\",)\n        elif verbosity == 1:\n            flags = ()\n        elif verbosity == 2:\n            flags = (\"--verbose\",)\n        else:\n            flags = (\"--verbose\", \"--debug\")\n        self.run_command(make_command(\"clone\", \"--noupdate\", *flags, url, dest))\n        self.run_command(\n            make_command(\"update\", *flags, rev_options.to_args()),\n            cwd=dest,\n        )\n\n    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:\n        repo_config = os.path.join(dest, self.dirname, \"hgrc\")\n        config = configparser.RawConfigParser()\n        try:\n            config.read(repo_config)\n            config.set(\"paths\", \"default\", url.secret)\n            with open(repo_config, \"w\") as config_file:\n                config.write(config_file)\n        except (OSError, configparser.NoSectionError) as exc:\n            logger.warning(\"Could not switch Mercurial repository to %s: %s\", url, exc)\n        else:\n            cmd_args = make_command(\"update\", \"-q\", rev_options.to_args())\n            self.run_command(cmd_args, cwd=dest)\n\n    def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:\n        self.run_command([\"pull\", \"-q\"], cwd=dest)\n        cmd_args = make_command(\"update\", \"-q\", rev_options.to_args())\n        self.run_command(cmd_args, cwd=dest)\n\n    @classmethod\n    def get_remote_url(cls, location: str) -> str:\n        url = cls.run_command(\n            [\"showconfig\", \"paths.default\"],\n            show_stdout=False,\n            stdout_only=True,\n            cwd=location,\n        ).strip()\n        if cls._is_local_repository(url):\n            url = path_to_url(url)\n        return url.strip()\n\n    @classmethod\n    def get_revision(cls, location: str) -> str:\n        \"\"\"\n        Return the repository-local changeset revision number, as an integer.\n        \"\"\"\n        current_revision = cls.run_command(\n            [\"parents\", \"--template={rev}\"],\n            show_stdout=False,\n            stdout_only=True,\n            cwd=location,\n        ).strip()\n        return current_revision\n\n    @classmethod\n    def get_requirement_revision(cls, location: str) -> str:\n        \"\"\"\n        Return the changeset identification hash, as a 40-character\n        hexadecimal string\n        \"\"\"\n        current_rev_hash = cls.run_command(\n            [\"parents\", \"--template={node}\"],\n            show_stdout=False,\n            stdout_only=True,\n            cwd=location,\n        ).strip()\n        return current_rev_hash\n\n    @classmethod\n    def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:\n        \"\"\"Always assume the versions don't match\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\subversion.py": {
      "sha": "523bb3d4d9c4",
      "lines": 324,
      "head": "import logging\nimport os\nimport re\nfrom typing import List, Optional, Tuple\n\nfrom pip._internal.utils.misc import (\n    HiddenText,\n    display_path,\n    is_console_interactive,\n    is_installable_dir,\n    split_auth_from_netloc,\n)\nfrom pip._internal.utils.subprocess import CommandArgs, make_command\nfrom pip._internal.vcs.versioncontrol import (\n    AuthInfo,\n    RemoteNotFoundError,\n    RevOptions,\n    VersionControl,\n    vcs,\n)\n\nlogger = logging.getLogger(__name__)\n\n_svn_xml_url_re = re.compile('url=\"([^\"]+)\"')\n_svn_rev_re = re.compile(r'committed-rev=\"(\\d+)\"')\n_svn_info_xml_rev_re = re.compile(r'\\s*revision=\"(\\d+)\"')\n_svn_info_xml_url_re = re.compile(r\"<url>(.*)</url>\")\n\n\nclass Subversion(VersionControl):\n    name = \"svn\"\n    dirname = \".svn\"\n    repo_name = \"checkout\"\n    schemes = (\"svn+ssh\", \"svn+http\", \"svn+https\", \"svn+svn\", \"svn+file\")\n\n    @classmethod\n    def should_add_vcs_url_prefix(cls, remote_url: str) -> bool:\n        return True\n\n    @staticmethod\n    def get_base_rev_args(rev: str) -> List[str]:\n        return [\"-r\", rev]\n\n    @classmethod\n    def get_revision(cls, location: str) -> str:\n        \"\"\"\n        Return the maximum revision for all files under a given location\n        \"\"\"\n        # Note: taken from setuptools.command.egg_info\n        revision = 0\n\n        for base, dirs, _ in os.walk(location):\n            if cls.dirname not in dirs:\n                dirs[:] = []\n                continue  # no sense walking uncontrolled subdirs\n            dirs.remove(cls.dirname)\n            entries_fn = os.path.join(base, cls.dirname, \"entries\")\n            if not os.path.exists(entries_fn):\n                # FIXME: should we warn?\n                continue\n\n            dirurl, localrev = cls._get_svn_url_rev(base)\n\n            if base == location:\n                assert dirurl is not None\n                base = dirurl + \"/\"  # save the root url\n            elif not dirurl or not dirurl.startswith(base):\n                dirs[:] = []\n                continue  # not part of the same svn tree, skip it\n            revision = max(revision, localrev)\n        return str(revision)\n\n    @classmethod\n    def get_netloc_and_auth(\n        cls, netloc: str, scheme: str\n    ) -> Tuple[str, Tuple[Optional[str], Optional[str]]]:\n        \"\"\"\n        This override allows the auth information to be passed to svn via the\n        --username and --password options instead of via the URL.\n        \"\"\"\n        if scheme == \"ssh\":\n            # The --username and --password options can't be used for\n            # svn+ssh URLs, so keep the auth information in the URL.\n            return super().get_netloc_and_auth(netloc, scheme)\n\n        return split_auth_from_netloc(netloc)\n\n    @classmethod\n    def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:\n        # hotfix the URL scheme after removing svn+ from svn+ssh:// re-add it\n        url, rev, user_pass = super().get_url_rev_and_auth(url)\n        if url.startswith(\"ssh://\"):\n            url = \"svn+\" + url\n        return url, rev, user_pass\n\n    @staticmethod\n    def make_rev_args(\n        username: Optional[str], password: Optional[HiddenText]\n    ) -> CommandArgs:\n        extra_args: CommandArgs = []\n        if username:\n            extra_args += [\"--username\", username]\n        if password:\n            extra_args += [\"--password\", password]\n\n        return extra_args\n\n    @classmethod\n    def get_remote_url(cls, location: str) -> str:\n        # In cases where the source is in a subdirectory, we have to look up in\n        # the location until we find a valid project root.\n        orig_location = location\n        while not is_installable_dir(location):\n            last_location = location\n            location = os.path.dirname(location)\n            if location == last_location:\n                # We've traversed up to the root of the filesystem without\n                # finding a Python project.\n                logger.warning(\n                    \"Could not find Python project for directory %s (tried all \"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\versioncontrol.py": {
      "sha": "db3d199e4269",
      "lines": 688,
      "head": "\"\"\"Handles all VCS (version control) support\"\"\"\n\nimport logging\nimport os\nimport shutil\nimport sys\nimport urllib.parse\nfrom dataclasses import dataclass, field\nfrom typing import (\n    Any,\n    Dict,\n    Iterable,\n    Iterator,\n    List,\n    Literal,\n    Mapping,\n    Optional,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pip._internal.cli.spinners import SpinnerInterface\nfrom pip._internal.exceptions import BadCommand, InstallationError\nfrom pip._internal.utils.misc import (\n    HiddenText,\n    ask_path_exists,\n    backup_dir,\n    display_path,\n    hide_url,\n    hide_value,\n    is_installable_dir,\n    rmtree,\n)\nfrom pip._internal.utils.subprocess import (\n    CommandArgs,\n    call_subprocess,\n    format_command_args,\n    make_command,\n)\n\n__all__ = [\"vcs\"]\n\n\nlogger = logging.getLogger(__name__)\n\nAuthInfo = Tuple[Optional[str], Optional[str]]\n\n\ndef is_url(name: str) -> bool:\n    \"\"\"\n    Return true if the name looks like a URL.\n    \"\"\"\n    scheme = urllib.parse.urlsplit(name).scheme\n    if not scheme:\n        return False\n    return scheme in [\"http\", \"https\", \"file\", \"ftp\"] + vcs.all_schemes\n\n\ndef make_vcs_requirement_url(\n    repo_url: str, rev: str, project_name: str, subdir: Optional[str] = None\n) -> str:\n    \"\"\"\n    Return the URL for a VCS requirement.\n\n    Args:\n      repo_url: the remote VCS url, with any needed VCS prefix (e.g. \"git+\").\n      project_name: the (unescaped) project name.\n    \"\"\"\n    egg_project_name = project_name.replace(\"-\", \"_\")\n    req = f\"{repo_url}@{rev}#egg={egg_project_name}\"\n    if subdir:\n        req += f\"&subdirectory={subdir}\"\n\n    return req\n\n\ndef find_path_to_project_root_from_repo_root(\n    location: str, repo_root: str\n) -> Optional[str]:\n    \"\"\"\n    Find the the Python project's root by searching up the filesystem from\n    `location`. Return the path to project root relative to `repo_root`.\n    Return None if the project root is `repo_root`, or cannot be found.\n    \"\"\"\n    # find project root.\n    orig_location = location\n    while not is_installable_dir(location):\n        last_location = location\n        location = os.path.dirname(location)\n        if location == last_location:\n            # We've traversed up to the root of the filesystem without\n            # finding a Python project.\n            logger.warning(\n                \"Could not find a Python project for directory %s (tried all \"\n                \"parent directories)\",\n                orig_location,\n            )\n            return None\n\n    if os.path.samefile(repo_root, location):\n        return None\n\n    return os.path.relpath(location, repo_root)\n\n\nclass RemoteNotFoundError(Exception):\n    pass\n\n\nclass RemoteNotValidError(Exception):\n    def __init__(self, url: str):\n        super().__init__(url)\n        self.url = url\n\n\n@dataclass(frozen=True)\nclass RevOptions:\n    \"\"\"\n    Encapsulates a VCS-specific revision to install, along with any VCS\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_internal\\vcs\\__init__.py": {
      "sha": "ddf20f97603f",
      "lines": 15,
      "head": "# Expose a limited set of classes and functions so callers outside of\n# the vcs package don't need to import deeper than `pip._internal.vcs`.\n# (The test directory may still need to import from a vcs sub-package.)\n# Import all vcs modules to register each VCS in the VcsSupport object.\nimport pip._internal.vcs.bazaar\nimport pip._internal.vcs.git\nimport pip._internal.vcs.mercurial\nimport pip._internal.vcs.subversion  # noqa: F401\nfrom pip._internal.vcs.versioncontrol import (  # noqa: F401\n    RemoteNotFoundError,\n    RemoteNotValidError,\n    is_url,\n    make_vcs_requirement_url,\n    vcs,\n)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\typing_extensions.py": {
      "sha": "38ccfce3facf",
      "lines": 4584,
      "head": "import abc\nimport builtins\nimport collections\nimport collections.abc\nimport contextlib\nimport enum\nimport functools\nimport inspect\nimport keyword\nimport operator\nimport sys\nimport types as _types\nimport typing\nimport warnings\n\n__all__ = [\n    # Super-special typing primitives.\n    'Any',\n    'ClassVar',\n    'Concatenate',\n    'Final',\n    'LiteralString',\n    'ParamSpec',\n    'ParamSpecArgs',\n    'ParamSpecKwargs',\n    'Self',\n    'Type',\n    'TypeVar',\n    'TypeVarTuple',\n    'Unpack',\n\n    # ABCs (from collections.abc).\n    'Awaitable',\n    'AsyncIterator',\n    'AsyncIterable',\n    'Coroutine',\n    'AsyncGenerator',\n    'AsyncContextManager',\n    'Buffer',\n    'ChainMap',\n\n    # Concrete collection types.\n    'ContextManager',\n    'Counter',\n    'Deque',\n    'DefaultDict',\n    'NamedTuple',\n    'OrderedDict',\n    'TypedDict',\n\n    # Structural checks, a.k.a. protocols.\n    'SupportsAbs',\n    'SupportsBytes',\n    'SupportsComplex',\n    'SupportsFloat',\n    'SupportsIndex',\n    'SupportsInt',\n    'SupportsRound',\n\n    # One-off things.\n    'Annotated',\n    'assert_never',\n    'assert_type',\n    'clear_overloads',\n    'dataclass_transform',\n    'deprecated',\n    'Doc',\n    'evaluate_forward_ref',\n    'get_overloads',\n    'final',\n    'Format',\n    'get_annotations',\n    'get_args',\n    'get_origin',\n    'get_original_bases',\n    'get_protocol_members',\n    'get_type_hints',\n    'IntVar',\n    'is_protocol',\n    'is_typeddict',\n    'Literal',\n    'NewType',\n    'overload',\n    'override',\n    'Protocol',\n    'reveal_type',\n    'runtime',\n    'runtime_checkable',\n    'Text',\n    'TypeAlias',\n    'TypeAliasType',\n    'TypeForm',\n    'TypeGuard',\n    'TypeIs',\n    'TYPE_CHECKING',\n    'Never',\n    'NoReturn',\n    'ReadOnly',\n    'Required',\n    'NotRequired',\n    'NoDefault',\n    'NoExtraItems',\n\n    # Pure aliases, have always been in typing\n    'AbstractSet',\n    'AnyStr',\n    'BinaryIO',\n    'Callable',\n    'Collection',\n    'Container',\n    'Dict',\n    'ForwardRef',\n    'FrozenSet',\n    'Generator',\n    'Generic',\n    'Hashable',\n    'IO',\n    'ItemsView',\n    'Iterable',\n    'Iterator',\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\vendor.txt": {
      "sha": "1ca9483fd4c4",
      "lines": 20,
      "head": "CacheControl==0.14.2\ndistlib==0.3.9\ndistro==1.9.0\nmsgpack==1.1.0\npackaging==25.0\nplatformdirs==4.3.7\npyproject-hooks==1.2.0\nrequests==2.32.3\n    certifi==2025.1.31\n    idna==3.10\n    urllib3==1.26.20\nrich==14.0.0\n    pygments==2.19.1\n    typing_extensions==4.13.2\nresolvelib==1.1.0\nsetuptools==70.3.0\ntomli==2.2.1\ntomli-w==1.2.0\ntruststore==0.10.1\ndependency-groups==1.3.1\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\__init__.py": {
      "sha": "c2ba1a9ec224",
      "lines": 117,
      "head": "\"\"\"\npip._vendor is for vendoring dependencies of pip to prevent needing pip to\ndepend on something external.\n\nFiles inside of pip._vendor should be considered immutable and should only be\nupdated to versions from upstream.\n\"\"\"\nfrom __future__ import absolute_import\n\nimport glob\nimport os.path\nimport sys\n\n# Downstream redistributors which have debundled our dependencies should also\n# patch this value to be true. This will trigger the additional patching\n# to cause things like \"six\" to be available as pip.\nDEBUNDLED = False\n\n# By default, look in this directory for a bunch of .whl files which we will\n# add to the beginning of sys.path before attempting to import anything. This\n# is done to support downstream re-distributors like Debian and Fedora who\n# wish to create their own Wheels for our dependencies to aid in debundling.\nWHEEL_DIR = os.path.abspath(os.path.dirname(__file__))\n\n\n# Define a small helper function to alias our vendored modules to the real ones\n# if the vendored ones do not exist. This idea of this was taken from\n# https://github.com/kennethreitz/requests/pull/2567.\ndef vendored(modulename):\n    vendored_name = \"{0}.{1}\".format(__name__, modulename)\n\n    try:\n        __import__(modulename, globals(), locals(), level=0)\n    except ImportError:\n        # We can just silently allow import failures to pass here. If we\n        # got to this point it means that ``import pip._vendor.whatever``\n        # failed and so did ``import whatever``. Since we're importing this\n        # upfront in an attempt to alias imports, not erroring here will\n        # just mean we get a regular import error whenever pip *actually*\n        # tries to import one of these modules to use it, which actually\n        # gives us a better error message than we would have otherwise\n        # gotten.\n        pass\n    else:\n        sys.modules[vendored_name] = sys.modules[modulename]\n        base, head = vendored_name.rsplit(\".\", 1)\n        setattr(sys.modules[base], head, sys.modules[modulename])\n\n\n# If we're operating in a debundled setup, then we want to go ahead and trigger\n# the aliasing of our vendored libraries as well as looking for wheels to add\n# to our sys.path. This will cause all of this code to be a no-op typically\n# however downstream redistributors can enable it in a consistent way across\n# all platforms.\nif DEBUNDLED:\n    # Actually look inside of WHEEL_DIR to find .whl files and add them to the\n    # front of our sys.path.\n    sys.path[:] = glob.glob(os.path.join(WHEEL_DIR, \"*.whl\")) + sys.path\n\n    # Actually alias all of our vendored dependencies.\n    vendored(\"cachecontrol\")\n    vendored(\"certifi\")\n    vendored(\"dependency-groups\")\n    vendored(\"distlib\")\n    vendored(\"distro\")\n    vendored(\"packaging\")\n    vendored(\"packaging.version\")\n    vendored(\"packaging.specifiers\")\n    vendored(\"pkg_resources\")\n    vendored(\"platformdirs\")\n    vendored(\"progress\")\n    vendored(\"pyproject_hooks\")\n    vendored(\"requests\")\n    vendored(\"requests.exceptions\")\n    vendored(\"requests.packages\")\n    vendored(\"requests.packages.urllib3\")\n    vendored(\"requests.packages.urllib3._collections\")\n    vendored(\"requests.packages.urllib3.connection\")\n    vendored(\"requests.packages.urllib3.connectionpool\")\n    vendored(\"requests.packages.urllib3.contrib\")\n    vendored(\"requests.packages.urllib3.contrib.ntlmpool\")\n    vendored(\"requests.packages.urllib3.contrib.pyopenssl\")\n    vendored(\"requests.packages.urllib3.exceptions\")\n    vendored(\"requests.packages.urllib3.fields\")\n    vendored(\"requests.packages.urllib3.filepost\")\n    vendored(\"requests.packages.urllib3.packages\")\n    vendored(\"requests.packages.urllib3.packages.ordered_dict\")\n    vendored(\"requests.packages.urllib3.packages.six\")\n    vendored(\"requests.packages.urllib3.packages.ssl_match_hostname\")\n    vendored(\"requests.packages.urllib3.packages.ssl_match_hostname.\"\n             \"_implementation\")\n    vendored(\"requests.packages.urllib3.poolmanager\")\n    vendored(\"requests.packages.urllib3.request\")\n    vendored(\"requests.packages.urllib3.response\")\n    vendored(\"requests.packages.urllib3.util\")\n    vendored(\"requests.packages.urllib3.util.connection\")\n    vendored(\"requests.packages.urllib3.util.request\")\n    vendored(\"requests.packages.urllib3.util.response\")\n    vendored(\"requests.packages.urllib3.util.retry\")\n    vendored(\"requests.packages.urllib3.util.ssl_\")\n    vendored(\"requests.packages.urllib3.util.timeout\")\n    vendored(\"requests.packages.urllib3.util.url\")\n    vendored(\"resolvelib\")\n    vendored(\"rich\")\n    vendored(\"rich.console\")\n    vendored(\"rich.highlighter\")\n    vendored(\"rich.logging\")\n    vendored(\"rich.markup\")\n    vendored(\"rich.progress\")\n    vendored(\"rich.segment\")\n    vendored(\"rich.style\")\n    vendored(\"rich.text\")\n    vendored(\"rich.traceback\")\n    if sys.version_info < (3, 11):\n        vendored(\"tomli\")\n    vendored(\"truststore\")\n    vendored(\"urllib3\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\adapter.py": {
      "sha": "87cedb543239",
      "lines": 168,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\nfrom __future__ import annotations\n\nimport functools\nimport types\nimport weakref\nimport zlib\nfrom typing import TYPE_CHECKING, Any, Collection, Mapping\n\nfrom pip._vendor.requests.adapters import HTTPAdapter\n\nfrom pip._vendor.cachecontrol.cache import DictCache\nfrom pip._vendor.cachecontrol.controller import PERMANENT_REDIRECT_STATUSES, CacheController\nfrom pip._vendor.cachecontrol.filewrapper import CallbackFileWrapper\n\nif TYPE_CHECKING:\n    from pip._vendor.requests import PreparedRequest, Response\n    from pip._vendor.urllib3 import HTTPResponse\n\n    from pip._vendor.cachecontrol.cache import BaseCache\n    from pip._vendor.cachecontrol.heuristics import BaseHeuristic\n    from pip._vendor.cachecontrol.serialize import Serializer\n\n\nclass CacheControlAdapter(HTTPAdapter):\n    invalidating_methods = {\"PUT\", \"PATCH\", \"DELETE\"}\n\n    def __init__(\n        self,\n        cache: BaseCache | None = None,\n        cache_etags: bool = True,\n        controller_class: type[CacheController] | None = None,\n        serializer: Serializer | None = None,\n        heuristic: BaseHeuristic | None = None,\n        cacheable_methods: Collection[str] | None = None,\n        *args: Any,\n        **kw: Any,\n    ) -> None:\n        super().__init__(*args, **kw)\n        self.cache = DictCache() if cache is None else cache\n        self.heuristic = heuristic\n        self.cacheable_methods = cacheable_methods or (\"GET\",)\n\n        controller_factory = controller_class or CacheController\n        self.controller = controller_factory(\n            self.cache, cache_etags=cache_etags, serializer=serializer\n        )\n\n    def send(\n        self,\n        request: PreparedRequest,\n        stream: bool = False,\n        timeout: None | float | tuple[float, float] | tuple[float, None] = None,\n        verify: bool | str = True,\n        cert: (None | bytes | str | tuple[bytes | str, bytes | str]) = None,\n        proxies: Mapping[str, str] | None = None,\n        cacheable_methods: Collection[str] | None = None,\n    ) -> Response:\n        \"\"\"\n        Send a request. Use the request information to see if it\n        exists in the cache and cache the response if we need to and can.\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if request.method in cacheable:\n            try:\n                cached_response = self.controller.cached_request(request)\n            except zlib.error:\n                cached_response = None\n            if cached_response:\n                return self.build_response(request, cached_response, from_cache=True)\n\n            # check for etags and add headers if appropriate\n            request.headers.update(self.controller.conditional_headers(request))\n\n        resp = super().send(request, stream, timeout, verify, cert, proxies)\n\n        return resp\n\n    def build_response(  # type: ignore[override]\n        self,\n        request: PreparedRequest,\n        response: HTTPResponse,\n        from_cache: bool = False,\n        cacheable_methods: Collection[str] | None = None,\n    ) -> Response:\n        \"\"\"\n        Build a response by making a request or using the cache.\n\n        This will end up calling send and returning a potentially\n        cached response\n        \"\"\"\n        cacheable = cacheable_methods or self.cacheable_methods\n        if not from_cache and request.method in cacheable:\n            # Check for any heuristics that might update headers\n            # before trying to cache.\n            if self.heuristic:\n                response = self.heuristic.apply(response)\n\n            # apply any expiration heuristics\n            if response.status == 304:\n                # We must have sent an ETag request. This could mean\n                # that we've been expired already or that we simply\n                # have an etag. In either case, we want to try and\n                # update the cache if that is the case.\n                cached_response = self.controller.update_cached_response(\n                    request, response\n                )\n\n                if cached_response is not response:\n                    from_cache = True\n\n                # We are done with the server response, read a\n                # possible response body (compliant servers will\n                # not return one, but we cannot be 100% sure) and\n                # release the connection back to the pool.\n                response.read(decode_content=False)\n                response.release_conn()\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\cache.py": {
      "sha": "0fc135d60859",
      "lines": 75,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\n\n\"\"\"\nThe cache object API for implementing caches. The default is a thread\nsafe in-memory dictionary.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom threading import Lock\nfrom typing import IO, TYPE_CHECKING, MutableMapping\n\nif TYPE_CHECKING:\n    from datetime import datetime\n\n\nclass BaseCache:\n    def get(self, key: str) -> bytes | None:\n        raise NotImplementedError()\n\n    def set(\n        self, key: str, value: bytes, expires: int | datetime | None = None\n    ) -> None:\n        raise NotImplementedError()\n\n    def delete(self, key: str) -> None:\n        raise NotImplementedError()\n\n    def close(self) -> None:\n        pass\n\n\nclass DictCache(BaseCache):\n    def __init__(self, init_dict: MutableMapping[str, bytes] | None = None) -> None:\n        self.lock = Lock()\n        self.data = init_dict or {}\n\n    def get(self, key: str) -> bytes | None:\n        return self.data.get(key, None)\n\n    def set(\n        self, key: str, value: bytes, expires: int | datetime | None = None\n    ) -> None:\n        with self.lock:\n            self.data.update({key: value})\n\n    def delete(self, key: str) -> None:\n        with self.lock:\n            if key in self.data:\n                self.data.pop(key)\n\n\nclass SeparateBodyBaseCache(BaseCache):\n    \"\"\"\n    In this variant, the body is not stored mixed in with the metadata, but is\n    passed in (as a bytes-like object) in a separate call to ``set_body()``.\n\n    That is, the expected interaction pattern is::\n\n        cache.set(key, serialized_metadata)\n        cache.set_body(key)\n\n    Similarly, the body should be loaded separately via ``get_body()``.\n    \"\"\"\n\n    def set_body(self, key: str, body: bytes) -> None:\n        raise NotImplementedError()\n\n    def get_body(self, key: str) -> IO[bytes] | None:\n        \"\"\"\n        Return the body as file-like object.\n        \"\"\"\n        raise NotImplementedError()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\controller.py": {
      "sha": "f6b2b89e857b",
      "lines": 511,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\n\n\"\"\"\nThe httplib2 algorithms ported for use with requests.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport calendar\nimport logging\nimport re\nimport time\nimport weakref\nfrom email.utils import parsedate_tz\nfrom typing import TYPE_CHECKING, Collection, Mapping\n\nfrom pip._vendor.requests.structures import CaseInsensitiveDict\n\nfrom pip._vendor.cachecontrol.cache import DictCache, SeparateBodyBaseCache\nfrom pip._vendor.cachecontrol.serialize import Serializer\n\nif TYPE_CHECKING:\n    from typing import Literal\n\n    from pip._vendor.requests import PreparedRequest\n    from pip._vendor.urllib3 import HTTPResponse\n\n    from pip._vendor.cachecontrol.cache import BaseCache\n\nlogger = logging.getLogger(__name__)\n\nURI = re.compile(r\"^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?\")\n\nPERMANENT_REDIRECT_STATUSES = (301, 308)\n\n\ndef parse_uri(uri: str) -> tuple[str, str, str, str, str]:\n    \"\"\"Parses a URI using the regex given in Appendix B of RFC 3986.\n\n    (scheme, authority, path, query, fragment) = parse_uri(uri)\n    \"\"\"\n    match = URI.match(uri)\n    assert match is not None\n    groups = match.groups()\n    return (groups[1], groups[3], groups[4], groups[6], groups[8])\n\n\nclass CacheController:\n    \"\"\"An interface to see if request should cached or not.\"\"\"\n\n    def __init__(\n        self,\n        cache: BaseCache | None = None,\n        cache_etags: bool = True,\n        serializer: Serializer | None = None,\n        status_codes: Collection[int] | None = None,\n    ):\n        self.cache = DictCache() if cache is None else cache\n        self.cache_etags = cache_etags\n        self.serializer = serializer or Serializer()\n        self.cacheable_status_codes = status_codes or (200, 203, 300, 301, 308)\n\n    @classmethod\n    def _urlnorm(cls, uri: str) -> str:\n        \"\"\"Normalize the URL to create a safe key for the cache\"\"\"\n        (scheme, authority, path, query, fragment) = parse_uri(uri)\n        if not scheme or not authority:\n            raise Exception(\"Only absolute URIs are allowed. uri = %s\" % uri)\n\n        scheme = scheme.lower()\n        authority = authority.lower()\n\n        if not path:\n            path = \"/\"\n\n        # Could do syntax based normalization of the URI before\n        # computing the digest. See Section 6.2.2 of Std 66.\n        request_uri = query and \"?\".join([path, query]) or path\n        defrag_uri = scheme + \"://\" + authority + request_uri\n\n        return defrag_uri\n\n    @classmethod\n    def cache_url(cls, uri: str) -> str:\n        return cls._urlnorm(uri)\n\n    def parse_cache_control(self, headers: Mapping[str, str]) -> dict[str, int | None]:\n        known_directives = {\n            # https://tools.ietf.org/html/rfc7234#section-5.2\n            \"max-age\": (int, True),\n            \"max-stale\": (int, False),\n            \"min-fresh\": (int, True),\n            \"no-cache\": (None, False),\n            \"no-store\": (None, False),\n            \"no-transform\": (None, False),\n            \"only-if-cached\": (None, False),\n            \"must-revalidate\": (None, False),\n            \"public\": (None, False),\n            \"private\": (None, False),\n            \"proxy-revalidate\": (None, False),\n            \"s-maxage\": (int, True),\n        }\n\n        cc_headers = headers.get(\"cache-control\", headers.get(\"Cache-Control\", \"\"))\n\n        retval: dict[str, int | None] = {}\n\n        for cc_directive in cc_headers.split(\",\"):\n            if not cc_directive.strip():\n                continue\n\n            parts = cc_directive.split(\"=\", 1)\n            directive = parts[0].strip()\n\n            try:\n                typ, required = known_directives[directive]\n            except KeyError:\n                logger.debug(\"Ignoring unknown cache-control directive: %s\", directive)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py": {
      "sha": "ba704c17823c",
      "lines": 119,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\nfrom __future__ import annotations\n\nimport mmap\nfrom tempfile import NamedTemporaryFile\nfrom typing import TYPE_CHECKING, Any, Callable\n\nif TYPE_CHECKING:\n    from http.client import HTTPResponse\n\n\nclass CallbackFileWrapper:\n    \"\"\"\n    Small wrapper around a fp object which will tee everything read into a\n    buffer, and when that file is closed it will execute a callback with the\n    contents of that buffer.\n\n    All attributes are proxied to the underlying file object.\n\n    This class uses members with a double underscore (__) leading prefix so as\n    not to accidentally shadow an attribute.\n\n    The data is stored in a temporary file until it is all available.  As long\n    as the temporary files directory is disk-based (sometimes it's a\n    memory-backed-``tmpfs`` on Linux), data will be unloaded to disk if memory\n    pressure is high.  For small files the disk usually won't be used at all,\n    it'll all be in the filesystem memory cache, so there should be no\n    performance impact.\n    \"\"\"\n\n    def __init__(\n        self, fp: HTTPResponse, callback: Callable[[bytes], None] | None\n    ) -> None:\n        self.__buf = NamedTemporaryFile(\"rb+\", delete=True)\n        self.__fp = fp\n        self.__callback = callback\n\n    def __getattr__(self, name: str) -> Any:\n        # The vagaries of garbage collection means that self.__fp is\n        # not always set.  By using __getattribute__ and the private\n        # name[0] allows looking up the attribute value and raising an\n        # AttributeError when it doesn't exist. This stop things from\n        # infinitely recursing calls to getattr in the case where\n        # self.__fp hasn't been set.\n        #\n        # [0] https://docs.python.org/2/reference/expressions.html#atom-identifiers\n        fp = self.__getattribute__(\"_CallbackFileWrapper__fp\")\n        return getattr(fp, name)\n\n    def __is_fp_closed(self) -> bool:\n        try:\n            return self.__fp.fp is None\n\n        except AttributeError:\n            pass\n\n        try:\n            closed: bool = self.__fp.closed\n            return closed\n\n        except AttributeError:\n            pass\n\n        # We just don't cache it then.\n        # TODO: Add some logging here...\n        return False\n\n    def _close(self) -> None:\n        if self.__callback:\n            if self.__buf.tell() == 0:\n                # Empty file:\n                result = b\"\"\n            else:\n                # Return the data without actually loading it into memory,\n                # relying on Python's buffer API and mmap(). mmap() just gives\n                # a view directly into the filesystem's memory cache, so it\n                # doesn't result in duplicate memory use.\n                self.__buf.seek(0, 0)\n                result = memoryview(\n                    mmap.mmap(self.__buf.fileno(), 0, access=mmap.ACCESS_READ)\n                )\n            self.__callback(result)\n\n        # We assign this to None here, because otherwise we can get into\n        # really tricky problems where the CPython interpreter dead locks\n        # because the callback is holding a reference to something which\n        # has a __del__ method. Setting this to None breaks the cycle\n        # and allows the garbage collector to do it's thing normally.\n        self.__callback = None\n\n        # Closing the temporary file releases memory and frees disk space.\n        # Important when caching big files.\n        self.__buf.close()\n\n    def read(self, amt: int | None = None) -> bytes:\n        data: bytes = self.__fp.read(amt)\n        if data:\n            # We may be dealing with b'', a sign that things are over:\n            # it's passed e.g. after we've already closed self.__buf.\n            self.__buf.write(data)\n        if self.__is_fp_closed():\n            self._close()\n\n        return data\n\n    def _safe_read(self, amt: int) -> bytes:\n        data: bytes = self.__fp._safe_read(amt)  # type: ignore[attr-defined]\n        if amt == 2 and data == b\"\\r\\n\":\n            # urllib executes this read to toss the CRLF at the end\n            # of the chunk.\n            return data\n\n        self.__buf.write(data)\n        if self.__is_fp_closed():\n            self._close()\n\n        return data\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\heuristics.py": {
      "sha": "4af5a786e9cc",
      "lines": 157,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\nfrom __future__ import annotations\n\nimport calendar\nimport time\nfrom datetime import datetime, timedelta, timezone\nfrom email.utils import formatdate, parsedate, parsedate_tz\nfrom typing import TYPE_CHECKING, Any, Mapping\n\nif TYPE_CHECKING:\n    from pip._vendor.urllib3 import HTTPResponse\n\nTIME_FMT = \"%a, %d %b %Y %H:%M:%S GMT\"\n\n\ndef expire_after(delta: timedelta, date: datetime | None = None) -> datetime:\n    date = date or datetime.now(timezone.utc)\n    return date + delta\n\n\ndef datetime_to_header(dt: datetime) -> str:\n    return formatdate(calendar.timegm(dt.timetuple()))\n\n\nclass BaseHeuristic:\n    def warning(self, response: HTTPResponse) -> str | None:\n        \"\"\"\n        Return a valid 1xx warning header value describing the cache\n        adjustments.\n\n        The response is provided too allow warnings like 113\n        http://tools.ietf.org/html/rfc7234#section-5.5.4 where we need\n        to explicitly say response is over 24 hours old.\n        \"\"\"\n        return '110 - \"Response is Stale\"'\n\n    def update_headers(self, response: HTTPResponse) -> dict[str, str]:\n        \"\"\"Update the response headers with any new headers.\n\n        NOTE: This SHOULD always include some Warning header to\n              signify that the response was cached by the client, not\n              by way of the provided headers.\n        \"\"\"\n        return {}\n\n    def apply(self, response: HTTPResponse) -> HTTPResponse:\n        updated_headers = self.update_headers(response)\n\n        if updated_headers:\n            response.headers.update(updated_headers)\n            warning_header_value = self.warning(response)\n            if warning_header_value is not None:\n                response.headers.update({\"Warning\": warning_header_value})\n\n        return response\n\n\nclass OneDayCache(BaseHeuristic):\n    \"\"\"\n    Cache the response by providing an expires 1 day in the\n    future.\n    \"\"\"\n\n    def update_headers(self, response: HTTPResponse) -> dict[str, str]:\n        headers = {}\n\n        if \"expires\" not in response.headers:\n            date = parsedate(response.headers[\"date\"])\n            expires = expire_after(\n                timedelta(days=1),\n                date=datetime(*date[:6], tzinfo=timezone.utc),  # type: ignore[index,misc]\n            )\n            headers[\"expires\"] = datetime_to_header(expires)\n            headers[\"cache-control\"] = \"public\"\n        return headers\n\n\nclass ExpiresAfter(BaseHeuristic):\n    \"\"\"\n    Cache **all** requests for a defined time period.\n    \"\"\"\n\n    def __init__(self, **kw: Any) -> None:\n        self.delta = timedelta(**kw)\n\n    def update_headers(self, response: HTTPResponse) -> dict[str, str]:\n        expires = expire_after(self.delta)\n        return {\"expires\": datetime_to_header(expires), \"cache-control\": \"public\"}\n\n    def warning(self, response: HTTPResponse) -> str | None:\n        tmpl = \"110 - Automatically cached for %s. Response might be stale\"\n        return tmpl % self.delta\n\n\nclass LastModified(BaseHeuristic):\n    \"\"\"\n    If there is no Expires header already, fall back on Last-Modified\n    using the heuristic from\n    http://tools.ietf.org/html/rfc7234#section-4.2.2\n    to calculate a reasonable value.\n\n    Firefox also does something like this per\n    https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching_FAQ\n    http://lxr.mozilla.org/mozilla-release/source/netwerk/protocol/http/nsHttpResponseHead.cpp#397\n    Unlike mozilla we limit this to 24-hr.\n    \"\"\"\n\n    cacheable_by_default_statuses = {\n        200,\n        203,\n        204,\n        206,\n        300,\n        301,\n        404,\n        405,\n        410,\n        414,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\serialize.py": {
      "sha": "05f19d4dd2fb",
      "lines": 146,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\nfrom __future__ import annotations\n\nimport io\nfrom typing import IO, TYPE_CHECKING, Any, Mapping, cast\n\nfrom pip._vendor import msgpack\nfrom pip._vendor.requests.structures import CaseInsensitiveDict\nfrom pip._vendor.urllib3 import HTTPResponse\n\nif TYPE_CHECKING:\n    from pip._vendor.requests import PreparedRequest\n\n\nclass Serializer:\n    serde_version = \"4\"\n\n    def dumps(\n        self,\n        request: PreparedRequest,\n        response: HTTPResponse,\n        body: bytes | None = None,\n    ) -> bytes:\n        response_headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(\n            response.headers\n        )\n\n        if body is None:\n            # When a body isn't passed in, we'll read the response. We\n            # also update the response with a new file handler to be\n            # sure it acts as though it was never read.\n            body = response.read(decode_content=False)\n            response._fp = io.BytesIO(body)  # type: ignore[assignment]\n            response.length_remaining = len(body)\n\n        data = {\n            \"response\": {\n                \"body\": body,  # Empty bytestring if body is stored separately\n                \"headers\": {str(k): str(v) for k, v in response.headers.items()},\n                \"status\": response.status,\n                \"version\": response.version,\n                \"reason\": str(response.reason),\n                \"decode_content\": response.decode_content,\n            }\n        }\n\n        # Construct our vary headers\n        data[\"vary\"] = {}\n        if \"vary\" in response_headers:\n            varied_headers = response_headers[\"vary\"].split(\",\")\n            for header in varied_headers:\n                header = str(header).strip()\n                header_value = request.headers.get(header, None)\n                if header_value is not None:\n                    header_value = str(header_value)\n                data[\"vary\"][header] = header_value\n\n        return b\",\".join([f\"cc={self.serde_version}\".encode(), self.serialize(data)])\n\n    def serialize(self, data: dict[str, Any]) -> bytes:\n        return cast(bytes, msgpack.dumps(data, use_bin_type=True))\n\n    def loads(\n        self,\n        request: PreparedRequest,\n        data: bytes,\n        body_file: IO[bytes] | None = None,\n    ) -> HTTPResponse | None:\n        # Short circuit if we've been given an empty set of data\n        if not data:\n            return None\n\n        # Previous versions of this library supported other serialization\n        # formats, but these have all been removed.\n        if not data.startswith(f\"cc={self.serde_version},\".encode()):\n            return None\n\n        data = data[5:]\n        return self._loads_v4(request, data, body_file)\n\n    def prepare_response(\n        self,\n        request: PreparedRequest,\n        cached: Mapping[str, Any],\n        body_file: IO[bytes] | None = None,\n    ) -> HTTPResponse | None:\n        \"\"\"Verify our vary headers match and construct a real urllib3\n        HTTPResponse object.\n        \"\"\"\n        # Special case the '*' Vary value as it means we cannot actually\n        # determine if the cached response is suitable for this request.\n        # This case is also handled in the controller code when creating\n        # a cache entry, but is left here for backwards compatibility.\n        if \"*\" in cached.get(\"vary\", {}):\n            return None\n\n        # Ensure that the Vary headers for the cached response match our\n        # request\n        for header, value in cached.get(\"vary\", {}).items():\n            if request.headers.get(header, None) != value:\n                return None\n\n        body_raw = cached[\"response\"].pop(\"body\")\n\n        headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(\n            data=cached[\"response\"][\"headers\"]\n        )\n        if headers.get(\"transfer-encoding\", \"\") == \"chunked\":\n            headers.pop(\"transfer-encoding\")\n\n        cached[\"response\"][\"headers\"] = headers\n\n        try:\n            body: IO[bytes]\n            if body_file is None:\n                body = io.BytesIO(body_raw)\n            else:\n                body = body_file\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\wrapper.py": {
      "sha": "b18a7cf7fafc",
      "lines": 43,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Collection\n\nfrom pip._vendor.cachecontrol.adapter import CacheControlAdapter\nfrom pip._vendor.cachecontrol.cache import DictCache\n\nif TYPE_CHECKING:\n    from pip._vendor import requests\n\n    from pip._vendor.cachecontrol.cache import BaseCache\n    from pip._vendor.cachecontrol.controller import CacheController\n    from pip._vendor.cachecontrol.heuristics import BaseHeuristic\n    from pip._vendor.cachecontrol.serialize import Serializer\n\n\ndef CacheControl(\n    sess: requests.Session,\n    cache: BaseCache | None = None,\n    cache_etags: bool = True,\n    serializer: Serializer | None = None,\n    heuristic: BaseHeuristic | None = None,\n    controller_class: type[CacheController] | None = None,\n    adapter_class: type[CacheControlAdapter] | None = None,\n    cacheable_methods: Collection[str] | None = None,\n) -> requests.Session:\n    cache = DictCache() if cache is None else cache\n    adapter_class = adapter_class or CacheControlAdapter\n    adapter = adapter_class(\n        cache,\n        cache_etags=cache_etags,\n        serializer=serializer,\n        heuristic=heuristic,\n        controller_class=controller_class,\n        cacheable_methods=cacheable_methods,\n    )\n    sess.mount(\"http://\", adapter)\n    sess.mount(\"https://\", adapter)\n\n    return sess\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\_cmd.py": {
      "sha": "f9f1c294b57d",
      "lines": 70,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\nfrom __future__ import annotations\n\nimport logging\nfrom argparse import ArgumentParser\nfrom typing import TYPE_CHECKING\n\nfrom pip._vendor import requests\n\nfrom pip._vendor.cachecontrol.adapter import CacheControlAdapter\nfrom pip._vendor.cachecontrol.cache import DictCache\nfrom pip._vendor.cachecontrol.controller import logger\n\nif TYPE_CHECKING:\n    from argparse import Namespace\n\n    from pip._vendor.cachecontrol.controller import CacheController\n\n\ndef setup_logging() -> None:\n    logger.setLevel(logging.DEBUG)\n    handler = logging.StreamHandler()\n    logger.addHandler(handler)\n\n\ndef get_session() -> requests.Session:\n    adapter = CacheControlAdapter(\n        DictCache(), cache_etags=True, serializer=None, heuristic=None\n    )\n    sess = requests.Session()\n    sess.mount(\"http://\", adapter)\n    sess.mount(\"https://\", adapter)\n\n    sess.cache_controller = adapter.controller  # type: ignore[attr-defined]\n    return sess\n\n\ndef get_args() -> Namespace:\n    parser = ArgumentParser()\n    parser.add_argument(\"url\", help=\"The URL to try and cache\")\n    return parser.parse_args()\n\n\ndef main() -> None:\n    args = get_args()\n    sess = get_session()\n\n    # Make a request to get a response\n    resp = sess.get(args.url)\n\n    # Turn on logging\n    setup_logging()\n\n    # try setting the cache\n    cache_controller: CacheController = (\n        sess.cache_controller  # type: ignore[attr-defined]\n    )\n    cache_controller.cache_response(resp.request, resp.raw)\n\n    # Now try to get it\n    if cache_controller.cached_request(resp.request):\n        print(\"Cached!\")\n    else:\n        print(\"Not cached :(\")\n\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\__init__.py": {
      "sha": "255c1cf1d816",
      "lines": 29,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\n\n\"\"\"CacheControl import Interface.\n\nMake it easy to import from cachecontrol without long namespaces.\n\"\"\"\n\n__author__ = \"Eric Larson\"\n__email__ = \"eric@ionrock.org\"\n__version__ = \"0.14.2\"\n\nfrom pip._vendor.cachecontrol.adapter import CacheControlAdapter\nfrom pip._vendor.cachecontrol.controller import CacheController\nfrom pip._vendor.cachecontrol.wrapper import CacheControl\n\n__all__ = [\n    \"__author__\",\n    \"__email__\",\n    \"__version__\",\n    \"CacheControlAdapter\",\n    \"CacheController\",\n    \"CacheControl\",\n]\n\nimport logging\n\nlogging.getLogger(__name__).addHandler(logging.NullHandler())\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\caches\\file_cache.py": {
      "sha": "ce90d5b470f2",
      "lines": 145,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\nfrom __future__ import annotations\n\nimport hashlib\nimport os\nimport tempfile\nfrom textwrap import dedent\nfrom typing import IO, TYPE_CHECKING\nfrom pathlib import Path\n\nfrom pip._vendor.cachecontrol.cache import BaseCache, SeparateBodyBaseCache\nfrom pip._vendor.cachecontrol.controller import CacheController\n\nif TYPE_CHECKING:\n    from datetime import datetime\n\n    from filelock import BaseFileLock\n\n\nclass _FileCacheMixin:\n    \"\"\"Shared implementation for both FileCache variants.\"\"\"\n\n    def __init__(\n        self,\n        directory: str | Path,\n        forever: bool = False,\n        filemode: int = 0o0600,\n        dirmode: int = 0o0700,\n        lock_class: type[BaseFileLock] | None = None,\n    ) -> None:\n        try:\n            if lock_class is None:\n                from filelock import FileLock\n\n                lock_class = FileLock\n        except ImportError:\n            notice = dedent(\n                \"\"\"\n            NOTE: In order to use the FileCache you must have\n            filelock installed. You can install it via pip:\n              pip install cachecontrol[filecache]\n            \"\"\"\n            )\n            raise ImportError(notice)\n\n        self.directory = directory\n        self.forever = forever\n        self.filemode = filemode\n        self.dirmode = dirmode\n        self.lock_class = lock_class\n\n    @staticmethod\n    def encode(x: str) -> str:\n        return hashlib.sha224(x.encode()).hexdigest()\n\n    def _fn(self, name: str) -> str:\n        # NOTE: This method should not change as some may depend on it.\n        #       See: https://github.com/ionrock/cachecontrol/issues/63\n        hashed = self.encode(name)\n        parts = list(hashed[:5]) + [hashed]\n        return os.path.join(self.directory, *parts)\n\n    def get(self, key: str) -> bytes | None:\n        name = self._fn(key)\n        try:\n            with open(name, \"rb\") as fh:\n                return fh.read()\n\n        except FileNotFoundError:\n            return None\n\n    def set(\n        self, key: str, value: bytes, expires: int | datetime | None = None\n    ) -> None:\n        name = self._fn(key)\n        self._write(name, value)\n\n    def _write(self, path: str, data: bytes) -> None:\n        \"\"\"\n        Safely write the data to the given path.\n        \"\"\"\n        # Make sure the directory exists\n        dirname = os.path.dirname(path)\n        os.makedirs(dirname, self.dirmode, exist_ok=True)\n\n        with self.lock_class(path + \".lock\"):\n            # Write our actual file\n            (fd, name) = tempfile.mkstemp(dir=dirname)\n            try:\n                os.write(fd, data)\n            finally:\n                os.close(fd)\n            os.chmod(name, self.filemode)\n            os.replace(name, path)\n\n    def _delete(self, key: str, suffix: str) -> None:\n        name = self._fn(key) + suffix\n        if not self.forever:\n            try:\n                os.remove(name)\n            except FileNotFoundError:\n                pass\n\n\nclass FileCache(_FileCacheMixin, BaseCache):\n    \"\"\"\n    Traditional FileCache: body is stored in memory, so not suitable for large\n    downloads.\n    \"\"\"\n\n    def delete(self, key: str) -> None:\n        self._delete(key, \"\")\n\n\nclass SeparateBodyFileCache(_FileCacheMixin, SeparateBodyBaseCache):\n    \"\"\"\n    Memory-efficient FileCache: body is stored in a separate file, reducing\n    peak memory usage.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\caches\\redis_cache.py": {
      "sha": "4049dd3d0f66",
      "lines": 48,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\nfrom __future__ import annotations\n\n\nfrom datetime import datetime, timezone\nfrom typing import TYPE_CHECKING\n\nfrom pip._vendor.cachecontrol.cache import BaseCache\n\nif TYPE_CHECKING:\n    from redis import Redis\n\n\nclass RedisCache(BaseCache):\n    def __init__(self, conn: Redis[bytes]) -> None:\n        self.conn = conn\n\n    def get(self, key: str) -> bytes | None:\n        return self.conn.get(key)\n\n    def set(\n        self, key: str, value: bytes, expires: int | datetime | None = None\n    ) -> None:\n        if not expires:\n            self.conn.set(key, value)\n        elif isinstance(expires, datetime):\n            now_utc = datetime.now(timezone.utc)\n            if expires.tzinfo is None:\n                now_utc = now_utc.replace(tzinfo=None)\n            delta = expires - now_utc\n            self.conn.setex(key, int(delta.total_seconds()), value)\n        else:\n            self.conn.setex(key, expires, value)\n\n    def delete(self, key: str) -> None:\n        self.conn.delete(key)\n\n    def clear(self) -> None:\n        \"\"\"Helper for clearing all the keys in a database. Use with\n        caution!\"\"\"\n        for key in self.conn.keys():\n            self.conn.delete(key)\n\n    def close(self) -> None:\n        \"\"\"Redis uses connection pooling, no need to close the connection.\"\"\"\n        pass\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\caches\\__init__.py": {
      "sha": "1e2ecfdebcf4",
      "lines": 8,
      "head": "# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\n\nfrom pip._vendor.cachecontrol.caches.file_cache import FileCache, SeparateBodyFileCache\nfrom pip._vendor.cachecontrol.caches.redis_cache import RedisCache\n\n__all__ = [\"FileCache\", \"SeparateBodyFileCache\", \"RedisCache\"]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\certifi\\core.py": {
      "sha": "134c12ec63cc",
      "lines": 114,
      "head": "\"\"\"\ncertifi.py\n~~~~~~~~~~\n\nThis module returns the installation location of cacert.pem or its contents.\n\"\"\"\nimport sys\nimport atexit\n\ndef exit_cacert_ctx() -> None:\n    _CACERT_CTX.__exit__(None, None, None)  # type: ignore[union-attr]\n\n\nif sys.version_info >= (3, 11):\n\n    from importlib.resources import as_file, files\n\n    _CACERT_CTX = None\n    _CACERT_PATH = None\n\n    def where() -> str:\n        # This is slightly terrible, but we want to delay extracting the file\n        # in cases where we're inside of a zipimport situation until someone\n        # actually calls where(), but we don't want to re-extract the file\n        # on every call of where(), so we'll do it once then store it in a\n        # global variable.\n        global _CACERT_CTX\n        global _CACERT_PATH\n        if _CACERT_PATH is None:\n            # This is slightly janky, the importlib.resources API wants you to\n            # manage the cleanup of this file, so it doesn't actually return a\n            # path, it returns a context manager that will give you the path\n            # when you enter it and will do any cleanup when you leave it. In\n            # the common case of not needing a temporary file, it will just\n            # return the file system location and the __exit__() is a no-op.\n            #\n            # We also have to hold onto the actual context manager, because\n            # it will do the cleanup whenever it gets garbage collected, so\n            # we will also store that at the global level as well.\n            _CACERT_CTX = as_file(files(\"pip._vendor.certifi\").joinpath(\"cacert.pem\"))\n            _CACERT_PATH = str(_CACERT_CTX.__enter__())\n            atexit.register(exit_cacert_ctx)\n\n        return _CACERT_PATH\n\n    def contents() -> str:\n        return files(\"pip._vendor.certifi\").joinpath(\"cacert.pem\").read_text(encoding=\"ascii\")\n\nelif sys.version_info >= (3, 7):\n\n    from importlib.resources import path as get_path, read_text\n\n    _CACERT_CTX = None\n    _CACERT_PATH = None\n\n    def where() -> str:\n        # This is slightly terrible, but we want to delay extracting the\n        # file in cases where we're inside of a zipimport situation until\n        # someone actually calls where(), but we don't want to re-extract\n        # the file on every call of where(), so we'll do it once then store\n        # it in a global variable.\n        global _CACERT_CTX\n        global _CACERT_PATH\n        if _CACERT_PATH is None:\n            # This is slightly janky, the importlib.resources API wants you\n            # to manage the cleanup of this file, so it doesn't actually\n            # return a path, it returns a context manager that will give\n            # you the path when you enter it and will do any cleanup when\n            # you leave it. In the common case of not needing a temporary\n            # file, it will just return the file system location and the\n            # __exit__() is a no-op.\n            #\n            # We also have to hold onto the actual context manager, because\n            # it will do the cleanup whenever it gets garbage collected, so\n            # we will also store that at the global level as well.\n            _CACERT_CTX = get_path(\"pip._vendor.certifi\", \"cacert.pem\")\n            _CACERT_PATH = str(_CACERT_CTX.__enter__())\n            atexit.register(exit_cacert_ctx)\n\n        return _CACERT_PATH\n\n    def contents() -> str:\n        return read_text(\"pip._vendor.certifi\", \"cacert.pem\", encoding=\"ascii\")\n\nelse:\n    import os\n    import types\n    from typing import Union\n\n    Package = Union[types.ModuleType, str]\n    Resource = Union[str, \"os.PathLike\"]\n\n    # This fallback will work for Python versions prior to 3.7 that lack the\n    # importlib.resources module but relies on the existing `where` function\n    # so won't address issues with environments like PyOxidizer that don't set\n    # __file__ on modules.\n    def read_text(\n        package: Package,\n        resource: Resource,\n        encoding: str = 'utf-8',\n        errors: str = 'strict'\n    ) -> str:\n        with open(where(), encoding=encoding) as data:\n            return data.read()\n\n    # If we don't have importlib.resources, then we will just do the old logic\n    # of assuming we're on the filesystem and munge the path directly.\n    def where() -> str:\n        f = os.path.dirname(__file__)\n\n        return os.path.join(f, \"cacert.pem\")\n\n    def contents() -> str:\n        return read_text(\"pip._vendor.certifi\", \"cacert.pem\", encoding=\"ascii\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\certifi\\__init__.py": {
      "sha": "fe74e03d30b4",
      "lines": 4,
      "head": "from .core import contents, where\n\n__all__ = [\"contents\", \"where\"]\n__version__ = \"2025.01.31\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\certifi\\__main__.py": {
      "sha": "94de655e7e05",
      "lines": 12,
      "head": "import argparse\n\nfrom pip._vendor.certifi import contents, where\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-c\", \"--contents\", action=\"store_true\")\nargs = parser.parse_args()\n\nif args.contents:\n    print(contents())\nelse:\n    print(where())\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\_implementation.py": {
      "sha": "f1ca63c1088e",
      "lines": 209,
      "head": "from __future__ import annotations\n\nimport dataclasses\nimport re\nfrom collections.abc import Mapping\n\nfrom pip._vendor.packaging.requirements import Requirement\n\n\ndef _normalize_name(name: str) -> str:\n    return re.sub(r\"[-_.]+\", \"-\", name).lower()\n\n\ndef _normalize_group_names(\n    dependency_groups: Mapping[str, str | Mapping[str, str]],\n) -> Mapping[str, str | Mapping[str, str]]:\n    original_names: dict[str, list[str]] = {}\n    normalized_groups = {}\n\n    for group_name, value in dependency_groups.items():\n        normed_group_name = _normalize_name(group_name)\n        original_names.setdefault(normed_group_name, []).append(group_name)\n        normalized_groups[normed_group_name] = value\n\n    errors = []\n    for normed_name, names in original_names.items():\n        if len(names) > 1:\n            errors.append(f\"{normed_name} ({', '.join(names)})\")\n    if errors:\n        raise ValueError(f\"Duplicate dependency group names: {', '.join(errors)}\")\n\n    return normalized_groups\n\n\n@dataclasses.dataclass\nclass DependencyGroupInclude:\n    include_group: str\n\n\nclass CyclicDependencyError(ValueError):\n    \"\"\"\n    An error representing the detection of a cycle.\n    \"\"\"\n\n    def __init__(self, requested_group: str, group: str, include_group: str) -> None:\n        self.requested_group = requested_group\n        self.group = group\n        self.include_group = include_group\n\n        if include_group == group:\n            reason = f\"{group} includes itself\"\n        else:\n            reason = f\"{include_group} -> {group}, {group} -> {include_group}\"\n        super().__init__(\n            \"Cyclic dependency group include while resolving \"\n            f\"{requested_group}: {reason}\"\n        )\n\n\nclass DependencyGroupResolver:\n    \"\"\"\n    A resolver for Dependency Group data.\n\n    This class handles caching, name normalization, cycle detection, and other\n    parsing requirements. There are only two public methods for exploring the data:\n    ``lookup()`` and ``resolve()``.\n\n    :param dependency_groups: A mapping, as provided via pyproject\n        ``[dependency-groups]``.\n    \"\"\"\n\n    def __init__(\n        self,\n        dependency_groups: Mapping[str, str | Mapping[str, str]],\n    ) -> None:\n        if not isinstance(dependency_groups, Mapping):\n            raise TypeError(\"Dependency Groups table is not a mapping\")\n        self.dependency_groups = _normalize_group_names(dependency_groups)\n        # a map of group names to parsed data\n        self._parsed_groups: dict[\n            str, tuple[Requirement | DependencyGroupInclude, ...]\n        ] = {}\n        # a map of group names to their ancestors, used for cycle detection\n        self._include_graph_ancestors: dict[str, tuple[str, ...]] = {}\n        # a cache of completed resolutions to Requirement lists\n        self._resolve_cache: dict[str, tuple[Requirement, ...]] = {}\n\n    def lookup(self, group: str) -> tuple[Requirement | DependencyGroupInclude, ...]:\n        \"\"\"\n        Lookup a group name, returning the parsed dependency data for that group.\n        This will not resolve includes.\n\n        :param group: the name of the group to lookup\n\n        :raises ValueError: if the data does not appear to be valid dependency group\n            data\n        :raises TypeError: if the data is not a string\n        :raises LookupError: if group name is absent\n        :raises packaging.requirements.InvalidRequirement: if a specifier is not valid\n        \"\"\"\n        if not isinstance(group, str):\n            raise TypeError(\"Dependency group name is not a str\")\n        group = _normalize_name(group)\n        return self._parse_group(group)\n\n    def resolve(self, group: str) -> tuple[Requirement, ...]:\n        \"\"\"\n        Resolve a dependency group to a list of requirements.\n\n        :param group: the name of the group to resolve\n\n        :raises TypeError: if the inputs appear to be the wrong types\n        :raises ValueError: if the data does not appear to be valid dependency group\n            data\n        :raises LookupError: if group name is absent\n        :raises packaging.requirements.InvalidRequirement: if a specifier is not valid\n        \"\"\"\n        if not isinstance(group, str):\n            raise TypeError(\"Dependency group name is not a str\")\n        group = _normalize_name(group)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\_lint_dependency_groups.py": {
      "sha": "a2638e576ac3",
      "lines": 59,
      "head": "from __future__ import annotations\n\nimport argparse\nimport sys\n\nfrom ._implementation import DependencyGroupResolver\nfrom ._toml_compat import tomllib\n\n\ndef main(*, argv: list[str] | None = None) -> None:\n    if tomllib is None:\n        print(\n            \"Usage error: dependency-groups CLI requires tomli or Python 3.11+\",\n            file=sys.stderr,\n        )\n        raise SystemExit(2)\n\n    parser = argparse.ArgumentParser(\n        description=(\n            \"Lint Dependency Groups for validity. \"\n            \"This will eagerly load and check all of your Dependency Groups.\"\n        )\n    )\n    parser.add_argument(\n        \"-f\",\n        \"--pyproject-file\",\n        default=\"pyproject.toml\",\n        help=\"The pyproject.toml file. Defaults to trying in the current directory.\",\n    )\n    args = parser.parse_args(argv if argv is not None else sys.argv[1:])\n\n    with open(args.pyproject_file, \"rb\") as fp:\n        pyproject = tomllib.load(fp)\n    dependency_groups_raw = pyproject.get(\"dependency-groups\", {})\n\n    errors: list[str] = []\n    try:\n        resolver = DependencyGroupResolver(dependency_groups_raw)\n    except (ValueError, TypeError) as e:\n        errors.append(f\"{type(e).__name__}: {e}\")\n    else:\n        for groupname in resolver.dependency_groups:\n            try:\n                resolver.resolve(groupname)\n            except (LookupError, ValueError, TypeError) as e:\n                errors.append(f\"{type(e).__name__}: {e}\")\n\n    if errors:\n        print(\"errors encountered while examining dependency groups:\")\n        for msg in errors:\n            print(f\"  {msg}\")\n        sys.exit(1)\n    else:\n        print(\"ok\")\n        sys.exit(0)\n\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\_pip_wrapper.py": {
      "sha": "8b75d17a5281",
      "lines": 62,
      "head": "from __future__ import annotations\n\nimport argparse\nimport subprocess\nimport sys\n\nfrom ._implementation import DependencyGroupResolver\nfrom ._toml_compat import tomllib\n\n\ndef _invoke_pip(deps: list[str]) -> None:\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *deps])\n\n\ndef main(*, argv: list[str] | None = None) -> None:\n    if tomllib is None:\n        print(\n            \"Usage error: dependency-groups CLI requires tomli or Python 3.11+\",\n            file=sys.stderr,\n        )\n        raise SystemExit(2)\n\n    parser = argparse.ArgumentParser(description=\"Install Dependency Groups.\")\n    parser.add_argument(\n        \"DEPENDENCY_GROUP\", nargs=\"+\", help=\"The dependency groups to install.\"\n    )\n    parser.add_argument(\n        \"-f\",\n        \"--pyproject-file\",\n        default=\"pyproject.toml\",\n        help=\"The pyproject.toml file. Defaults to trying in the current directory.\",\n    )\n    args = parser.parse_args(argv if argv is not None else sys.argv[1:])\n\n    with open(args.pyproject_file, \"rb\") as fp:\n        pyproject = tomllib.load(fp)\n    dependency_groups_raw = pyproject.get(\"dependency-groups\", {})\n\n    errors: list[str] = []\n    resolved: list[str] = []\n    try:\n        resolver = DependencyGroupResolver(dependency_groups_raw)\n    except (ValueError, TypeError) as e:\n        errors.append(f\"{type(e).__name__}: {e}\")\n    else:\n        for groupname in args.DEPENDENCY_GROUP:\n            try:\n                resolved.extend(str(r) for r in resolver.resolve(groupname))\n            except (LookupError, ValueError, TypeError) as e:\n                errors.append(f\"{type(e).__name__}: {e}\")\n\n    if errors:\n        print(\"errors encountered while examining dependency groups:\")\n        for msg in errors:\n            print(f\"  {msg}\")\n        sys.exit(1)\n\n    _invoke_pip(resolved)\n\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\_toml_compat.py": {
      "sha": "aa953a64120b",
      "lines": 9,
      "head": "try:\n    import tomllib\nexcept ImportError:\n    try:\n        from pip._vendor import tomli as tomllib  # type: ignore[no-redef, unused-ignore]\n    except ModuleNotFoundError:  # pragma: no cover\n        tomllib = None  # type: ignore[assignment, unused-ignore]\n\n__all__ = (\"tomllib\",)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\__init__.py": {
      "sha": "9f7d1c94b33e",
      "lines": 13,
      "head": "from ._implementation import (\n    CyclicDependencyError,\n    DependencyGroupInclude,\n    DependencyGroupResolver,\n    resolve,\n)\n\n__all__ = (\n    \"CyclicDependencyError\",\n    \"DependencyGroupInclude\",\n    \"DependencyGroupResolver\",\n    \"resolve\",\n)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\dependency_groups\\__main__.py": {
      "sha": "bcf28fa0271b",
      "lines": 65,
      "head": "import argparse\nimport sys\n\nfrom ._implementation import resolve\nfrom ._toml_compat import tomllib\n\n\ndef main() -> None:\n    if tomllib is None:\n        print(\n            \"Usage error: dependency-groups CLI requires tomli or Python 3.11+\",\n            file=sys.stderr,\n        )\n        raise SystemExit(2)\n\n    parser = argparse.ArgumentParser(\n        description=(\n            \"A dependency-groups CLI. Prints out a resolved group, newline-delimited.\"\n        )\n    )\n    parser.add_argument(\n        \"GROUP_NAME\", nargs=\"*\", help=\"The dependency group(s) to resolve.\"\n    )\n    parser.add_argument(\n        \"-f\",\n        \"--pyproject-file\",\n        default=\"pyproject.toml\",\n        help=\"The pyproject.toml file. Defaults to trying in the current directory.\",\n    )\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        help=\"An output file. Defaults to stdout.\",\n    )\n    parser.add_argument(\n        \"-l\",\n        \"--list\",\n        action=\"store_true\",\n        help=\"List the available dependency groups\",\n    )\n    args = parser.parse_args()\n\n    with open(args.pyproject_file, \"rb\") as fp:\n        pyproject = tomllib.load(fp)\n\n    dependency_groups_raw = pyproject.get(\"dependency-groups\", {})\n\n    if args.list:\n        print(*dependency_groups_raw.keys())\n        return\n    if not args.GROUP_NAME:\n        print(\"A GROUP_NAME is required\", file=sys.stderr)\n        raise SystemExit(3)\n\n    content = \"\\n\".join(resolve(dependency_groups_raw, *args.GROUP_NAME))\n\n    if args.output is None or args.output == \"-\":\n        print(content)\n    else:\n        with open(args.output, \"w\", encoding=\"utf-8\") as fp:\n            print(content, file=fp)\n\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\compat.py": {
      "sha": "d4f491ec2a8d",
      "lines": 1137,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2013-2017 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\nfrom __future__ import absolute_import\n\nimport os\nimport re\nimport shutil\nimport sys\n\ntry:\n    import ssl\nexcept ImportError:  # pragma: no cover\n    ssl = None\n\nif sys.version_info[0] < 3:  # pragma: no cover\n    from StringIO import StringIO\n    string_types = basestring,\n    text_type = unicode\n    from types import FileType as file_type\n    import __builtin__ as builtins\n    import ConfigParser as configparser\n    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urlunsplit\n    from urllib import (urlretrieve, quote as _quote, unquote, url2pathname,\n                        pathname2url, ContentTooShortError, splittype)\n\n    def quote(s):\n        if isinstance(s, unicode):\n            s = s.encode('utf-8')\n        return _quote(s)\n\n    import urllib2\n    from urllib2 import (Request, urlopen, URLError, HTTPError,\n                         HTTPBasicAuthHandler, HTTPPasswordMgr, HTTPHandler,\n                         HTTPRedirectHandler, build_opener)\n    if ssl:\n        from urllib2 import HTTPSHandler\n    import httplib\n    import xmlrpclib\n    import Queue as queue\n    from HTMLParser import HTMLParser\n    import htmlentitydefs\n    raw_input = raw_input\n    from itertools import ifilter as filter\n    from itertools import ifilterfalse as filterfalse\n\n    # Leaving this around for now, in case it needs resurrecting in some way\n    # _userprog = None\n    # def splituser(host):\n    # \"\"\"splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.\"\"\"\n    # global _userprog\n    # if _userprog is None:\n    # import re\n    # _userprog = re.compile('^(.*)@(.*)$')\n\n    # match = _userprog.match(host)\n    # if match: return match.group(1, 2)\n    # return None, host\n\nelse:  # pragma: no cover\n    from io import StringIO\n    string_types = str,\n    text_type = str\n    from io import TextIOWrapper as file_type\n    import builtins\n    import configparser\n    from urllib.parse import (urlparse, urlunparse, urljoin, quote, unquote,\n                              urlsplit, urlunsplit, splittype)\n    from urllib.request import (urlopen, urlretrieve, Request, url2pathname,\n                                pathname2url, HTTPBasicAuthHandler,\n                                HTTPPasswordMgr, HTTPHandler,\n                                HTTPRedirectHandler, build_opener)\n    if ssl:\n        from urllib.request import HTTPSHandler\n    from urllib.error import HTTPError, URLError, ContentTooShortError\n    import http.client as httplib\n    import urllib.request as urllib2\n    import xmlrpc.client as xmlrpclib\n    import queue\n    from html.parser import HTMLParser\n    import html.entities as htmlentitydefs\n    raw_input = input\n    from itertools import filterfalse\n    filter = filter\n\ntry:\n    from ssl import match_hostname, CertificateError\nexcept ImportError:  # pragma: no cover\n\n    class CertificateError(ValueError):\n        pass\n\n    def _dnsname_match(dn, hostname, max_wildcards=1):\n        \"\"\"Matching according to RFC 6125, section 6.4.3\n\n        http://tools.ietf.org/html/rfc6125#section-6.4.3\n        \"\"\"\n        pats = []\n        if not dn:\n            return False\n\n        parts = dn.split('.')\n        leftmost, remainder = parts[0], parts[1:]\n\n        wildcards = leftmost.count('*')\n        if wildcards > max_wildcards:\n            # Issue #17980: avoid denials of service by refusing more\n            # than one wildcard per fragment.  A survey of established\n            # policy among SSL implementations showed it to be a\n            # reasonable choice.\n            raise CertificateError(\n                \"too many wildcards in certificate DNS name: \" + repr(dn))\n\n        # speed up common case w/o wildcards\n        if not wildcards:\n            return dn.lower() == hostname.lower()\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\database.py": {
      "sha": "567a99b381e5",
      "lines": 1329,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2012-2023 The Python Software Foundation.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\n\"\"\"PEP 376 implementation.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport base64\nimport codecs\nimport contextlib\nimport hashlib\nimport logging\nimport os\nimport posixpath\nimport sys\nimport zipimport\n\nfrom . import DistlibException, resources\nfrom .compat import StringIO\nfrom .version import get_scheme, UnsupportedVersionError\nfrom .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME)\nfrom .util import (parse_requirement, cached_property, parse_name_and_version, read_exports, write_exports, CSVReader,\n                   CSVWriter)\n\n__all__ = [\n    'Distribution', 'BaseInstalledDistribution', 'InstalledDistribution', 'EggInfoDistribution', 'DistributionPath'\n]\n\nlogger = logging.getLogger(__name__)\n\nEXPORTS_FILENAME = 'pydist-exports.json'\nCOMMANDS_FILENAME = 'pydist-commands.json'\n\nDIST_FILES = ('INSTALLER', METADATA_FILENAME, 'RECORD', 'REQUESTED', 'RESOURCES', EXPORTS_FILENAME, 'SHARED')\n\nDISTINFO_EXT = '.dist-info'\n\n\nclass _Cache(object):\n    \"\"\"\n    A simple cache mapping names and .dist-info paths to distributions\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialise an instance. There is normally one for each DistributionPath.\n        \"\"\"\n        self.name = {}\n        self.path = {}\n        self.generated = False\n\n    def clear(self):\n        \"\"\"\n        Clear the cache, setting it to its initial state.\n        \"\"\"\n        self.name.clear()\n        self.path.clear()\n        self.generated = False\n\n    def add(self, dist):\n        \"\"\"\n        Add a distribution to the cache.\n        :param dist: The distribution to add.\n        \"\"\"\n        if dist.path not in self.path:\n            self.path[dist.path] = dist\n            self.name.setdefault(dist.key, []).append(dist)\n\n\nclass DistributionPath(object):\n    \"\"\"\n    Represents a set of distributions installed on a path (typically sys.path).\n    \"\"\"\n\n    def __init__(self, path=None, include_egg=False):\n        \"\"\"\n        Create an instance from a path, optionally including legacy (distutils/\n        setuptools/distribute) distributions.\n        :param path: The path to use, as a list of directories. If not specified,\n                     sys.path is used.\n        :param include_egg: If True, this instance will look for and return legacy\n                            distributions as well as those based on PEP 376.\n        \"\"\"\n        if path is None:\n            path = sys.path\n        self.path = path\n        self._include_dist = True\n        self._include_egg = include_egg\n\n        self._cache = _Cache()\n        self._cache_egg = _Cache()\n        self._cache_enabled = True\n        self._scheme = get_scheme('default')\n\n    def _get_cache_enabled(self):\n        return self._cache_enabled\n\n    def _set_cache_enabled(self, value):\n        self._cache_enabled = value\n\n    cache_enabled = property(_get_cache_enabled, _set_cache_enabled)\n\n    def clear_cache(self):\n        \"\"\"\n        Clears the internal cache.\n        \"\"\"\n        self._cache.clear()\n        self._cache_egg.clear()\n\n    def _yield_distributions(self):\n        \"\"\"\n        Yield .dist-info and/or .egg(-info) distributions.\n        \"\"\"\n        # We need to check if we've seen some resources already, because on\n        # some Linux systems (e.g. some Debian/Ubuntu variants) there are\n        # symlinks which alias other files in the environment.\n        seen = set()\n        for path in self.path:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\index.py": {
      "sha": "742277dd9d3c",
      "lines": 508,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2013-2023 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\nimport hashlib\nimport logging\nimport os\nimport shutil\nimport subprocess\nimport tempfile\ntry:\n    from threading import Thread\nexcept ImportError:  # pragma: no cover\n    from dummy_threading import Thread\n\nfrom . import DistlibException\nfrom .compat import (HTTPBasicAuthHandler, Request, HTTPPasswordMgr,\n                     urlparse, build_opener, string_types)\nfrom .util import zip_dir, ServerProxy\n\nlogger = logging.getLogger(__name__)\n\nDEFAULT_INDEX = 'https://pypi.org/pypi'\nDEFAULT_REALM = 'pypi'\n\n\nclass PackageIndex(object):\n    \"\"\"\n    This class represents a package index compatible with PyPI, the Python\n    Package Index.\n    \"\"\"\n\n    boundary = b'----------ThIs_Is_tHe_distlib_index_bouNdaRY_$'\n\n    def __init__(self, url=None):\n        \"\"\"\n        Initialise an instance.\n\n        :param url: The URL of the index. If not specified, the URL for PyPI is\n                    used.\n        \"\"\"\n        self.url = url or DEFAULT_INDEX\n        self.read_configuration()\n        scheme, netloc, path, params, query, frag = urlparse(self.url)\n        if params or query or frag or scheme not in ('http', 'https'):\n            raise DistlibException('invalid repository: %s' % self.url)\n        self.password_handler = None\n        self.ssl_verifier = None\n        self.gpg = None\n        self.gpg_home = None\n        with open(os.devnull, 'w') as sink:\n            # Use gpg by default rather than gpg2, as gpg2 insists on\n            # prompting for passwords\n            for s in ('gpg', 'gpg2'):\n                try:\n                    rc = subprocess.check_call([s, '--version'], stdout=sink,\n                                               stderr=sink)\n                    if rc == 0:\n                        self.gpg = s\n                        break\n                except OSError:\n                    pass\n\n    def _get_pypirc_command(self):\n        \"\"\"\n        Get the distutils command for interacting with PyPI configurations.\n        :return: the command.\n        \"\"\"\n        from .util import _get_pypirc_command as cmd\n        return cmd()\n\n    def read_configuration(self):\n        \"\"\"\n        Read the PyPI access configuration as supported by distutils. This populates\n        ``username``, ``password``, ``realm`` and ``url`` attributes from the\n        configuration.\n        \"\"\"\n        from .util import _load_pypirc\n        cfg = _load_pypirc(self)\n        self.username = cfg.get('username')\n        self.password = cfg.get('password')\n        self.realm = cfg.get('realm', 'pypi')\n        self.url = cfg.get('repository', self.url)\n\n    def save_configuration(self):\n        \"\"\"\n        Save the PyPI access configuration. You must have set ``username`` and\n        ``password`` attributes before calling this method.\n        \"\"\"\n        self.check_credentials()\n        from .util import _store_pypirc\n        _store_pypirc(self)\n\n    def check_credentials(self):\n        \"\"\"\n        Check that ``username`` and ``password`` have been set, and raise an\n        exception if not.\n        \"\"\"\n        if self.username is None or self.password is None:\n            raise DistlibException('username and password must be set')\n        pm = HTTPPasswordMgr()\n        _, netloc, _, _, _, _ = urlparse(self.url)\n        pm.add_password(self.realm, netloc, self.username, self.password)\n        self.password_handler = HTTPBasicAuthHandler(pm)\n\n    def register(self, metadata):  # pragma: no cover\n        \"\"\"\n        Register a distribution on PyPI, using the provided metadata.\n\n        :param metadata: A :class:`Metadata` instance defining at least a name\n                         and version number for the distribution to be\n                         registered.\n        :return: The HTTP response received from PyPI upon submission of the\n                request.\n        \"\"\"\n        self.check_credentials()\n        metadata.validate()\n        d = metadata.todict()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\locators.py": {
      "sha": "9ea4315030dd",
      "lines": 1295,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2012-2023 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\n\nimport gzip\nfrom io import BytesIO\nimport json\nimport logging\nimport os\nimport posixpath\nimport re\ntry:\n    import threading\nexcept ImportError:  # pragma: no cover\n    import dummy_threading as threading\nimport zlib\n\nfrom . import DistlibException\nfrom .compat import (urljoin, urlparse, urlunparse, url2pathname, pathname2url, queue, quote, unescape, build_opener,\n                     HTTPRedirectHandler as BaseRedirectHandler, text_type, Request, HTTPError, URLError)\nfrom .database import Distribution, DistributionPath, make_dist\nfrom .metadata import Metadata, MetadataInvalidError\nfrom .util import (cached_property, ensure_slash, split_filename, get_project_data, parse_requirement,\n                   parse_name_and_version, ServerProxy, normalize_name)\nfrom .version import get_scheme, UnsupportedVersionError\nfrom .wheel import Wheel, is_compatible\n\nlogger = logging.getLogger(__name__)\n\nHASHER_HASH = re.compile(r'^(\\w+)=([a-f0-9]+)')\nCHARSET = re.compile(r';\\s*charset\\s*=\\s*(.*)\\s*$', re.I)\nHTML_CONTENT_TYPE = re.compile('text/html|application/x(ht)?ml')\nDEFAULT_INDEX = 'https://pypi.org/pypi'\n\n\ndef get_all_distribution_names(url=None):\n    \"\"\"\n    Return all distribution names known by an index.\n    :param url: The URL of the index.\n    :return: A list of all known distribution names.\n    \"\"\"\n    if url is None:\n        url = DEFAULT_INDEX\n    client = ServerProxy(url, timeout=3.0)\n    try:\n        return client.list_packages()\n    finally:\n        client('close')()\n\n\nclass RedirectHandler(BaseRedirectHandler):\n    \"\"\"\n    A class to work around a bug in some Python 3.2.x releases.\n    \"\"\"\n\n    # There's a bug in the base version for some 3.2.x\n    # (e.g. 3.2.2 on Ubuntu Oneiric). If a Location header\n    # returns e.g. /abc, it bails because it says the scheme ''\n    # is bogus, when actually it should use the request's\n    # URL for the scheme. See Python issue #13696.\n    def http_error_302(self, req, fp, code, msg, headers):\n        # Some servers (incorrectly) return multiple Location headers\n        # (so probably same goes for URI).  Use first header.\n        newurl = None\n        for key in ('location', 'uri'):\n            if key in headers:\n                newurl = headers[key]\n                break\n        if newurl is None:  # pragma: no cover\n            return\n        urlparts = urlparse(newurl)\n        if urlparts.scheme == '':\n            newurl = urljoin(req.get_full_url(), newurl)\n            if hasattr(headers, 'replace_header'):\n                headers.replace_header(key, newurl)\n            else:\n                headers[key] = newurl\n        return BaseRedirectHandler.http_error_302(self, req, fp, code, msg, headers)\n\n    http_error_301 = http_error_303 = http_error_307 = http_error_302\n\n\nclass Locator(object):\n    \"\"\"\n    A base class for locators - things that locate distributions.\n    \"\"\"\n    source_extensions = ('.tar.gz', '.tar.bz2', '.tar', '.zip', '.tgz', '.tbz')\n    binary_extensions = ('.egg', '.exe', '.whl')\n    excluded_extensions = ('.pdf', )\n\n    # A list of tags indicating which wheels you want to match. The default\n    # value of None matches against the tags compatible with the running\n    # Python. If you want to match other values, set wheel_tags on a locator\n    # instance to a list of tuples (pyver, abi, arch) which you want to match.\n    wheel_tags = None\n\n    downloadable_extensions = source_extensions + ('.whl', )\n\n    def __init__(self, scheme='default'):\n        \"\"\"\n        Initialise an instance.\n        :param scheme: Because locators look for most recent versions, they\n                       need to know the version scheme to use. This specifies\n                       the current PEP-recommended scheme - use ``'legacy'``\n                       if you need to support existing distributions on PyPI.\n        \"\"\"\n        self._cache = {}\n        self.scheme = scheme\n        # Because of bugs in some of the handlers on some of the platforms,\n        # we use our own opener rather than just using urlopen.\n        self.opener = build_opener(RedirectHandler())\n        # If get_project() is called from locate(), the matcher instance\n        # is set from the requirement passed to locate(). See issue #18 for\n        # why this can be useful to know.\n        self.matcher = None\n        self.errors = queue.Queue()\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\manifest.py": {
      "sha": "4f3923e9575c",
      "lines": 384,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2012-2023 Python Software Foundation.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\n\"\"\"\nClass representing the list of files in a distribution.\n\nEquivalent to distutils.filelist, but fixes some problems.\n\"\"\"\nimport fnmatch\nimport logging\nimport os\nimport re\nimport sys\n\nfrom . import DistlibException\nfrom .compat import fsdecode\nfrom .util import convert_path\n\n\n__all__ = ['Manifest']\n\nlogger = logging.getLogger(__name__)\n\n# a \\ followed by some spaces + EOL\n_COLLAPSE_PATTERN = re.compile('\\\\\\\\w*\\n', re.M)\n_COMMENTED_LINE = re.compile('#.*?(?=\\n)|\\n(?=$)', re.M | re.S)\n\n#\n# Due to the different results returned by fnmatch.translate, we need\n# to do slightly different processing for Python 2.7 and 3.2 ... this needed\n# to be brought in for Python 3.6 onwards.\n#\n_PYTHON_VERSION = sys.version_info[:2]\n\n\nclass Manifest(object):\n    \"\"\"\n    A list of files built by exploring the filesystem and filtered by applying various\n    patterns to what we find there.\n    \"\"\"\n\n    def __init__(self, base=None):\n        \"\"\"\n        Initialise an instance.\n\n        :param base: The base directory to explore under.\n        \"\"\"\n        self.base = os.path.abspath(os.path.normpath(base or os.getcwd()))\n        self.prefix = self.base + os.sep\n        self.allfiles = None\n        self.files = set()\n\n    #\n    # Public API\n    #\n\n    def findall(self):\n        \"\"\"Find all files under the base and set ``allfiles`` to the absolute\n        pathnames of files found.\n        \"\"\"\n        from stat import S_ISREG, S_ISDIR, S_ISLNK\n\n        self.allfiles = allfiles = []\n        root = self.base\n        stack = [root]\n        pop = stack.pop\n        push = stack.append\n\n        while stack:\n            root = pop()\n            names = os.listdir(root)\n\n            for name in names:\n                fullname = os.path.join(root, name)\n\n                # Avoid excess stat calls -- just one will do, thank you!\n                stat = os.stat(fullname)\n                mode = stat.st_mode\n                if S_ISREG(mode):\n                    allfiles.append(fsdecode(fullname))\n                elif S_ISDIR(mode) and not S_ISLNK(mode):\n                    push(fullname)\n\n    def add(self, item):\n        \"\"\"\n        Add a file to the manifest.\n\n        :param item: The pathname to add. This can be relative to the base.\n        \"\"\"\n        if not item.startswith(self.prefix):\n            item = os.path.join(self.base, item)\n        self.files.add(os.path.normpath(item))\n\n    def add_many(self, items):\n        \"\"\"\n        Add a list of files to the manifest.\n\n        :param items: The pathnames to add. These can be relative to the base.\n        \"\"\"\n        for item in items:\n            self.add(item)\n\n    def sorted(self, wantdirs=False):\n        \"\"\"\n        Return sorted files in directory order\n        \"\"\"\n\n        def add_dir(dirs, d):\n            dirs.add(d)\n            logger.debug('add_dir added %s', d)\n            if d != self.base:\n                parent, _ = os.path.split(d)\n                assert parent not in ('', '/')\n                add_dir(dirs, parent)\n\n        result = set(self.files)    # make a copy!\n        if wantdirs:\n            dirs = set()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\markers.py": {
      "sha": "f4856e264654",
      "lines": 162,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2012-2023 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\n\"\"\"\nParser for the environment markers micro-language defined in PEP 508.\n\"\"\"\n\n# Note: In PEP 345, the micro-language was Python compatible, so the ast\n# module could be used to parse it. However, PEP 508 introduced operators such\n# as ~= and === which aren't in Python, necessitating a different approach.\n\nimport os\nimport re\nimport sys\nimport platform\n\nfrom .compat import string_types\nfrom .util import in_venv, parse_marker\nfrom .version import LegacyVersion as LV\n\n__all__ = ['interpret']\n\n_VERSION_PATTERN = re.compile(r'((\\d+(\\.\\d+)*\\w*)|\\'(\\d+(\\.\\d+)*\\w*)\\'|\\\"(\\d+(\\.\\d+)*\\w*)\\\")')\n_VERSION_MARKERS = {'python_version', 'python_full_version'}\n\n\ndef _is_version_marker(s):\n    return isinstance(s, string_types) and s in _VERSION_MARKERS\n\n\ndef _is_literal(o):\n    if not isinstance(o, string_types) or not o:\n        return False\n    return o[0] in '\\'\"'\n\n\ndef _get_versions(s):\n    return {LV(m.groups()[0]) for m in _VERSION_PATTERN.finditer(s)}\n\n\nclass Evaluator(object):\n    \"\"\"\n    This class is used to evaluate marker expressions.\n    \"\"\"\n\n    operations = {\n        '==': lambda x, y: x == y,\n        '===': lambda x, y: x == y,\n        '~=': lambda x, y: x == y or x > y,\n        '!=': lambda x, y: x != y,\n        '<': lambda x, y: x < y,\n        '<=': lambda x, y: x == y or x < y,\n        '>': lambda x, y: x > y,\n        '>=': lambda x, y: x == y or x > y,\n        'and': lambda x, y: x and y,\n        'or': lambda x, y: x or y,\n        'in': lambda x, y: x in y,\n        'not in': lambda x, y: x not in y,\n    }\n\n    def evaluate(self, expr, context):\n        \"\"\"\n        Evaluate a marker expression returned by the :func:`parse_requirement`\n        function in the specified context.\n        \"\"\"\n        if isinstance(expr, string_types):\n            if expr[0] in '\\'\"':\n                result = expr[1:-1]\n            else:\n                if expr not in context:\n                    raise SyntaxError('unknown variable: %s' % expr)\n                result = context[expr]\n        else:\n            assert isinstance(expr, dict)\n            op = expr['op']\n            if op not in self.operations:\n                raise NotImplementedError('op not implemented: %s' % op)\n            elhs = expr['lhs']\n            erhs = expr['rhs']\n            if _is_literal(expr['lhs']) and _is_literal(expr['rhs']):\n                raise SyntaxError('invalid comparison: %s %s %s' % (elhs, op, erhs))\n\n            lhs = self.evaluate(elhs, context)\n            rhs = self.evaluate(erhs, context)\n            if ((_is_version_marker(elhs) or _is_version_marker(erhs)) and\n                    op in ('<', '<=', '>', '>=', '===', '==', '!=', '~=')):\n                lhs = LV(lhs)\n                rhs = LV(rhs)\n            elif _is_version_marker(elhs) and op in ('in', 'not in'):\n                lhs = LV(lhs)\n                rhs = _get_versions(rhs)\n            result = self.operations[op](lhs, rhs)\n        return result\n\n\n_DIGITS = re.compile(r'\\d+\\.\\d+')\n\n\ndef default_context():\n\n    def format_full_version(info):\n        version = '%s.%s.%s' % (info.major, info.minor, info.micro)\n        kind = info.releaselevel\n        if kind != 'final':\n            version += kind[0] + str(info.serial)\n        return version\n\n    if hasattr(sys, 'implementation'):\n        implementation_version = format_full_version(sys.implementation.version)\n        implementation_name = sys.implementation.name\n    else:\n        implementation_version = '0'\n        implementation_name = ''\n\n    ppv = platform.python_version()\n    m = _DIGITS.match(ppv)\n    pv = m.group(0)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\metadata.py": {
      "sha": "d80f0eff18d0",
      "lines": 1031,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2012 The Python Software Foundation.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\n\"\"\"Implementation of the Metadata for Python packages PEPs.\n\nSupports all metadata formats (1.0, 1.1, 1.2, 1.3/2.1 and 2.2).\n\"\"\"\nfrom __future__ import unicode_literals\n\nimport codecs\nfrom email import message_from_file\nimport json\nimport logging\nimport re\n\nfrom . import DistlibException, __version__\nfrom .compat import StringIO, string_types, text_type\nfrom .markers import interpret\nfrom .util import extract_by_key, get_extras\nfrom .version import get_scheme, PEP440_VERSION_RE\n\nlogger = logging.getLogger(__name__)\n\n\nclass MetadataMissingError(DistlibException):\n    \"\"\"A required metadata is missing\"\"\"\n\n\nclass MetadataConflictError(DistlibException):\n    \"\"\"Attempt to read or write metadata fields that are conflictual.\"\"\"\n\n\nclass MetadataUnrecognizedVersionError(DistlibException):\n    \"\"\"Unknown metadata version number.\"\"\"\n\n\nclass MetadataInvalidError(DistlibException):\n    \"\"\"A metadata value is invalid\"\"\"\n\n\n# public API of this module\n__all__ = ['Metadata', 'PKG_INFO_ENCODING', 'PKG_INFO_PREFERRED_VERSION']\n\n# Encoding used for the PKG-INFO files\nPKG_INFO_ENCODING = 'utf-8'\n\n# preferred version. Hopefully will be changed\n# to 1.2 once PEP 345 is supported everywhere\nPKG_INFO_PREFERRED_VERSION = '1.1'\n\n_LINE_PREFIX_1_2 = re.compile('\\n       \\\\|')\n_LINE_PREFIX_PRE_1_2 = re.compile('\\n        ')\n_241_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform', 'Summary', 'Description', 'Keywords', 'Home-page',\n               'Author', 'Author-email', 'License')\n\n_314_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform', 'Supported-Platform', 'Summary', 'Description',\n               'Keywords', 'Home-page', 'Author', 'Author-email', 'License', 'Classifier', 'Download-URL', 'Obsoletes',\n               'Provides', 'Requires')\n\n_314_MARKERS = ('Obsoletes', 'Provides', 'Requires', 'Classifier', 'Download-URL')\n\n_345_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform', 'Supported-Platform', 'Summary', 'Description',\n               'Keywords', 'Home-page', 'Author', 'Author-email', 'Maintainer', 'Maintainer-email', 'License',\n               'Classifier', 'Download-URL', 'Obsoletes-Dist', 'Project-URL', 'Provides-Dist', 'Requires-Dist',\n               'Requires-Python', 'Requires-External')\n\n_345_MARKERS = ('Provides-Dist', 'Requires-Dist', 'Requires-Python', 'Obsoletes-Dist', 'Requires-External',\n                'Maintainer', 'Maintainer-email', 'Project-URL')\n\n_426_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform', 'Supported-Platform', 'Summary', 'Description',\n               'Keywords', 'Home-page', 'Author', 'Author-email', 'Maintainer', 'Maintainer-email', 'License',\n               'Classifier', 'Download-URL', 'Obsoletes-Dist', 'Project-URL', 'Provides-Dist', 'Requires-Dist',\n               'Requires-Python', 'Requires-External', 'Private-Version', 'Obsoleted-By', 'Setup-Requires-Dist',\n               'Extension', 'Provides-Extra')\n\n_426_MARKERS = ('Private-Version', 'Provides-Extra', 'Obsoleted-By', 'Setup-Requires-Dist', 'Extension')\n\n# See issue #106: Sometimes 'Requires' and 'Provides' occur wrongly in\n# the metadata. Include them in the tuple literal below to allow them\n# (for now).\n# Ditto for Obsoletes - see issue #140.\n_566_FIELDS = _426_FIELDS + ('Description-Content-Type', 'Requires', 'Provides', 'Obsoletes')\n\n_566_MARKERS = ('Description-Content-Type', )\n\n_643_MARKERS = ('Dynamic', 'License-File')\n\n_643_FIELDS = _566_FIELDS + _643_MARKERS\n\n_ALL_FIELDS = set()\n_ALL_FIELDS.update(_241_FIELDS)\n_ALL_FIELDS.update(_314_FIELDS)\n_ALL_FIELDS.update(_345_FIELDS)\n_ALL_FIELDS.update(_426_FIELDS)\n_ALL_FIELDS.update(_566_FIELDS)\n_ALL_FIELDS.update(_643_FIELDS)\n\nEXTRA_RE = re.compile(r'''extra\\s*==\\s*(\"([^\"]+)\"|'([^']+)')''')\n\n\ndef _version2fieldlist(version):\n    if version == '1.0':\n        return _241_FIELDS\n    elif version == '1.1':\n        return _314_FIELDS\n    elif version == '1.2':\n        return _345_FIELDS\n    elif version in ('1.3', '2.1'):\n        # avoid adding field names if already there\n        return _345_FIELDS + tuple(f for f in _566_FIELDS if f not in _345_FIELDS)\n    elif version == '2.0':\n        raise ValueError('Metadata 2.0 is withdrawn and not supported')\n        # return _426_FIELDS\n    elif version == '2.2':\n        return _643_FIELDS\n    raise MetadataUnrecognizedVersionError(version)\n\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\resources.py": {
      "sha": "cb59892b3253",
      "lines": 358,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2013-2017 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\nfrom __future__ import unicode_literals\n\nimport bisect\nimport io\nimport logging\nimport os\nimport pkgutil\nimport sys\nimport types\nimport zipimport\n\nfrom . import DistlibException\nfrom .util import cached_property, get_cache_base, Cache\n\nlogger = logging.getLogger(__name__)\n\n\ncache = None    # created when needed\n\n\nclass ResourceCache(Cache):\n    def __init__(self, base=None):\n        if base is None:\n            # Use native string to avoid issues on 2.x: see Python #20140.\n            base = os.path.join(get_cache_base(), str('resource-cache'))\n        super(ResourceCache, self).__init__(base)\n\n    def is_stale(self, resource, path):\n        \"\"\"\n        Is the cache stale for the given resource?\n\n        :param resource: The :class:`Resource` being cached.\n        :param path: The path of the resource in the cache.\n        :return: True if the cache is stale.\n        \"\"\"\n        # Cache invalidation is a hard problem :-)\n        return True\n\n    def get(self, resource):\n        \"\"\"\n        Get a resource into the cache,\n\n        :param resource: A :class:`Resource` instance.\n        :return: The pathname of the resource in the cache.\n        \"\"\"\n        prefix, path = resource.finder.get_cache_info(resource)\n        if prefix is None:\n            result = path\n        else:\n            result = os.path.join(self.base, self.prefix_to_dir(prefix), path)\n            dirname = os.path.dirname(result)\n            if not os.path.isdir(dirname):\n                os.makedirs(dirname)\n            if not os.path.exists(result):\n                stale = True\n            else:\n                stale = self.is_stale(resource, path)\n            if stale:\n                # write the bytes of the resource to the cache location\n                with open(result, 'wb') as f:\n                    f.write(resource.bytes)\n        return result\n\n\nclass ResourceBase(object):\n    def __init__(self, finder, name):\n        self.finder = finder\n        self.name = name\n\n\nclass Resource(ResourceBase):\n    \"\"\"\n    A class representing an in-package resource, such as a data file. This is\n    not normally instantiated by user code, but rather by a\n    :class:`ResourceFinder` which manages the resource.\n    \"\"\"\n    is_container = False        # Backwards compatibility\n\n    def as_stream(self):\n        \"\"\"\n        Get the resource as a stream.\n\n        This is not a property to make it obvious that it returns a new stream\n        each time.\n        \"\"\"\n        return self.finder.get_stream(self)\n\n    @cached_property\n    def file_path(self):\n        global cache\n        if cache is None:\n            cache = ResourceCache()\n        return cache.get(self)\n\n    @cached_property\n    def bytes(self):\n        return self.finder.get_bytes(self)\n\n    @cached_property\n    def size(self):\n        return self.finder.get_size(self)\n\n\nclass ResourceContainer(ResourceBase):\n    is_container = True     # Backwards compatibility\n\n    @cached_property\n    def resources(self):\n        return self.finder.get_resources(self)\n\n\nclass ResourceFinder(object):\n    \"\"\"\n    Resource finder for file system resources.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\scripts.py": {
      "sha": "cb4d608970a1",
      "lines": 447,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2013-2023 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\nfrom io import BytesIO\nimport logging\nimport os\nimport re\nimport struct\nimport sys\nimport time\nfrom zipfile import ZipInfo\n\nfrom .compat import sysconfig, detect_encoding, ZipFile\nfrom .resources import finder\nfrom .util import (FileOperator, get_export_entry, convert_path, get_executable, get_platform, in_venv)\n\nlogger = logging.getLogger(__name__)\n\n_DEFAULT_MANIFEST = '''\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<assembly xmlns=\"urn:schemas-microsoft-com:asm.v1\" manifestVersion=\"1.0\">\n <assemblyIdentity version=\"1.0.0.0\"\n processorArchitecture=\"X86\"\n name=\"%s\"\n type=\"win32\"/>\n\n <!-- Identify the application security requirements. -->\n <trustInfo xmlns=\"urn:schemas-microsoft-com:asm.v3\">\n <security>\n <requestedPrivileges>\n <requestedExecutionLevel level=\"asInvoker\" uiAccess=\"false\"/>\n </requestedPrivileges>\n </security>\n </trustInfo>\n</assembly>'''.strip()\n\n# check if Python is called on the first line with this expression\nFIRST_LINE_RE = re.compile(b'^#!.*pythonw?[0-9.]*([ \\t].*)?$')\nSCRIPT_TEMPLATE = r'''# -*- coding: utf-8 -*-\nimport re\nimport sys\nfrom %(module)s import %(import_name)s\nif __name__ == '__main__':\n    sys.argv[0] = re.sub(r'(-script\\.pyw|\\.exe)?$', '', sys.argv[0])\n    sys.exit(%(func)s())\n'''\n\n# Pre-fetch the contents of all executable wrapper stubs.\n# This is to address https://github.com/pypa/pip/issues/12666.\n# When updating pip, we rename the old pip in place before installing the\n# new version. If we try to fetch a wrapper *after* that rename, the finder\n# machinery will be confused as the package is no longer available at the\n# location where it was imported from. So we load everything into memory in\n# advance.\n\nif os.name == 'nt' or (os.name == 'java' and os._name == 'nt'):\n    # Issue 31: don't hardcode an absolute package name, but\n    # determine it relative to the current package\n    DISTLIB_PACKAGE = __name__.rsplit('.', 1)[0]\n\n    WRAPPERS = {\n        r.name: r.bytes\n        for r in finder(DISTLIB_PACKAGE).iterator(\"\")\n        if r.name.endswith(\".exe\")\n    }\n\n\ndef enquote_executable(executable):\n    if ' ' in executable:\n        # make sure we quote only the executable in case of env\n        # for example /usr/bin/env \"/dir with spaces/bin/jython\"\n        # instead of \"/usr/bin/env /dir with spaces/bin/jython\"\n        # otherwise whole\n        if executable.startswith('/usr/bin/env '):\n            env, _executable = executable.split(' ', 1)\n            if ' ' in _executable and not _executable.startswith('\"'):\n                executable = '%s \"%s\"' % (env, _executable)\n        else:\n            if not executable.startswith('\"'):\n                executable = '\"%s\"' % executable\n    return executable\n\n\n# Keep the old name around (for now), as there is at least one project using it!\n_enquote_executable = enquote_executable\n\n\nclass ScriptMaker(object):\n    \"\"\"\n    A class to copy or create scripts from source scripts or callable\n    specifications.\n    \"\"\"\n    script_template = SCRIPT_TEMPLATE\n\n    executable = None  # for shebangs\n\n    def __init__(self, source_dir, target_dir, add_launchers=True, dry_run=False, fileop=None):\n        self.source_dir = source_dir\n        self.target_dir = target_dir\n        self.add_launchers = add_launchers\n        self.force = False\n        self.clobber = False\n        # It only makes sense to set mode bits on POSIX.\n        self.set_mode = (os.name == 'posix') or (os.name == 'java' and os._name == 'posix')\n        self.variants = set(('', 'X.Y'))\n        self._fileop = fileop or FileOperator(dry_run)\n\n        self._is_nt = os.name == 'nt' or (os.name == 'java' and os._name == 'nt')\n        self.version_info = sys.version_info\n\n    def _get_alternate_executable(self, executable, options):\n        if options.get('gui', False) and self._is_nt:  # pragma: no cover\n            dn, fn = os.path.split(executable)\n            fn = fn.replace('python', 'pythonw')\n            executable = os.path.join(dn, fn)\n        return executable\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\util.py": {
      "sha": "9e4e2a442c8a",
      "lines": 1984,
      "head": "#\n# Copyright (C) 2012-2023 The Python Software Foundation.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\nimport codecs\nfrom collections import deque\nimport contextlib\nimport csv\nfrom glob import iglob as std_iglob\nimport io\nimport json\nimport logging\nimport os\nimport py_compile\nimport re\nimport socket\ntry:\n    import ssl\nexcept ImportError:  # pragma: no cover\n    ssl = None\nimport subprocess\nimport sys\nimport tarfile\nimport tempfile\nimport textwrap\n\ntry:\n    import threading\nexcept ImportError:  # pragma: no cover\n    import dummy_threading as threading\nimport time\n\nfrom . import DistlibException\nfrom .compat import (string_types, text_type, shutil, raw_input, StringIO, cache_from_source, urlopen, urljoin, httplib,\n                     xmlrpclib, HTTPHandler, BaseConfigurator, valid_ident, Container, configparser, URLError, ZipFile,\n                     fsdecode, unquote, urlparse)\n\nlogger = logging.getLogger(__name__)\n\n#\n# Requirement parsing code as per PEP 508\n#\n\nIDENTIFIER = re.compile(r'^([\\w\\.-]+)\\s*')\nVERSION_IDENTIFIER = re.compile(r'^([\\w\\.*+-]+)\\s*')\nCOMPARE_OP = re.compile(r'^(<=?|>=?|={2,3}|[~!]=)\\s*')\nMARKER_OP = re.compile(r'^((<=?)|(>=?)|={2,3}|[~!]=|in|not\\s+in)\\s*')\nOR = re.compile(r'^or\\b\\s*')\nAND = re.compile(r'^and\\b\\s*')\nNON_SPACE = re.compile(r'(\\S+)\\s*')\nSTRING_CHUNK = re.compile(r'([\\s\\w\\.{}()*+#:;,/?!~`@$%^&=|<>\\[\\]-]+)')\n\n\ndef parse_marker(marker_string):\n    \"\"\"\n    Parse a marker string and return a dictionary containing a marker expression.\n\n    The dictionary will contain keys \"op\", \"lhs\" and \"rhs\" for non-terminals in\n    the expression grammar, or strings. A string contained in quotes is to be\n    interpreted as a literal string, and a string not contained in quotes is a\n    variable (such as os_name).\n    \"\"\"\n\n    def marker_var(remaining):\n        # either identifier, or literal string\n        m = IDENTIFIER.match(remaining)\n        if m:\n            result = m.groups()[0]\n            remaining = remaining[m.end():]\n        elif not remaining:\n            raise SyntaxError('unexpected end of input')\n        else:\n            q = remaining[0]\n            if q not in '\\'\"':\n                raise SyntaxError('invalid expression: %s' % remaining)\n            oq = '\\'\"'.replace(q, '')\n            remaining = remaining[1:]\n            parts = [q]\n            while remaining:\n                # either a string chunk, or oq, or q to terminate\n                if remaining[0] == q:\n                    break\n                elif remaining[0] == oq:\n                    parts.append(oq)\n                    remaining = remaining[1:]\n                else:\n                    m = STRING_CHUNK.match(remaining)\n                    if not m:\n                        raise SyntaxError('error in string literal: %s' % remaining)\n                    parts.append(m.groups()[0])\n                    remaining = remaining[m.end():]\n            else:\n                s = ''.join(parts)\n                raise SyntaxError('unterminated string: %s' % s)\n            parts.append(q)\n            result = ''.join(parts)\n            remaining = remaining[1:].lstrip()  # skip past closing quote\n        return result, remaining\n\n    def marker_expr(remaining):\n        if remaining and remaining[0] == '(':\n            result, remaining = marker(remaining[1:].lstrip())\n            if remaining[0] != ')':\n                raise SyntaxError('unterminated parenthesis: %s' % remaining)\n            remaining = remaining[1:].lstrip()\n        else:\n            lhs, remaining = marker_var(remaining)\n            while remaining:\n                m = MARKER_OP.match(remaining)\n                if not m:\n                    break\n                op = m.groups()[0]\n                remaining = remaining[m.end():]\n                rhs, remaining = marker_var(remaining)\n                lhs = {'op': op, 'lhs': lhs, 'rhs': rhs}\n            result = lhs\n        return result, remaining\n\n    def marker_and(remaining):\n        lhs, remaining = marker_expr(remaining)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\version.py": {
      "sha": "0f65f2c7f70b",
      "lines": 750,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2012-2023 The Python Software Foundation.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\n\"\"\"\nImplementation of a flexible versioning scheme providing support for PEP-440,\nsetuptools-compatible and semantic versioning.\n\"\"\"\n\nimport logging\nimport re\n\nfrom .compat import string_types\nfrom .util import parse_requirement\n\n__all__ = ['NormalizedVersion', 'NormalizedMatcher',\n           'LegacyVersion', 'LegacyMatcher',\n           'SemanticVersion', 'SemanticMatcher',\n           'UnsupportedVersionError', 'get_scheme']\n\nlogger = logging.getLogger(__name__)\n\n\nclass UnsupportedVersionError(ValueError):\n    \"\"\"This is an unsupported version.\"\"\"\n    pass\n\n\nclass Version(object):\n    def __init__(self, s):\n        self._string = s = s.strip()\n        self._parts = parts = self.parse(s)\n        assert isinstance(parts, tuple)\n        assert len(parts) > 0\n\n    def parse(self, s):\n        raise NotImplementedError('please implement in a subclass')\n\n    def _check_compatible(self, other):\n        if type(self) != type(other):\n            raise TypeError('cannot compare %r and %r' % (self, other))\n\n    def __eq__(self, other):\n        self._check_compatible(other)\n        return self._parts == other._parts\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n    def __lt__(self, other):\n        self._check_compatible(other)\n        return self._parts < other._parts\n\n    def __gt__(self, other):\n        return not (self.__lt__(other) or self.__eq__(other))\n\n    def __le__(self, other):\n        return self.__lt__(other) or self.__eq__(other)\n\n    def __ge__(self, other):\n        return self.__gt__(other) or self.__eq__(other)\n\n    # See http://docs.python.org/reference/datamodel#object.__hash__\n    def __hash__(self):\n        return hash(self._parts)\n\n    def __repr__(self):\n        return \"%s('%s')\" % (self.__class__.__name__, self._string)\n\n    def __str__(self):\n        return self._string\n\n    @property\n    def is_prerelease(self):\n        raise NotImplementedError('Please implement in subclasses.')\n\n\nclass Matcher(object):\n    version_class = None\n\n    # value is either a callable or the name of a method\n    _operators = {\n        '<': lambda v, c, p: v < c,\n        '>': lambda v, c, p: v > c,\n        '<=': lambda v, c, p: v == c or v < c,\n        '>=': lambda v, c, p: v == c or v > c,\n        '==': lambda v, c, p: v == c,\n        '===': lambda v, c, p: v == c,\n        # by default, compatible => >=.\n        '~=': lambda v, c, p: v == c or v > c,\n        '!=': lambda v, c, p: v != c,\n    }\n\n    # this is a method only to support alternative implementations\n    # via overriding\n    def parse_requirement(self, s):\n        return parse_requirement(s)\n\n    def __init__(self, s):\n        if self.version_class is None:\n            raise ValueError('Please specify a version class')\n        self._string = s = s.strip()\n        r = self.parse_requirement(s)\n        if not r:\n            raise ValueError('Not valid: %r' % s)\n        self.name = r.name\n        self.key = self.name.lower()    # for case-insensitive comparisons\n        clist = []\n        if r.constraints:\n            # import pdb; pdb.set_trace()\n            for op, s in r.constraints:\n                if s.endswith('.*'):\n                    if op not in ('==', '!='):\n                        raise ValueError('\\'.*\\' not allowed for '\n                                         '%r constraints' % op)\n                    # Could be a partial version (e.g. for '2.*') which\n                    # won't parse as a version, so keep it as a string\n                    vn, prefix = s[:-2], True\n                    # Just to check that vn is a valid version\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\wheel.py": {
      "sha": "1fef539f07ac",
      "lines": 1100,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2013-2023 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\nfrom __future__ import unicode_literals\n\nimport base64\nimport codecs\nimport datetime\nfrom email import message_from_file\nimport hashlib\nimport json\nimport logging\nimport os\nimport posixpath\nimport re\nimport shutil\nimport sys\nimport tempfile\nimport zipfile\n\nfrom . import __version__, DistlibException\nfrom .compat import sysconfig, ZipFile, fsdecode, text_type, filter\nfrom .database import InstalledDistribution\nfrom .metadata import Metadata, WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME\nfrom .util import (FileOperator, convert_path, CSVReader, CSVWriter, Cache, cached_property, get_cache_base,\n                   read_exports, tempdir, get_platform)\nfrom .version import NormalizedVersion, UnsupportedVersionError\n\nlogger = logging.getLogger(__name__)\n\ncache = None  # created when needed\n\nif hasattr(sys, 'pypy_version_info'):  # pragma: no cover\n    IMP_PREFIX = 'pp'\nelif sys.platform.startswith('java'):  # pragma: no cover\n    IMP_PREFIX = 'jy'\nelif sys.platform == 'cli':  # pragma: no cover\n    IMP_PREFIX = 'ip'\nelse:\n    IMP_PREFIX = 'cp'\n\nVER_SUFFIX = sysconfig.get_config_var('py_version_nodot')\nif not VER_SUFFIX:  # pragma: no cover\n    VER_SUFFIX = '%s%s' % sys.version_info[:2]\nPYVER = 'py' + VER_SUFFIX\nIMPVER = IMP_PREFIX + VER_SUFFIX\n\nARCH = get_platform().replace('-', '_').replace('.', '_')\n\nABI = sysconfig.get_config_var('SOABI')\nif ABI and ABI.startswith('cpython-'):\n    ABI = ABI.replace('cpython-', 'cp').split('-')[0]\nelse:\n\n    def _derive_abi():\n        parts = ['cp', VER_SUFFIX]\n        if sysconfig.get_config_var('Py_DEBUG'):\n            parts.append('d')\n        if IMP_PREFIX == 'cp':\n            vi = sys.version_info[:2]\n            if vi < (3, 8):\n                wpm = sysconfig.get_config_var('WITH_PYMALLOC')\n                if wpm is None:\n                    wpm = True\n                if wpm:\n                    parts.append('m')\n                if vi < (3, 3):\n                    us = sysconfig.get_config_var('Py_UNICODE_SIZE')\n                    if us == 4 or (us is None and sys.maxunicode == 0x10FFFF):\n                        parts.append('u')\n        return ''.join(parts)\n\n    ABI = _derive_abi()\n    del _derive_abi\n\nFILENAME_RE = re.compile(\n    r'''\n(?P<nm>[^-]+)\n-(?P<vn>\\d+[^-]*)\n(-(?P<bn>\\d+[^-]*))?\n-(?P<py>\\w+\\d+(\\.\\w+\\d+)*)\n-(?P<bi>\\w+)\n-(?P<ar>\\w+(\\.\\w+)*)\n\\.whl$\n''', re.IGNORECASE | re.VERBOSE)\n\nNAME_VERSION_RE = re.compile(r'''\n(?P<nm>[^-]+)\n-(?P<vn>\\d+[^-]*)\n(-(?P<bn>\\d+[^-]*))?$\n''', re.IGNORECASE | re.VERBOSE)\n\nSHEBANG_RE = re.compile(br'\\s*#![^\\r\\n]*')\nSHEBANG_DETAIL_RE = re.compile(br'^(\\s*#!(\"[^\"]+\"|\\S+))\\s+(.*)$')\nSHEBANG_PYTHON = b'#!python'\nSHEBANG_PYTHONW = b'#!pythonw'\n\nif os.sep == '/':\n    to_posix = lambda o: o\nelse:\n    to_posix = lambda o: o.replace(os.sep, '/')\n\nif sys.version_info[0] < 3:\n    import imp\nelse:\n    imp = None\n    import importlib.machinery\n    import importlib.util\n\n\ndef _get_suffixes():\n    if imp:\n        return [s[0] for s in imp.get_suffixes()]\n    else:\n        return importlib.machinery.EXTENSION_SUFFIXES\n\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distlib\\__init__.py": {
      "sha": "f8e81bd8c110",
      "lines": 33,
      "head": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2012-2023 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\nimport logging\n\n__version__ = '0.3.9'\n\n\nclass DistlibException(Exception):\n    pass\n\n\ntry:\n    from logging import NullHandler\nexcept ImportError:  # pragma: no cover\n\n    class NullHandler(logging.Handler):\n\n        def handle(self, record):\n            pass\n\n        def emit(self, record):\n            pass\n\n        def createLock(self):\n            self.lock = None\n\n\nlogger = logging.getLogger(__name__)\nlogger.addHandler(NullHandler())\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distro\\distro.py": {
      "sha": "3d81b2572ba6",
      "lines": 1403,
      "head": "#!/usr/bin/env python\n# Copyright 2015-2021 Nir Cohen\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nThe ``distro`` package (``distro`` stands for Linux Distribution) provides\ninformation about the Linux distribution it runs on, such as a reliable\nmachine-readable distro ID, or version information.\n\nIt is the recommended replacement for Python's original\n:py:func:`platform.linux_distribution` function, but it provides much more\nfunctionality. An alternative implementation became necessary because Python\n3.5 deprecated this function, and Python 3.8 removed it altogether. Its\npredecessor function :py:func:`platform.dist` was already deprecated since\nPython 2.6 and removed in Python 3.8. Still, there are many cases in which\naccess to OS distribution information is needed. See `Python issue 1322\n<https://bugs.python.org/issue1322>`_ for more information.\n\"\"\"\n\nimport argparse\nimport json\nimport logging\nimport os\nimport re\nimport shlex\nimport subprocess\nimport sys\nimport warnings\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    Optional,\n    Sequence,\n    TextIO,\n    Tuple,\n    Type,\n)\n\ntry:\n    from typing import TypedDict\nexcept ImportError:\n    # Python 3.7\n    TypedDict = dict\n\n__version__ = \"1.9.0\"\n\n\nclass VersionDict(TypedDict):\n    major: str\n    minor: str\n    build_number: str\n\n\nclass InfoDict(TypedDict):\n    id: str\n    version: str\n    version_parts: VersionDict\n    like: str\n    codename: str\n\n\n_UNIXCONFDIR = os.environ.get(\"UNIXCONFDIR\", \"/etc\")\n_UNIXUSRLIBDIR = os.environ.get(\"UNIXUSRLIBDIR\", \"/usr/lib\")\n_OS_RELEASE_BASENAME = \"os-release\"\n\n#: Translation table for normalizing the \"ID\" attribute defined in os-release\n#: files, for use by the :func:`distro.id` method.\n#:\n#: * Key: Value as defined in the os-release file, translated to lower case,\n#:   with blanks translated to underscores.\n#:\n#: * Value: Normalized value.\nNORMALIZED_OS_ID = {\n    \"ol\": \"oracle\",  # Oracle Linux\n    \"opensuse-leap\": \"opensuse\",  # Newer versions of OpenSuSE report as opensuse-leap\n}\n\n#: Translation table for normalizing the \"Distributor ID\" attribute returned by\n#: the lsb_release command, for use by the :func:`distro.id` method.\n#:\n#: * Key: Value as returned by the lsb_release command, translated to lower\n#:   case, with blanks translated to underscores.\n#:\n#: * Value: Normalized value.\nNORMALIZED_LSB_ID = {\n    \"enterpriseenterpriseas\": \"oracle\",  # Oracle Enterprise Linux 4\n    \"enterpriseenterpriseserver\": \"oracle\",  # Oracle Linux 5\n    \"redhatenterpriseworkstation\": \"rhel\",  # RHEL 6, 7 Workstation\n    \"redhatenterpriseserver\": \"rhel\",  # RHEL 6, 7 Server\n    \"redhatenterprisecomputenode\": \"rhel\",  # RHEL 6 ComputeNode\n}\n\n#: Translation table for normalizing the distro ID derived from the file name\n#: of distro release files, for use by the :func:`distro.id` method.\n#:\n#: * Key: Value as derived from the file name of a distro release file,\n#:   translated to lower case, with blanks translated to underscores.\n#:\n#: * Value: Normalized value.\nNORMALIZED_DISTRO_ID = {\n    \"redhat\": \"rhel\",  # RHEL 6.x, 7.x\n}\n\n# Pattern for content of distro release file (reversed)\n_DISTRO_RELEASE_CONTENT_REVERSED_PATTERN = re.compile(\n    r\"(?:[^)]*\\)(.*)\\()? *(?:STL )?([\\d.+\\-a-z]*\\d) *(?:esaeler *)?(.+)\"\n)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distro\\__init__.py": {
      "sha": "4a736116da5e",
      "lines": 54,
      "head": "from .distro import (\n    NORMALIZED_DISTRO_ID,\n    NORMALIZED_LSB_ID,\n    NORMALIZED_OS_ID,\n    LinuxDistribution,\n    __version__,\n    build_number,\n    codename,\n    distro_release_attr,\n    distro_release_info,\n    id,\n    info,\n    like,\n    linux_distribution,\n    lsb_release_attr,\n    lsb_release_info,\n    major_version,\n    minor_version,\n    name,\n    os_release_attr,\n    os_release_info,\n    uname_attr,\n    uname_info,\n    version,\n    version_parts,\n)\n\n__all__ = [\n    \"NORMALIZED_DISTRO_ID\",\n    \"NORMALIZED_LSB_ID\",\n    \"NORMALIZED_OS_ID\",\n    \"LinuxDistribution\",\n    \"build_number\",\n    \"codename\",\n    \"distro_release_attr\",\n    \"distro_release_info\",\n    \"id\",\n    \"info\",\n    \"like\",\n    \"linux_distribution\",\n    \"lsb_release_attr\",\n    \"lsb_release_info\",\n    \"major_version\",\n    \"minor_version\",\n    \"name\",\n    \"os_release_attr\",\n    \"os_release_info\",\n    \"uname_attr\",\n    \"uname_info\",\n    \"version\",\n    \"version_parts\",\n]\n\n__version__ = __version__\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\distro\\__main__.py": {
      "sha": "be9d6fcd0deb",
      "lines": 4,
      "head": "from .distro import main\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\codec.py": {
      "sha": "c326ea0e90cd",
      "lines": 122,
      "head": "import codecs\nimport re\nfrom typing import Any, Optional, Tuple\n\nfrom .core import IDNAError, alabel, decode, encode, ulabel\n\n_unicode_dots_re = re.compile(\"[\\u002e\\u3002\\uff0e\\uff61]\")\n\n\nclass Codec(codecs.Codec):\n    def encode(self, data: str, errors: str = \"strict\") -> Tuple[bytes, int]:\n        if errors != \"strict\":\n            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))\n\n        if not data:\n            return b\"\", 0\n\n        return encode(data), len(data)\n\n    def decode(self, data: bytes, errors: str = \"strict\") -> Tuple[str, int]:\n        if errors != \"strict\":\n            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))\n\n        if not data:\n            return \"\", 0\n\n        return decode(data), len(data)\n\n\nclass IncrementalEncoder(codecs.BufferedIncrementalEncoder):\n    def _buffer_encode(self, data: str, errors: str, final: bool) -> Tuple[bytes, int]:\n        if errors != \"strict\":\n            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))\n\n        if not data:\n            return b\"\", 0\n\n        labels = _unicode_dots_re.split(data)\n        trailing_dot = b\"\"\n        if labels:\n            if not labels[-1]:\n                trailing_dot = b\".\"\n                del labels[-1]\n            elif not final:\n                # Keep potentially unfinished label until the next call\n                del labels[-1]\n                if labels:\n                    trailing_dot = b\".\"\n\n        result = []\n        size = 0\n        for label in labels:\n            result.append(alabel(label))\n            if size:\n                size += 1\n            size += len(label)\n\n        # Join with U+002E\n        result_bytes = b\".\".join(result) + trailing_dot\n        size += len(trailing_dot)\n        return result_bytes, size\n\n\nclass IncrementalDecoder(codecs.BufferedIncrementalDecoder):\n    def _buffer_decode(self, data: Any, errors: str, final: bool) -> Tuple[str, int]:\n        if errors != \"strict\":\n            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))\n\n        if not data:\n            return (\"\", 0)\n\n        if not isinstance(data, str):\n            data = str(data, \"ascii\")\n\n        labels = _unicode_dots_re.split(data)\n        trailing_dot = \"\"\n        if labels:\n            if not labels[-1]:\n                trailing_dot = \".\"\n                del labels[-1]\n            elif not final:\n                # Keep potentially unfinished label until the next call\n                del labels[-1]\n                if labels:\n                    trailing_dot = \".\"\n\n        result = []\n        size = 0\n        for label in labels:\n            result.append(ulabel(label))\n            if size:\n                size += 1\n            size += len(label)\n\n        result_str = \".\".join(result) + trailing_dot\n        size += len(trailing_dot)\n        return (result_str, size)\n\n\nclass StreamWriter(Codec, codecs.StreamWriter):\n    pass\n\n\nclass StreamReader(Codec, codecs.StreamReader):\n    pass\n\n\ndef search_function(name: str) -> Optional[codecs.CodecInfo]:\n    if name != \"idna2008\":\n        return None\n    return codecs.CodecInfo(\n        name=name,\n        encode=Codec().encode,\n        decode=Codec().decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamwriter=StreamWriter,\n        streamreader=StreamReader,\n    )\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\compat.py": {
      "sha": "b422d026efa3",
      "lines": 15,
      "head": "from typing import Any, Union\n\nfrom .core import decode, encode\n\n\ndef ToASCII(label: str) -> bytes:\n    return encode(label)\n\n\ndef ToUnicode(label: Union[bytes, bytearray]) -> str:\n    return decode(label)\n\n\ndef nameprep(s: Any) -> None:\n    raise NotImplementedError(\"IDNA 2008 does not utilise nameprep protocol\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\core.py": {
      "sha": "fdb292d5720b",
      "lines": 437,
      "head": "import bisect\nimport re\nimport unicodedata\nfrom typing import Optional, Union\n\nfrom . import idnadata\nfrom .intranges import intranges_contain\n\n_virama_combining_class = 9\n_alabel_prefix = b\"xn--\"\n_unicode_dots_re = re.compile(\"[\\u002e\\u3002\\uff0e\\uff61]\")\n\n\nclass IDNAError(UnicodeError):\n    \"\"\"Base exception for all IDNA-encoding related problems\"\"\"\n\n    pass\n\n\nclass IDNABidiError(IDNAError):\n    \"\"\"Exception when bidirectional requirements are not satisfied\"\"\"\n\n    pass\n\n\nclass InvalidCodepoint(IDNAError):\n    \"\"\"Exception when a disallowed or unallocated codepoint is used\"\"\"\n\n    pass\n\n\nclass InvalidCodepointContext(IDNAError):\n    \"\"\"Exception when the codepoint is not valid in the context it is used\"\"\"\n\n    pass\n\n\ndef _combining_class(cp: int) -> int:\n    v = unicodedata.combining(chr(cp))\n    if v == 0:\n        if not unicodedata.name(chr(cp)):\n            raise ValueError(\"Unknown character in unicodedata\")\n    return v\n\n\ndef _is_script(cp: str, script: str) -> bool:\n    return intranges_contain(ord(cp), idnadata.scripts[script])\n\n\ndef _punycode(s: str) -> bytes:\n    return s.encode(\"punycode\")\n\n\ndef _unot(s: int) -> str:\n    return \"U+{:04X}\".format(s)\n\n\ndef valid_label_length(label: Union[bytes, str]) -> bool:\n    if len(label) > 63:\n        return False\n    return True\n\n\ndef valid_string_length(label: Union[bytes, str], trailing_dot: bool) -> bool:\n    if len(label) > (254 if trailing_dot else 253):\n        return False\n    return True\n\n\ndef check_bidi(label: str, check_ltr: bool = False) -> bool:\n    # Bidi rules should only be applied if string contains RTL characters\n    bidi_label = False\n    for idx, cp in enumerate(label, 1):\n        direction = unicodedata.bidirectional(cp)\n        if direction == \"\":\n            # String likely comes from a newer version of Unicode\n            raise IDNABidiError(\"Unknown directionality in label {} at position {}\".format(repr(label), idx))\n        if direction in [\"R\", \"AL\", \"AN\"]:\n            bidi_label = True\n    if not bidi_label and not check_ltr:\n        return True\n\n    # Bidi rule 1\n    direction = unicodedata.bidirectional(label[0])\n    if direction in [\"R\", \"AL\"]:\n        rtl = True\n    elif direction == \"L\":\n        rtl = False\n    else:\n        raise IDNABidiError(\"First codepoint in label {} must be directionality L, R or AL\".format(repr(label)))\n\n    valid_ending = False\n    number_type: Optional[str] = None\n    for idx, cp in enumerate(label, 1):\n        direction = unicodedata.bidirectional(cp)\n\n        if rtl:\n            # Bidi rule 2\n            if direction not in [\n                \"R\",\n                \"AL\",\n                \"AN\",\n                \"EN\",\n                \"ES\",\n                \"CS\",\n                \"ET\",\n                \"ON\",\n                \"BN\",\n                \"NSM\",\n            ]:\n                raise IDNABidiError(\"Invalid direction for codepoint at position {} in a right-to-left label\".format(idx))\n            # Bidi rule 3\n            if direction in [\"R\", \"AL\", \"EN\", \"AN\"]:\n                valid_ending = True\n            elif direction != \"NSM\":\n                valid_ending = False\n            # Bidi rule 4\n            if direction in [\"AN\", \"EN\"]:\n                if not number_type:\n                    number_type = direction\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\idnadata.py": {
      "sha": "4c9e8b910da0",
      "lines": 4243,
      "head": "# This file is automatically generated by tools/idna-data\n\n__version__ = \"15.1.0\"\nscripts = {\n    \"Greek\": (\n        0x37000000374,\n        0x37500000378,\n        0x37A0000037E,\n        0x37F00000380,\n        0x38400000385,\n        0x38600000387,\n        0x3880000038B,\n        0x38C0000038D,\n        0x38E000003A2,\n        0x3A3000003E2,\n        0x3F000000400,\n        0x1D2600001D2B,\n        0x1D5D00001D62,\n        0x1D6600001D6B,\n        0x1DBF00001DC0,\n        0x1F0000001F16,\n        0x1F1800001F1E,\n        0x1F2000001F46,\n        0x1F4800001F4E,\n        0x1F5000001F58,\n        0x1F5900001F5A,\n        0x1F5B00001F5C,\n        0x1F5D00001F5E,\n        0x1F5F00001F7E,\n        0x1F8000001FB5,\n        0x1FB600001FC5,\n        0x1FC600001FD4,\n        0x1FD600001FDC,\n        0x1FDD00001FF0,\n        0x1FF200001FF5,\n        0x1FF600001FFF,\n        0x212600002127,\n        0xAB650000AB66,\n        0x101400001018F,\n        0x101A0000101A1,\n        0x1D2000001D246,\n    ),\n    \"Han\": (\n        0x2E8000002E9A,\n        0x2E9B00002EF4,\n        0x2F0000002FD6,\n        0x300500003006,\n        0x300700003008,\n        0x30210000302A,\n        0x30380000303C,\n        0x340000004DC0,\n        0x4E000000A000,\n        0xF9000000FA6E,\n        0xFA700000FADA,\n        0x16FE200016FE4,\n        0x16FF000016FF2,\n        0x200000002A6E0,\n        0x2A7000002B73A,\n        0x2B7400002B81E,\n        0x2B8200002CEA2,\n        0x2CEB00002EBE1,\n        0x2EBF00002EE5E,\n        0x2F8000002FA1E,\n        0x300000003134B,\n        0x31350000323B0,\n    ),\n    \"Hebrew\": (\n        0x591000005C8,\n        0x5D0000005EB,\n        0x5EF000005F5,\n        0xFB1D0000FB37,\n        0xFB380000FB3D,\n        0xFB3E0000FB3F,\n        0xFB400000FB42,\n        0xFB430000FB45,\n        0xFB460000FB50,\n    ),\n    \"Hiragana\": (\n        0x304100003097,\n        0x309D000030A0,\n        0x1B0010001B120,\n        0x1B1320001B133,\n        0x1B1500001B153,\n        0x1F2000001F201,\n    ),\n    \"Katakana\": (\n        0x30A1000030FB,\n        0x30FD00003100,\n        0x31F000003200,\n        0x32D0000032FF,\n        0x330000003358,\n        0xFF660000FF70,\n        0xFF710000FF9E,\n        0x1AFF00001AFF4,\n        0x1AFF50001AFFC,\n        0x1AFFD0001AFFF,\n        0x1B0000001B001,\n        0x1B1200001B123,\n        0x1B1550001B156,\n        0x1B1640001B168,\n    ),\n}\njoining_types = {\n    0xAD: 84,\n    0x300: 84,\n    0x301: 84,\n    0x302: 84,\n    0x303: 84,\n    0x304: 84,\n    0x305: 84,\n    0x306: 84,\n    0x307: 84,\n    0x308: 84,\n    0x309: 84,\n    0x30A: 84,\n    0x30B: 84,\n    0x30C: 84,\n    0x30D: 84,\n    0x30E: 84,\n    0x30F: 84,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\intranges.py": {
      "sha": "6eaa004ade4e",
      "lines": 57,
      "head": "\"\"\"\nGiven a list of integers, made up of (hopefully) a small number of long runs\nof consecutive integers, compute a representation of the form\n((start1, end1), (start2, end2) ...). Then answer the question \"was x present\nin the original list?\" in time O(log(# runs)).\n\"\"\"\n\nimport bisect\nfrom typing import List, Tuple\n\n\ndef intranges_from_list(list_: List[int]) -> Tuple[int, ...]:\n    \"\"\"Represent a list of integers as a sequence of ranges:\n    ((start_0, end_0), (start_1, end_1), ...), such that the original\n    integers are exactly those x such that start_i <= x < end_i for some i.\n\n    Ranges are encoded as single integers (start << 32 | end), not as tuples.\n    \"\"\"\n\n    sorted_list = sorted(list_)\n    ranges = []\n    last_write = -1\n    for i in range(len(sorted_list)):\n        if i + 1 < len(sorted_list):\n            if sorted_list[i] == sorted_list[i + 1] - 1:\n                continue\n        current_range = sorted_list[last_write + 1 : i + 1]\n        ranges.append(_encode_range(current_range[0], current_range[-1] + 1))\n        last_write = i\n\n    return tuple(ranges)\n\n\ndef _encode_range(start: int, end: int) -> int:\n    return (start << 32) | end\n\n\ndef _decode_range(r: int) -> Tuple[int, int]:\n    return (r >> 32), (r & ((1 << 32) - 1))\n\n\ndef intranges_contain(int_: int, ranges: Tuple[int, ...]) -> bool:\n    \"\"\"Determine if `int_` falls into one of the ranges in `ranges`.\"\"\"\n    tuple_ = _encode_range(int_, 0)\n    pos = bisect.bisect_left(ranges, tuple_)\n    # we could be immediately ahead of a tuple (start, end)\n    # with start < int_ <= end\n    if pos > 0:\n        left, right = _decode_range(ranges[pos - 1])\n        if left <= int_ < right:\n            return True\n    # or we could be immediately behind a tuple (int_, end)\n    if pos < len(ranges):\n        left, _ = _decode_range(ranges[pos])\n        if left == int_:\n            return True\n    return False\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\package_data.py": {
      "sha": "fb51b9874f7a",
      "lines": 1,
      "head": "__version__ = \"3.10\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\uts46data.py": {
      "sha": "1656dbb17e98",
      "lines": 8681,
      "head": "# This file is automatically generated by tools/idna-data\n# vim: set fileencoding=utf-8 :\n\nfrom typing import List, Tuple, Union\n\n\"\"\"IDNA Mapping Table from UTS46.\"\"\"\n\n\n__version__ = \"15.1.0\"\n\n\ndef _seg_0() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:\n    return [\n        (0x0, \"3\"),\n        (0x1, \"3\"),\n        (0x2, \"3\"),\n        (0x3, \"3\"),\n        (0x4, \"3\"),\n        (0x5, \"3\"),\n        (0x6, \"3\"),\n        (0x7, \"3\"),\n        (0x8, \"3\"),\n        (0x9, \"3\"),\n        (0xA, \"3\"),\n        (0xB, \"3\"),\n        (0xC, \"3\"),\n        (0xD, \"3\"),\n        (0xE, \"3\"),\n        (0xF, \"3\"),\n        (0x10, \"3\"),\n        (0x11, \"3\"),\n        (0x12, \"3\"),\n        (0x13, \"3\"),\n        (0x14, \"3\"),\n        (0x15, \"3\"),\n        (0x16, \"3\"),\n        (0x17, \"3\"),\n        (0x18, \"3\"),\n        (0x19, \"3\"),\n        (0x1A, \"3\"),\n        (0x1B, \"3\"),\n        (0x1C, \"3\"),\n        (0x1D, \"3\"),\n        (0x1E, \"3\"),\n        (0x1F, \"3\"),\n        (0x20, \"3\"),\n        (0x21, \"3\"),\n        (0x22, \"3\"),\n        (0x23, \"3\"),\n        (0x24, \"3\"),\n        (0x25, \"3\"),\n        (0x26, \"3\"),\n        (0x27, \"3\"),\n        (0x28, \"3\"),\n        (0x29, \"3\"),\n        (0x2A, \"3\"),\n        (0x2B, \"3\"),\n        (0x2C, \"3\"),\n        (0x2D, \"V\"),\n        (0x2E, \"V\"),\n        (0x2F, \"3\"),\n        (0x30, \"V\"),\n        (0x31, \"V\"),\n        (0x32, \"V\"),\n        (0x33, \"V\"),\n        (0x34, \"V\"),\n        (0x35, \"V\"),\n        (0x36, \"V\"),\n        (0x37, \"V\"),\n        (0x38, \"V\"),\n        (0x39, \"V\"),\n        (0x3A, \"3\"),\n        (0x3B, \"3\"),\n        (0x3C, \"3\"),\n        (0x3D, \"3\"),\n        (0x3E, \"3\"),\n        (0x3F, \"3\"),\n        (0x40, \"3\"),\n        (0x41, \"M\", \"a\"),\n        (0x42, \"M\", \"b\"),\n        (0x43, \"M\", \"c\"),\n        (0x44, \"M\", \"d\"),\n        (0x45, \"M\", \"e\"),\n        (0x46, \"M\", \"f\"),\n        (0x47, \"M\", \"g\"),\n        (0x48, \"M\", \"h\"),\n        (0x49, \"M\", \"i\"),\n        (0x4A, \"M\", \"j\"),\n        (0x4B, \"M\", \"k\"),\n        (0x4C, \"M\", \"l\"),\n        (0x4D, \"M\", \"m\"),\n        (0x4E, \"M\", \"n\"),\n        (0x4F, \"M\", \"o\"),\n        (0x50, \"M\", \"p\"),\n        (0x51, \"M\", \"q\"),\n        (0x52, \"M\", \"r\"),\n        (0x53, \"M\", \"s\"),\n        (0x54, \"M\", \"t\"),\n        (0x55, \"M\", \"u\"),\n        (0x56, \"M\", \"v\"),\n        (0x57, \"M\", \"w\"),\n        (0x58, \"M\", \"x\"),\n        (0x59, \"M\", \"y\"),\n        (0x5A, \"M\", \"z\"),\n        (0x5B, \"3\"),\n        (0x5C, \"3\"),\n        (0x5D, \"3\"),\n        (0x5E, \"3\"),\n        (0x5F, \"3\"),\n        (0x60, \"3\"),\n        (0x61, \"V\"),\n        (0x62, \"V\"),\n        (0x63, \"V\"),\n    ]\n\n\ndef _seg_1() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:\n    return [\n        (0x64, \"V\"),\n        (0x65, \"V\"),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\idna\\__init__.py": {
      "sha": "d4af52a5c4f4",
      "lines": 45,
      "head": "from .core import (\n    IDNABidiError,\n    IDNAError,\n    InvalidCodepoint,\n    InvalidCodepointContext,\n    alabel,\n    check_bidi,\n    check_hyphen_ok,\n    check_initial_combiner,\n    check_label,\n    check_nfc,\n    decode,\n    encode,\n    ulabel,\n    uts46_remap,\n    valid_contextj,\n    valid_contexto,\n    valid_label_length,\n    valid_string_length,\n)\nfrom .intranges import intranges_contain\nfrom .package_data import __version__\n\n__all__ = [\n    \"__version__\",\n    \"IDNABidiError\",\n    \"IDNAError\",\n    \"InvalidCodepoint\",\n    \"InvalidCodepointContext\",\n    \"alabel\",\n    \"check_bidi\",\n    \"check_hyphen_ok\",\n    \"check_initial_combiner\",\n    \"check_label\",\n    \"check_nfc\",\n    \"decode\",\n    \"encode\",\n    \"intranges_contain\",\n    \"ulabel\",\n    \"uts46_remap\",\n    \"valid_contextj\",\n    \"valid_contexto\",\n    \"valid_label_length\",\n    \"valid_string_length\",\n]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\msgpack\\exceptions.py": {
      "sha": "4ceae08460a4",
      "lines": 48,
      "head": "class UnpackException(Exception):\n    \"\"\"Base class for some exceptions raised while unpacking.\n\n    NOTE: unpack may raise exception other than subclass of\n    UnpackException.  If you want to catch all error, catch\n    Exception instead.\n    \"\"\"\n\n\nclass BufferFull(UnpackException):\n    pass\n\n\nclass OutOfData(UnpackException):\n    pass\n\n\nclass FormatError(ValueError, UnpackException):\n    \"\"\"Invalid msgpack format\"\"\"\n\n\nclass StackError(ValueError, UnpackException):\n    \"\"\"Too nested\"\"\"\n\n\n# Deprecated.  Use ValueError instead\nUnpackValueError = ValueError\n\n\nclass ExtraData(UnpackValueError):\n    \"\"\"ExtraData is raised when there is trailing data.\n\n    This exception is raised while only one-shot (not streaming)\n    unpack.\n    \"\"\"\n\n    def __init__(self, unpacked, extra):\n        self.unpacked = unpacked\n        self.extra = extra\n\n    def __str__(self):\n        return \"unpack(b) received extra data.\"\n\n\n# Deprecated.  Use Exception instead to catch all exception during packing.\nPackException = Exception\nPackValueError = ValueError\nPackOverflowError = OverflowError\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\msgpack\\ext.py": {
      "sha": "eca62dc33fe1",
      "lines": 170,
      "head": "import datetime\nimport struct\nfrom collections import namedtuple\n\n\nclass ExtType(namedtuple(\"ExtType\", \"code data\")):\n    \"\"\"ExtType represents ext type in msgpack.\"\"\"\n\n    def __new__(cls, code, data):\n        if not isinstance(code, int):\n            raise TypeError(\"code must be int\")\n        if not isinstance(data, bytes):\n            raise TypeError(\"data must be bytes\")\n        if not 0 <= code <= 127:\n            raise ValueError(\"code must be 0~127\")\n        return super().__new__(cls, code, data)\n\n\nclass Timestamp:\n    \"\"\"Timestamp represents the Timestamp extension type in msgpack.\n\n    When built with Cython, msgpack uses C methods to pack and unpack `Timestamp`.\n    When using pure-Python msgpack, :func:`to_bytes` and :func:`from_bytes` are used to pack and\n    unpack `Timestamp`.\n\n    This class is immutable: Do not override seconds and nanoseconds.\n    \"\"\"\n\n    __slots__ = [\"seconds\", \"nanoseconds\"]\n\n    def __init__(self, seconds, nanoseconds=0):\n        \"\"\"Initialize a Timestamp object.\n\n        :param int seconds:\n            Number of seconds since the UNIX epoch (00:00:00 UTC Jan 1 1970, minus leap seconds).\n            May be negative.\n\n        :param int nanoseconds:\n            Number of nanoseconds to add to `seconds` to get fractional time.\n            Maximum is 999_999_999.  Default is 0.\n\n        Note: Negative times (before the UNIX epoch) are represented as neg. seconds + pos. ns.\n        \"\"\"\n        if not isinstance(seconds, int):\n            raise TypeError(\"seconds must be an integer\")\n        if not isinstance(nanoseconds, int):\n            raise TypeError(\"nanoseconds must be an integer\")\n        if not (0 <= nanoseconds < 10**9):\n            raise ValueError(\"nanoseconds must be a non-negative integer less than 999999999.\")\n        self.seconds = seconds\n        self.nanoseconds = nanoseconds\n\n    def __repr__(self):\n        \"\"\"String representation of Timestamp.\"\"\"\n        return f\"Timestamp(seconds={self.seconds}, nanoseconds={self.nanoseconds})\"\n\n    def __eq__(self, other):\n        \"\"\"Check for equality with another Timestamp object\"\"\"\n        if type(other) is self.__class__:\n            return self.seconds == other.seconds and self.nanoseconds == other.nanoseconds\n        return False\n\n    def __ne__(self, other):\n        \"\"\"not-equals method (see :func:`__eq__()`)\"\"\"\n        return not self.__eq__(other)\n\n    def __hash__(self):\n        return hash((self.seconds, self.nanoseconds))\n\n    @staticmethod\n    def from_bytes(b):\n        \"\"\"Unpack bytes into a `Timestamp` object.\n\n        Used for pure-Python msgpack unpacking.\n\n        :param b: Payload from msgpack ext message with code -1\n        :type b: bytes\n\n        :returns: Timestamp object unpacked from msgpack ext payload\n        :rtype: Timestamp\n        \"\"\"\n        if len(b) == 4:\n            seconds = struct.unpack(\"!L\", b)[0]\n            nanoseconds = 0\n        elif len(b) == 8:\n            data64 = struct.unpack(\"!Q\", b)[0]\n            seconds = data64 & 0x00000003FFFFFFFF\n            nanoseconds = data64 >> 34\n        elif len(b) == 12:\n            nanoseconds, seconds = struct.unpack(\"!Iq\", b)\n        else:\n            raise ValueError(\n                \"Timestamp type can only be created from 32, 64, or 96-bit byte objects\"\n            )\n        return Timestamp(seconds, nanoseconds)\n\n    def to_bytes(self):\n        \"\"\"Pack this Timestamp object into bytes.\n\n        Used for pure-Python msgpack packing.\n\n        :returns data: Payload for EXT message with code -1 (timestamp type)\n        :rtype: bytes\n        \"\"\"\n        if (self.seconds >> 34) == 0:  # seconds is non-negative and fits in 34 bits\n            data64 = self.nanoseconds << 34 | self.seconds\n            if data64 & 0xFFFFFFFF00000000 == 0:\n                # nanoseconds is zero and seconds < 2**32, so timestamp 32\n                data = struct.pack(\"!L\", data64)\n            else:\n                # timestamp 64\n                data = struct.pack(\"!Q\", data64)\n        else:\n            # timestamp 96\n            data = struct.pack(\"!Iq\", self.nanoseconds, self.seconds)\n        return data\n\n    @staticmethod\n    def from_unix(unix_sec):\n        \"\"\"Create a Timestamp from posix timestamp in seconds.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\msgpack\\fallback.py": {
      "sha": "6598daab9910",
      "lines": 929,
      "head": "\"\"\"Fallback pure Python implementation of msgpack\"\"\"\n\nimport struct\nimport sys\nfrom datetime import datetime as _DateTime\n\nif hasattr(sys, \"pypy_version_info\"):\n    from __pypy__ import newlist_hint\n    from __pypy__.builders import BytesBuilder\n\n    _USING_STRINGBUILDER = True\n\n    class BytesIO:\n        def __init__(self, s=b\"\"):\n            if s:\n                self.builder = BytesBuilder(len(s))\n                self.builder.append(s)\n            else:\n                self.builder = BytesBuilder()\n\n        def write(self, s):\n            if isinstance(s, memoryview):\n                s = s.tobytes()\n            elif isinstance(s, bytearray):\n                s = bytes(s)\n            self.builder.append(s)\n\n        def getvalue(self):\n            return self.builder.build()\n\nelse:\n    from io import BytesIO\n\n    _USING_STRINGBUILDER = False\n\n    def newlist_hint(size):\n        return []\n\n\nfrom .exceptions import BufferFull, ExtraData, FormatError, OutOfData, StackError\nfrom .ext import ExtType, Timestamp\n\nEX_SKIP = 0\nEX_CONSTRUCT = 1\nEX_READ_ARRAY_HEADER = 2\nEX_READ_MAP_HEADER = 3\n\nTYPE_IMMEDIATE = 0\nTYPE_ARRAY = 1\nTYPE_MAP = 2\nTYPE_RAW = 3\nTYPE_BIN = 4\nTYPE_EXT = 5\n\nDEFAULT_RECURSE_LIMIT = 511\n\n\ndef _check_type_strict(obj, t, type=type, tuple=tuple):\n    if type(t) is tuple:\n        return type(obj) in t\n    else:\n        return type(obj) is t\n\n\ndef _get_data_from_buffer(obj):\n    view = memoryview(obj)\n    if view.itemsize != 1:\n        raise ValueError(\"cannot unpack from multi-byte object\")\n    return view\n\n\ndef unpackb(packed, **kwargs):\n    \"\"\"\n    Unpack an object from `packed`.\n\n    Raises ``ExtraData`` when *packed* contains extra bytes.\n    Raises ``ValueError`` when *packed* is incomplete.\n    Raises ``FormatError`` when *packed* is not valid msgpack.\n    Raises ``StackError`` when *packed* contains too nested.\n    Other exceptions can be raised during unpacking.\n\n    See :class:`Unpacker` for options.\n    \"\"\"\n    unpacker = Unpacker(None, max_buffer_size=len(packed), **kwargs)\n    unpacker.feed(packed)\n    try:\n        ret = unpacker._unpack()\n    except OutOfData:\n        raise ValueError(\"Unpack failed: incomplete input\")\n    except RecursionError:\n        raise StackError\n    if unpacker._got_extradata():\n        raise ExtraData(ret, unpacker._get_extradata())\n    return ret\n\n\n_NO_FORMAT_USED = \"\"\n_MSGPACK_HEADERS = {\n    0xC4: (1, _NO_FORMAT_USED, TYPE_BIN),\n    0xC5: (2, \">H\", TYPE_BIN),\n    0xC6: (4, \">I\", TYPE_BIN),\n    0xC7: (2, \"Bb\", TYPE_EXT),\n    0xC8: (3, \">Hb\", TYPE_EXT),\n    0xC9: (5, \">Ib\", TYPE_EXT),\n    0xCA: (4, \">f\"),\n    0xCB: (8, \">d\"),\n    0xCC: (1, _NO_FORMAT_USED),\n    0xCD: (2, \">H\"),\n    0xCE: (4, \">I\"),\n    0xCF: (8, \">Q\"),\n    0xD0: (1, \"b\"),\n    0xD1: (2, \">h\"),\n    0xD2: (4, \">i\"),\n    0xD3: (8, \">q\"),\n    0xD4: (1, \"b1s\", TYPE_EXT),\n    0xD5: (2, \"b2s\", TYPE_EXT),\n    0xD6: (4, \"b4s\", TYPE_EXT),\n    0xD7: (8, \"b8s\", TYPE_EXT),\n    0xD8: (16, \"b16s\", TYPE_EXT),\n    0xD9: (1, _NO_FORMAT_USED, TYPE_RAW),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\msgpack\\__init__.py": {
      "sha": "82af82668d0f",
      "lines": 55,
      "head": "# ruff: noqa: F401\nimport os\n\nfrom .exceptions import *  # noqa: F403\nfrom .ext import ExtType, Timestamp\n\nversion = (1, 1, 0)\n__version__ = \"1.1.0\"\n\n\nif os.environ.get(\"MSGPACK_PUREPYTHON\"):\n    from .fallback import Packer, Unpacker, unpackb\nelse:\n    try:\n        from ._cmsgpack import Packer, Unpacker, unpackb\n    except ImportError:\n        from .fallback import Packer, Unpacker, unpackb\n\n\ndef pack(o, stream, **kwargs):\n    \"\"\"\n    Pack object `o` and write it to `stream`\n\n    See :class:`Packer` for options.\n    \"\"\"\n    packer = Packer(**kwargs)\n    stream.write(packer.pack(o))\n\n\ndef packb(o, **kwargs):\n    \"\"\"\n    Pack object `o` and return packed bytes\n\n    See :class:`Packer` for options.\n    \"\"\"\n    return Packer(**kwargs).pack(o)\n\n\ndef unpack(stream, **kwargs):\n    \"\"\"\n    Unpack an object from `stream`.\n\n    Raises `ExtraData` when `stream` contains extra bytes.\n    See :class:`Unpacker` for options.\n    \"\"\"\n    data = stream.read()\n    return unpackb(data, **kwargs)\n\n\n# alias for compatibility to simplejson/marshal/pickle.\nload = unpack\nloads = unpackb\n\ndump = pack\ndumps = packb\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\markers.py": {
      "sha": "0d069835202b",
      "lines": 362,
      "head": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\nfrom __future__ import annotations\n\nimport operator\nimport os\nimport platform\nimport sys\nfrom typing import AbstractSet, Any, Callable, Literal, TypedDict, Union, cast\n\nfrom ._parser import MarkerAtom, MarkerList, Op, Value, Variable\nfrom ._parser import parse_marker as _parse_marker\nfrom ._tokenizer import ParserSyntaxError\nfrom .specifiers import InvalidSpecifier, Specifier\nfrom .utils import canonicalize_name\n\n__all__ = [\n    \"EvaluateContext\",\n    \"InvalidMarker\",\n    \"Marker\",\n    \"UndefinedComparison\",\n    \"UndefinedEnvironmentName\",\n    \"default_environment\",\n]\n\nOperator = Callable[[str, Union[str, AbstractSet[str]]], bool]\nEvaluateContext = Literal[\"metadata\", \"lock_file\", \"requirement\"]\nMARKERS_ALLOWING_SET = {\"extras\", \"dependency_groups\"}\n\n\nclass InvalidMarker(ValueError):\n    \"\"\"\n    An invalid marker was found, users should refer to PEP 508.\n    \"\"\"\n\n\nclass UndefinedComparison(ValueError):\n    \"\"\"\n    An invalid operation was attempted on a value that doesn't support it.\n    \"\"\"\n\n\nclass UndefinedEnvironmentName(ValueError):\n    \"\"\"\n    A name was attempted to be used that does not exist inside of the\n    environment.\n    \"\"\"\n\n\nclass Environment(TypedDict):\n    implementation_name: str\n    \"\"\"The implementation's identifier, e.g. ``'cpython'``.\"\"\"\n\n    implementation_version: str\n    \"\"\"\n    The implementation's version, e.g. ``'3.13.0a2'`` for CPython 3.13.0a2, or\n    ``'7.3.13'`` for PyPy3.10 v7.3.13.\n    \"\"\"\n\n    os_name: str\n    \"\"\"\n    The value of :py:data:`os.name`. The name of the operating system dependent module\n    imported, e.g. ``'posix'``.\n    \"\"\"\n\n    platform_machine: str\n    \"\"\"\n    Returns the machine type, e.g. ``'i386'``.\n\n    An empty string if the value cannot be determined.\n    \"\"\"\n\n    platform_release: str\n    \"\"\"\n    The system's release, e.g. ``'2.2.0'`` or ``'NT'``.\n\n    An empty string if the value cannot be determined.\n    \"\"\"\n\n    platform_system: str\n    \"\"\"\n    The system/OS name, e.g. ``'Linux'``, ``'Windows'`` or ``'Java'``.\n\n    An empty string if the value cannot be determined.\n    \"\"\"\n\n    platform_version: str\n    \"\"\"\n    The system's release version, e.g. ``'#3 on degas'``.\n\n    An empty string if the value cannot be determined.\n    \"\"\"\n\n    python_full_version: str\n    \"\"\"\n    The Python version as string ``'major.minor.patchlevel'``.\n\n    Note that unlike the Python :py:data:`sys.version`, this value will always include\n    the patchlevel (it defaults to 0).\n    \"\"\"\n\n    platform_python_implementation: str\n    \"\"\"\n    A string identifying the Python implementation, e.g. ``'CPython'``.\n    \"\"\"\n\n    python_version: str\n    \"\"\"The Python version as string ``'major.minor'``.\"\"\"\n\n    sys_platform: str\n    \"\"\"\n    This string contains a platform identifier that can be used to append\n    platform-specific components to :py:data:`sys.path`, for instance.\n\n    For Unix systems, except on Linux and AIX, this is the lowercased OS name as\n    returned by ``uname -s`` with the first part of the version as returned by\n    ``uname -r`` appended, e.g. ``'sunos5'`` or ``'freebsd8'``, at the time when Python\n    was built.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\metadata.py": {
      "sha": "9a47c487e344",
      "lines": 862,
      "head": "from __future__ import annotations\n\nimport email.feedparser\nimport email.header\nimport email.message\nimport email.parser\nimport email.policy\nimport pathlib\nimport sys\nimport typing\nfrom typing import (\n    Any,\n    Callable,\n    Generic,\n    Literal,\n    TypedDict,\n    cast,\n)\n\nfrom . import licenses, requirements, specifiers, utils\nfrom . import version as version_module\nfrom .licenses import NormalizedLicenseExpression\n\nT = typing.TypeVar(\"T\")\n\n\nif sys.version_info >= (3, 11):  # pragma: no cover\n    ExceptionGroup = ExceptionGroup\nelse:  # pragma: no cover\n\n    class ExceptionGroup(Exception):\n        \"\"\"A minimal implementation of :external:exc:`ExceptionGroup` from Python 3.11.\n\n        If :external:exc:`ExceptionGroup` is already defined by Python itself,\n        that version is used instead.\n        \"\"\"\n\n        message: str\n        exceptions: list[Exception]\n\n        def __init__(self, message: str, exceptions: list[Exception]) -> None:\n            self.message = message\n            self.exceptions = exceptions\n\n        def __repr__(self) -> str:\n            return f\"{self.__class__.__name__}({self.message!r}, {self.exceptions!r})\"\n\n\nclass InvalidMetadata(ValueError):\n    \"\"\"A metadata field contains invalid data.\"\"\"\n\n    field: str\n    \"\"\"The name of the field that contains invalid data.\"\"\"\n\n    def __init__(self, field: str, message: str) -> None:\n        self.field = field\n        super().__init__(message)\n\n\n# The RawMetadata class attempts to make as few assumptions about the underlying\n# serialization formats as possible. The idea is that as long as a serialization\n# formats offer some very basic primitives in *some* way then we can support\n# serializing to and from that format.\nclass RawMetadata(TypedDict, total=False):\n    \"\"\"A dictionary of raw core metadata.\n\n    Each field in core metadata maps to a key of this dictionary (when data is\n    provided). The key is lower-case and underscores are used instead of dashes\n    compared to the equivalent core metadata field. Any core metadata field that\n    can be specified multiple times or can hold multiple values in a single\n    field have a key with a plural name. See :class:`Metadata` whose attributes\n    match the keys of this dictionary.\n\n    Core metadata fields that can be specified multiple times are stored as a\n    list or dict depending on which is appropriate for the field. Any fields\n    which hold multiple values in a single field are stored as a list.\n\n    \"\"\"\n\n    # Metadata 1.0 - PEP 241\n    metadata_version: str\n    name: str\n    version: str\n    platforms: list[str]\n    summary: str\n    description: str\n    keywords: list[str]\n    home_page: str\n    author: str\n    author_email: str\n    license: str\n\n    # Metadata 1.1 - PEP 314\n    supported_platforms: list[str]\n    download_url: str\n    classifiers: list[str]\n    requires: list[str]\n    provides: list[str]\n    obsoletes: list[str]\n\n    # Metadata 1.2 - PEP 345\n    maintainer: str\n    maintainer_email: str\n    requires_dist: list[str]\n    provides_dist: list[str]\n    obsoletes_dist: list[str]\n    requires_python: str\n    requires_external: list[str]\n    project_urls: dict[str, str]\n\n    # Metadata 2.0\n    # PEP 426 attempted to completely revamp the metadata format\n    # but got stuck without ever being able to build consensus on\n    # it and ultimately ended up withdrawn.\n    #\n    # However, a number of tools had started emitting METADATA with\n    # `2.0` Metadata-Version, so for historical reasons, this version\n    # was skipped.\n\n    # Metadata 2.1 - PEP 566\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py": {
      "sha": "1c36b3e629a0",
      "lines": 91,
      "head": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\nfrom __future__ import annotations\n\nfrom typing import Any, Iterator\n\nfrom ._parser import parse_requirement as _parse_requirement\nfrom ._tokenizer import ParserSyntaxError\nfrom .markers import Marker, _normalize_extra_values\nfrom .specifiers import SpecifierSet\nfrom .utils import canonicalize_name\n\n\nclass InvalidRequirement(ValueError):\n    \"\"\"\n    An invalid requirement was found, users should refer to PEP 508.\n    \"\"\"\n\n\nclass Requirement:\n    \"\"\"Parse a requirement.\n\n    Parse a given requirement string into its parts, such as name, specifier,\n    URL, and extras. Raises InvalidRequirement on a badly-formed requirement\n    string.\n    \"\"\"\n\n    # TODO: Can we test whether something is contained within a requirement?\n    #       If so how do we do that? Do we need to test against the _name_ of\n    #       the thing as well as the version? What about the markers?\n    # TODO: Can we normalize the name and extra name?\n\n    def __init__(self, requirement_string: str) -> None:\n        try:\n            parsed = _parse_requirement(requirement_string)\n        except ParserSyntaxError as e:\n            raise InvalidRequirement(str(e)) from e\n\n        self.name: str = parsed.name\n        self.url: str | None = parsed.url or None\n        self.extras: set[str] = set(parsed.extras or [])\n        self.specifier: SpecifierSet = SpecifierSet(parsed.specifier)\n        self.marker: Marker | None = None\n        if parsed.marker is not None:\n            self.marker = Marker.__new__(Marker)\n            self.marker._markers = _normalize_extra_values(parsed.marker)\n\n    def _iter_parts(self, name: str) -> Iterator[str]:\n        yield name\n\n        if self.extras:\n            formatted_extras = \",\".join(sorted(self.extras))\n            yield f\"[{formatted_extras}]\"\n\n        if self.specifier:\n            yield str(self.specifier)\n\n        if self.url:\n            yield f\"@ {self.url}\"\n            if self.marker:\n                yield \" \"\n\n        if self.marker:\n            yield f\"; {self.marker}\"\n\n    def __str__(self) -> str:\n        return \"\".join(self._iter_parts(self.name))\n\n    def __repr__(self) -> str:\n        return f\"<Requirement('{self}')>\"\n\n    def __hash__(self) -> int:\n        return hash(\n            (\n                self.__class__.__name__,\n                *self._iter_parts(canonicalize_name(self.name)),\n            )\n        )\n\n    def __eq__(self, other: Any) -> bool:\n        if not isinstance(other, Requirement):\n            return NotImplemented\n\n        return (\n            canonicalize_name(self.name) == canonicalize_name(other.name)\n            and self.extras == other.extras\n            and self.specifier == other.specifier\n            and self.url == other.url\n            and self.marker == other.marker\n        )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\specifiers.py": {
      "sha": "a9c95cd27c7c",
      "lines": 1019,
      "head": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\"\"\"\n.. testsetup::\n\n    from pip._vendor.packaging.specifiers import Specifier, SpecifierSet, InvalidSpecifier\n    from pip._vendor.packaging.version import Version\n\"\"\"\n\nfrom __future__ import annotations\n\nimport abc\nimport itertools\nimport re\nfrom typing import Callable, Iterable, Iterator, TypeVar, Union\n\nfrom .utils import canonicalize_version\nfrom .version import Version\n\nUnparsedVersion = Union[Version, str]\nUnparsedVersionVar = TypeVar(\"UnparsedVersionVar\", bound=UnparsedVersion)\nCallableOperator = Callable[[Version, str], bool]\n\n\ndef _coerce_version(version: UnparsedVersion) -> Version:\n    if not isinstance(version, Version):\n        version = Version(version)\n    return version\n\n\nclass InvalidSpecifier(ValueError):\n    \"\"\"\n    Raised when attempting to create a :class:`Specifier` with a specifier\n    string that is invalid.\n\n    >>> Specifier(\"lolwat\")\n    Traceback (most recent call last):\n        ...\n    packaging.specifiers.InvalidSpecifier: Invalid specifier: 'lolwat'\n    \"\"\"\n\n\nclass BaseSpecifier(metaclass=abc.ABCMeta):\n    @abc.abstractmethod\n    def __str__(self) -> str:\n        \"\"\"\n        Returns the str representation of this Specifier-like object. This\n        should be representative of the Specifier itself.\n        \"\"\"\n\n    @abc.abstractmethod\n    def __hash__(self) -> int:\n        \"\"\"\n        Returns a hash value for this Specifier-like object.\n        \"\"\"\n\n    @abc.abstractmethod\n    def __eq__(self, other: object) -> bool:\n        \"\"\"\n        Returns a boolean representing whether or not the two Specifier-like\n        objects are equal.\n\n        :param other: The other object to check against.\n        \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def prereleases(self) -> bool | None:\n        \"\"\"Whether or not pre-releases as a whole are allowed.\n\n        This can be set to either ``True`` or ``False`` to explicitly enable or disable\n        prereleases or it can be set to ``None`` (the default) to use default semantics.\n        \"\"\"\n\n    @prereleases.setter\n    def prereleases(self, value: bool) -> None:\n        \"\"\"Setter for :attr:`prereleases`.\n\n        :param value: The value to set.\n        \"\"\"\n\n    @abc.abstractmethod\n    def contains(self, item: str, prereleases: bool | None = None) -> bool:\n        \"\"\"\n        Determines if the given item is contained within this specifier.\n        \"\"\"\n\n    @abc.abstractmethod\n    def filter(\n        self, iterable: Iterable[UnparsedVersionVar], prereleases: bool | None = None\n    ) -> Iterator[UnparsedVersionVar]:\n        \"\"\"\n        Takes an iterable of items and filters them so that only items which\n        are contained within this specifier are allowed in it.\n        \"\"\"\n\n\nclass Specifier(BaseSpecifier):\n    \"\"\"This class abstracts handling of version specifiers.\n\n    .. tip::\n\n        It is generally not required to instantiate this manually. You should instead\n        prefer to work with :class:`SpecifierSet` instead, which can parse\n        comma-separated version specifiers (which is what package metadata contains).\n    \"\"\"\n\n    _operator_regex_str = r\"\"\"\n        (?P<operator>(~=|==|!=|<=|>=|<|>|===))\n        \"\"\"\n    _version_regex_str = r\"\"\"\n        (?P<version>\n            (?:\n                # The identity operators allow for an escape hatch that will\n                # do an exact string match of the version you wish to install.\n                # This will not be parsed by PEP 440 and we cannot determine\n                # any semantic meaning from it. This operator is discouraged\n                # but included entirely as an escape hatch.\n                (?<====)  # Only match for the identity operator\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\tags.py": {
      "sha": "d97189349cae",
      "lines": 656,
      "head": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\nfrom __future__ import annotations\n\nimport logging\nimport platform\nimport re\nimport struct\nimport subprocess\nimport sys\nimport sysconfig\nfrom importlib.machinery import EXTENSION_SUFFIXES\nfrom typing import (\n    Iterable,\n    Iterator,\n    Sequence,\n    Tuple,\n    cast,\n)\n\nfrom . import _manylinux, _musllinux\n\nlogger = logging.getLogger(__name__)\n\nPythonVersion = Sequence[int]\nAppleVersion = Tuple[int, int]\n\nINTERPRETER_SHORT_NAMES: dict[str, str] = {\n    \"python\": \"py\",  # Generic.\n    \"cpython\": \"cp\",\n    \"pypy\": \"pp\",\n    \"ironpython\": \"ip\",\n    \"jython\": \"jy\",\n}\n\n\n_32_BIT_INTERPRETER = struct.calcsize(\"P\") == 4\n\n\nclass Tag:\n    \"\"\"\n    A representation of the tag triple for a wheel.\n\n    Instances are considered immutable and thus are hashable. Equality checking\n    is also supported.\n    \"\"\"\n\n    __slots__ = [\"_abi\", \"_hash\", \"_interpreter\", \"_platform\"]\n\n    def __init__(self, interpreter: str, abi: str, platform: str) -> None:\n        self._interpreter = interpreter.lower()\n        self._abi = abi.lower()\n        self._platform = platform.lower()\n        # The __hash__ of every single element in a Set[Tag] will be evaluated each time\n        # that a set calls its `.disjoint()` method, which may be called hundreds of\n        # times when scanning a page of links for packages with tags matching that\n        # Set[Tag]. Pre-computing the value here produces significant speedups for\n        # downstream consumers.\n        self._hash = hash((self._interpreter, self._abi, self._platform))\n\n    @property\n    def interpreter(self) -> str:\n        return self._interpreter\n\n    @property\n    def abi(self) -> str:\n        return self._abi\n\n    @property\n    def platform(self) -> str:\n        return self._platform\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, Tag):\n            return NotImplemented\n\n        return (\n            (self._hash == other._hash)  # Short-circuit ASAP for perf reasons.\n            and (self._platform == other._platform)\n            and (self._abi == other._abi)\n            and (self._interpreter == other._interpreter)\n        )\n\n    def __hash__(self) -> int:\n        return self._hash\n\n    def __str__(self) -> str:\n        return f\"{self._interpreter}-{self._abi}-{self._platform}\"\n\n    def __repr__(self) -> str:\n        return f\"<{self} @ {id(self)}>\"\n\n\ndef parse_tag(tag: str) -> frozenset[Tag]:\n    \"\"\"\n    Parses the provided tag (e.g. `py3-none-any`) into a frozenset of Tag instances.\n\n    Returning a set is required due to the possibility that the tag is a\n    compressed tag set.\n    \"\"\"\n    tags = set()\n    interpreters, abis, platforms = tag.split(\"-\")\n    for interpreter in interpreters.split(\".\"):\n        for abi in abis.split(\".\"):\n            for platform_ in platforms.split(\".\"):\n                tags.add(Tag(interpreter, abi, platform_))\n    return frozenset(tags)\n\n\ndef _get_config_var(name: str, warn: bool = False) -> int | str | None:\n    value: int | str | None = sysconfig.get_config_var(name)\n    if value is None and warn:\n        logger.debug(\n            \"Config variable '%s' is unset, Python ABI tag may be incorrect\", name\n        )\n    return value\n\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\utils.py": {
      "sha": "a5dd9d67bec3",
      "lines": 163,
      "head": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\nfrom __future__ import annotations\n\nimport functools\nimport re\nfrom typing import NewType, Tuple, Union, cast\n\nfrom .tags import Tag, parse_tag\nfrom .version import InvalidVersion, Version, _TrimmedRelease\n\nBuildTag = Union[Tuple[()], Tuple[int, str]]\nNormalizedName = NewType(\"NormalizedName\", str)\n\n\nclass InvalidName(ValueError):\n    \"\"\"\n    An invalid distribution name; users should refer to the packaging user guide.\n    \"\"\"\n\n\nclass InvalidWheelFilename(ValueError):\n    \"\"\"\n    An invalid wheel filename was found, users should refer to PEP 427.\n    \"\"\"\n\n\nclass InvalidSdistFilename(ValueError):\n    \"\"\"\n    An invalid sdist filename was found, users should refer to the packaging user guide.\n    \"\"\"\n\n\n# Core metadata spec for `Name`\n_validate_regex = re.compile(\n    r\"^([A-Z0-9]|[A-Z0-9][A-Z0-9._-]*[A-Z0-9])$\", re.IGNORECASE\n)\n_canonicalize_regex = re.compile(r\"[-_.]+\")\n_normalized_regex = re.compile(r\"^([a-z0-9]|[a-z0-9]([a-z0-9-](?!--))*[a-z0-9])$\")\n# PEP 427: The build number must start with a digit.\n_build_tag_regex = re.compile(r\"(\\d+)(.*)\")\n\n\ndef canonicalize_name(name: str, *, validate: bool = False) -> NormalizedName:\n    if validate and not _validate_regex.match(name):\n        raise InvalidName(f\"name is invalid: {name!r}\")\n    # This is taken from PEP 503.\n    value = _canonicalize_regex.sub(\"-\", name).lower()\n    return cast(NormalizedName, value)\n\n\ndef is_normalized_name(name: str) -> bool:\n    return _normalized_regex.match(name) is not None\n\n\n@functools.singledispatch\ndef canonicalize_version(\n    version: Version | str, *, strip_trailing_zero: bool = True\n) -> str:\n    \"\"\"\n    Return a canonical form of a version as a string.\n\n    >>> canonicalize_version('1.0.1')\n    '1.0.1'\n\n    Per PEP 625, versions may have multiple canonical forms, differing\n    only by trailing zeros.\n\n    >>> canonicalize_version('1.0.0')\n    '1'\n    >>> canonicalize_version('1.0.0', strip_trailing_zero=False)\n    '1.0.0'\n\n    Invalid versions are returned unaltered.\n\n    >>> canonicalize_version('foo bar baz')\n    'foo bar baz'\n    \"\"\"\n    return str(_TrimmedRelease(str(version)) if strip_trailing_zero else version)\n\n\n@canonicalize_version.register\ndef _(version: str, *, strip_trailing_zero: bool = True) -> str:\n    try:\n        parsed = Version(version)\n    except InvalidVersion:\n        # Legacy versions cannot be normalized\n        return version\n    return canonicalize_version(parsed, strip_trailing_zero=strip_trailing_zero)\n\n\ndef parse_wheel_filename(\n    filename: str,\n) -> tuple[NormalizedName, Version, BuildTag, frozenset[Tag]]:\n    if not filename.endswith(\".whl\"):\n        raise InvalidWheelFilename(\n            f\"Invalid wheel filename (extension must be '.whl'): {filename!r}\"\n        )\n\n    filename = filename[:-4]\n    dashes = filename.count(\"-\")\n    if dashes not in (4, 5):\n        raise InvalidWheelFilename(\n            f\"Invalid wheel filename (wrong number of parts): {filename!r}\"\n        )\n\n    parts = filename.split(\"-\", dashes - 2)\n    name_part = parts[0]\n    # See PEP 427 for the rules on escaping the project name.\n    if \"__\" in name_part or re.match(r\"^[\\w\\d._]*$\", name_part, re.UNICODE) is None:\n        raise InvalidWheelFilename(f\"Invalid project name: {filename!r}\")\n    name = canonicalize_name(name_part)\n\n    try:\n        version = Version(parts[1])\n    except InvalidVersion as e:\n        raise InvalidWheelFilename(\n            f\"Invalid wheel filename (invalid version): {filename!r}\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\version.py": {
      "sha": "1468fbad399c",
      "lines": 582,
      "head": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\"\"\"\n.. testsetup::\n\n    from pip._vendor.packaging.version import parse, Version\n\"\"\"\n\nfrom __future__ import annotations\n\nimport itertools\nimport re\nfrom typing import Any, Callable, NamedTuple, SupportsInt, Tuple, Union\n\nfrom ._structures import Infinity, InfinityType, NegativeInfinity, NegativeInfinityType\n\n__all__ = [\"VERSION_PATTERN\", \"InvalidVersion\", \"Version\", \"parse\"]\n\nLocalType = Tuple[Union[int, str], ...]\n\nCmpPrePostDevType = Union[InfinityType, NegativeInfinityType, Tuple[str, int]]\nCmpLocalType = Union[\n    NegativeInfinityType,\n    Tuple[Union[Tuple[int, str], Tuple[NegativeInfinityType, Union[int, str]]], ...],\n]\nCmpKey = Tuple[\n    int,\n    Tuple[int, ...],\n    CmpPrePostDevType,\n    CmpPrePostDevType,\n    CmpPrePostDevType,\n    CmpLocalType,\n]\nVersionComparisonMethod = Callable[[CmpKey, CmpKey], bool]\n\n\nclass _Version(NamedTuple):\n    epoch: int\n    release: tuple[int, ...]\n    dev: tuple[str, int] | None\n    pre: tuple[str, int] | None\n    post: tuple[str, int] | None\n    local: LocalType | None\n\n\ndef parse(version: str) -> Version:\n    \"\"\"Parse the given version string.\n\n    >>> parse('1.0.dev1')\n    <Version('1.0.dev1')>\n\n    :param version: The version string to parse.\n    :raises InvalidVersion: When the version string is not a valid version.\n    \"\"\"\n    return Version(version)\n\n\nclass InvalidVersion(ValueError):\n    \"\"\"Raised when a version string is not a valid version.\n\n    >>> Version(\"invalid\")\n    Traceback (most recent call last):\n        ...\n    packaging.version.InvalidVersion: Invalid version: 'invalid'\n    \"\"\"\n\n\nclass _BaseVersion:\n    _key: tuple[Any, ...]\n\n    def __hash__(self) -> int:\n        return hash(self._key)\n\n    # Please keep the duplicated `isinstance` check\n    # in the six comparisons hereunder\n    # unless you find a way to avoid adding overhead function calls.\n    def __lt__(self, other: _BaseVersion) -> bool:\n        if not isinstance(other, _BaseVersion):\n            return NotImplemented\n\n        return self._key < other._key\n\n    def __le__(self, other: _BaseVersion) -> bool:\n        if not isinstance(other, _BaseVersion):\n            return NotImplemented\n\n        return self._key <= other._key\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, _BaseVersion):\n            return NotImplemented\n\n        return self._key == other._key\n\n    def __ge__(self, other: _BaseVersion) -> bool:\n        if not isinstance(other, _BaseVersion):\n            return NotImplemented\n\n        return self._key >= other._key\n\n    def __gt__(self, other: _BaseVersion) -> bool:\n        if not isinstance(other, _BaseVersion):\n            return NotImplemented\n\n        return self._key > other._key\n\n    def __ne__(self, other: object) -> bool:\n        if not isinstance(other, _BaseVersion):\n            return NotImplemented\n\n        return self._key != other._key\n\n\n# Deliberately not anchored to the start and end of the string, to make it\n# easier for 3rd party code to reuse\n_VERSION_PATTERN = r\"\"\"\n    v?\n    (?:\n        (?:(?P<epoch>[0-9]+)!)?                           # epoch\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_elffile.py": {
      "sha": "814eabe72f6f",
      "lines": 109,
      "head": "\"\"\"\nELF file parser.\n\nThis provides a class ``ELFFile`` that parses an ELF executable in a similar\ninterface to ``ZipFile``. Only the read interface is implemented.\n\nBased on: https://gist.github.com/lyssdod/f51579ae8d93c8657a5564aefc2ffbca\nELF header: https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\n\"\"\"\n\nfrom __future__ import annotations\n\nimport enum\nimport os\nimport struct\nfrom typing import IO\n\n\nclass ELFInvalid(ValueError):\n    pass\n\n\nclass EIClass(enum.IntEnum):\n    C32 = 1\n    C64 = 2\n\n\nclass EIData(enum.IntEnum):\n    Lsb = 1\n    Msb = 2\n\n\nclass EMachine(enum.IntEnum):\n    I386 = 3\n    S390 = 22\n    Arm = 40\n    X8664 = 62\n    AArc64 = 183\n\n\nclass ELFFile:\n    \"\"\"\n    Representation of an ELF executable.\n    \"\"\"\n\n    def __init__(self, f: IO[bytes]) -> None:\n        self._f = f\n\n        try:\n            ident = self._read(\"16B\")\n        except struct.error as e:\n            raise ELFInvalid(\"unable to parse identification\") from e\n        magic = bytes(ident[:4])\n        if magic != b\"\\x7fELF\":\n            raise ELFInvalid(f\"invalid magic: {magic!r}\")\n\n        self.capacity = ident[4]  # Format for program header (bitness).\n        self.encoding = ident[5]  # Data structure encoding (endianness).\n\n        try:\n            # e_fmt: Format for program header.\n            # p_fmt: Format for section header.\n            # p_idx: Indexes to find p_type, p_offset, and p_filesz.\n            e_fmt, self._p_fmt, self._p_idx = {\n                (1, 1): (\"<HHIIIIIHHH\", \"<IIIIIIII\", (0, 1, 4)),  # 32-bit LSB.\n                (1, 2): (\">HHIIIIIHHH\", \">IIIIIIII\", (0, 1, 4)),  # 32-bit MSB.\n                (2, 1): (\"<HHIQQQIHHH\", \"<IIQQQQQQ\", (0, 2, 5)),  # 64-bit LSB.\n                (2, 2): (\">HHIQQQIHHH\", \">IIQQQQQQ\", (0, 2, 5)),  # 64-bit MSB.\n            }[(self.capacity, self.encoding)]\n        except KeyError as e:\n            raise ELFInvalid(\n                f\"unrecognized capacity ({self.capacity}) or encoding ({self.encoding})\"\n            ) from e\n\n        try:\n            (\n                _,\n                self.machine,  # Architecture type.\n                _,\n                _,\n                self._e_phoff,  # Offset of program header.\n                _,\n                self.flags,  # Processor-specific flags.\n                _,\n                self._e_phentsize,  # Size of section.\n                self._e_phnum,  # Number of sections.\n            ) = self._read(e_fmt)\n        except struct.error as e:\n            raise ELFInvalid(\"unable to parse machine and section information\") from e\n\n    def _read(self, fmt: str) -> tuple[int, ...]:\n        return struct.unpack(fmt, self._f.read(struct.calcsize(fmt)))\n\n    @property\n    def interpreter(self) -> str | None:\n        \"\"\"\n        The path recorded in the ``PT_INTERP`` section header.\n        \"\"\"\n        for index in range(self._e_phnum):\n            self._f.seek(self._e_phoff + self._e_phentsize * index)\n            try:\n                data = self._read(self._p_fmt)\n            except struct.error:\n                continue\n            if data[self._p_idx[0]] != 3:  # Not PT_INTERP.\n                continue\n            self._f.seek(data[self._p_idx[1]])\n            return os.fsdecode(self._f.read(data[self._p_idx[2]])).strip(\"\\0\")\n        return None\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_manylinux.py": {
      "sha": "2f18803aede0",
      "lines": 262,
      "head": "from __future__ import annotations\n\nimport collections\nimport contextlib\nimport functools\nimport os\nimport re\nimport sys\nimport warnings\nfrom typing import Generator, Iterator, NamedTuple, Sequence\n\nfrom ._elffile import EIClass, EIData, ELFFile, EMachine\n\nEF_ARM_ABIMASK = 0xFF000000\nEF_ARM_ABI_VER5 = 0x05000000\nEF_ARM_ABI_FLOAT_HARD = 0x00000400\n\n\n# `os.PathLike` not a generic type until Python 3.9, so sticking with `str`\n# as the type for `path` until then.\n@contextlib.contextmanager\ndef _parse_elf(path: str) -> Generator[ELFFile | None, None, None]:\n    try:\n        with open(path, \"rb\") as f:\n            yield ELFFile(f)\n    except (OSError, TypeError, ValueError):\n        yield None\n\n\ndef _is_linux_armhf(executable: str) -> bool:\n    # hard-float ABI can be detected from the ELF header of the running\n    # process\n    # https://static.docs.arm.com/ihi0044/g/aaelf32.pdf\n    with _parse_elf(executable) as f:\n        return (\n            f is not None\n            and f.capacity == EIClass.C32\n            and f.encoding == EIData.Lsb\n            and f.machine == EMachine.Arm\n            and f.flags & EF_ARM_ABIMASK == EF_ARM_ABI_VER5\n            and f.flags & EF_ARM_ABI_FLOAT_HARD == EF_ARM_ABI_FLOAT_HARD\n        )\n\n\ndef _is_linux_i686(executable: str) -> bool:\n    with _parse_elf(executable) as f:\n        return (\n            f is not None\n            and f.capacity == EIClass.C32\n            and f.encoding == EIData.Lsb\n            and f.machine == EMachine.I386\n        )\n\n\ndef _have_compatible_abi(executable: str, archs: Sequence[str]) -> bool:\n    if \"armv7l\" in archs:\n        return _is_linux_armhf(executable)\n    if \"i686\" in archs:\n        return _is_linux_i686(executable)\n    allowed_archs = {\n        \"x86_64\",\n        \"aarch64\",\n        \"ppc64\",\n        \"ppc64le\",\n        \"s390x\",\n        \"loongarch64\",\n        \"riscv64\",\n    }\n    return any(arch in allowed_archs for arch in archs)\n\n\n# If glibc ever changes its major version, we need to know what the last\n# minor version was, so we can build the complete list of all versions.\n# For now, guess what the highest minor version might be, assume it will\n# be 50 for testing. Once this actually happens, update the dictionary\n# with the actual value.\n_LAST_GLIBC_MINOR: dict[int, int] = collections.defaultdict(lambda: 50)\n\n\nclass _GLibCVersion(NamedTuple):\n    major: int\n    minor: int\n\n\ndef _glibc_version_string_confstr() -> str | None:\n    \"\"\"\n    Primary implementation of glibc_version_string using os.confstr.\n    \"\"\"\n    # os.confstr is quite a bit faster than ctypes.DLL. It's also less likely\n    # to be broken or missing. This strategy is used in the standard library\n    # platform module.\n    # https://github.com/python/cpython/blob/fcf1d003bf4f0100c/Lib/platform.py#L175-L183\n    try:\n        # Should be a string like \"glibc 2.17\".\n        version_string: str | None = os.confstr(\"CS_GNU_LIBC_VERSION\")\n        assert version_string is not None\n        _, version = version_string.rsplit()\n    except (AssertionError, AttributeError, OSError, ValueError):\n        # os.confstr() or CS_GNU_LIBC_VERSION not available (or a bad value)...\n        return None\n    return version\n\n\ndef _glibc_version_string_ctypes() -> str | None:\n    \"\"\"\n    Fallback implementation of glibc_version_string using ctypes.\n    \"\"\"\n    try:\n        import ctypes\n    except ImportError:\n        return None\n\n    # ctypes.CDLL(None) internally calls dlopen(NULL), and as the dlopen\n    # manpage says, \"If filename is NULL, then the returned handle is for the\n    # main program\". This way we can let the linker do the work to figure out\n    # which libc our process is actually using.\n    #\n    # We must also handle the special case where the executable is not a\n    # dynamically linked executable. This can occur when using musl libc,\n    # for example. In this situation, dlopen() will error, leading to an\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_musllinux.py": {
      "sha": "7d4819fd7cc7",
      "lines": 85,
      "head": "\"\"\"PEP 656 support.\n\nThis module implements logic to detect if the currently running Python is\nlinked against musl, and what musl version is used.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport functools\nimport re\nimport subprocess\nimport sys\nfrom typing import Iterator, NamedTuple, Sequence\n\nfrom ._elffile import ELFFile\n\n\nclass _MuslVersion(NamedTuple):\n    major: int\n    minor: int\n\n\ndef _parse_musl_version(output: str) -> _MuslVersion | None:\n    lines = [n for n in (n.strip() for n in output.splitlines()) if n]\n    if len(lines) < 2 or lines[0][:4] != \"musl\":\n        return None\n    m = re.match(r\"Version (\\d+)\\.(\\d+)\", lines[1])\n    if not m:\n        return None\n    return _MuslVersion(major=int(m.group(1)), minor=int(m.group(2)))\n\n\n@functools.lru_cache\ndef _get_musl_version(executable: str) -> _MuslVersion | None:\n    \"\"\"Detect currently-running musl runtime version.\n\n    This is done by checking the specified executable's dynamic linking\n    information, and invoking the loader to parse its output for a version\n    string. If the loader is musl, the output would be something like::\n\n        musl libc (x86_64)\n        Version 1.2.2\n        Dynamic Program Loader\n    \"\"\"\n    try:\n        with open(executable, \"rb\") as f:\n            ld = ELFFile(f).interpreter\n    except (OSError, TypeError, ValueError):\n        return None\n    if ld is None or \"musl\" not in ld:\n        return None\n    proc = subprocess.run([ld], stderr=subprocess.PIPE, text=True)\n    return _parse_musl_version(proc.stderr)\n\n\ndef platform_tags(archs: Sequence[str]) -> Iterator[str]:\n    \"\"\"Generate musllinux tags compatible to the current platform.\n\n    :param archs: Sequence of compatible architectures.\n        The first one shall be the closest to the actual architecture and be the part of\n        platform tag after the ``linux_`` prefix, e.g. ``x86_64``.\n        The ``linux_`` prefix is assumed as a prerequisite for the current platform to\n        be musllinux-compatible.\n\n    :returns: An iterator of compatible musllinux tags.\n    \"\"\"\n    sys_musl = _get_musl_version(sys.executable)\n    if sys_musl is None:  # Python not dynamically linked against musl.\n        return\n    for arch in archs:\n        for minor in range(sys_musl.minor, -1, -1):\n            yield f\"musllinux_{sys_musl.major}_{minor}_{arch}\"\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import sysconfig\n\n    plat = sysconfig.get_platform()\n    assert plat.startswith(\"linux-\"), \"not linux\"\n\n    print(\"plat:\", plat)\n    print(\"musl:\", _get_musl_version(sys.executable))\n    print(\"tags:\", end=\" \")\n    for t in platform_tags(re.sub(r\"[.-]\", \"_\", plat.split(\"-\", 1)[-1])):\n        print(t, end=\"\\n      \")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_parser.py": {
      "sha": "be98192ea624",
      "lines": 353,
      "head": "\"\"\"Handwritten parser of dependency specifiers.\n\nThe docstring for each __parse_* function contains EBNF-inspired grammar representing\nthe implementation.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport ast\nfrom typing import NamedTuple, Sequence, Tuple, Union\n\nfrom ._tokenizer import DEFAULT_RULES, Tokenizer\n\n\nclass Node:\n    def __init__(self, value: str) -> None:\n        self.value = value\n\n    def __str__(self) -> str:\n        return self.value\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__}('{self}')>\"\n\n    def serialize(self) -> str:\n        raise NotImplementedError\n\n\nclass Variable(Node):\n    def serialize(self) -> str:\n        return str(self)\n\n\nclass Value(Node):\n    def serialize(self) -> str:\n        return f'\"{self}\"'\n\n\nclass Op(Node):\n    def serialize(self) -> str:\n        return str(self)\n\n\nMarkerVar = Union[Variable, Value]\nMarkerItem = Tuple[MarkerVar, Op, MarkerVar]\nMarkerAtom = Union[MarkerItem, Sequence[\"MarkerAtom\"]]\nMarkerList = Sequence[Union[\"MarkerList\", MarkerAtom, str]]\n\n\nclass ParsedRequirement(NamedTuple):\n    name: str\n    url: str\n    extras: list[str]\n    specifier: str\n    marker: MarkerList | None\n\n\n# --------------------------------------------------------------------------------------\n# Recursive descent parser for dependency specifier\n# --------------------------------------------------------------------------------------\ndef parse_requirement(source: str) -> ParsedRequirement:\n    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n\n\ndef _parse_requirement(tokenizer: Tokenizer) -> ParsedRequirement:\n    \"\"\"\n    requirement = WS? IDENTIFIER WS? extras WS? requirement_details\n    \"\"\"\n    tokenizer.consume(\"WS\")\n\n    name_token = tokenizer.expect(\n        \"IDENTIFIER\", expected=\"package name at the start of dependency specifier\"\n    )\n    name = name_token.text\n    tokenizer.consume(\"WS\")\n\n    extras = _parse_extras(tokenizer)\n    tokenizer.consume(\"WS\")\n\n    url, specifier, marker = _parse_requirement_details(tokenizer)\n    tokenizer.expect(\"END\", expected=\"end of dependency specifier\")\n\n    return ParsedRequirement(name, url, extras, specifier, marker)\n\n\ndef _parse_requirement_details(\n    tokenizer: Tokenizer,\n) -> tuple[str, str, MarkerList | None]:\n    \"\"\"\n    requirement_details = AT URL (WS requirement_marker?)?\n                        | specifier WS? (requirement_marker)?\n    \"\"\"\n\n    specifier = \"\"\n    url = \"\"\n    marker = None\n\n    if tokenizer.check(\"AT\"):\n        tokenizer.read()\n        tokenizer.consume(\"WS\")\n\n        url_start = tokenizer.position\n        url = tokenizer.expect(\"URL\", expected=\"URL after @\").text\n        if tokenizer.check(\"END\", peek=True):\n            return (url, specifier, marker)\n\n        tokenizer.expect(\"WS\", expected=\"whitespace after URL\")\n\n        # The input might end after whitespace.\n        if tokenizer.check(\"END\", peek=True):\n            return (url, specifier, marker)\n\n        marker = _parse_requirement_marker(\n            tokenizer, span_start=url_start, after=\"URL and whitespace\"\n        )\n    else:\n        specifier_start = tokenizer.position\n        specifier = _parse_specifier(tokenizer)\n        tokenizer.consume(\"WS\")\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_structures.py": {
      "sha": "fe0c3747cf14",
      "lines": 61,
      "head": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\n\nclass InfinityType:\n    def __repr__(self) -> str:\n        return \"Infinity\"\n\n    def __hash__(self) -> int:\n        return hash(repr(self))\n\n    def __lt__(self, other: object) -> bool:\n        return False\n\n    def __le__(self, other: object) -> bool:\n        return False\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, self.__class__)\n\n    def __gt__(self, other: object) -> bool:\n        return True\n\n    def __ge__(self, other: object) -> bool:\n        return True\n\n    def __neg__(self: object) -> \"NegativeInfinityType\":\n        return NegativeInfinity\n\n\nInfinity = InfinityType()\n\n\nclass NegativeInfinityType:\n    def __repr__(self) -> str:\n        return \"-Infinity\"\n\n    def __hash__(self) -> int:\n        return hash(repr(self))\n\n    def __lt__(self, other: object) -> bool:\n        return True\n\n    def __le__(self, other: object) -> bool:\n        return True\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, self.__class__)\n\n    def __gt__(self, other: object) -> bool:\n        return False\n\n    def __ge__(self, other: object) -> bool:\n        return False\n\n    def __neg__(self: object) -> InfinityType:\n        return Infinity\n\n\nNegativeInfinity = NegativeInfinityType()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\_tokenizer.py": {
      "sha": "9d97ac5f90c7",
      "lines": 195,
      "head": "from __future__ import annotations\n\nimport contextlib\nimport re\nfrom dataclasses import dataclass\nfrom typing import Iterator, NoReturn\n\nfrom .specifiers import Specifier\n\n\n@dataclass\nclass Token:\n    name: str\n    text: str\n    position: int\n\n\nclass ParserSyntaxError(Exception):\n    \"\"\"The provided source text could not be parsed correctly.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        source: str,\n        span: tuple[int, int],\n    ) -> None:\n        self.span = span\n        self.message = message\n        self.source = source\n\n        super().__init__()\n\n    def __str__(self) -> str:\n        marker = \" \" * self.span[0] + \"~\" * (self.span[1] - self.span[0]) + \"^\"\n        return \"\\n    \".join([self.message, self.source, marker])\n\n\nDEFAULT_RULES: dict[str, str | re.Pattern[str]] = {\n    \"LEFT_PARENTHESIS\": r\"\\(\",\n    \"RIGHT_PARENTHESIS\": r\"\\)\",\n    \"LEFT_BRACKET\": r\"\\[\",\n    \"RIGHT_BRACKET\": r\"\\]\",\n    \"SEMICOLON\": r\";\",\n    \"COMMA\": r\",\",\n    \"QUOTED_STRING\": re.compile(\n        r\"\"\"\n            (\n                ('[^']*')\n                |\n                (\"[^\"]*\")\n            )\n        \"\"\",\n        re.VERBOSE,\n    ),\n    \"OP\": r\"(===|==|~=|!=|<=|>=|<|>)\",\n    \"BOOLOP\": r\"\\b(or|and)\\b\",\n    \"IN\": r\"\\bin\\b\",\n    \"NOT\": r\"\\bnot\\b\",\n    \"VARIABLE\": re.compile(\n        r\"\"\"\n            \\b(\n                python_version\n                |python_full_version\n                |os[._]name\n                |sys[._]platform\n                |platform_(release|system)\n                |platform[._](version|machine|python_implementation)\n                |python_implementation\n                |implementation_(name|version)\n                |extras?\n                |dependency_groups\n            )\\b\n        \"\"\",\n        re.VERBOSE,\n    ),\n    \"SPECIFIER\": re.compile(\n        Specifier._operator_regex_str + Specifier._version_regex_str,\n        re.VERBOSE | re.IGNORECASE,\n    ),\n    \"AT\": r\"\\@\",\n    \"URL\": r\"[^ \\t]+\",\n    \"IDENTIFIER\": r\"\\b[a-zA-Z0-9][a-zA-Z0-9._-]*\\b\",\n    \"VERSION_PREFIX_TRAIL\": r\"\\.\\*\",\n    \"VERSION_LOCAL_LABEL_TRAIL\": r\"\\+[a-z0-9]+(?:[-_\\.][a-z0-9]+)*\",\n    \"WS\": r\"[ \\t]+\",\n    \"END\": r\"$\",\n}\n\n\nclass Tokenizer:\n    \"\"\"Context-sensitive token parsing.\n\n    Provides methods to examine the input stream to check whether the next token\n    matches.\n    \"\"\"\n\n    def __init__(\n        self,\n        source: str,\n        *,\n        rules: dict[str, str | re.Pattern[str]],\n    ) -> None:\n        self.source = source\n        self.rules: dict[str, re.Pattern[str]] = {\n            name: re.compile(pattern) for name, pattern in rules.items()\n        }\n        self.next_token: Token | None = None\n        self.position = 0\n\n    def consume(self, name: str) -> None:\n        \"\"\"Move beyond provided token name, if at current position.\"\"\"\n        if self.check(name):\n            self.read()\n\n    def check(self, name: str, *, peek: bool = False) -> bool:\n        \"\"\"Check whether the next token has the provided name.\n\n        By default, if the check succeeds, the token *must* be read before\n        another check. If `peek` is set to `True`, the token is not loaded and\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\__init__.py": {
      "sha": "2588add9e0f3",
      "lines": 15,
      "head": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\n__title__ = \"packaging\"\n__summary__ = \"Core utilities for Python packages\"\n__uri__ = \"https://github.com/pypa/packaging\"\n\n__version__ = \"25.0\"\n\n__author__ = \"Donald Stufft and individual contributors\"\n__email__ = \"donald@stufft.io\"\n\n__license__ = \"BSD-2-Clause or Apache-2.0\"\n__copyright__ = f\"2014 {__author__}\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\licenses\\_spdx.py": {
      "sha": "ebf0b2cfba0c",
      "lines": 759,
      "head": "\nfrom __future__ import annotations\n\nfrom typing import TypedDict\n\nclass SPDXLicense(TypedDict):\n    id: str\n    deprecated: bool\n\nclass SPDXException(TypedDict):\n    id: str\n    deprecated: bool\n\n\nVERSION = '3.25.0'\n\nLICENSES: dict[str, SPDXLicense] = {\n    '0bsd': {'id': '0BSD', 'deprecated': False},\n    '3d-slicer-1.0': {'id': '3D-Slicer-1.0', 'deprecated': False},\n    'aal': {'id': 'AAL', 'deprecated': False},\n    'abstyles': {'id': 'Abstyles', 'deprecated': False},\n    'adacore-doc': {'id': 'AdaCore-doc', 'deprecated': False},\n    'adobe-2006': {'id': 'Adobe-2006', 'deprecated': False},\n    'adobe-display-postscript': {'id': 'Adobe-Display-PostScript', 'deprecated': False},\n    'adobe-glyph': {'id': 'Adobe-Glyph', 'deprecated': False},\n    'adobe-utopia': {'id': 'Adobe-Utopia', 'deprecated': False},\n    'adsl': {'id': 'ADSL', 'deprecated': False},\n    'afl-1.1': {'id': 'AFL-1.1', 'deprecated': False},\n    'afl-1.2': {'id': 'AFL-1.2', 'deprecated': False},\n    'afl-2.0': {'id': 'AFL-2.0', 'deprecated': False},\n    'afl-2.1': {'id': 'AFL-2.1', 'deprecated': False},\n    'afl-3.0': {'id': 'AFL-3.0', 'deprecated': False},\n    'afmparse': {'id': 'Afmparse', 'deprecated': False},\n    'agpl-1.0': {'id': 'AGPL-1.0', 'deprecated': True},\n    'agpl-1.0-only': {'id': 'AGPL-1.0-only', 'deprecated': False},\n    'agpl-1.0-or-later': {'id': 'AGPL-1.0-or-later', 'deprecated': False},\n    'agpl-3.0': {'id': 'AGPL-3.0', 'deprecated': True},\n    'agpl-3.0-only': {'id': 'AGPL-3.0-only', 'deprecated': False},\n    'agpl-3.0-or-later': {'id': 'AGPL-3.0-or-later', 'deprecated': False},\n    'aladdin': {'id': 'Aladdin', 'deprecated': False},\n    'amd-newlib': {'id': 'AMD-newlib', 'deprecated': False},\n    'amdplpa': {'id': 'AMDPLPA', 'deprecated': False},\n    'aml': {'id': 'AML', 'deprecated': False},\n    'aml-glslang': {'id': 'AML-glslang', 'deprecated': False},\n    'ampas': {'id': 'AMPAS', 'deprecated': False},\n    'antlr-pd': {'id': 'ANTLR-PD', 'deprecated': False},\n    'antlr-pd-fallback': {'id': 'ANTLR-PD-fallback', 'deprecated': False},\n    'any-osi': {'id': 'any-OSI', 'deprecated': False},\n    'apache-1.0': {'id': 'Apache-1.0', 'deprecated': False},\n    'apache-1.1': {'id': 'Apache-1.1', 'deprecated': False},\n    'apache-2.0': {'id': 'Apache-2.0', 'deprecated': False},\n    'apafml': {'id': 'APAFML', 'deprecated': False},\n    'apl-1.0': {'id': 'APL-1.0', 'deprecated': False},\n    'app-s2p': {'id': 'App-s2p', 'deprecated': False},\n    'apsl-1.0': {'id': 'APSL-1.0', 'deprecated': False},\n    'apsl-1.1': {'id': 'APSL-1.1', 'deprecated': False},\n    'apsl-1.2': {'id': 'APSL-1.2', 'deprecated': False},\n    'apsl-2.0': {'id': 'APSL-2.0', 'deprecated': False},\n    'arphic-1999': {'id': 'Arphic-1999', 'deprecated': False},\n    'artistic-1.0': {'id': 'Artistic-1.0', 'deprecated': False},\n    'artistic-1.0-cl8': {'id': 'Artistic-1.0-cl8', 'deprecated': False},\n    'artistic-1.0-perl': {'id': 'Artistic-1.0-Perl', 'deprecated': False},\n    'artistic-2.0': {'id': 'Artistic-2.0', 'deprecated': False},\n    'aswf-digital-assets-1.0': {'id': 'ASWF-Digital-Assets-1.0', 'deprecated': False},\n    'aswf-digital-assets-1.1': {'id': 'ASWF-Digital-Assets-1.1', 'deprecated': False},\n    'baekmuk': {'id': 'Baekmuk', 'deprecated': False},\n    'bahyph': {'id': 'Bahyph', 'deprecated': False},\n    'barr': {'id': 'Barr', 'deprecated': False},\n    'bcrypt-solar-designer': {'id': 'bcrypt-Solar-Designer', 'deprecated': False},\n    'beerware': {'id': 'Beerware', 'deprecated': False},\n    'bitstream-charter': {'id': 'Bitstream-Charter', 'deprecated': False},\n    'bitstream-vera': {'id': 'Bitstream-Vera', 'deprecated': False},\n    'bittorrent-1.0': {'id': 'BitTorrent-1.0', 'deprecated': False},\n    'bittorrent-1.1': {'id': 'BitTorrent-1.1', 'deprecated': False},\n    'blessing': {'id': 'blessing', 'deprecated': False},\n    'blueoak-1.0.0': {'id': 'BlueOak-1.0.0', 'deprecated': False},\n    'boehm-gc': {'id': 'Boehm-GC', 'deprecated': False},\n    'borceux': {'id': 'Borceux', 'deprecated': False},\n    'brian-gladman-2-clause': {'id': 'Brian-Gladman-2-Clause', 'deprecated': False},\n    'brian-gladman-3-clause': {'id': 'Brian-Gladman-3-Clause', 'deprecated': False},\n    'bsd-1-clause': {'id': 'BSD-1-Clause', 'deprecated': False},\n    'bsd-2-clause': {'id': 'BSD-2-Clause', 'deprecated': False},\n    'bsd-2-clause-darwin': {'id': 'BSD-2-Clause-Darwin', 'deprecated': False},\n    'bsd-2-clause-first-lines': {'id': 'BSD-2-Clause-first-lines', 'deprecated': False},\n    'bsd-2-clause-freebsd': {'id': 'BSD-2-Clause-FreeBSD', 'deprecated': True},\n    'bsd-2-clause-netbsd': {'id': 'BSD-2-Clause-NetBSD', 'deprecated': True},\n    'bsd-2-clause-patent': {'id': 'BSD-2-Clause-Patent', 'deprecated': False},\n    'bsd-2-clause-views': {'id': 'BSD-2-Clause-Views', 'deprecated': False},\n    'bsd-3-clause': {'id': 'BSD-3-Clause', 'deprecated': False},\n    'bsd-3-clause-acpica': {'id': 'BSD-3-Clause-acpica', 'deprecated': False},\n    'bsd-3-clause-attribution': {'id': 'BSD-3-Clause-Attribution', 'deprecated': False},\n    'bsd-3-clause-clear': {'id': 'BSD-3-Clause-Clear', 'deprecated': False},\n    'bsd-3-clause-flex': {'id': 'BSD-3-Clause-flex', 'deprecated': False},\n    'bsd-3-clause-hp': {'id': 'BSD-3-Clause-HP', 'deprecated': False},\n    'bsd-3-clause-lbnl': {'id': 'BSD-3-Clause-LBNL', 'deprecated': False},\n    'bsd-3-clause-modification': {'id': 'BSD-3-Clause-Modification', 'deprecated': False},\n    'bsd-3-clause-no-military-license': {'id': 'BSD-3-Clause-No-Military-License', 'deprecated': False},\n    'bsd-3-clause-no-nuclear-license': {'id': 'BSD-3-Clause-No-Nuclear-License', 'deprecated': False},\n    'bsd-3-clause-no-nuclear-license-2014': {'id': 'BSD-3-Clause-No-Nuclear-License-2014', 'deprecated': False},\n    'bsd-3-clause-no-nuclear-warranty': {'id': 'BSD-3-Clause-No-Nuclear-Warranty', 'deprecated': False},\n    'bsd-3-clause-open-mpi': {'id': 'BSD-3-Clause-Open-MPI', 'deprecated': False},\n    'bsd-3-clause-sun': {'id': 'BSD-3-Clause-Sun', 'deprecated': False},\n    'bsd-4-clause': {'id': 'BSD-4-Clause', 'deprecated': False},\n    'bsd-4-clause-shortened': {'id': 'BSD-4-Clause-Shortened', 'deprecated': False},\n    'bsd-4-clause-uc': {'id': 'BSD-4-Clause-UC', 'deprecated': False},\n    'bsd-4.3reno': {'id': 'BSD-4.3RENO', 'deprecated': False},\n    'bsd-4.3tahoe': {'id': 'BSD-4.3TAHOE', 'deprecated': False},\n    'bsd-advertising-acknowledgement': {'id': 'BSD-Advertising-Acknowledgement', 'deprecated': False},\n    'bsd-attribution-hpnd-disclaimer': {'id': 'BSD-Attribution-HPND-disclaimer', 'deprecated': False},\n    'bsd-inferno-nettverk': {'id': 'BSD-Inferno-Nettverk', 'deprecated': False},\n    'bsd-protection': {'id': 'BSD-Protection', 'deprecated': False},\n    'bsd-source-beginning-file': {'id': 'BSD-Source-beginning-file', 'deprecated': False},\n    'bsd-source-code': {'id': 'BSD-Source-Code', 'deprecated': False},\n    'bsd-systemics': {'id': 'BSD-Systemics', 'deprecated': False},\n    'bsd-systemics-w3works': {'id': 'BSD-Systemics-W3Works', 'deprecated': False},\n    'bsl-1.0': {'id': 'BSL-1.0', 'deprecated': False},\n    'busl-1.1': {'id': 'BUSL-1.1', 'deprecated': False},\n    'bzip2-1.0.5': {'id': 'bzip2-1.0.5', 'deprecated': True},\n    'bzip2-1.0.6': {'id': 'bzip2-1.0.6', 'deprecated': False},\n    'c-uda-1.0': {'id': 'C-UDA-1.0', 'deprecated': False},\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\packaging\\licenses\\__init__.py": {
      "sha": "3789a63235cf",
      "lines": 145,
      "head": "#######################################################################################\n#\n# Adapted from:\n#  https://github.com/pypa/hatch/blob/5352e44/backend/src/hatchling/licenses/parse.py\n#\n# MIT License\n#\n# Copyright (c) 2017-present Ofek Lev <oss@ofek.dev>\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy of this\n# software and associated documentation files (the \"Software\"), to deal in the Software\n# without restriction, including without limitation the rights to use, copy, modify,\n# merge, publish, distribute, sublicense, and/or sell copies of the Software, and to\n# permit persons to whom the Software is furnished to do so, subject to the following\n# conditions:\n#\n# The above copyright notice and this permission notice shall be included in all copies\n# or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\n# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n# PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE\n# OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n#\n#\n# With additional allowance of arbitrary `LicenseRef-` identifiers, not just\n# `LicenseRef-Public-Domain` and `LicenseRef-Proprietary`.\n#\n#######################################################################################\nfrom __future__ import annotations\n\nimport re\nfrom typing import NewType, cast\n\nfrom pip._vendor.packaging.licenses._spdx import EXCEPTIONS, LICENSES\n\n__all__ = [\n    \"InvalidLicenseExpression\",\n    \"NormalizedLicenseExpression\",\n    \"canonicalize_license_expression\",\n]\n\nlicense_ref_allowed = re.compile(\"^[A-Za-z0-9.-]*$\")\n\nNormalizedLicenseExpression = NewType(\"NormalizedLicenseExpression\", str)\n\n\nclass InvalidLicenseExpression(ValueError):\n    \"\"\"Raised when a license-expression string is invalid\n\n    >>> canonicalize_license_expression(\"invalid\")\n    Traceback (most recent call last):\n        ...\n    packaging.licenses.InvalidLicenseExpression: Invalid license expression: 'invalid'\n    \"\"\"\n\n\ndef canonicalize_license_expression(\n    raw_license_expression: str,\n) -> NormalizedLicenseExpression:\n    if not raw_license_expression:\n        message = f\"Invalid license expression: {raw_license_expression!r}\"\n        raise InvalidLicenseExpression(message)\n\n    # Pad any parentheses so tokenization can be achieved by merely splitting on\n    # whitespace.\n    license_expression = raw_license_expression.replace(\"(\", \" ( \").replace(\")\", \" ) \")\n    licenseref_prefix = \"LicenseRef-\"\n    license_refs = {\n        ref.lower(): \"LicenseRef-\" + ref[len(licenseref_prefix) :]\n        for ref in license_expression.split()\n        if ref.lower().startswith(licenseref_prefix.lower())\n    }\n\n    # Normalize to lower case so we can look up licenses/exceptions\n    # and so boolean operators are Python-compatible.\n    license_expression = license_expression.lower()\n\n    tokens = license_expression.split()\n\n    # Rather than implementing boolean logic, we create an expression that Python can\n    # parse. Everything that is not involved with the grammar itself is treated as\n    # `False` and the expression should evaluate as such.\n    python_tokens = []\n    for token in tokens:\n        if token not in {\"or\", \"and\", \"with\", \"(\", \")\"}:\n            python_tokens.append(\"False\")\n        elif token == \"with\":\n            python_tokens.append(\"or\")\n        elif token == \"(\" and python_tokens and python_tokens[-1] not in {\"or\", \"and\"}:\n            message = f\"Invalid license expression: {raw_license_expression!r}\"\n            raise InvalidLicenseExpression(message)\n        else:\n            python_tokens.append(token)\n\n    python_expression = \" \".join(python_tokens)\n    try:\n        invalid = eval(python_expression, globals(), locals())\n    except Exception:\n        invalid = True\n\n    if invalid is not False:\n        message = f\"Invalid license expression: {raw_license_expression!r}\"\n        raise InvalidLicenseExpression(message) from None\n\n    # Take a final pass to check for unknown licenses/exceptions.\n    normalized_tokens = []\n    for token in tokens:\n        if token in {\"or\", \"and\", \"with\", \"(\", \")\"}:\n            normalized_tokens.append(token.upper())\n            continue\n\n        if normalized_tokens and normalized_tokens[-1] == \"WITH\":\n            if token not in EXCEPTIONS:\n                message = f\"Unknown license exception: {token!r}\"\n                raise InvalidLicenseExpression(message)\n\n            normalized_tokens.append(EXCEPTIONS[token][\"id\"])\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py": {
      "sha": "4f42afb04338",
      "lines": 3676,
      "head": "# TODO: Add Generic type annotations to initialized collections.\n# For now we'd simply use implicit Any/Unknown which would add redundant annotations\n# mypy: disable-error-code=\"var-annotated\"\n\"\"\"\nPackage resource API\n--------------------\n\nA resource is a logical file contained within a package, or a logical\nsubdirectory thereof.  The package resource API expects resource names\nto have their path parts separated with ``/``, *not* whatever the local\npath separator is.  Do not use os.path operations to manipulate resource\nnames being passed into the API.\n\nThe package resource API is designed to work with normal filesystem packages,\n.egg files, and unpacked .egg files.  It can also work in a limited way with\n.zip files and with custom PEP 302 loaders that support the ``get_data()``\nmethod.\n\nThis module is deprecated. Users are directed to :mod:`importlib.resources`,\n:mod:`importlib.metadata` and :pypi:`packaging` instead.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\n\nif sys.version_info < (3, 8):  # noqa: UP036 # Check for unsupported versions\n    raise RuntimeError(\"Python 3.8 or later is required\")\n\nimport os\nimport io\nimport time\nimport re\nimport types\nfrom typing import (\n    Any,\n    Literal,\n    Dict,\n    Iterator,\n    Mapping,\n    MutableSequence,\n    NamedTuple,\n    NoReturn,\n    Tuple,\n    Union,\n    TYPE_CHECKING,\n    Protocol,\n    Callable,\n    Iterable,\n    TypeVar,\n    overload,\n)\nimport zipfile\nimport zipimport\nimport warnings\nimport stat\nimport functools\nimport pkgutil\nimport operator\nimport platform\nimport collections\nimport plistlib\nimport email.parser\nimport errno\nimport tempfile\nimport textwrap\nimport inspect\nimport ntpath\nimport posixpath\nimport importlib\nimport importlib.abc\nimport importlib.machinery\nfrom pkgutil import get_importer\n\nimport _imp\n\n# capture these to bypass sandboxing\nfrom os import utime\nfrom os import open as os_open\nfrom os.path import isdir, split\n\ntry:\n    from os import mkdir, rename, unlink\n\n    WRITE_SUPPORT = True\nexcept ImportError:\n    # no write support, probably under GAE\n    WRITE_SUPPORT = False\n\nfrom pip._internal.utils._jaraco_text import (\n    yield_lines,\n    drop_comment,\n    join_continuation,\n)\nfrom pip._vendor.packaging import markers as _packaging_markers\nfrom pip._vendor.packaging import requirements as _packaging_requirements\nfrom pip._vendor.packaging import utils as _packaging_utils\nfrom pip._vendor.packaging import version as _packaging_version\nfrom pip._vendor.platformdirs import user_cache_dir as _user_cache_dir\n\nif TYPE_CHECKING:\n    from _typeshed import BytesPath, StrPath, StrOrBytesPath\n    from pip._vendor.typing_extensions import Self\n\n\n# Patch: Remove deprecation warning from vendored pkg_resources.\n# Setting PYTHONWARNINGS=error to verify builds produce no warnings\n# causes immediate exceptions.\n# See https://github.com/pypa/pip/issues/12243\n\n\n_T = TypeVar(\"_T\")\n_DistributionT = TypeVar(\"_DistributionT\", bound=\"Distribution\")\n# Type aliases\n_NestedStr = Union[str, Iterable[Union[str, Iterable[\"_NestedStr\"]]]]\n_InstallerTypeT = Callable[[\"Requirement\"], \"_DistributionT\"]\n_InstallerType = Callable[[\"Requirement\"], Union[\"Distribution\", None]]\n_PkgReqType = Union[str, \"Requirement\"]\n_EPDistType = Union[\"Distribution\", _PkgReqType]\n_MetadataType = Union[\"IResourceProvider\", None]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\android.py": {
      "sha": "7a2d943ee499",
      "lines": 249,
      "head": "\"\"\"Android.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport re\nimport sys\nfrom functools import lru_cache\nfrom typing import TYPE_CHECKING, cast\n\nfrom .api import PlatformDirsABC\n\n\nclass Android(PlatformDirsABC):\n    \"\"\"\n    Follows the guidance `from here <https://android.stackexchange.com/a/216132>`_.\n\n    Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`, `version\n    <platformdirs.api.PlatformDirsABC.version>`, `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.\n\n    \"\"\"\n\n    @property\n    def user_data_dir(self) -> str:\n        \"\"\":return: data directory tied to the user, e.g. ``/data/user/<userid>/<packagename>/files/<AppName>``\"\"\"\n        return self._append_app_name_and_version(cast(\"str\", _android_folder()), \"files\")\n\n    @property\n    def site_data_dir(self) -> str:\n        \"\"\":return: data directory shared by users, same as `user_data_dir`\"\"\"\n        return self.user_data_dir\n\n    @property\n    def user_config_dir(self) -> str:\n        \"\"\"\n        :return: config directory tied to the user, e.g. \\\n        ``/data/user/<userid>/<packagename>/shared_prefs/<AppName>``\n        \"\"\"\n        return self._append_app_name_and_version(cast(\"str\", _android_folder()), \"shared_prefs\")\n\n    @property\n    def site_config_dir(self) -> str:\n        \"\"\":return: config directory shared by the users, same as `user_config_dir`\"\"\"\n        return self.user_config_dir\n\n    @property\n    def user_cache_dir(self) -> str:\n        \"\"\":return: cache directory tied to the user, e.g.,``/data/user/<userid>/<packagename>/cache/<AppName>``\"\"\"\n        return self._append_app_name_and_version(cast(\"str\", _android_folder()), \"cache\")\n\n    @property\n    def site_cache_dir(self) -> str:\n        \"\"\":return: cache directory shared by users, same as `user_cache_dir`\"\"\"\n        return self.user_cache_dir\n\n    @property\n    def user_state_dir(self) -> str:\n        \"\"\":return: state directory tied to the user, same as `user_data_dir`\"\"\"\n        return self.user_data_dir\n\n    @property\n    def user_log_dir(self) -> str:\n        \"\"\"\n        :return: log directory tied to the user, same as `user_cache_dir` if not opinionated else ``log`` in it,\n          e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>/log``\n        \"\"\"\n        path = self.user_cache_dir\n        if self.opinion:\n            path = os.path.join(path, \"log\")  # noqa: PTH118\n        return path\n\n    @property\n    def user_documents_dir(self) -> str:\n        \"\"\":return: documents directory tied to the user e.g. ``/storage/emulated/0/Documents``\"\"\"\n        return _android_documents_folder()\n\n    @property\n    def user_downloads_dir(self) -> str:\n        \"\"\":return: downloads directory tied to the user e.g. ``/storage/emulated/0/Downloads``\"\"\"\n        return _android_downloads_folder()\n\n    @property\n    def user_pictures_dir(self) -> str:\n        \"\"\":return: pictures directory tied to the user e.g. ``/storage/emulated/0/Pictures``\"\"\"\n        return _android_pictures_folder()\n\n    @property\n    def user_videos_dir(self) -> str:\n        \"\"\":return: videos directory tied to the user e.g. ``/storage/emulated/0/DCIM/Camera``\"\"\"\n        return _android_videos_folder()\n\n    @property\n    def user_music_dir(self) -> str:\n        \"\"\":return: music directory tied to the user e.g. ``/storage/emulated/0/Music``\"\"\"\n        return _android_music_folder()\n\n    @property\n    def user_desktop_dir(self) -> str:\n        \"\"\":return: desktop directory tied to the user e.g. ``/storage/emulated/0/Desktop``\"\"\"\n        return \"/storage/emulated/0/Desktop\"\n\n    @property\n    def user_runtime_dir(self) -> str:\n        \"\"\"\n        :return: runtime directory tied to the user, same as `user_cache_dir` if not opinionated else ``tmp`` in it,\n          e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>/tmp``\n        \"\"\"\n        path = self.user_cache_dir\n        if self.opinion:\n            path = os.path.join(path, \"tmp\")  # noqa: PTH118\n        return path\n\n    @property\n    def site_runtime_dir(self) -> str:\n        \"\"\":return: runtime directory shared by users, same as `user_runtime_dir`\"\"\"\n        return self.user_runtime_dir\n\n\n@lru_cache(maxsize=1)\ndef _android_folder() -> str | None:  # noqa: C901\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\api.py": {
      "sha": "48e9c60b3afa",
      "lines": 299,
      "head": "\"\"\"Base API.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from collections.abc import Iterator\n    from typing import Literal\n\n\nclass PlatformDirsABC(ABC):  # noqa: PLR0904\n    \"\"\"Abstract base class for platform directories.\"\"\"\n\n    def __init__(  # noqa: PLR0913, PLR0917\n        self,\n        appname: str | None = None,\n        appauthor: str | Literal[False] | None = None,\n        version: str | None = None,\n        roaming: bool = False,  # noqa: FBT001, FBT002\n        multipath: bool = False,  # noqa: FBT001, FBT002\n        opinion: bool = True,  # noqa: FBT001, FBT002\n        ensure_exists: bool = False,  # noqa: FBT001, FBT002\n    ) -> None:\n        \"\"\"\n        Create a new platform directory.\n\n        :param appname: See `appname`.\n        :param appauthor: See `appauthor`.\n        :param version: See `version`.\n        :param roaming: See `roaming`.\n        :param multipath: See `multipath`.\n        :param opinion: See `opinion`.\n        :param ensure_exists: See `ensure_exists`.\n\n        \"\"\"\n        self.appname = appname  #: The name of application.\n        self.appauthor = appauthor\n        \"\"\"\n        The name of the app author or distributing body for this application.\n\n        Typically, it is the owning company name. Defaults to `appname`. You may pass ``False`` to disable it.\n\n        \"\"\"\n        self.version = version\n        \"\"\"\n        An optional version path element to append to the path.\n\n        You might want to use this if you want multiple versions of your app to be able to run independently. If used,\n        this would typically be ``<major>.<minor>``.\n\n        \"\"\"\n        self.roaming = roaming\n        \"\"\"\n        Whether to use the roaming appdata directory on Windows.\n\n        That means that for users on a Windows network setup for roaming profiles, this user data will be synced on\n        login (see\n        `here <https://technet.microsoft.com/en-us/library/cc766489(WS.10).aspx>`_).\n\n        \"\"\"\n        self.multipath = multipath\n        \"\"\"\n        An optional parameter which indicates that the entire list of data dirs should be returned.\n\n        By default, the first item would only be returned.\n\n        \"\"\"\n        self.opinion = opinion  #: A flag to indicating to use opinionated values.\n        self.ensure_exists = ensure_exists\n        \"\"\"\n        Optionally create the directory (and any missing parents) upon access if it does not exist.\n\n        By default, no directories are created.\n\n        \"\"\"\n\n    def _append_app_name_and_version(self, *base: str) -> str:\n        params = list(base[1:])\n        if self.appname:\n            params.append(self.appname)\n            if self.version:\n                params.append(self.version)\n        path = os.path.join(base[0], *params)  # noqa: PTH118\n        self._optionally_create_directory(path)\n        return path\n\n    def _optionally_create_directory(self, path: str) -> None:\n        if self.ensure_exists:\n            Path(path).mkdir(parents=True, exist_ok=True)\n\n    def _first_item_as_path_if_multipath(self, directory: str) -> Path:\n        if self.multipath:\n            # If multipath is True, the first path is returned.\n            directory = directory.split(os.pathsep)[0]\n        return Path(directory)\n\n    @property\n    @abstractmethod\n    def user_data_dir(self) -> str:\n        \"\"\":return: data directory tied to the user\"\"\"\n\n    @property\n    @abstractmethod\n    def site_data_dir(self) -> str:\n        \"\"\":return: data directory shared by users\"\"\"\n\n    @property\n    @abstractmethod\n    def user_config_dir(self) -> str:\n        \"\"\":return: config directory tied to the user\"\"\"\n\n    @property\n    @abstractmethod\n    def site_config_dir(self) -> str:\n        \"\"\":return: config directory shared by the users\"\"\"\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\macos.py": {
      "sha": "1754b1fd09cb",
      "lines": 144,
      "head": "\"\"\"macOS.\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\nimport sys\nfrom typing import TYPE_CHECKING\n\nfrom .api import PlatformDirsABC\n\nif TYPE_CHECKING:\n    from pathlib import Path\n\n\nclass MacOS(PlatformDirsABC):\n    \"\"\"\n    Platform directories for the macOS operating system.\n\n    Follows the guidance from\n    `Apple documentation <https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/MacOSXDirectories/MacOSXDirectories.html>`_.\n    Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`,\n    `version <platformdirs.api.PlatformDirsABC.version>`,\n    `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.\n\n    \"\"\"\n\n    @property\n    def user_data_dir(self) -> str:\n        \"\"\":return: data directory tied to the user, e.g. ``~/Library/Application Support/$appname/$version``\"\"\"\n        return self._append_app_name_and_version(os.path.expanduser(\"~/Library/Application Support\"))  # noqa: PTH111\n\n    @property\n    def site_data_dir(self) -> str:\n        \"\"\"\n        :return: data directory shared by users, e.g. ``/Library/Application Support/$appname/$version``.\n          If we're using a Python binary managed by `Homebrew <https://brew.sh>`_, the directory\n          will be under the Homebrew prefix, e.g. ``/opt/homebrew/share/$appname/$version``.\n          If `multipath <platformdirs.api.PlatformDirsABC.multipath>` is enabled, and we're in Homebrew,\n          the response is a multi-path string separated by \":\", e.g.\n          ``/opt/homebrew/share/$appname/$version:/Library/Application Support/$appname/$version``\n        \"\"\"\n        is_homebrew = sys.prefix.startswith(\"/opt/homebrew\")\n        path_list = [self._append_app_name_and_version(\"/opt/homebrew/share\")] if is_homebrew else []\n        path_list.append(self._append_app_name_and_version(\"/Library/Application Support\"))\n        if self.multipath:\n            return os.pathsep.join(path_list)\n        return path_list[0]\n\n    @property\n    def site_data_path(self) -> Path:\n        \"\"\":return: data path shared by users. Only return the first item, even if ``multipath`` is set to ``True``\"\"\"\n        return self._first_item_as_path_if_multipath(self.site_data_dir)\n\n    @property\n    def user_config_dir(self) -> str:\n        \"\"\":return: config directory tied to the user, same as `user_data_dir`\"\"\"\n        return self.user_data_dir\n\n    @property\n    def site_config_dir(self) -> str:\n        \"\"\":return: config directory shared by the users, same as `site_data_dir`\"\"\"\n        return self.site_data_dir\n\n    @property\n    def user_cache_dir(self) -> str:\n        \"\"\":return: cache directory tied to the user, e.g. ``~/Library/Caches/$appname/$version``\"\"\"\n        return self._append_app_name_and_version(os.path.expanduser(\"~/Library/Caches\"))  # noqa: PTH111\n\n    @property\n    def site_cache_dir(self) -> str:\n        \"\"\"\n        :return: cache directory shared by users, e.g. ``/Library/Caches/$appname/$version``.\n          If we're using a Python binary managed by `Homebrew <https://brew.sh>`_, the directory\n          will be under the Homebrew prefix, e.g. ``/opt/homebrew/var/cache/$appname/$version``.\n          If `multipath <platformdirs.api.PlatformDirsABC.multipath>` is enabled, and we're in Homebrew,\n          the response is a multi-path string separated by \":\", e.g.\n          ``/opt/homebrew/var/cache/$appname/$version:/Library/Caches/$appname/$version``\n        \"\"\"\n        is_homebrew = sys.prefix.startswith(\"/opt/homebrew\")\n        path_list = [self._append_app_name_and_version(\"/opt/homebrew/var/cache\")] if is_homebrew else []\n        path_list.append(self._append_app_name_and_version(\"/Library/Caches\"))\n        if self.multipath:\n            return os.pathsep.join(path_list)\n        return path_list[0]\n\n    @property\n    def site_cache_path(self) -> Path:\n        \"\"\":return: cache path shared by users. Only return the first item, even if ``multipath`` is set to ``True``\"\"\"\n        return self._first_item_as_path_if_multipath(self.site_cache_dir)\n\n    @property\n    def user_state_dir(self) -> str:\n        \"\"\":return: state directory tied to the user, same as `user_data_dir`\"\"\"\n        return self.user_data_dir\n\n    @property\n    def user_log_dir(self) -> str:\n        \"\"\":return: log directory tied to the user, e.g. ``~/Library/Logs/$appname/$version``\"\"\"\n        return self._append_app_name_and_version(os.path.expanduser(\"~/Library/Logs\"))  # noqa: PTH111\n\n    @property\n    def user_documents_dir(self) -> str:\n        \"\"\":return: documents directory tied to the user, e.g. ``~/Documents``\"\"\"\n        return os.path.expanduser(\"~/Documents\")  # noqa: PTH111\n\n    @property\n    def user_downloads_dir(self) -> str:\n        \"\"\":return: downloads directory tied to the user, e.g. ``~/Downloads``\"\"\"\n        return os.path.expanduser(\"~/Downloads\")  # noqa: PTH111\n\n    @property\n    def user_pictures_dir(self) -> str:\n        \"\"\":return: pictures directory tied to the user, e.g. ``~/Pictures``\"\"\"\n        return os.path.expanduser(\"~/Pictures\")  # noqa: PTH111\n\n    @property\n    def user_videos_dir(self) -> str:\n        \"\"\":return: videos directory tied to the user, e.g. ``~/Movies``\"\"\"\n        return os.path.expanduser(\"~/Movies\")  # noqa: PTH111\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\unix.py": {
      "sha": "250bc10a8efa",
      "lines": 272,
      "head": "\"\"\"Unix.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport sys\nfrom configparser import ConfigParser\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, NoReturn\n\nfrom .api import PlatformDirsABC\n\nif TYPE_CHECKING:\n    from collections.abc import Iterator\n\nif sys.platform == \"win32\":\n\n    def getuid() -> NoReturn:\n        msg = \"should only be used on Unix\"\n        raise RuntimeError(msg)\n\nelse:\n    from os import getuid\n\n\nclass Unix(PlatformDirsABC):  # noqa: PLR0904\n    \"\"\"\n    On Unix/Linux, we follow the `XDG Basedir Spec <https://specifications.freedesktop.org/basedir-spec/basedir-spec-\n    latest.html>`_.\n\n    The spec allows overriding directories with environment variables. The examples shown are the default values,\n    alongside the name of the environment variable that overrides them. Makes use of the `appname\n    <platformdirs.api.PlatformDirsABC.appname>`, `version <platformdirs.api.PlatformDirsABC.version>`, `multipath\n    <platformdirs.api.PlatformDirsABC.multipath>`, `opinion <platformdirs.api.PlatformDirsABC.opinion>`, `ensure_exists\n    <platformdirs.api.PlatformDirsABC.ensure_exists>`.\n\n    \"\"\"\n\n    @property\n    def user_data_dir(self) -> str:\n        \"\"\"\n        :return: data directory tied to the user, e.g. ``~/.local/share/$appname/$version`` or\n         ``$XDG_DATA_HOME/$appname/$version``\n        \"\"\"\n        path = os.environ.get(\"XDG_DATA_HOME\", \"\")\n        if not path.strip():\n            path = os.path.expanduser(\"~/.local/share\")  # noqa: PTH111\n        return self._append_app_name_and_version(path)\n\n    @property\n    def _site_data_dirs(self) -> list[str]:\n        path = os.environ.get(\"XDG_DATA_DIRS\", \"\")\n        if not path.strip():\n            path = f\"/usr/local/share{os.pathsep}/usr/share\"\n        return [self._append_app_name_and_version(p) for p in path.split(os.pathsep)]\n\n    @property\n    def site_data_dir(self) -> str:\n        \"\"\"\n        :return: data directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>` is\n         enabled and ``XDG_DATA_DIRS`` is set and a multi path the response is also a multi path separated by the\n         OS path separator), e.g. ``/usr/local/share/$appname/$version`` or ``/usr/share/$appname/$version``\n        \"\"\"\n        # XDG default for $XDG_DATA_DIRS; only first, if multipath is False\n        dirs = self._site_data_dirs\n        if not self.multipath:\n            return dirs[0]\n        return os.pathsep.join(dirs)\n\n    @property\n    def user_config_dir(self) -> str:\n        \"\"\"\n        :return: config directory tied to the user, e.g. ``~/.config/$appname/$version`` or\n         ``$XDG_CONFIG_HOME/$appname/$version``\n        \"\"\"\n        path = os.environ.get(\"XDG_CONFIG_HOME\", \"\")\n        if not path.strip():\n            path = os.path.expanduser(\"~/.config\")  # noqa: PTH111\n        return self._append_app_name_and_version(path)\n\n    @property\n    def _site_config_dirs(self) -> list[str]:\n        path = os.environ.get(\"XDG_CONFIG_DIRS\", \"\")\n        if not path.strip():\n            path = \"/etc/xdg\"\n        return [self._append_app_name_and_version(p) for p in path.split(os.pathsep)]\n\n    @property\n    def site_config_dir(self) -> str:\n        \"\"\"\n        :return: config directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>`\n         is enabled and ``XDG_CONFIG_DIRS`` is set and a multi path the response is also a multi path separated by\n         the OS path separator), e.g. ``/etc/xdg/$appname/$version``\n        \"\"\"\n        # XDG default for $XDG_CONFIG_DIRS only first, if multipath is False\n        dirs = self._site_config_dirs\n        if not self.multipath:\n            return dirs[0]\n        return os.pathsep.join(dirs)\n\n    @property\n    def user_cache_dir(self) -> str:\n        \"\"\"\n        :return: cache directory tied to the user, e.g. ``~/.cache/$appname/$version`` or\n         ``~/$XDG_CACHE_HOME/$appname/$version``\n        \"\"\"\n        path = os.environ.get(\"XDG_CACHE_HOME\", \"\")\n        if not path.strip():\n            path = os.path.expanduser(\"~/.cache\")  # noqa: PTH111\n        return self._append_app_name_and_version(path)\n\n    @property\n    def site_cache_dir(self) -> str:\n        \"\"\":return: cache directory shared by users, e.g. ``/var/cache/$appname/$version``\"\"\"\n        return self._append_app_name_and_version(\"/var/cache\")\n\n    @property\n    def user_state_dir(self) -> str:\n        \"\"\"\n        :return: state directory tied to the user, e.g. ``~/.local/state/$appname/$version`` or\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\version.py": {
      "sha": "9a25ef2327ff",
      "lines": 21,
      "head": "# file generated by setuptools-scm\n# don't change, don't track in version control\n\n__all__ = [\"__version__\", \"__version_tuple__\", \"version\", \"version_tuple\"]\n\nTYPE_CHECKING = False\nif TYPE_CHECKING:\n    from typing import Tuple\n    from typing import Union\n\n    VERSION_TUPLE = Tuple[Union[int, str], ...]\nelse:\n    VERSION_TUPLE = object\n\nversion: str\n__version__: str\n__version_tuple__: VERSION_TUPLE\nversion_tuple: VERSION_TUPLE\n\n__version__ = version = '4.3.7'\n__version_tuple__ = version_tuple = (4, 3, 7)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\windows.py": {
      "sha": "920d92beeaa2",
      "lines": 272,
      "head": "\"\"\"Windows.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport sys\nfrom functools import lru_cache\nfrom typing import TYPE_CHECKING\n\nfrom .api import PlatformDirsABC\n\nif TYPE_CHECKING:\n    from collections.abc import Callable\n\n\nclass Windows(PlatformDirsABC):\n    \"\"\"\n    `MSDN on where to store app data files <https://learn.microsoft.com/en-us/windows/win32/shell/knownfolderid>`_.\n\n    Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`, `appauthor\n    <platformdirs.api.PlatformDirsABC.appauthor>`, `version <platformdirs.api.PlatformDirsABC.version>`, `roaming\n    <platformdirs.api.PlatformDirsABC.roaming>`, `opinion <platformdirs.api.PlatformDirsABC.opinion>`, `ensure_exists\n    <platformdirs.api.PlatformDirsABC.ensure_exists>`.\n\n    \"\"\"\n\n    @property\n    def user_data_dir(self) -> str:\n        \"\"\"\n        :return: data directory tied to the user, e.g.\n         ``%USERPROFILE%\\\\AppData\\\\Local\\\\$appauthor\\\\$appname`` (not roaming) or\n         ``%USERPROFILE%\\\\AppData\\\\Roaming\\\\$appauthor\\\\$appname`` (roaming)\n        \"\"\"\n        const = \"CSIDL_APPDATA\" if self.roaming else \"CSIDL_LOCAL_APPDATA\"\n        path = os.path.normpath(get_win_folder(const))\n        return self._append_parts(path)\n\n    def _append_parts(self, path: str, *, opinion_value: str | None = None) -> str:\n        params = []\n        if self.appname:\n            if self.appauthor is not False:\n                author = self.appauthor or self.appname\n                params.append(author)\n            params.append(self.appname)\n            if opinion_value is not None and self.opinion:\n                params.append(opinion_value)\n            if self.version:\n                params.append(self.version)\n        path = os.path.join(path, *params)  # noqa: PTH118\n        self._optionally_create_directory(path)\n        return path\n\n    @property\n    def site_data_dir(self) -> str:\n        \"\"\":return: data directory shared by users, e.g. ``C:\\\\ProgramData\\\\$appauthor\\\\$appname``\"\"\"\n        path = os.path.normpath(get_win_folder(\"CSIDL_COMMON_APPDATA\"))\n        return self._append_parts(path)\n\n    @property\n    def user_config_dir(self) -> str:\n        \"\"\":return: config directory tied to the user, same as `user_data_dir`\"\"\"\n        return self.user_data_dir\n\n    @property\n    def site_config_dir(self) -> str:\n        \"\"\":return: config directory shared by the users, same as `site_data_dir`\"\"\"\n        return self.site_data_dir\n\n    @property\n    def user_cache_dir(self) -> str:\n        \"\"\"\n        :return: cache directory tied to the user (if opinionated with ``Cache`` folder within ``$appname``) e.g.\n         ``%USERPROFILE%\\\\AppData\\\\Local\\\\$appauthor\\\\$appname\\\\Cache\\\\$version``\n        \"\"\"\n        path = os.path.normpath(get_win_folder(\"CSIDL_LOCAL_APPDATA\"))\n        return self._append_parts(path, opinion_value=\"Cache\")\n\n    @property\n    def site_cache_dir(self) -> str:\n        \"\"\":return: cache directory shared by users, e.g. ``C:\\\\ProgramData\\\\$appauthor\\\\$appname\\\\Cache\\\\$version``\"\"\"\n        path = os.path.normpath(get_win_folder(\"CSIDL_COMMON_APPDATA\"))\n        return self._append_parts(path, opinion_value=\"Cache\")\n\n    @property\n    def user_state_dir(self) -> str:\n        \"\"\":return: state directory tied to the user, same as `user_data_dir`\"\"\"\n        return self.user_data_dir\n\n    @property\n    def user_log_dir(self) -> str:\n        \"\"\":return: log directory tied to the user, same as `user_data_dir` if not opinionated else ``Logs`` in it\"\"\"\n        path = self.user_data_dir\n        if self.opinion:\n            path = os.path.join(path, \"Logs\")  # noqa: PTH118\n            self._optionally_create_directory(path)\n        return path\n\n    @property\n    def user_documents_dir(self) -> str:\n        \"\"\":return: documents directory tied to the user e.g. ``%USERPROFILE%\\\\Documents``\"\"\"\n        return os.path.normpath(get_win_folder(\"CSIDL_PERSONAL\"))\n\n    @property\n    def user_downloads_dir(self) -> str:\n        \"\"\":return: downloads directory tied to the user e.g. ``%USERPROFILE%\\\\Downloads``\"\"\"\n        return os.path.normpath(get_win_folder(\"CSIDL_DOWNLOADS\"))\n\n    @property\n    def user_pictures_dir(self) -> str:\n        \"\"\":return: pictures directory tied to the user e.g. ``%USERPROFILE%\\\\Pictures``\"\"\"\n        return os.path.normpath(get_win_folder(\"CSIDL_MYPICTURES\"))\n\n    @property\n    def user_videos_dir(self) -> str:\n        \"\"\":return: videos directory tied to the user e.g. ``%USERPROFILE%\\\\Videos``\"\"\"\n        return os.path.normpath(get_win_folder(\"CSIDL_MYVIDEO\"))\n\n    @property\n    def user_music_dir(self) -> str:\n        \"\"\":return: music directory tied to the user e.g. ``%USERPROFILE%\\\\Music``\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\__init__.py": {
      "sha": "fdf29a0698c8",
      "lines": 631,
      "head": "\"\"\"\nUtilities for determining application-specific dirs.\n\nSee <https://github.com/platformdirs/platformdirs> for details and usage.\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport sys\nfrom typing import TYPE_CHECKING\n\nfrom .api import PlatformDirsABC\nfrom .version import __version__\nfrom .version import __version_tuple__ as __version_info__\n\nif TYPE_CHECKING:\n    from pathlib import Path\n    from typing import Literal\n\nif sys.platform == \"win32\":\n    from pip._vendor.platformdirs.windows import Windows as _Result\nelif sys.platform == \"darwin\":\n    from pip._vendor.platformdirs.macos import MacOS as _Result\nelse:\n    from pip._vendor.platformdirs.unix import Unix as _Result\n\n\ndef _set_platform_dir_class() -> type[PlatformDirsABC]:\n    if os.getenv(\"ANDROID_DATA\") == \"/data\" and os.getenv(\"ANDROID_ROOT\") == \"/system\":\n        if os.getenv(\"SHELL\") or os.getenv(\"PREFIX\"):\n            return _Result\n\n        from pip._vendor.platformdirs.android import _android_folder  # noqa: PLC0415\n\n        if _android_folder() is not None:\n            from pip._vendor.platformdirs.android import Android  # noqa: PLC0415\n\n            return Android  # return to avoid redefinition of a result\n\n    return _Result\n\n\nif TYPE_CHECKING:\n    # Work around mypy issue: https://github.com/python/mypy/issues/10962\n    PlatformDirs = _Result\nelse:\n    PlatformDirs = _set_platform_dir_class()  #: Currently active platform\nAppDirs = PlatformDirs  #: Backwards compatibility with appdirs\n\n\ndef user_data_dir(\n    appname: str | None = None,\n    appauthor: str | Literal[False] | None = None,\n    version: str | None = None,\n    roaming: bool = False,  # noqa: FBT001, FBT002\n    ensure_exists: bool = False,  # noqa: FBT001, FBT002\n) -> str:\n    \"\"\"\n    :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.\n    :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.\n    :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.\n    :param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.\n    :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.\n    :returns: data directory tied to the user\n    \"\"\"\n    return PlatformDirs(\n        appname=appname,\n        appauthor=appauthor,\n        version=version,\n        roaming=roaming,\n        ensure_exists=ensure_exists,\n    ).user_data_dir\n\n\ndef site_data_dir(\n    appname: str | None = None,\n    appauthor: str | Literal[False] | None = None,\n    version: str | None = None,\n    multipath: bool = False,  # noqa: FBT001, FBT002\n    ensure_exists: bool = False,  # noqa: FBT001, FBT002\n) -> str:\n    \"\"\"\n    :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.\n    :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.\n    :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.\n    :param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.\n    :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.\n    :returns: data directory shared by users\n    \"\"\"\n    return PlatformDirs(\n        appname=appname,\n        appauthor=appauthor,\n        version=version,\n        multipath=multipath,\n        ensure_exists=ensure_exists,\n    ).site_data_dir\n\n\ndef user_config_dir(\n    appname: str | None = None,\n    appauthor: str | Literal[False] | None = None,\n    version: str | None = None,\n    roaming: bool = False,  # noqa: FBT001, FBT002\n    ensure_exists: bool = False,  # noqa: FBT001, FBT002\n) -> str:\n    \"\"\"\n    :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.\n    :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.\n    :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.\n    :param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.\n    :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.\n    :returns: config directory tied to the user\n    \"\"\"\n    return PlatformDirs(\n        appname=appname,\n        appauthor=appauthor,\n        version=version,\n        roaming=roaming,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\platformdirs\\__main__.py": {
      "sha": "214809a801ca",
      "lines": 55,
      "head": "\"\"\"Main entry point.\"\"\"\n\nfrom __future__ import annotations\n\nfrom pip._vendor.platformdirs import PlatformDirs, __version__\n\nPROPS = (\n    \"user_data_dir\",\n    \"user_config_dir\",\n    \"user_cache_dir\",\n    \"user_state_dir\",\n    \"user_log_dir\",\n    \"user_documents_dir\",\n    \"user_downloads_dir\",\n    \"user_pictures_dir\",\n    \"user_videos_dir\",\n    \"user_music_dir\",\n    \"user_runtime_dir\",\n    \"site_data_dir\",\n    \"site_config_dir\",\n    \"site_cache_dir\",\n    \"site_runtime_dir\",\n)\n\n\ndef main() -> None:\n    \"\"\"Run the main entry point.\"\"\"\n    app_name = \"MyApp\"\n    app_author = \"MyCompany\"\n\n    print(f\"-- platformdirs {__version__} --\")  # noqa: T201\n\n    print(\"-- app dirs (with optional 'version')\")  # noqa: T201\n    dirs = PlatformDirs(app_name, app_author, version=\"1.0\")\n    for prop in PROPS:\n        print(f\"{prop}: {getattr(dirs, prop)}\")  # noqa: T201\n\n    print(\"\\n-- app dirs (without optional 'version')\")  # noqa: T201\n    dirs = PlatformDirs(app_name, app_author)\n    for prop in PROPS:\n        print(f\"{prop}: {getattr(dirs, prop)}\")  # noqa: T201\n\n    print(\"\\n-- app dirs (without optional 'appauthor')\")  # noqa: T201\n    dirs = PlatformDirs(app_name)\n    for prop in PROPS:\n        print(f\"{prop}: {getattr(dirs, prop)}\")  # noqa: T201\n\n    print(\"\\n-- app dirs (with disabled 'appauthor')\")  # noqa: T201\n    dirs = PlatformDirs(app_name, appauthor=False)\n    for prop in PROPS:\n        print(f\"{prop}: {getattr(dirs, prop)}\")  # noqa: T201\n\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\console.py": {
      "sha": "5c8c5670ebfa",
      "lines": 70,
      "head": "\"\"\"\n    pygments.console\n    ~~~~~~~~~~~~~~~~\n\n    Format colored console output.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nesc = \"\\x1b[\"\n\ncodes = {}\ncodes[\"\"] = \"\"\ncodes[\"reset\"] = esc + \"39;49;00m\"\n\ncodes[\"bold\"] = esc + \"01m\"\ncodes[\"faint\"] = esc + \"02m\"\ncodes[\"standout\"] = esc + \"03m\"\ncodes[\"underline\"] = esc + \"04m\"\ncodes[\"blink\"] = esc + \"05m\"\ncodes[\"overline\"] = esc + \"06m\"\n\ndark_colors = [\"black\", \"red\", \"green\", \"yellow\", \"blue\",\n               \"magenta\", \"cyan\", \"gray\"]\nlight_colors = [\"brightblack\", \"brightred\", \"brightgreen\", \"brightyellow\", \"brightblue\",\n                \"brightmagenta\", \"brightcyan\", \"white\"]\n\nx = 30\nfor dark, light in zip(dark_colors, light_colors):\n    codes[dark] = esc + \"%im\" % x\n    codes[light] = esc + \"%im\" % (60 + x)\n    x += 1\n\ndel dark, light, x\n\ncodes[\"white\"] = codes[\"bold\"]\n\n\ndef reset_color():\n    return codes[\"reset\"]\n\n\ndef colorize(color_key, text):\n    return codes[color_key] + text + codes[\"reset\"]\n\n\ndef ansiformat(attr, text):\n    \"\"\"\n    Format ``text`` with a color and/or some attributes::\n\n        color       normal color\n        *color*     bold color\n        _color_     underlined color\n        +color+     blinking color\n    \"\"\"\n    result = []\n    if attr[:1] == attr[-1:] == '+':\n        result.append(codes['blink'])\n        attr = attr[1:-1]\n    if attr[:1] == attr[-1:] == '*':\n        result.append(codes['bold'])\n        attr = attr[1:-1]\n    if attr[:1] == attr[-1:] == '_':\n        result.append(codes['underline'])\n        attr = attr[1:-1]\n    result.append(codes[attr])\n    result.append(text)\n    result.append(codes['reset'])\n    return ''.join(result)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\filter.py": {
      "sha": "22aee50d8196",
      "lines": 70,
      "head": "\"\"\"\n    pygments.filter\n    ~~~~~~~~~~~~~~~\n\n    Module that implements the default filter.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\n\ndef apply_filters(stream, filters, lexer=None):\n    \"\"\"\n    Use this method to apply an iterable of filters to\n    a stream. If lexer is given it's forwarded to the\n    filter, otherwise the filter receives `None`.\n    \"\"\"\n    def _apply(filter_, stream):\n        yield from filter_.filter(lexer, stream)\n    for filter_ in filters:\n        stream = _apply(filter_, stream)\n    return stream\n\n\ndef simplefilter(f):\n    \"\"\"\n    Decorator that converts a function into a filter::\n\n        @simplefilter\n        def lowercase(self, lexer, stream, options):\n            for ttype, value in stream:\n                yield ttype, value.lower()\n    \"\"\"\n    return type(f.__name__, (FunctionFilter,), {\n        '__module__': getattr(f, '__module__'),\n        '__doc__': f.__doc__,\n        'function': f,\n    })\n\n\nclass Filter:\n    \"\"\"\n    Default filter. Subclass this class or use the `simplefilter`\n    decorator to create own filters.\n    \"\"\"\n\n    def __init__(self, **options):\n        self.options = options\n\n    def filter(self, lexer, stream):\n        raise NotImplementedError()\n\n\nclass FunctionFilter(Filter):\n    \"\"\"\n    Abstract class used by `simplefilter` to create simple\n    function filters on the fly. The `simplefilter` decorator\n    automatically creates subclasses of this class for\n    functions passed to it.\n    \"\"\"\n    function = None\n\n    def __init__(self, **options):\n        if not hasattr(self, 'function'):\n            raise TypeError(f'{self.__class__.__name__!r} used without bound function')\n        Filter.__init__(self, **options)\n\n    def filter(self, lexer, stream):\n        # pylint: disable=not-callable\n        yield from self.function(lexer, stream, self.options)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\formatter.py": {
      "sha": "49e9f33841a5",
      "lines": 129,
      "head": "\"\"\"\n    pygments.formatter\n    ~~~~~~~~~~~~~~~~~~\n\n    Base formatter class.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport codecs\n\nfrom pip._vendor.pygments.util import get_bool_opt\nfrom pip._vendor.pygments.styles import get_style_by_name\n\n__all__ = ['Formatter']\n\n\ndef _lookup_style(style):\n    if isinstance(style, str):\n        return get_style_by_name(style)\n    return style\n\n\nclass Formatter:\n    \"\"\"\n    Converts a token stream to text.\n\n    Formatters should have attributes to help selecting them. These\n    are similar to the corresponding :class:`~pygments.lexer.Lexer`\n    attributes.\n\n    .. autoattribute:: name\n       :no-value:\n\n    .. autoattribute:: aliases\n       :no-value:\n\n    .. autoattribute:: filenames\n       :no-value:\n\n    You can pass options as keyword arguments to the constructor.\n    All formatters accept these basic options:\n\n    ``style``\n        The style to use, can be a string or a Style subclass\n        (default: \"default\"). Not used by e.g. the\n        TerminalFormatter.\n    ``full``\n        Tells the formatter to output a \"full\" document, i.e.\n        a complete self-contained document. This doesn't have\n        any effect for some formatters (default: false).\n    ``title``\n        If ``full`` is true, the title that should be used to\n        caption the document (default: '').\n    ``encoding``\n        If given, must be an encoding name. This will be used to\n        convert the Unicode token strings to byte strings in the\n        output. If it is \"\" or None, Unicode strings will be written\n        to the output file, which most file-like objects do not\n        support (default: None).\n    ``outencoding``\n        Overrides ``encoding`` if given.\n\n    \"\"\"\n\n    #: Full name for the formatter, in human-readable form.\n    name = None\n\n    #: A list of short, unique identifiers that can be used to lookup\n    #: the formatter from a list, e.g. using :func:`.get_formatter_by_name()`.\n    aliases = []\n\n    #: A list of fnmatch patterns that match filenames for which this\n    #: formatter can produce output. The patterns in this list should be unique\n    #: among all formatters.\n    filenames = []\n\n    #: If True, this formatter outputs Unicode strings when no encoding\n    #: option is given.\n    unicodeoutput = True\n\n    def __init__(self, **options):\n        \"\"\"\n        As with lexers, this constructor takes arbitrary optional arguments,\n        and if you override it, you should first process your own options, then\n        call the base class implementation.\n        \"\"\"\n        self.style = _lookup_style(options.get('style', 'default'))\n        self.full = get_bool_opt(options, 'full', False)\n        self.title = options.get('title', '')\n        self.encoding = options.get('encoding', None) or None\n        if self.encoding in ('guess', 'chardet'):\n            # can happen for e.g. pygmentize -O encoding=guess\n            self.encoding = 'utf-8'\n        self.encoding = options.get('outencoding') or self.encoding\n        self.options = options\n\n    def get_style_defs(self, arg=''):\n        \"\"\"\n        This method must return statements or declarations suitable to define\n        the current style for subsequent highlighted text (e.g. CSS classes\n        in the `HTMLFormatter`).\n\n        The optional argument `arg` can be used to modify the generation and\n        is formatter dependent (it is standardized because it can be given on\n        the command line).\n\n        This method is called by the ``-S`` :doc:`command-line option <cmdline>`,\n        the `arg` is then given by the ``-a`` option.\n        \"\"\"\n        return ''\n\n    def format(self, tokensource, outfile):\n        \"\"\"\n        This method must format the tokens from the `tokensource` iterable and\n        write the formatted version to the file object `outfile`.\n\n        Formatter options can control how exactly the tokens are converted.\n        \"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\lexer.py": {
      "sha": "6009299b5190",
      "lines": 963,
      "head": "\"\"\"\n    pygments.lexer\n    ~~~~~~~~~~~~~~\n\n    Base lexer classes.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nimport sys\nimport time\n\nfrom pip._vendor.pygments.filter import apply_filters, Filter\nfrom pip._vendor.pygments.filters import get_filter_by_name\nfrom pip._vendor.pygments.token import Error, Text, Other, Whitespace, _TokenType\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt, get_list_opt, \\\n    make_analysator, Future, guess_decode\nfrom pip._vendor.pygments.regexopt import regex_opt\n\n__all__ = ['Lexer', 'RegexLexer', 'ExtendedRegexLexer', 'DelegatingLexer',\n           'LexerContext', 'include', 'inherit', 'bygroups', 'using', 'this',\n           'default', 'words', 'line_re']\n\nline_re = re.compile('.*?\\n')\n\n_encoding_map = [(b'\\xef\\xbb\\xbf', 'utf-8'),\n                 (b'\\xff\\xfe\\0\\0', 'utf-32'),\n                 (b'\\0\\0\\xfe\\xff', 'utf-32be'),\n                 (b'\\xff\\xfe', 'utf-16'),\n                 (b'\\xfe\\xff', 'utf-16be')]\n\n_default_analyse = staticmethod(lambda x: 0.0)\n\n\nclass LexerMeta(type):\n    \"\"\"\n    This metaclass automagically converts ``analyse_text`` methods into\n    static methods which always return float values.\n    \"\"\"\n\n    def __new__(mcs, name, bases, d):\n        if 'analyse_text' in d:\n            d['analyse_text'] = make_analysator(d['analyse_text'])\n        return type.__new__(mcs, name, bases, d)\n\n\nclass Lexer(metaclass=LexerMeta):\n    \"\"\"\n    Lexer for a specific language.\n\n    See also :doc:`lexerdevelopment`, a high-level guide to writing\n    lexers.\n\n    Lexer classes have attributes used for choosing the most appropriate\n    lexer based on various criteria.\n\n    .. autoattribute:: name\n       :no-value:\n    .. autoattribute:: aliases\n       :no-value:\n    .. autoattribute:: filenames\n       :no-value:\n    .. autoattribute:: alias_filenames\n    .. autoattribute:: mimetypes\n       :no-value:\n    .. autoattribute:: priority\n\n    Lexers included in Pygments should have two additional attributes:\n\n    .. autoattribute:: url\n       :no-value:\n    .. autoattribute:: version_added\n       :no-value:\n\n    Lexers included in Pygments may have additional attributes:\n\n    .. autoattribute:: _example\n       :no-value:\n\n    You can pass options to the constructor. The basic options recognized\n    by all lexers and processed by the base `Lexer` class are:\n\n    ``stripnl``\n        Strip leading and trailing newlines from the input (default: True).\n    ``stripall``\n        Strip all leading and trailing whitespace from the input\n        (default: False).\n    ``ensurenl``\n        Make sure that the input ends with a newline (default: True).  This\n        is required for some lexers that consume input linewise.\n\n        .. versionadded:: 1.3\n\n    ``tabsize``\n        If given and greater than 0, expand tabs in the input (default: 0).\n    ``encoding``\n        If given, must be an encoding name. This encoding will be used to\n        convert the input string to Unicode, if it is not already a Unicode\n        string (default: ``'guess'``, which uses a simple UTF-8 / Locale /\n        Latin1 detection.  Can also be ``'chardet'`` to use the chardet\n        library, if it is installed.\n    ``inencoding``\n        Overrides the ``encoding`` if given.\n    \"\"\"\n\n    #: Full name of the lexer, in human-readable form\n    name = None\n\n    #: A list of short, unique identifiers that can be used to look\n    #: up the lexer from a list, e.g., using `get_lexer_by_name()`.\n    aliases = []\n\n    #: A list of `fnmatch` patterns that match filenames which contain\n    #: content for this lexer. The patterns in this list should be unique among\n    #: all lexers.\n    filenames = []\n\n    #: A list of `fnmatch` patterns that match filenames which may or may not\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\modeline.py": {
      "sha": "ebe8bb1196d8",
      "lines": 43,
      "head": "\"\"\"\n    pygments.modeline\n    ~~~~~~~~~~~~~~~~~\n\n    A simple modeline parser (based on pymodeline).\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\n\n__all__ = ['get_filetype_from_buffer']\n\n\nmodeline_re = re.compile(r'''\n    (?: vi | vim | ex ) (?: [<=>]? \\d* )? :\n    .* (?: ft | filetype | syn | syntax ) = ( [^:\\s]+ )\n''', re.VERBOSE)\n\n\ndef get_filetype_from_line(l): # noqa: E741\n    m = modeline_re.search(l)\n    if m:\n        return m.group(1)\n\n\ndef get_filetype_from_buffer(buf, max_lines=5):\n    \"\"\"\n    Scan the buffer for modelines and return filetype if one is found.\n    \"\"\"\n    lines = buf.splitlines()\n    for line in lines[-1:-max_lines-1:-1]:\n        ret = get_filetype_from_line(line)\n        if ret:\n            return ret\n    for i in range(max_lines, -1, -1):\n        if i < len(lines):\n            ret = get_filetype_from_line(lines[i])\n            if ret:\n                return ret\n\n    return None\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\plugin.py": {
      "sha": "8d19506e58e5",
      "lines": 72,
      "head": "\"\"\"\n    pygments.plugin\n    ~~~~~~~~~~~~~~~\n\n    Pygments plugin interface.\n\n    lexer plugins::\n\n        [pygments.lexers]\n        yourlexer = yourmodule:YourLexer\n\n    formatter plugins::\n\n        [pygments.formatters]\n        yourformatter = yourformatter:YourFormatter\n        /.ext = yourformatter:YourFormatter\n\n    As you can see, you can define extensions for the formatter\n    with a leading slash.\n\n    syntax plugins::\n\n        [pygments.styles]\n        yourstyle = yourstyle:YourStyle\n\n    filter plugin::\n\n        [pygments.filter]\n        yourfilter = yourfilter:YourFilter\n\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\nfrom importlib.metadata import entry_points\n\nLEXER_ENTRY_POINT = 'pygments.lexers'\nFORMATTER_ENTRY_POINT = 'pygments.formatters'\nSTYLE_ENTRY_POINT = 'pygments.styles'\nFILTER_ENTRY_POINT = 'pygments.filters'\n\n\ndef iter_entry_points(group_name):\n    groups = entry_points()\n    if hasattr(groups, 'select'):\n        # New interface in Python 3.10 and newer versions of the\n        # importlib_metadata backport.\n        return groups.select(group=group_name)\n    else:\n        # Older interface, deprecated in Python 3.10 and recent\n        # importlib_metadata, but we need it in Python 3.8 and 3.9.\n        return groups.get(group_name, [])\n\n\ndef find_plugin_lexers():\n    for entrypoint in iter_entry_points(LEXER_ENTRY_POINT):\n        yield entrypoint.load()\n\n\ndef find_plugin_formatters():\n    for entrypoint in iter_entry_points(FORMATTER_ENTRY_POINT):\n        yield entrypoint.name, entrypoint.load()\n\n\ndef find_plugin_styles():\n    for entrypoint in iter_entry_points(STYLE_ENTRY_POINT):\n        yield entrypoint.name, entrypoint.load()\n\n\ndef find_plugin_filters():\n    for entrypoint in iter_entry_points(FILTER_ENTRY_POINT):\n        yield entrypoint.name, entrypoint.load()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\regexopt.py": {
      "sha": "31722252d752",
      "lines": 91,
      "head": "\"\"\"\n    pygments.regexopt\n    ~~~~~~~~~~~~~~~~~\n\n    An algorithm that generates optimized regexes for matching long lists of\n    literal strings.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nfrom re import escape\nfrom os.path import commonprefix\nfrom itertools import groupby\nfrom operator import itemgetter\n\nCS_ESCAPE = re.compile(r'[\\[\\^\\\\\\-\\]]')\nFIRST_ELEMENT = itemgetter(0)\n\n\ndef make_charset(letters):\n    return '[' + CS_ESCAPE.sub(lambda m: '\\\\' + m.group(), ''.join(letters)) + ']'\n\n\ndef regex_opt_inner(strings, open_paren):\n    \"\"\"Return a regex that matches any string in the sorted list of strings.\"\"\"\n    close_paren = open_paren and ')' or ''\n    # print strings, repr(open_paren)\n    if not strings:\n        # print '-> nothing left'\n        return ''\n    first = strings[0]\n    if len(strings) == 1:\n        # print '-> only 1 string'\n        return open_paren + escape(first) + close_paren\n    if not first:\n        # print '-> first string empty'\n        return open_paren + regex_opt_inner(strings[1:], '(?:') \\\n            + '?' + close_paren\n    if len(first) == 1:\n        # multiple one-char strings? make a charset\n        oneletter = []\n        rest = []\n        for s in strings:\n            if len(s) == 1:\n                oneletter.append(s)\n            else:\n                rest.append(s)\n        if len(oneletter) > 1:  # do we have more than one oneletter string?\n            if rest:\n                # print '-> 1-character + rest'\n                return open_paren + regex_opt_inner(rest, '') + '|' \\\n                    + make_charset(oneletter) + close_paren\n            # print '-> only 1-character'\n            return open_paren + make_charset(oneletter) + close_paren\n    prefix = commonprefix(strings)\n    if prefix:\n        plen = len(prefix)\n        # we have a prefix for all strings\n        # print '-> prefix:', prefix\n        return open_paren + escape(prefix) \\\n            + regex_opt_inner([s[plen:] for s in strings], '(?:') \\\n            + close_paren\n    # is there a suffix?\n    strings_rev = [s[::-1] for s in strings]\n    suffix = commonprefix(strings_rev)\n    if suffix:\n        slen = len(suffix)\n        # print '-> suffix:', suffix[::-1]\n        return open_paren \\\n            + regex_opt_inner(sorted(s[:-slen] for s in strings), '(?:') \\\n            + escape(suffix[::-1]) + close_paren\n    # recurse on common 1-string prefixes\n    # print '-> last resort'\n    return open_paren + \\\n        '|'.join(regex_opt_inner(list(group[1]), '')\n                 for group in groupby(strings, lambda s: s[0] == first[0])) \\\n        + close_paren\n\n\ndef regex_opt(strings, prefix='', suffix=''):\n    \"\"\"Return a compiled regex that matches any string in the given list.\n\n    The strings to match must be literal strings, not regexes.  They will be\n    regex-escaped.\n\n    *prefix* and *suffix* are pre- and appended to the final regex.\n    \"\"\"\n    strings = sorted(strings)\n    return prefix + regex_opt_inner(strings, '(') + suffix\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\scanner.py": {
      "sha": "c4c06e8ac2e5",
      "lines": 104,
      "head": "\"\"\"\n    pygments.scanner\n    ~~~~~~~~~~~~~~~~\n\n    This library implements a regex based scanner. Some languages\n    like Pascal are easy to parse but have some keywords that\n    depend on the context. Because of this it's impossible to lex\n    that just by using a regular expression lexer like the\n    `RegexLexer`.\n\n    Have a look at the `DelphiLexer` to get an idea of how to use\n    this scanner.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\nimport re\n\n\nclass EndOfText(RuntimeError):\n    \"\"\"\n    Raise if end of text is reached and the user\n    tried to call a match function.\n    \"\"\"\n\n\nclass Scanner:\n    \"\"\"\n    Simple scanner\n\n    All method patterns are regular expression strings (not\n    compiled expressions!)\n    \"\"\"\n\n    def __init__(self, text, flags=0):\n        \"\"\"\n        :param text:    The text which should be scanned\n        :param flags:   default regular expression flags\n        \"\"\"\n        self.data = text\n        self.data_length = len(text)\n        self.start_pos = 0\n        self.pos = 0\n        self.flags = flags\n        self.last = None\n        self.match = None\n        self._re_cache = {}\n\n    def eos(self):\n        \"\"\"`True` if the scanner reached the end of text.\"\"\"\n        return self.pos >= self.data_length\n    eos = property(eos, eos.__doc__)\n\n    def check(self, pattern):\n        \"\"\"\n        Apply `pattern` on the current position and return\n        the match object. (Doesn't touch pos). Use this for\n        lookahead.\n        \"\"\"\n        if self.eos:\n            raise EndOfText()\n        if pattern not in self._re_cache:\n            self._re_cache[pattern] = re.compile(pattern, self.flags)\n        return self._re_cache[pattern].match(self.data, self.pos)\n\n    def test(self, pattern):\n        \"\"\"Apply a pattern on the current position and check\n        if it patches. Doesn't touch pos.\n        \"\"\"\n        return self.check(pattern) is not None\n\n    def scan(self, pattern):\n        \"\"\"\n        Scan the text for the given pattern and update pos/match\n        and related fields. The return value is a boolean that\n        indicates if the pattern matched. The matched value is\n        stored on the instance as ``match``, the last value is\n        stored as ``last``. ``start_pos`` is the position of the\n        pointer before the pattern was matched, ``pos`` is the\n        end position.\n        \"\"\"\n        if self.eos:\n            raise EndOfText()\n        if pattern not in self._re_cache:\n            self._re_cache[pattern] = re.compile(pattern, self.flags)\n        self.last = self.match\n        m = self._re_cache[pattern].match(self.data, self.pos)\n        if m is None:\n            return False\n        self.start_pos = m.start()\n        self.pos = m.end()\n        self.match = m.group()\n        return True\n\n    def get_char(self):\n        \"\"\"Scan exactly one char.\"\"\"\n        self.scan('.')\n\n    def __repr__(self):\n        return '<%s %d/%d>' % (\n            self.__class__.__name__,\n            self.pos,\n            self.data_length\n        )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\sphinxext.py": {
      "sha": "3571f8279c60",
      "lines": 247,
      "head": "\"\"\"\n    pygments.sphinxext\n    ~~~~~~~~~~~~~~~~~~\n\n    Sphinx extension to generate automatic documentation of lexers,\n    formatters and filters.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport sys\n\nfrom docutils import nodes\nfrom docutils.statemachine import ViewList\nfrom docutils.parsers.rst import Directive\nfrom sphinx.util.nodes import nested_parse_with_titles\n\n\nMODULEDOC = '''\n.. module:: %s\n\n%s\n%s\n'''\n\nLEXERDOC = '''\n.. class:: %s\n\n    :Short names: %s\n    :Filenames:   %s\n    :MIME types:  %s\n\n    %s\n\n    %s\n\n'''\n\nFMTERDOC = '''\n.. class:: %s\n\n    :Short names: %s\n    :Filenames: %s\n\n    %s\n\n'''\n\nFILTERDOC = '''\n.. class:: %s\n\n    :Name: %s\n\n    %s\n\n'''\n\n\nclass PygmentsDoc(Directive):\n    \"\"\"\n    A directive to collect all lexers/formatters/filters and generate\n    autoclass directives for them.\n    \"\"\"\n    has_content = False\n    required_arguments = 1\n    optional_arguments = 0\n    final_argument_whitespace = False\n    option_spec = {}\n\n    def run(self):\n        self.filenames = set()\n        if self.arguments[0] == 'lexers':\n            out = self.document_lexers()\n        elif self.arguments[0] == 'formatters':\n            out = self.document_formatters()\n        elif self.arguments[0] == 'filters':\n            out = self.document_filters()\n        elif self.arguments[0] == 'lexers_overview':\n            out = self.document_lexers_overview()\n        else:\n            raise Exception('invalid argument for \"pygmentsdoc\" directive')\n        node = nodes.compound()\n        vl = ViewList(out.split('\\n'), source='')\n        nested_parse_with_titles(self.state, vl, node)\n        for fn in self.filenames:\n            self.state.document.settings.record_dependencies.add(fn)\n        return node.children\n\n    def document_lexers_overview(self):\n        \"\"\"Generate a tabular overview of all lexers.\n\n        The columns are the lexer name, the extensions handled by this lexer\n        (or \"None\"), the aliases and a link to the lexer class.\"\"\"\n        from pip._vendor.pygments.lexers._mapping import LEXERS\n        from pip._vendor.pygments.lexers import find_lexer_class\n        out = []\n\n        table = []\n\n        def format_link(name, url):\n            if url:\n                return f'`{name} <{url}>`_'\n            return name\n\n        for classname, data in sorted(LEXERS.items(), key=lambda x: x[1][1].lower()):\n            lexer_cls = find_lexer_class(data[1])\n            extensions = lexer_cls.filenames + lexer_cls.alias_filenames\n\n            table.append({\n                'name': format_link(data[1], lexer_cls.url),\n                'extensions': ', '.join(extensions).replace('*', '\\\\*').replace('_', '\\\\') or 'None',\n                'aliases': ', '.join(data[2]),\n                'class': f'{data[0]}.{classname}'\n            })\n\n        column_names = ['name', 'extensions', 'aliases', 'class']\n        column_lengths = [max([len(row[column]) for row in table if row[column]])\n                          for column in column_names]\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\style.py": {
      "sha": "bf890c68fdad",
      "lines": 203,
      "head": "\"\"\"\n    pygments.style\n    ~~~~~~~~~~~~~~\n\n    Basic style object.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.token import Token, STANDARD_TYPES\n\n# Default mapping of ansixxx to RGB colors.\n_ansimap = {\n    # dark\n    'ansiblack': '000000',\n    'ansired': '7f0000',\n    'ansigreen': '007f00',\n    'ansiyellow': '7f7fe0',\n    'ansiblue': '00007f',\n    'ansimagenta': '7f007f',\n    'ansicyan': '007f7f',\n    'ansigray': 'e5e5e5',\n    # normal\n    'ansibrightblack': '555555',\n    'ansibrightred': 'ff0000',\n    'ansibrightgreen': '00ff00',\n    'ansibrightyellow': 'ffff00',\n    'ansibrightblue': '0000ff',\n    'ansibrightmagenta': 'ff00ff',\n    'ansibrightcyan': '00ffff',\n    'ansiwhite': 'ffffff',\n}\n# mapping of deprecated #ansixxx colors to new color names\n_deprecated_ansicolors = {\n    # dark\n    '#ansiblack': 'ansiblack',\n    '#ansidarkred': 'ansired',\n    '#ansidarkgreen': 'ansigreen',\n    '#ansibrown': 'ansiyellow',\n    '#ansidarkblue': 'ansiblue',\n    '#ansipurple': 'ansimagenta',\n    '#ansiteal': 'ansicyan',\n    '#ansilightgray': 'ansigray',\n    # normal\n    '#ansidarkgray': 'ansibrightblack',\n    '#ansired': 'ansibrightred',\n    '#ansigreen': 'ansibrightgreen',\n    '#ansiyellow': 'ansibrightyellow',\n    '#ansiblue': 'ansibrightblue',\n    '#ansifuchsia': 'ansibrightmagenta',\n    '#ansiturquoise': 'ansibrightcyan',\n    '#ansiwhite': 'ansiwhite',\n}\nansicolors = set(_ansimap)\n\n\nclass StyleMeta(type):\n\n    def __new__(mcs, name, bases, dct):\n        obj = type.__new__(mcs, name, bases, dct)\n        for token in STANDARD_TYPES:\n            if token not in obj.styles:\n                obj.styles[token] = ''\n\n        def colorformat(text):\n            if text in ansicolors:\n                return text\n            if text[0:1] == '#':\n                col = text[1:]\n                if len(col) == 6:\n                    return col\n                elif len(col) == 3:\n                    return col[0] * 2 + col[1] * 2 + col[2] * 2\n            elif text == '':\n                return ''\n            elif text.startswith('var') or text.startswith('calc'):\n                return text\n            assert False, f\"wrong color format {text!r}\"\n\n        _styles = obj._styles = {}\n\n        for ttype in obj.styles:\n            for token in ttype.split():\n                if token in _styles:\n                    continue\n                ndef = _styles.get(token.parent, None)\n                styledefs = obj.styles.get(token, '').split()\n                if not ndef or token is None:\n                    ndef = ['', 0, 0, 0, '', '', 0, 0, 0]\n                elif 'noinherit' in styledefs and token is not Token:\n                    ndef = _styles[Token][:]\n                else:\n                    ndef = ndef[:]\n                _styles[token] = ndef\n                for styledef in obj.styles.get(token, '').split():\n                    if styledef == 'noinherit':\n                        pass\n                    elif styledef == 'bold':\n                        ndef[1] = 1\n                    elif styledef == 'nobold':\n                        ndef[1] = 0\n                    elif styledef == 'italic':\n                        ndef[2] = 1\n                    elif styledef == 'noitalic':\n                        ndef[2] = 0\n                    elif styledef == 'underline':\n                        ndef[3] = 1\n                    elif styledef == 'nounderline':\n                        ndef[3] = 0\n                    elif styledef[:3] == 'bg:':\n                        ndef[4] = colorformat(styledef[3:])\n                    elif styledef[:7] == 'border:':\n                        ndef[5] = colorformat(styledef[7:])\n                    elif styledef == 'roman':\n                        ndef[6] = 1\n                    elif styledef == 'sans':\n                        ndef[7] = 1\n                    elif styledef == 'mono':\n                        ndef[8] = 1\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\token.py": {
      "sha": "32b05670edd5",
      "lines": 214,
      "head": "\"\"\"\n    pygments.token\n    ~~~~~~~~~~~~~~\n\n    Basic token types and the standard tokens.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\n\nclass _TokenType(tuple):\n    parent = None\n\n    def split(self):\n        buf = []\n        node = self\n        while node is not None:\n            buf.append(node)\n            node = node.parent\n        buf.reverse()\n        return buf\n\n    def __init__(self, *args):\n        # no need to call super.__init__\n        self.subtypes = set()\n\n    def __contains__(self, val):\n        return self is val or (\n            type(val) is self.__class__ and\n            val[:len(self)] == self\n        )\n\n    def __getattr__(self, val):\n        if not val or not val[0].isupper():\n            return tuple.__getattribute__(self, val)\n        new = _TokenType(self + (val,))\n        setattr(self, val, new)\n        self.subtypes.add(new)\n        new.parent = self\n        return new\n\n    def __repr__(self):\n        return 'Token' + (self and '.' or '') + '.'.join(self)\n\n    def __copy__(self):\n        # These instances are supposed to be singletons\n        return self\n\n    def __deepcopy__(self, memo):\n        # These instances are supposed to be singletons\n        return self\n\n\nToken = _TokenType()\n\n# Special token types\nText = Token.Text\nWhitespace = Text.Whitespace\nEscape = Token.Escape\nError = Token.Error\n# Text that doesn't belong to this lexer (e.g. HTML in PHP)\nOther = Token.Other\n\n# Common token types for source code\nKeyword = Token.Keyword\nName = Token.Name\nLiteral = Token.Literal\nString = Literal.String\nNumber = Literal.Number\nPunctuation = Token.Punctuation\nOperator = Token.Operator\nComment = Token.Comment\n\n# Generic types for non-source code\nGeneric = Token.Generic\n\n# String and some others are not direct children of Token.\n# alias them:\nToken.Token = Token\nToken.String = String\nToken.Number = Number\n\n\ndef is_token_subtype(ttype, other):\n    \"\"\"\n    Return True if ``ttype`` is a subtype of ``other``.\n\n    exists for backwards compatibility. use ``ttype in other`` now.\n    \"\"\"\n    return ttype in other\n\n\ndef string_to_tokentype(s):\n    \"\"\"\n    Convert a string into a token type::\n\n        >>> string_to_token('String.Double')\n        Token.Literal.String.Double\n        >>> string_to_token('Token.Literal.Number')\n        Token.Literal.Number\n        >>> string_to_token('')\n        Token\n\n    Tokens that are already tokens are returned unchanged:\n\n        >>> string_to_token(String)\n        Token.Literal.String\n    \"\"\"\n    if isinstance(s, _TokenType):\n        return s\n    if not s:\n        return Token\n    node = Token\n    for item in s.split('.'):\n        node = getattr(node, item)\n    return node\n\n\n# Map standard token types to short names, used in CSS class naming.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\unistring.py": {
      "sha": "e4646d78fa69",
      "lines": 153,
      "head": "\"\"\"\n    pygments.unistring\n    ~~~~~~~~~~~~~~~~~~\n\n    Strings of all Unicode characters of a certain category.\n    Used for matching in Unicode-aware languages. Run to regenerate.\n\n    Inspired by chartypes_create.py from the MoinMoin project.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nCc = '\\x00-\\x1f\\x7f-\\x9f'\n\nCf = '\\xad\\u0600-\\u0605\\u061c\\u06dd\\u070f\\u08e2\\u180e\\u200b-\\u200f\\u202a-\\u202e\\u2060-\\u2064\\u2066-\\u206f\\ufeff\\ufff9-\\ufffb\\U000110bd\\U000110cd\\U0001bca0-\\U0001bca3\\U0001d173-\\U0001d17a\\U000e0001\\U000e0020-\\U000e007f'\n\nCn = '\\u0378-\\u0379\\u0380-\\u0383\\u038b\\u038d\\u03a2\\u0530\\u0557-\\u0558\\u058b-\\u058c\\u0590\\u05c8-\\u05cf\\u05eb-\\u05ee\\u05f5-\\u05ff\\u061d\\u070e\\u074b-\\u074c\\u07b2-\\u07bf\\u07fb-\\u07fc\\u082e-\\u082f\\u083f\\u085c-\\u085d\\u085f\\u086b-\\u089f\\u08b5\\u08be-\\u08d2\\u0984\\u098d-\\u098e\\u0991-\\u0992\\u09a9\\u09b1\\u09b3-\\u09b5\\u09ba-\\u09bb\\u09c5-\\u09c6\\u09c9-\\u09ca\\u09cf-\\u09d6\\u09d8-\\u09db\\u09de\\u09e4-\\u09e5\\u09ff-\\u0a00\\u0a04\\u0a0b-\\u0a0e\\u0a11-\\u0a12\\u0a29\\u0a31\\u0a34\\u0a37\\u0a3a-\\u0a3b\\u0a3d\\u0a43-\\u0a46\\u0a49-\\u0a4a\\u0a4e-\\u0a50\\u0a52-\\u0a58\\u0a5d\\u0a5f-\\u0a65\\u0a77-\\u0a80\\u0a84\\u0a8e\\u0a92\\u0aa9\\u0ab1\\u0ab4\\u0aba-\\u0abb\\u0ac6\\u0aca\\u0ace-\\u0acf\\u0ad1-\\u0adf\\u0ae4-\\u0ae5\\u0af2-\\u0af8\\u0b00\\u0b04\\u0b0d-\\u0b0e\\u0b11-\\u0b12\\u0b29\\u0b31\\u0b34\\u0b3a-\\u0b3b\\u0b45-\\u0b46\\u0b49-\\u0b4a\\u0b4e-\\u0b55\\u0b58-\\u0b5b\\u0b5e\\u0b64-\\u0b65\\u0b78-\\u0b81\\u0b84\\u0b8b-\\u0b8d\\u0b91\\u0b96-\\u0b98\\u0b9b\\u0b9d\\u0ba0-\\u0ba2\\u0ba5-\\u0ba7\\u0bab-\\u0bad\\u0bba-\\u0bbd\\u0bc3-\\u0bc5\\u0bc9\\u0bce-\\u0bcf\\u0bd1-\\u0bd6\\u0bd8-\\u0be5\\u0bfb-\\u0bff\\u0c0d\\u0c11\\u0c29\\u0c3a-\\u0c3c\\u0c45\\u0c49\\u0c4e-\\u0c54\\u0c57\\u0c5b-\\u0c5f\\u0c64-\\u0c65\\u0c70-\\u0c77\\u0c8d\\u0c91\\u0ca9\\u0cb4\\u0cba-\\u0cbb\\u0cc5\\u0cc9\\u0cce-\\u0cd4\\u0cd7-\\u0cdd\\u0cdf\\u0ce4-\\u0ce5\\u0cf0\\u0cf3-\\u0cff\\u0d04\\u0d0d\\u0d11\\u0d45\\u0d49\\u0d50-\\u0d53\\u0d64-\\u0d65\\u0d80-\\u0d81\\u0d84\\u0d97-\\u0d99\\u0db2\\u0dbc\\u0dbe-\\u0dbf\\u0dc7-\\u0dc9\\u0dcb-\\u0dce\\u0dd5\\u0dd7\\u0de0-\\u0de5\\u0df0-\\u0df1\\u0df5-\\u0e00\\u0e3b-\\u0e3e\\u0e5c-\\u0e80\\u0e83\\u0e85-\\u0e86\\u0e89\\u0e8b-\\u0e8c\\u0e8e-\\u0e93\\u0e98\\u0ea0\\u0ea4\\u0ea6\\u0ea8-\\u0ea9\\u0eac\\u0eba\\u0ebe-\\u0ebf\\u0ec5\\u0ec7\\u0ece-\\u0ecf\\u0eda-\\u0edb\\u0ee0-\\u0eff\\u0f48\\u0f6d-\\u0f70\\u0f98\\u0fbd\\u0fcd\\u0fdb-\\u0fff\\u10c6\\u10c8-\\u10cc\\u10ce-\\u10cf\\u1249\\u124e-\\u124f\\u1257\\u1259\\u125e-\\u125f\\u1289\\u128e-\\u128f\\u12b1\\u12b6-\\u12b7\\u12bf\\u12c1\\u12c6-\\u12c7\\u12d7\\u1311\\u1316-\\u1317\\u135b-\\u135c\\u137d-\\u137f\\u139a-\\u139f\\u13f6-\\u13f7\\u13fe-\\u13ff\\u169d-\\u169f\\u16f9-\\u16ff\\u170d\\u1715-\\u171f\\u1737-\\u173f\\u1754-\\u175f\\u176d\\u1771\\u1774-\\u177f\\u17de-\\u17df\\u17ea-\\u17ef\\u17fa-\\u17ff\\u180f\\u181a-\\u181f\\u1879-\\u187f\\u18ab-\\u18af\\u18f6-\\u18ff\\u191f\\u192c-\\u192f\\u193c-\\u193f\\u1941-\\u1943\\u196e-\\u196f\\u1975-\\u197f\\u19ac-\\u19af\\u19ca-\\u19cf\\u19db-\\u19dd\\u1a1c-\\u1a1d\\u1a5f\\u1a7d-\\u1a7e\\u1a8a-\\u1a8f\\u1a9a-\\u1a9f\\u1aae-\\u1aaf\\u1abf-\\u1aff\\u1b4c-\\u1b4f\\u1b7d-\\u1b7f\\u1bf4-\\u1bfb\\u1c38-\\u1c3a\\u1c4a-\\u1c4c\\u1c89-\\u1c8f\\u1cbb-\\u1cbc\\u1cc8-\\u1ccf\\u1cfa-\\u1cff\\u1dfa\\u1f16-\\u1f17\\u1f1e-\\u1f1f\\u1f46-\\u1f47\\u1f4e-\\u1f4f\\u1f58\\u1f5a\\u1f5c\\u1f5e\\u1f7e-\\u1f7f\\u1fb5\\u1fc5\\u1fd4-\\u1fd5\\u1fdc\\u1ff0-\\u1ff1\\u1ff5\\u1fff\\u2065\\u2072-\\u2073\\u208f\\u209d-\\u209f\\u20c0-\\u20cf\\u20f1-\\u20ff\\u218c-\\u218f\\u2427-\\u243f\\u244b-\\u245f\\u2b74-\\u2b75\\u2b96-\\u2b97\\u2bc9\\u2bff\\u2c2f\\u2c5f\\u2cf4-\\u2cf8\\u2d26\\u2d28-\\u2d2c\\u2d2e-\\u2d2f\\u2d68-\\u2d6e\\u2d71-\\u2d7e\\u2d97-\\u2d9f\\u2da7\\u2daf\\u2db7\\u2dbf\\u2dc7\\u2dcf\\u2dd7\\u2ddf\\u2e4f-\\u2e7f\\u2e9a\\u2ef4-\\u2eff\\u2fd6-\\u2fef\\u2ffc-\\u2fff\\u3040\\u3097-\\u3098\\u3100-\\u3104\\u3130\\u318f\\u31bb-\\u31bf\\u31e4-\\u31ef\\u321f\\u32ff\\u4db6-\\u4dbf\\u9ff0-\\u9fff\\ua48d-\\ua48f\\ua4c7-\\ua4cf\\ua62c-\\ua63f\\ua6f8-\\ua6ff\\ua7ba-\\ua7f6\\ua82c-\\ua82f\\ua83a-\\ua83f\\ua878-\\ua87f\\ua8c6-\\ua8cd\\ua8da-\\ua8df\\ua954-\\ua95e\\ua97d-\\ua97f\\ua9ce\\ua9da-\\ua9dd\\ua9ff\\uaa37-\\uaa3f\\uaa4e-\\uaa4f\\uaa5a-\\uaa5b\\uaac3-\\uaada\\uaaf7-\\uab00\\uab07-\\uab08\\uab0f-\\uab10\\uab17-\\uab1f\\uab27\\uab2f\\uab66-\\uab6f\\uabee-\\uabef\\uabfa-\\uabff\\ud7a4-\\ud7af\\ud7c7-\\ud7ca\\ud7fc-\\ud7ff\\ufa6e-\\ufa6f\\ufada-\\ufaff\\ufb07-\\ufb12\\ufb18-\\ufb1c\\ufb37\\ufb3d\\ufb3f\\ufb42\\ufb45\\ufbc2-\\ufbd2\\ufd40-\\ufd4f\\ufd90-\\ufd91\\ufdc8-\\ufdef\\ufdfe-\\ufdff\\ufe1a-\\ufe1f\\ufe53\\ufe67\\ufe6c-\\ufe6f\\ufe75\\ufefd-\\ufefe\\uff00\\uffbf-\\uffc1\\uffc8-\\uffc9\\uffd0-\\uffd1\\uffd8-\\uffd9\\uffdd-\\uffdf\\uffe7\\uffef-\\ufff8\\ufffe-\\uffff\\U0001000c\\U00010027\\U0001003b\\U0001003e\\U0001004e-\\U0001004f\\U0001005e-\\U0001007f\\U000100fb-\\U000100ff\\U00010103-\\U00010106\\U00010134-\\U00010136\\U0001018f\\U0001019c-\\U0001019f\\U000101a1-\\U000101cf\\U000101fe-\\U0001027f\\U0001029d-\\U0001029f\\U000102d1-\\U000102df\\U000102fc-\\U000102ff\\U00010324-\\U0001032c\\U0001034b-\\U0001034f\\U0001037b-\\U0001037f\\U0001039e\\U000103c4-\\U000103c7\\U000103d6-\\U000103ff\\U0001049e-\\U0001049f\\U000104aa-\\U000104af\\U000104d4-\\U000104d7\\U000104fc-\\U000104ff\\U00010528-\\U0001052f\\U00010564-\\U0001056e\\U00010570-\\U000105ff\\U00010737-\\U0001073f\\U00010756-\\U0001075f\\U00010768-\\U000107ff\\U00010806-\\U00010807\\U00010809\\U00010836\\U00010839-\\U0001083b\\U0001083d-\\U0001083e\\U00010856\\U0001089f-\\U000108a6\\U000108b0-\\U000108df\\U000108f3\\U000108f6-\\U000108fa\\U0001091c-\\U0001091e\\U0001093a-\\U0001093e\\U00010940-\\U0001097f\\U000109b8-\\U000109bb\\U000109d0-\\U000109d1\\U00010a04\\U00010a07-\\U00010a0b\\U00010a14\\U00010a18\\U00010a36-\\U00010a37\\U00010a3b-\\U00010a3e\\U00010a49-\\U00010a4f\\U00010a59-\\U00010a5f\\U00010aa0-\\U00010abf\\U00010ae7-\\U00010aea\\U00010af7-\\U00010aff\\U00010b36-\\U00010b38\\U00010b56-\\U00010b57\\U00010b73-\\U00010b77\\U00010b92-\\U00010b98\\U00010b9d-\\U00010ba8\\U00010bb0-\\U00010bff\\U00010c49-\\U00010c7f\\U00010cb3-\\U00010cbf\\U00010cf3-\\U00010cf9\\U00010d28-\\U00010d2f\\U00010d3a-\\U00010e5f\\U00010e7f-\\U00010eff\\U00010f28-\\U00010f2f\\U00010f5a-\\U00010fff\\U0001104e-\\U00011051\\U00011070-\\U0001107e\\U000110c2-\\U000110cc\\U000110ce-\\U000110cf\\U000110e9-\\U000110ef\\U000110fa-\\U000110ff\\U00011135\\U00011147-\\U0001114f\\U00011177-\\U0001117f\\U000111ce-\\U000111cf\\U000111e0\\U000111f5-\\U000111ff\\U00011212\\U0001123f-\\U0001127f\\U00011287\\U00011289\\U0001128e\\U0001129e\\U000112aa-\\U000112af\\U000112eb-\\U000112ef\\U000112fa-\\U000112ff\\U00011304\\U0001130d-\\U0001130e\\U00011311-\\U00011312\\U00011329\\U00011331\\U00011334\\U0001133a\\U00011345-\\U00011346\\U00011349-\\U0001134a\\U0001134e-\\U0001134f\\U00011351-\\U00011356\\U00011358-\\U0001135c\\U00011364-\\U00011365\\U0001136d-\\U0001136f\\U00011375-\\U000113ff\\U0001145a\\U0001145c\\U0001145f-\\U0001147f\\U000114c8-\\U000114cf\\U000114da-\\U0001157f\\U000115b6-\\U000115b7\\U000115de-\\U000115ff\\U00011645-\\U0001164f\\U0001165a-\\U0001165f\\U0001166d-\\U0001167f\\U000116b8-\\U000116bf\\U000116ca-\\U000116ff\\U0001171b-\\U0001171c\\U0001172c-\\U0001172f\\U00011740-\\U000117ff\\U0001183c-\\U0001189f\\U000118f3-\\U000118fe\\U00011900-\\U000119ff\\U00011a48-\\U00011a4f\\U00011a84-\\U00011a85\\U00011aa3-\\U00011abf\\U00011af9-\\U00011bff\\U00011c09\\U00011c37\\U00011c46-\\U00011c4f\\U00011c6d-\\U00011c6f\\U00011c90-\\U00011c91\\U00011ca8\\U00011cb7-\\U00011cff\\U00011d07\\U00011d0a\\U00011d37-\\U00011d39\\U00011d3b\\U00011d3e\\U00011d48-\\U00011d4f\\U00011d5a-\\U00011d5f\\U00011d66\\U00011d69\\U00011d8f\\U00011d92\\U00011d99-\\U00011d9f\\U00011daa-\\U00011edf\\U00011ef9-\\U00011fff\\U0001239a-\\U000123ff\\U0001246f\\U00012475-\\U0001247f\\U00012544-\\U00012fff\\U0001342f-\\U000143ff\\U00014647-\\U000167ff\\U00016a39-\\U00016a3f\\U00016a5f\\U00016a6a-\\U00016a6d\\U00016a70-\\U00016acf\\U00016aee-\\U00016aef\\U00016af6-\\U00016aff\\U00016b46-\\U00016b4f\\U00016b5a\\U00016b62\\U00016b78-\\U00016b7c\\U00016b90-\\U00016e3f\\U00016e9b-\\U00016eff\\U00016f45-\\U00016f4f\\U00016f7f-\\U00016f8e\\U00016fa0-\\U00016fdf\\U00016fe2-\\U00016fff\\U000187f2-\\U000187ff\\U00018af3-\\U0001afff\\U0001b11f-\\U0001b16f\\U0001b2fc-\\U0001bbff\\U0001bc6b-\\U0001bc6f\\U0001bc7d-\\U0001bc7f\\U0001bc89-\\U0001bc8f\\U0001bc9a-\\U0001bc9b\\U0001bca4-\\U0001cfff\\U0001d0f6-\\U0001d0ff\\U0001d127-\\U0001d128\\U0001d1e9-\\U0001d1ff\\U0001d246-\\U0001d2df\\U0001d2f4-\\U0001d2ff\\U0001d357-\\U0001d35f\\U0001d379-\\U0001d3ff\\U0001d455\\U0001d49d\\U0001d4a0-\\U0001d4a1\\U0001d4a3-\\U0001d4a4\\U0001d4a7-\\U0001d4a8\\U0001d4ad\\U0001d4ba\\U0001d4bc\\U0001d4c4\\U0001d506\\U0001d50b-\\U0001d50c\\U0001d515\\U0001d51d\\U0001d53a\\U0001d53f\\U0001d545\\U0001d547-\\U0001d549\\U0001d551\\U0001d6a6-\\U0001d6a7\\U0001d7cc-\\U0001d7cd\\U0001da8c-\\U0001da9a\\U0001daa0\\U0001dab0-\\U0001dfff\\U0001e007\\U0001e019-\\U0001e01a\\U0001e022\\U0001e025\\U0001e02b-\\U0001e7ff\\U0001e8c5-\\U0001e8c6\\U0001e8d7-\\U0001e8ff\\U0001e94b-\\U0001e94f\\U0001e95a-\\U0001e95d\\U0001e960-\\U0001ec70\\U0001ecb5-\\U0001edff\\U0001ee04\\U0001ee20\\U0001ee23\\U0001ee25-\\U0001ee26\\U0001ee28\\U0001ee33\\U0001ee38\\U0001ee3a\\U0001ee3c-\\U0001ee41\\U0001ee43-\\U0001ee46\\U0001ee48\\U0001ee4a\\U0001ee4c\\U0001ee50\\U0001ee53\\U0001ee55-\\U0001ee56\\U0001ee58\\U0001ee5a\\U0001ee5c\\U0001ee5e\\U0001ee60\\U0001ee63\\U0001ee65-\\U0001ee66\\U0001ee6b\\U0001ee73\\U0001ee78\\U0001ee7d\\U0001ee7f\\U0001ee8a\\U0001ee9c-\\U0001eea0\\U0001eea4\\U0001eeaa\\U0001eebc-\\U0001eeef\\U0001eef2-\\U0001efff\\U0001f02c-\\U0001f02f\\U0001f094-\\U0001f09f\\U0001f0af-\\U0001f0b0\\U0001f0c0\\U0001f0d0\\U0001f0f6-\\U0001f0ff\\U0001f10d-\\U0001f10f\\U0001f16c-\\U0001f16f\\U0001f1ad-\\U0001f1e5\\U0001f203-\\U0001f20f\\U0001f23c-\\U0001f23f\\U0001f249-\\U0001f24f\\U0001f252-\\U0001f25f\\U0001f266-\\U0001f2ff\\U0001f6d5-\\U0001f6df\\U0001f6ed-\\U0001f6ef\\U0001f6fa-\\U0001f6ff\\U0001f774-\\U0001f77f\\U0001f7d9-\\U0001f7ff\\U0001f80c-\\U0001f80f\\U0001f848-\\U0001f84f\\U0001f85a-\\U0001f85f\\U0001f888-\\U0001f88f\\U0001f8ae-\\U0001f8ff\\U0001f90c-\\U0001f90f\\U0001f93f\\U0001f971-\\U0001f972\\U0001f977-\\U0001f979\\U0001f97b\\U0001f9a3-\\U0001f9af\\U0001f9ba-\\U0001f9bf\\U0001f9c3-\\U0001f9cf\\U0001fa00-\\U0001fa5f\\U0001fa6e-\\U0001ffff\\U0002a6d7-\\U0002a6ff\\U0002b735-\\U0002b73f\\U0002b81e-\\U0002b81f\\U0002cea2-\\U0002ceaf\\U0002ebe1-\\U0002f7ff\\U0002fa1e-\\U000e0000\\U000e0002-\\U000e001f\\U000e0080-\\U000e00ff\\U000e01f0-\\U000effff\\U000ffffe-\\U000fffff\\U0010fffe-\\U0010ffff'\n\nCo = '\\ue000-\\uf8ff\\U000f0000-\\U000ffffd\\U00100000-\\U0010fffd'\n\nCs = '\\ud800-\\udbff\\\\\\udc00\\udc01-\\udfff'\n\nLl = 'a-z\\xb5\\xdf-\\xf6\\xf8-\\xff\\u0101\\u0103\\u0105\\u0107\\u0109\\u010b\\u010d\\u010f\\u0111\\u0113\\u0115\\u0117\\u0119\\u011b\\u011d\\u011f\\u0121\\u0123\\u0125\\u0127\\u0129\\u012b\\u012d\\u012f\\u0131\\u0133\\u0135\\u0137-\\u0138\\u013a\\u013c\\u013e\\u0140\\u0142\\u0144\\u0146\\u0148-\\u0149\\u014b\\u014d\\u014f\\u0151\\u0153\\u0155\\u0157\\u0159\\u015b\\u015d\\u015f\\u0161\\u0163\\u0165\\u0167\\u0169\\u016b\\u016d\\u016f\\u0171\\u0173\\u0175\\u0177\\u017a\\u017c\\u017e-\\u0180\\u0183\\u0185\\u0188\\u018c-\\u018d\\u0192\\u0195\\u0199-\\u019b\\u019e\\u01a1\\u01a3\\u01a5\\u01a8\\u01aa-\\u01ab\\u01ad\\u01b0\\u01b4\\u01b6\\u01b9-\\u01ba\\u01bd-\\u01bf\\u01c6\\u01c9\\u01cc\\u01ce\\u01d0\\u01d2\\u01d4\\u01d6\\u01d8\\u01da\\u01dc-\\u01dd\\u01df\\u01e1\\u01e3\\u01e5\\u01e7\\u01e9\\u01eb\\u01ed\\u01ef-\\u01f0\\u01f3\\u01f5\\u01f9\\u01fb\\u01fd\\u01ff\\u0201\\u0203\\u0205\\u0207\\u0209\\u020b\\u020d\\u020f\\u0211\\u0213\\u0215\\u0217\\u0219\\u021b\\u021d\\u021f\\u0221\\u0223\\u0225\\u0227\\u0229\\u022b\\u022d\\u022f\\u0231\\u0233-\\u0239\\u023c\\u023f-\\u0240\\u0242\\u0247\\u0249\\u024b\\u024d\\u024f-\\u0293\\u0295-\\u02af\\u0371\\u0373\\u0377\\u037b-\\u037d\\u0390\\u03ac-\\u03ce\\u03d0-\\u03d1\\u03d5-\\u03d7\\u03d9\\u03db\\u03dd\\u03df\\u03e1\\u03e3\\u03e5\\u03e7\\u03e9\\u03eb\\u03ed\\u03ef-\\u03f3\\u03f5\\u03f8\\u03fb-\\u03fc\\u0430-\\u045f\\u0461\\u0463\\u0465\\u0467\\u0469\\u046b\\u046d\\u046f\\u0471\\u0473\\u0475\\u0477\\u0479\\u047b\\u047d\\u047f\\u0481\\u048b\\u048d\\u048f\\u0491\\u0493\\u0495\\u0497\\u0499\\u049b\\u049d\\u049f\\u04a1\\u04a3\\u04a5\\u04a7\\u04a9\\u04ab\\u04ad\\u04af\\u04b1\\u04b3\\u04b5\\u04b7\\u04b9\\u04bb\\u04bd\\u04bf\\u04c2\\u04c4\\u04c6\\u04c8\\u04ca\\u04cc\\u04ce-\\u04cf\\u04d1\\u04d3\\u04d5\\u04d7\\u04d9\\u04db\\u04dd\\u04df\\u04e1\\u04e3\\u04e5\\u04e7\\u04e9\\u04eb\\u04ed\\u04ef\\u04f1\\u04f3\\u04f5\\u04f7\\u04f9\\u04fb\\u04fd\\u04ff\\u0501\\u0503\\u0505\\u0507\\u0509\\u050b\\u050d\\u050f\\u0511\\u0513\\u0515\\u0517\\u0519\\u051b\\u051d\\u051f\\u0521\\u0523\\u0525\\u0527\\u0529\\u052b\\u052d\\u052f\\u0560-\\u0588\\u10d0-\\u10fa\\u10fd-\\u10ff\\u13f8-\\u13fd\\u1c80-\\u1c88\\u1d00-\\u1d2b\\u1d6b-\\u1d77\\u1d79-\\u1d9a\\u1e01\\u1e03\\u1e05\\u1e07\\u1e09\\u1e0b\\u1e0d\\u1e0f\\u1e11\\u1e13\\u1e15\\u1e17\\u1e19\\u1e1b\\u1e1d\\u1e1f\\u1e21\\u1e23\\u1e25\\u1e27\\u1e29\\u1e2b\\u1e2d\\u1e2f\\u1e31\\u1e33\\u1e35\\u1e37\\u1e39\\u1e3b\\u1e3d\\u1e3f\\u1e41\\u1e43\\u1e45\\u1e47\\u1e49\\u1e4b\\u1e4d\\u1e4f\\u1e51\\u1e53\\u1e55\\u1e57\\u1e59\\u1e5b\\u1e5d\\u1e5f\\u1e61\\u1e63\\u1e65\\u1e67\\u1e69\\u1e6b\\u1e6d\\u1e6f\\u1e71\\u1e73\\u1e75\\u1e77\\u1e79\\u1e7b\\u1e7d\\u1e7f\\u1e81\\u1e83\\u1e85\\u1e87\\u1e89\\u1e8b\\u1e8d\\u1e8f\\u1e91\\u1e93\\u1e95-\\u1e9d\\u1e9f\\u1ea1\\u1ea3\\u1ea5\\u1ea7\\u1ea9\\u1eab\\u1ead\\u1eaf\\u1eb1\\u1eb3\\u1eb5\\u1eb7\\u1eb9\\u1ebb\\u1ebd\\u1ebf\\u1ec1\\u1ec3\\u1ec5\\u1ec7\\u1ec9\\u1ecb\\u1ecd\\u1ecf\\u1ed1\\u1ed3\\u1ed5\\u1ed7\\u1ed9\\u1edb\\u1edd\\u1edf\\u1ee1\\u1ee3\\u1ee5\\u1ee7\\u1ee9\\u1eeb\\u1eed\\u1eef\\u1ef1\\u1ef3\\u1ef5\\u1ef7\\u1ef9\\u1efb\\u1efd\\u1eff-\\u1f07\\u1f10-\\u1f15\\u1f20-\\u1f27\\u1f30-\\u1f37\\u1f40-\\u1f45\\u1f50-\\u1f57\\u1f60-\\u1f67\\u1f70-\\u1f7d\\u1f80-\\u1f87\\u1f90-\\u1f97\\u1fa0-\\u1fa7\\u1fb0-\\u1fb4\\u1fb6-\\u1fb7\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fc7\\u1fd0-\\u1fd3\\u1fd6-\\u1fd7\\u1fe0-\\u1fe7\\u1ff2-\\u1ff4\\u1ff6-\\u1ff7\\u210a\\u210e-\\u210f\\u2113\\u212f\\u2134\\u2139\\u213c-\\u213d\\u2146-\\u2149\\u214e\\u2184\\u2c30-\\u2c5e\\u2c61\\u2c65-\\u2c66\\u2c68\\u2c6a\\u2c6c\\u2c71\\u2c73-\\u2c74\\u2c76-\\u2c7b\\u2c81\\u2c83\\u2c85\\u2c87\\u2c89\\u2c8b\\u2c8d\\u2c8f\\u2c91\\u2c93\\u2c95\\u2c97\\u2c99\\u2c9b\\u2c9d\\u2c9f\\u2ca1\\u2ca3\\u2ca5\\u2ca7\\u2ca9\\u2cab\\u2cad\\u2caf\\u2cb1\\u2cb3\\u2cb5\\u2cb7\\u2cb9\\u2cbb\\u2cbd\\u2cbf\\u2cc1\\u2cc3\\u2cc5\\u2cc7\\u2cc9\\u2ccb\\u2ccd\\u2ccf\\u2cd1\\u2cd3\\u2cd5\\u2cd7\\u2cd9\\u2cdb\\u2cdd\\u2cdf\\u2ce1\\u2ce3-\\u2ce4\\u2cec\\u2cee\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\ua641\\ua643\\ua645\\ua647\\ua649\\ua64b\\ua64d\\ua64f\\ua651\\ua653\\ua655\\ua657\\ua659\\ua65b\\ua65d\\ua65f\\ua661\\ua663\\ua665\\ua667\\ua669\\ua66b\\ua66d\\ua681\\ua683\\ua685\\ua687\\ua689\\ua68b\\ua68d\\ua68f\\ua691\\ua693\\ua695\\ua697\\ua699\\ua69b\\ua723\\ua725\\ua727\\ua729\\ua72b\\ua72d\\ua72f-\\ua731\\ua733\\ua735\\ua737\\ua739\\ua73b\\ua73d\\ua73f\\ua741\\ua743\\ua745\\ua747\\ua749\\ua74b\\ua74d\\ua74f\\ua751\\ua753\\ua755\\ua757\\ua759\\ua75b\\ua75d\\ua75f\\ua761\\ua763\\ua765\\ua767\\ua769\\ua76b\\ua76d\\ua76f\\ua771-\\ua778\\ua77a\\ua77c\\ua77f\\ua781\\ua783\\ua785\\ua787\\ua78c\\ua78e\\ua791\\ua793-\\ua795\\ua797\\ua799\\ua79b\\ua79d\\ua79f\\ua7a1\\ua7a3\\ua7a5\\ua7a7\\ua7a9\\ua7af\\ua7b5\\ua7b7\\ua7b9\\ua7fa\\uab30-\\uab5a\\uab60-\\uab65\\uab70-\\uabbf\\ufb00-\\ufb06\\ufb13-\\ufb17\\uff41-\\uff5a\\U00010428-\\U0001044f\\U000104d8-\\U000104fb\\U00010cc0-\\U00010cf2\\U000118c0-\\U000118df\\U00016e60-\\U00016e7f\\U0001d41a-\\U0001d433\\U0001d44e-\\U0001d454\\U0001d456-\\U0001d467\\U0001d482-\\U0001d49b\\U0001d4b6-\\U0001d4b9\\U0001d4bb\\U0001d4bd-\\U0001d4c3\\U0001d4c5-\\U0001d4cf\\U0001d4ea-\\U0001d503\\U0001d51e-\\U0001d537\\U0001d552-\\U0001d56b\\U0001d586-\\U0001d59f\\U0001d5ba-\\U0001d5d3\\U0001d5ee-\\U0001d607\\U0001d622-\\U0001d63b\\U0001d656-\\U0001d66f\\U0001d68a-\\U0001d6a5\\U0001d6c2-\\U0001d6da\\U0001d6dc-\\U0001d6e1\\U0001d6fc-\\U0001d714\\U0001d716-\\U0001d71b\\U0001d736-\\U0001d74e\\U0001d750-\\U0001d755\\U0001d770-\\U0001d788\\U0001d78a-\\U0001d78f\\U0001d7aa-\\U0001d7c2\\U0001d7c4-\\U0001d7c9\\U0001d7cb\\U0001e922-\\U0001e943'\n\nLm = '\\u02b0-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0374\\u037a\\u0559\\u0640\\u06e5-\\u06e6\\u07f4-\\u07f5\\u07fa\\u081a\\u0824\\u0828\\u0971\\u0e46\\u0ec6\\u10fc\\u17d7\\u1843\\u1aa7\\u1c78-\\u1c7d\\u1d2c-\\u1d6a\\u1d78\\u1d9b-\\u1dbf\\u2071\\u207f\\u2090-\\u209c\\u2c7c-\\u2c7d\\u2d6f\\u2e2f\\u3005\\u3031-\\u3035\\u303b\\u309d-\\u309e\\u30fc-\\u30fe\\ua015\\ua4f8-\\ua4fd\\ua60c\\ua67f\\ua69c-\\ua69d\\ua717-\\ua71f\\ua770\\ua788\\ua7f8-\\ua7f9\\ua9cf\\ua9e6\\uaa70\\uaadd\\uaaf3-\\uaaf4\\uab5c-\\uab5f\\uff70\\uff9e-\\uff9f\\U00016b40-\\U00016b43\\U00016f93-\\U00016f9f\\U00016fe0-\\U00016fe1'\n\nLo = '\\xaa\\xba\\u01bb\\u01c0-\\u01c3\\u0294\\u05d0-\\u05ea\\u05ef-\\u05f2\\u0620-\\u063f\\u0641-\\u064a\\u066e-\\u066f\\u0671-\\u06d3\\u06d5\\u06ee-\\u06ef\\u06fa-\\u06fc\\u06ff\\u0710\\u0712-\\u072f\\u074d-\\u07a5\\u07b1\\u07ca-\\u07ea\\u0800-\\u0815\\u0840-\\u0858\\u0860-\\u086a\\u08a0-\\u08b4\\u08b6-\\u08bd\\u0904-\\u0939\\u093d\\u0950\\u0958-\\u0961\\u0972-\\u0980\\u0985-\\u098c\\u098f-\\u0990\\u0993-\\u09a8\\u09aa-\\u09b0\\u09b2\\u09b6-\\u09b9\\u09bd\\u09ce\\u09dc-\\u09dd\\u09df-\\u09e1\\u09f0-\\u09f1\\u09fc\\u0a05-\\u0a0a\\u0a0f-\\u0a10\\u0a13-\\u0a28\\u0a2a-\\u0a30\\u0a32-\\u0a33\\u0a35-\\u0a36\\u0a38-\\u0a39\\u0a59-\\u0a5c\\u0a5e\\u0a72-\\u0a74\\u0a85-\\u0a8d\\u0a8f-\\u0a91\\u0a93-\\u0aa8\\u0aaa-\\u0ab0\\u0ab2-\\u0ab3\\u0ab5-\\u0ab9\\u0abd\\u0ad0\\u0ae0-\\u0ae1\\u0af9\\u0b05-\\u0b0c\\u0b0f-\\u0b10\\u0b13-\\u0b28\\u0b2a-\\u0b30\\u0b32-\\u0b33\\u0b35-\\u0b39\\u0b3d\\u0b5c-\\u0b5d\\u0b5f-\\u0b61\\u0b71\\u0b83\\u0b85-\\u0b8a\\u0b8e-\\u0b90\\u0b92-\\u0b95\\u0b99-\\u0b9a\\u0b9c\\u0b9e-\\u0b9f\\u0ba3-\\u0ba4\\u0ba8-\\u0baa\\u0bae-\\u0bb9\\u0bd0\\u0c05-\\u0c0c\\u0c0e-\\u0c10\\u0c12-\\u0c28\\u0c2a-\\u0c39\\u0c3d\\u0c58-\\u0c5a\\u0c60-\\u0c61\\u0c80\\u0c85-\\u0c8c\\u0c8e-\\u0c90\\u0c92-\\u0ca8\\u0caa-\\u0cb3\\u0cb5-\\u0cb9\\u0cbd\\u0cde\\u0ce0-\\u0ce1\\u0cf1-\\u0cf2\\u0d05-\\u0d0c\\u0d0e-\\u0d10\\u0d12-\\u0d3a\\u0d3d\\u0d4e\\u0d54-\\u0d56\\u0d5f-\\u0d61\\u0d7a-\\u0d7f\\u0d85-\\u0d96\\u0d9a-\\u0db1\\u0db3-\\u0dbb\\u0dbd\\u0dc0-\\u0dc6\\u0e01-\\u0e30\\u0e32-\\u0e33\\u0e40-\\u0e45\\u0e81-\\u0e82\\u0e84\\u0e87-\\u0e88\\u0e8a\\u0e8d\\u0e94-\\u0e97\\u0e99-\\u0e9f\\u0ea1-\\u0ea3\\u0ea5\\u0ea7\\u0eaa-\\u0eab\\u0ead-\\u0eb0\\u0eb2-\\u0eb3\\u0ebd\\u0ec0-\\u0ec4\\u0edc-\\u0edf\\u0f00\\u0f40-\\u0f47\\u0f49-\\u0f6c\\u0f88-\\u0f8c\\u1000-\\u102a\\u103f\\u1050-\\u1055\\u105a-\\u105d\\u1061\\u1065-\\u1066\\u106e-\\u1070\\u1075-\\u1081\\u108e\\u1100-\\u1248\\u124a-\\u124d\\u1250-\\u1256\\u1258\\u125a-\\u125d\\u1260-\\u1288\\u128a-\\u128d\\u1290-\\u12b0\\u12b2-\\u12b5\\u12b8-\\u12be\\u12c0\\u12c2-\\u12c5\\u12c8-\\u12d6\\u12d8-\\u1310\\u1312-\\u1315\\u1318-\\u135a\\u1380-\\u138f\\u1401-\\u166c\\u166f-\\u167f\\u1681-\\u169a\\u16a0-\\u16ea\\u16f1-\\u16f8\\u1700-\\u170c\\u170e-\\u1711\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u176c\\u176e-\\u1770\\u1780-\\u17b3\\u17dc\\u1820-\\u1842\\u1844-\\u1878\\u1880-\\u1884\\u1887-\\u18a8\\u18aa\\u18b0-\\u18f5\\u1900-\\u191e\\u1950-\\u196d\\u1970-\\u1974\\u1980-\\u19ab\\u19b0-\\u19c9\\u1a00-\\u1a16\\u1a20-\\u1a54\\u1b05-\\u1b33\\u1b45-\\u1b4b\\u1b83-\\u1ba0\\u1bae-\\u1baf\\u1bba-\\u1be5\\u1c00-\\u1c23\\u1c4d-\\u1c4f\\u1c5a-\\u1c77\\u1ce9-\\u1cec\\u1cee-\\u1cf1\\u1cf5-\\u1cf6\\u2135-\\u2138\\u2d30-\\u2d67\\u2d80-\\u2d96\\u2da0-\\u2da6\\u2da8-\\u2dae\\u2db0-\\u2db6\\u2db8-\\u2dbe\\u2dc0-\\u2dc6\\u2dc8-\\u2dce\\u2dd0-\\u2dd6\\u2dd8-\\u2dde\\u3006\\u303c\\u3041-\\u3096\\u309f\\u30a1-\\u30fa\\u30ff\\u3105-\\u312f\\u3131-\\u318e\\u31a0-\\u31ba\\u31f0-\\u31ff\\u3400-\\u4db5\\u4e00-\\u9fef\\ua000-\\ua014\\ua016-\\ua48c\\ua4d0-\\ua4f7\\ua500-\\ua60b\\ua610-\\ua61f\\ua62a-\\ua62b\\ua66e\\ua6a0-\\ua6e5\\ua78f\\ua7f7\\ua7fb-\\ua801\\ua803-\\ua805\\ua807-\\ua80a\\ua80c-\\ua822\\ua840-\\ua873\\ua882-\\ua8b3\\ua8f2-\\ua8f7\\ua8fb\\ua8fd-\\ua8fe\\ua90a-\\ua925\\ua930-\\ua946\\ua960-\\ua97c\\ua984-\\ua9b2\\ua9e0-\\ua9e4\\ua9e7-\\ua9ef\\ua9fa-\\ua9fe\\uaa00-\\uaa28\\uaa40-\\uaa42\\uaa44-\\uaa4b\\uaa60-\\uaa6f\\uaa71-\\uaa76\\uaa7a\\uaa7e-\\uaaaf\\uaab1\\uaab5-\\uaab6\\uaab9-\\uaabd\\uaac0\\uaac2\\uaadb-\\uaadc\\uaae0-\\uaaea\\uaaf2\\uab01-\\uab06\\uab09-\\uab0e\\uab11-\\uab16\\uab20-\\uab26\\uab28-\\uab2e\\uabc0-\\uabe2\\uac00-\\ud7a3\\ud7b0-\\ud7c6\\ud7cb-\\ud7fb\\uf900-\\ufa6d\\ufa70-\\ufad9\\ufb1d\\ufb1f-\\ufb28\\ufb2a-\\ufb36\\ufb38-\\ufb3c\\ufb3e\\ufb40-\\ufb41\\ufb43-\\ufb44\\ufb46-\\ufbb1\\ufbd3-\\ufd3d\\ufd50-\\ufd8f\\ufd92-\\ufdc7\\ufdf0-\\ufdfb\\ufe70-\\ufe74\\ufe76-\\ufefc\\uff66-\\uff6f\\uff71-\\uff9d\\uffa0-\\uffbe\\uffc2-\\uffc7\\uffca-\\uffcf\\uffd2-\\uffd7\\uffda-\\uffdc\\U00010000-\\U0001000b\\U0001000d-\\U00010026\\U00010028-\\U0001003a\\U0001003c-\\U0001003d\\U0001003f-\\U0001004d\\U00010050-\\U0001005d\\U00010080-\\U000100fa\\U00010280-\\U0001029c\\U000102a0-\\U000102d0\\U00010300-\\U0001031f\\U0001032d-\\U00010340\\U00010342-\\U00010349\\U00010350-\\U00010375\\U00010380-\\U0001039d\\U000103a0-\\U000103c3\\U000103c8-\\U000103cf\\U00010450-\\U0001049d\\U00010500-\\U00010527\\U00010530-\\U00010563\\U00010600-\\U00010736\\U00010740-\\U00010755\\U00010760-\\U00010767\\U00010800-\\U00010805\\U00010808\\U0001080a-\\U00010835\\U00010837-\\U00010838\\U0001083c\\U0001083f-\\U00010855\\U00010860-\\U00010876\\U00010880-\\U0001089e\\U000108e0-\\U000108f2\\U000108f4-\\U000108f5\\U00010900-\\U00010915\\U00010920-\\U00010939\\U00010980-\\U000109b7\\U000109be-\\U000109bf\\U00010a00\\U00010a10-\\U00010a13\\U00010a15-\\U00010a17\\U00010a19-\\U00010a35\\U00010a60-\\U00010a7c\\U00010a80-\\U00010a9c\\U00010ac0-\\U00010ac7\\U00010ac9-\\U00010ae4\\U00010b00-\\U00010b35\\U00010b40-\\U00010b55\\U00010b60-\\U00010b72\\U00010b80-\\U00010b91\\U00010c00-\\U00010c48\\U00010d00-\\U00010d23\\U00010f00-\\U00010f1c\\U00010f27\\U00010f30-\\U00010f45\\U00011003-\\U00011037\\U00011083-\\U000110af\\U000110d0-\\U000110e8\\U00011103-\\U00011126\\U00011144\\U00011150-\\U00011172\\U00011176\\U00011183-\\U000111b2\\U000111c1-\\U000111c4\\U000111da\\U000111dc\\U00011200-\\U00011211\\U00011213-\\U0001122b\\U00011280-\\U00011286\\U00011288\\U0001128a-\\U0001128d\\U0001128f-\\U0001129d\\U0001129f-\\U000112a8\\U000112b0-\\U000112de\\U00011305-\\U0001130c\\U0001130f-\\U00011310\\U00011313-\\U00011328\\U0001132a-\\U00011330\\U00011332-\\U00011333\\U00011335-\\U00011339\\U0001133d\\U00011350\\U0001135d-\\U00011361\\U00011400-\\U00011434\\U00011447-\\U0001144a\\U00011480-\\U000114af\\U000114c4-\\U000114c5\\U000114c7\\U00011580-\\U000115ae\\U000115d8-\\U000115db\\U00011600-\\U0001162f\\U00011644\\U00011680-\\U000116aa\\U00011700-\\U0001171a\\U00011800-\\U0001182b\\U000118ff\\U00011a00\\U00011a0b-\\U00011a32\\U00011a3a\\U00011a50\\U00011a5c-\\U00011a83\\U00011a86-\\U00011a89\\U00011a9d\\U00011ac0-\\U00011af8\\U00011c00-\\U00011c08\\U00011c0a-\\U00011c2e\\U00011c40\\U00011c72-\\U00011c8f\\U00011d00-\\U00011d06\\U00011d08-\\U00011d09\\U00011d0b-\\U00011d30\\U00011d46\\U00011d60-\\U00011d65\\U00011d67-\\U00011d68\\U00011d6a-\\U00011d89\\U00011d98\\U00011ee0-\\U00011ef2\\U00012000-\\U00012399\\U00012480-\\U00012543\\U00013000-\\U0001342e\\U00014400-\\U00014646\\U00016800-\\U00016a38\\U00016a40-\\U00016a5e\\U00016ad0-\\U00016aed\\U00016b00-\\U00016b2f\\U00016b63-\\U00016b77\\U00016b7d-\\U00016b8f\\U00016f00-\\U00016f44\\U00016f50\\U00017000-\\U000187f1\\U00018800-\\U00018af2\\U0001b000-\\U0001b11e\\U0001b170-\\U0001b2fb\\U0001bc00-\\U0001bc6a\\U0001bc70-\\U0001bc7c\\U0001bc80-\\U0001bc88\\U0001bc90-\\U0001bc99\\U0001e800-\\U0001e8c4\\U0001ee00-\\U0001ee03\\U0001ee05-\\U0001ee1f\\U0001ee21-\\U0001ee22\\U0001ee24\\U0001ee27\\U0001ee29-\\U0001ee32\\U0001ee34-\\U0001ee37\\U0001ee39\\U0001ee3b\\U0001ee42\\U0001ee47\\U0001ee49\\U0001ee4b\\U0001ee4d-\\U0001ee4f\\U0001ee51-\\U0001ee52\\U0001ee54\\U0001ee57\\U0001ee59\\U0001ee5b\\U0001ee5d\\U0001ee5f\\U0001ee61-\\U0001ee62\\U0001ee64\\U0001ee67-\\U0001ee6a\\U0001ee6c-\\U0001ee72\\U0001ee74-\\U0001ee77\\U0001ee79-\\U0001ee7c\\U0001ee7e\\U0001ee80-\\U0001ee89\\U0001ee8b-\\U0001ee9b\\U0001eea1-\\U0001eea3\\U0001eea5-\\U0001eea9\\U0001eeab-\\U0001eebb\\U00020000-\\U0002a6d6\\U0002a700-\\U0002b734\\U0002b740-\\U0002b81d\\U0002b820-\\U0002cea1\\U0002ceb0-\\U0002ebe0\\U0002f800-\\U0002fa1d'\n\nLt = '\\u01c5\\u01c8\\u01cb\\u01f2\\u1f88-\\u1f8f\\u1f98-\\u1f9f\\u1fa8-\\u1faf\\u1fbc\\u1fcc\\u1ffc'\n\nLu = 'A-Z\\xc0-\\xd6\\xd8-\\xde\\u0100\\u0102\\u0104\\u0106\\u0108\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u037f\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u038f\\u0391-\\u03a1\\u03a3-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0524\\u0526\\u0528\\u052a\\u052c\\u052e\\u0531-\\u0556\\u10a0-\\u10c5\\u10c7\\u10cd\\u13a0-\\u13f5\\u1c90-\\u1cba\\u1cbd-\\u1cbf\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59\\u1f5b\\u1f5d\\u1f5f\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67\\u2c69\\u2c6b\\u2c6d-\\u2c70\\u2c72\\u2c75\\u2c7e-\\u2c80\\u2c82\\u2c84\\u2c86\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\u2ceb\\u2ced\\u2cf2\\ua640\\ua642\\ua644\\ua646\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a\\ua65c\\ua65e\\ua660\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696\\ua698\\ua69a\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\ua78d\\ua790\\ua792\\ua796\\ua798\\ua79a\\ua79c\\ua79e\\ua7a0\\ua7a2\\ua7a4\\ua7a6\\ua7a8\\ua7aa-\\ua7ae\\ua7b0-\\ua7b4\\ua7b6\\ua7b8\\uff21-\\uff3a\\U00010400-\\U00010427\\U000104b0-\\U000104d3\\U00010c80-\\U00010cb2\\U000118a0-\\U000118bf\\U00016e40-\\U00016e5f\\U0001d400-\\U0001d419\\U0001d434-\\U0001d44d\\U0001d468-\\U0001d481\\U0001d49c\\U0001d49e-\\U0001d49f\\U0001d4a2\\U0001d4a5-\\U0001d4a6\\U0001d4a9-\\U0001d4ac\\U0001d4ae-\\U0001d4b5\\U0001d4d0-\\U0001d4e9\\U0001d504-\\U0001d505\\U0001d507-\\U0001d50a\\U0001d50d-\\U0001d514\\U0001d516-\\U0001d51c\\U0001d538-\\U0001d539\\U0001d53b-\\U0001d53e\\U0001d540-\\U0001d544\\U0001d546\\U0001d54a-\\U0001d550\\U0001d56c-\\U0001d585\\U0001d5a0-\\U0001d5b9\\U0001d5d4-\\U0001d5ed\\U0001d608-\\U0001d621\\U0001d63c-\\U0001d655\\U0001d670-\\U0001d689\\U0001d6a8-\\U0001d6c0\\U0001d6e2-\\U0001d6fa\\U0001d71c-\\U0001d734\\U0001d756-\\U0001d76e\\U0001d790-\\U0001d7a8\\U0001d7ca\\U0001e900-\\U0001e921'\n\nMc = '\\u0903\\u093b\\u093e-\\u0940\\u0949-\\u094c\\u094e-\\u094f\\u0982-\\u0983\\u09be-\\u09c0\\u09c7-\\u09c8\\u09cb-\\u09cc\\u09d7\\u0a03\\u0a3e-\\u0a40\\u0a83\\u0abe-\\u0ac0\\u0ac9\\u0acb-\\u0acc\\u0b02-\\u0b03\\u0b3e\\u0b40\\u0b47-\\u0b48\\u0b4b-\\u0b4c\\u0b57\\u0bbe-\\u0bbf\\u0bc1-\\u0bc2\\u0bc6-\\u0bc8\\u0bca-\\u0bcc\\u0bd7\\u0c01-\\u0c03\\u0c41-\\u0c44\\u0c82-\\u0c83\\u0cbe\\u0cc0-\\u0cc4\\u0cc7-\\u0cc8\\u0cca-\\u0ccb\\u0cd5-\\u0cd6\\u0d02-\\u0d03\\u0d3e-\\u0d40\\u0d46-\\u0d48\\u0d4a-\\u0d4c\\u0d57\\u0d82-\\u0d83\\u0dcf-\\u0dd1\\u0dd8-\\u0ddf\\u0df2-\\u0df3\\u0f3e-\\u0f3f\\u0f7f\\u102b-\\u102c\\u1031\\u1038\\u103b-\\u103c\\u1056-\\u1057\\u1062-\\u1064\\u1067-\\u106d\\u1083-\\u1084\\u1087-\\u108c\\u108f\\u109a-\\u109c\\u17b6\\u17be-\\u17c5\\u17c7-\\u17c8\\u1923-\\u1926\\u1929-\\u192b\\u1930-\\u1931\\u1933-\\u1938\\u1a19-\\u1a1a\\u1a55\\u1a57\\u1a61\\u1a63-\\u1a64\\u1a6d-\\u1a72\\u1b04\\u1b35\\u1b3b\\u1b3d-\\u1b41\\u1b43-\\u1b44\\u1b82\\u1ba1\\u1ba6-\\u1ba7\\u1baa\\u1be7\\u1bea-\\u1bec\\u1bee\\u1bf2-\\u1bf3\\u1c24-\\u1c2b\\u1c34-\\u1c35\\u1ce1\\u1cf2-\\u1cf3\\u1cf7\\u302e-\\u302f\\ua823-\\ua824\\ua827\\ua880-\\ua881\\ua8b4-\\ua8c3\\ua952-\\ua953\\ua983\\ua9b4-\\ua9b5\\ua9ba-\\ua9bb\\ua9bd-\\ua9c0\\uaa2f-\\uaa30\\uaa33-\\uaa34\\uaa4d\\uaa7b\\uaa7d\\uaaeb\\uaaee-\\uaaef\\uaaf5\\uabe3-\\uabe4\\uabe6-\\uabe7\\uabe9-\\uabea\\uabec\\U00011000\\U00011002\\U00011082\\U000110b0-\\U000110b2\\U000110b7-\\U000110b8\\U0001112c\\U00011145-\\U00011146\\U00011182\\U000111b3-\\U000111b5\\U000111bf-\\U000111c0\\U0001122c-\\U0001122e\\U00011232-\\U00011233\\U00011235\\U000112e0-\\U000112e2\\U00011302-\\U00011303\\U0001133e-\\U0001133f\\U00011341-\\U00011344\\U00011347-\\U00011348\\U0001134b-\\U0001134d\\U00011357\\U00011362-\\U00011363\\U00011435-\\U00011437\\U00011440-\\U00011441\\U00011445\\U000114b0-\\U000114b2\\U000114b9\\U000114bb-\\U000114be\\U000114c1\\U000115af-\\U000115b1\\U000115b8-\\U000115bb\\U000115be\\U00011630-\\U00011632\\U0001163b-\\U0001163c\\U0001163e\\U000116ac\\U000116ae-\\U000116af\\U000116b6\\U00011720-\\U00011721\\U00011726\\U0001182c-\\U0001182e\\U00011838\\U00011a39\\U00011a57-\\U00011a58\\U00011a97\\U00011c2f\\U00011c3e\\U00011ca9\\U00011cb1\\U00011cb4\\U00011d8a-\\U00011d8e\\U00011d93-\\U00011d94\\U00011d96\\U00011ef5-\\U00011ef6\\U00016f51-\\U00016f7e\\U0001d165-\\U0001d166\\U0001d16d-\\U0001d172'\n\nMe = '\\u0488-\\u0489\\u1abe\\u20dd-\\u20e0\\u20e2-\\u20e4\\ua670-\\ua672'\n\nMn = '\\u0300-\\u036f\\u0483-\\u0487\\u0591-\\u05bd\\u05bf\\u05c1-\\u05c2\\u05c4-\\u05c5\\u05c7\\u0610-\\u061a\\u064b-\\u065f\\u0670\\u06d6-\\u06dc\\u06df-\\u06e4\\u06e7-\\u06e8\\u06ea-\\u06ed\\u0711\\u0730-\\u074a\\u07a6-\\u07b0\\u07eb-\\u07f3\\u07fd\\u0816-\\u0819\\u081b-\\u0823\\u0825-\\u0827\\u0829-\\u082d\\u0859-\\u085b\\u08d3-\\u08e1\\u08e3-\\u0902\\u093a\\u093c\\u0941-\\u0948\\u094d\\u0951-\\u0957\\u0962-\\u0963\\u0981\\u09bc\\u09c1-\\u09c4\\u09cd\\u09e2-\\u09e3\\u09fe\\u0a01-\\u0a02\\u0a3c\\u0a41-\\u0a42\\u0a47-\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a70-\\u0a71\\u0a75\\u0a81-\\u0a82\\u0abc\\u0ac1-\\u0ac5\\u0ac7-\\u0ac8\\u0acd\\u0ae2-\\u0ae3\\u0afa-\\u0aff\\u0b01\\u0b3c\\u0b3f\\u0b41-\\u0b44\\u0b4d\\u0b56\\u0b62-\\u0b63\\u0b82\\u0bc0\\u0bcd\\u0c00\\u0c04\\u0c3e-\\u0c40\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55-\\u0c56\\u0c62-\\u0c63\\u0c81\\u0cbc\\u0cbf\\u0cc6\\u0ccc-\\u0ccd\\u0ce2-\\u0ce3\\u0d00-\\u0d01\\u0d3b-\\u0d3c\\u0d41-\\u0d44\\u0d4d\\u0d62-\\u0d63\\u0dca\\u0dd2-\\u0dd4\\u0dd6\\u0e31\\u0e34-\\u0e3a\\u0e47-\\u0e4e\\u0eb1\\u0eb4-\\u0eb9\\u0ebb-\\u0ebc\\u0ec8-\\u0ecd\\u0f18-\\u0f19\\u0f35\\u0f37\\u0f39\\u0f71-\\u0f7e\\u0f80-\\u0f84\\u0f86-\\u0f87\\u0f8d-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u102d-\\u1030\\u1032-\\u1037\\u1039-\\u103a\\u103d-\\u103e\\u1058-\\u1059\\u105e-\\u1060\\u1071-\\u1074\\u1082\\u1085-\\u1086\\u108d\\u109d\\u135d-\\u135f\\u1712-\\u1714\\u1732-\\u1734\\u1752-\\u1753\\u1772-\\u1773\\u17b4-\\u17b5\\u17b7-\\u17bd\\u17c6\\u17c9-\\u17d3\\u17dd\\u180b-\\u180d\\u1885-\\u1886\\u18a9\\u1920-\\u1922\\u1927-\\u1928\\u1932\\u1939-\\u193b\\u1a17-\\u1a18\\u1a1b\\u1a56\\u1a58-\\u1a5e\\u1a60\\u1a62\\u1a65-\\u1a6c\\u1a73-\\u1a7c\\u1a7f\\u1ab0-\\u1abd\\u1b00-\\u1b03\\u1b34\\u1b36-\\u1b3a\\u1b3c\\u1b42\\u1b6b-\\u1b73\\u1b80-\\u1b81\\u1ba2-\\u1ba5\\u1ba8-\\u1ba9\\u1bab-\\u1bad\\u1be6\\u1be8-\\u1be9\\u1bed\\u1bef-\\u1bf1\\u1c2c-\\u1c33\\u1c36-\\u1c37\\u1cd0-\\u1cd2\\u1cd4-\\u1ce0\\u1ce2-\\u1ce8\\u1ced\\u1cf4\\u1cf8-\\u1cf9\\u1dc0-\\u1df9\\u1dfb-\\u1dff\\u20d0-\\u20dc\\u20e1\\u20e5-\\u20f0\\u2cef-\\u2cf1\\u2d7f\\u2de0-\\u2dff\\u302a-\\u302d\\u3099-\\u309a\\ua66f\\ua674-\\ua67d\\ua69e-\\ua69f\\ua6f0-\\ua6f1\\ua802\\ua806\\ua80b\\ua825-\\ua826\\ua8c4-\\ua8c5\\ua8e0-\\ua8f1\\ua8ff\\ua926-\\ua92d\\ua947-\\ua951\\ua980-\\ua982\\ua9b3\\ua9b6-\\ua9b9\\ua9bc\\ua9e5\\uaa29-\\uaa2e\\uaa31-\\uaa32\\uaa35-\\uaa36\\uaa43\\uaa4c\\uaa7c\\uaab0\\uaab2-\\uaab4\\uaab7-\\uaab8\\uaabe-\\uaabf\\uaac1\\uaaec-\\uaaed\\uaaf6\\uabe5\\uabe8\\uabed\\ufb1e\\ufe00-\\ufe0f\\ufe20-\\ufe2f\\U000101fd\\U000102e0\\U00010376-\\U0001037a\\U00010a01-\\U00010a03\\U00010a05-\\U00010a06\\U00010a0c-\\U00010a0f\\U00010a38-\\U00010a3a\\U00010a3f\\U00010ae5-\\U00010ae6\\U00010d24-\\U00010d27\\U00010f46-\\U00010f50\\U00011001\\U00011038-\\U00011046\\U0001107f-\\U00011081\\U000110b3-\\U000110b6\\U000110b9-\\U000110ba\\U00011100-\\U00011102\\U00011127-\\U0001112b\\U0001112d-\\U00011134\\U00011173\\U00011180-\\U00011181\\U000111b6-\\U000111be\\U000111c9-\\U000111cc\\U0001122f-\\U00011231\\U00011234\\U00011236-\\U00011237\\U0001123e\\U000112df\\U000112e3-\\U000112ea\\U00011300-\\U00011301\\U0001133b-\\U0001133c\\U00011340\\U00011366-\\U0001136c\\U00011370-\\U00011374\\U00011438-\\U0001143f\\U00011442-\\U00011444\\U00011446\\U0001145e\\U000114b3-\\U000114b8\\U000114ba\\U000114bf-\\U000114c0\\U000114c2-\\U000114c3\\U000115b2-\\U000115b5\\U000115bc-\\U000115bd\\U000115bf-\\U000115c0\\U000115dc-\\U000115dd\\U00011633-\\U0001163a\\U0001163d\\U0001163f-\\U00011640\\U000116ab\\U000116ad\\U000116b0-\\U000116b5\\U000116b7\\U0001171d-\\U0001171f\\U00011722-\\U00011725\\U00011727-\\U0001172b\\U0001182f-\\U00011837\\U00011839-\\U0001183a\\U00011a01-\\U00011a0a\\U00011a33-\\U00011a38\\U00011a3b-\\U00011a3e\\U00011a47\\U00011a51-\\U00011a56\\U00011a59-\\U00011a5b\\U00011a8a-\\U00011a96\\U00011a98-\\U00011a99\\U00011c30-\\U00011c36\\U00011c38-\\U00011c3d\\U00011c3f\\U00011c92-\\U00011ca7\\U00011caa-\\U00011cb0\\U00011cb2-\\U00011cb3\\U00011cb5-\\U00011cb6\\U00011d31-\\U00011d36\\U00011d3a\\U00011d3c-\\U00011d3d\\U00011d3f-\\U00011d45\\U00011d47\\U00011d90-\\U00011d91\\U00011d95\\U00011d97\\U00011ef3-\\U00011ef4\\U00016af0-\\U00016af4\\U00016b30-\\U00016b36\\U00016f8f-\\U00016f92\\U0001bc9d-\\U0001bc9e\\U0001d167-\\U0001d169\\U0001d17b-\\U0001d182\\U0001d185-\\U0001d18b\\U0001d1aa-\\U0001d1ad\\U0001d242-\\U0001d244\\U0001da00-\\U0001da36\\U0001da3b-\\U0001da6c\\U0001da75\\U0001da84\\U0001da9b-\\U0001da9f\\U0001daa1-\\U0001daaf\\U0001e000-\\U0001e006\\U0001e008-\\U0001e018\\U0001e01b-\\U0001e021\\U0001e023-\\U0001e024\\U0001e026-\\U0001e02a\\U0001e8d0-\\U0001e8d6\\U0001e944-\\U0001e94a\\U000e0100-\\U000e01ef'\n\nNd = '0-9\\u0660-\\u0669\\u06f0-\\u06f9\\u07c0-\\u07c9\\u0966-\\u096f\\u09e6-\\u09ef\\u0a66-\\u0a6f\\u0ae6-\\u0aef\\u0b66-\\u0b6f\\u0be6-\\u0bef\\u0c66-\\u0c6f\\u0ce6-\\u0cef\\u0d66-\\u0d6f\\u0de6-\\u0def\\u0e50-\\u0e59\\u0ed0-\\u0ed9\\u0f20-\\u0f29\\u1040-\\u1049\\u1090-\\u1099\\u17e0-\\u17e9\\u1810-\\u1819\\u1946-\\u194f\\u19d0-\\u19d9\\u1a80-\\u1a89\\u1a90-\\u1a99\\u1b50-\\u1b59\\u1bb0-\\u1bb9\\u1c40-\\u1c49\\u1c50-\\u1c59\\ua620-\\ua629\\ua8d0-\\ua8d9\\ua900-\\ua909\\ua9d0-\\ua9d9\\ua9f0-\\ua9f9\\uaa50-\\uaa59\\uabf0-\\uabf9\\uff10-\\uff19\\U000104a0-\\U000104a9\\U00010d30-\\U00010d39\\U00011066-\\U0001106f\\U000110f0-\\U000110f9\\U00011136-\\U0001113f\\U000111d0-\\U000111d9\\U000112f0-\\U000112f9\\U00011450-\\U00011459\\U000114d0-\\U000114d9\\U00011650-\\U00011659\\U000116c0-\\U000116c9\\U00011730-\\U00011739\\U000118e0-\\U000118e9\\U00011c50-\\U00011c59\\U00011d50-\\U00011d59\\U00011da0-\\U00011da9\\U00016a60-\\U00016a69\\U00016b50-\\U00016b59\\U0001d7ce-\\U0001d7ff\\U0001e950-\\U0001e959'\n\nNl = '\\u16ee-\\u16f0\\u2160-\\u2182\\u2185-\\u2188\\u3007\\u3021-\\u3029\\u3038-\\u303a\\ua6e6-\\ua6ef\\U00010140-\\U00010174\\U00010341\\U0001034a\\U000103d1-\\U000103d5\\U00012400-\\U0001246e'\n\nNo = '\\xb2-\\xb3\\xb9\\xbc-\\xbe\\u09f4-\\u09f9\\u0b72-\\u0b77\\u0bf0-\\u0bf2\\u0c78-\\u0c7e\\u0d58-\\u0d5e\\u0d70-\\u0d78\\u0f2a-\\u0f33\\u1369-\\u137c\\u17f0-\\u17f9\\u19da\\u2070\\u2074-\\u2079\\u2080-\\u2089\\u2150-\\u215f\\u2189\\u2460-\\u249b\\u24ea-\\u24ff\\u2776-\\u2793\\u2cfd\\u3192-\\u3195\\u3220-\\u3229\\u3248-\\u324f\\u3251-\\u325f\\u3280-\\u3289\\u32b1-\\u32bf\\ua830-\\ua835\\U00010107-\\U00010133\\U00010175-\\U00010178\\U0001018a-\\U0001018b\\U000102e1-\\U000102fb\\U00010320-\\U00010323\\U00010858-\\U0001085f\\U00010879-\\U0001087f\\U000108a7-\\U000108af\\U000108fb-\\U000108ff\\U00010916-\\U0001091b\\U000109bc-\\U000109bd\\U000109c0-\\U000109cf\\U000109d2-\\U000109ff\\U00010a40-\\U00010a48\\U00010a7d-\\U00010a7e\\U00010a9d-\\U00010a9f\\U00010aeb-\\U00010aef\\U00010b58-\\U00010b5f\\U00010b78-\\U00010b7f\\U00010ba9-\\U00010baf\\U00010cfa-\\U00010cff\\U00010e60-\\U00010e7e\\U00010f1d-\\U00010f26\\U00010f51-\\U00010f54\\U00011052-\\U00011065\\U000111e1-\\U000111f4\\U0001173a-\\U0001173b\\U000118ea-\\U000118f2\\U00011c5a-\\U00011c6c\\U00016b5b-\\U00016b61\\U00016e80-\\U00016e96\\U0001d2e0-\\U0001d2f3\\U0001d360-\\U0001d378\\U0001e8c7-\\U0001e8cf\\U0001ec71-\\U0001ecab\\U0001ecad-\\U0001ecaf\\U0001ecb1-\\U0001ecb4\\U0001f100-\\U0001f10c'\n\nPc = '_\\u203f-\\u2040\\u2054\\ufe33-\\ufe34\\ufe4d-\\ufe4f\\uff3f'\n\nPd = '\\\\-\\u058a\\u05be\\u1400\\u1806\\u2010-\\u2015\\u2e17\\u2e1a\\u2e3a-\\u2e3b\\u2e40\\u301c\\u3030\\u30a0\\ufe31-\\ufe32\\ufe58\\ufe63\\uff0d'\n\nPe = ')\\\\]}\\u0f3b\\u0f3d\\u169c\\u2046\\u207e\\u208e\\u2309\\u230b\\u232a\\u2769\\u276b\\u276d\\u276f\\u2771\\u2773\\u2775\\u27c6\\u27e7\\u27e9\\u27eb\\u27ed\\u27ef\\u2984\\u2986\\u2988\\u298a\\u298c\\u298e\\u2990\\u2992\\u2994\\u2996\\u2998\\u29d9\\u29db\\u29fd\\u2e23\\u2e25\\u2e27\\u2e29\\u3009\\u300b\\u300d\\u300f\\u3011\\u3015\\u3017\\u3019\\u301b\\u301e-\\u301f\\ufd3e\\ufe18\\ufe36\\ufe38\\ufe3a\\ufe3c\\ufe3e\\ufe40\\ufe42\\ufe44\\ufe48\\ufe5a\\ufe5c\\ufe5e\\uff09\\uff3d\\uff5d\\uff60\\uff63'\n\nPf = '\\xbb\\u2019\\u201d\\u203a\\u2e03\\u2e05\\u2e0a\\u2e0d\\u2e1d\\u2e21'\n\nPi = '\\xab\\u2018\\u201b-\\u201c\\u201f\\u2039\\u2e02\\u2e04\\u2e09\\u2e0c\\u2e1c\\u2e20'\n\nPo = \"!-#%-'*,.-/:-;?-@\\\\\\\\\\xa1\\xa7\\xb6-\\xb7\\xbf\\u037e\\u0387\\u055a-\\u055f\\u0589\\u05c0\\u05c3\\u05c6\\u05f3-\\u05f4\\u0609-\\u060a\\u060c-\\u060d\\u061b\\u061e-\\u061f\\u066a-\\u066d\\u06d4\\u0700-\\u070d\\u07f7-\\u07f9\\u0830-\\u083e\\u085e\\u0964-\\u0965\\u0970\\u09fd\\u0a76\\u0af0\\u0c84\\u0df4\\u0e4f\\u0e5a-\\u0e5b\\u0f04-\\u0f12\\u0f14\\u0f85\\u0fd0-\\u0fd4\\u0fd9-\\u0fda\\u104a-\\u104f\\u10fb\\u1360-\\u1368\\u166d-\\u166e\\u16eb-\\u16ed\\u1735-\\u1736\\u17d4-\\u17d6\\u17d8-\\u17da\\u1800-\\u1805\\u1807-\\u180a\\u1944-\\u1945\\u1a1e-\\u1a1f\\u1aa0-\\u1aa6\\u1aa8-\\u1aad\\u1b5a-\\u1b60\\u1bfc-\\u1bff\\u1c3b-\\u1c3f\\u1c7e-\\u1c7f\\u1cc0-\\u1cc7\\u1cd3\\u2016-\\u2017\\u2020-\\u2027\\u2030-\\u2038\\u203b-\\u203e\\u2041-\\u2043\\u2047-\\u2051\\u2053\\u2055-\\u205e\\u2cf9-\\u2cfc\\u2cfe-\\u2cff\\u2d70\\u2e00-\\u2e01\\u2e06-\\u2e08\\u2e0b\\u2e0e-\\u2e16\\u2e18-\\u2e19\\u2e1b\\u2e1e-\\u2e1f\\u2e2a-\\u2e2e\\u2e30-\\u2e39\\u2e3c-\\u2e3f\\u2e41\\u2e43-\\u2e4e\\u3001-\\u3003\\u303d\\u30fb\\ua4fe-\\ua4ff\\ua60d-\\ua60f\\ua673\\ua67e\\ua6f2-\\ua6f7\\ua874-\\ua877\\ua8ce-\\ua8cf\\ua8f8-\\ua8fa\\ua8fc\\ua92e-\\ua92f\\ua95f\\ua9c1-\\ua9cd\\ua9de-\\ua9df\\uaa5c-\\uaa5f\\uaade-\\uaadf\\uaaf0-\\uaaf1\\uabeb\\ufe10-\\ufe16\\ufe19\\ufe30\\ufe45-\\ufe46\\ufe49-\\ufe4c\\ufe50-\\ufe52\\ufe54-\\ufe57\\ufe5f-\\ufe61\\ufe68\\ufe6a-\\ufe6b\\uff01-\\uff03\\uff05-\\uff07\\uff0a\\uff0c\\uff0e-\\uff0f\\uff1a-\\uff1b\\uff1f-\\uff20\\uff3c\\uff61\\uff64-\\uff65\\U00010100-\\U00010102\\U0001039f\\U000103d0\\U0001056f\\U00010857\\U0001091f\\U0001093f\\U00010a50-\\U00010a58\\U00010a7f\\U00010af0-\\U00010af6\\U00010b39-\\U00010b3f\\U00010b99-\\U00010b9c\\U00010f55-\\U00010f59\\U00011047-\\U0001104d\\U000110bb-\\U000110bc\\U000110be-\\U000110c1\\U00011140-\\U00011143\\U00011174-\\U00011175\\U000111c5-\\U000111c8\\U000111cd\\U000111db\\U000111dd-\\U000111df\\U00011238-\\U0001123d\\U000112a9\\U0001144b-\\U0001144f\\U0001145b\\U0001145d\\U000114c6\\U000115c1-\\U000115d7\\U00011641-\\U00011643\\U00011660-\\U0001166c\\U0001173c-\\U0001173e\\U0001183b\\U00011a3f-\\U00011a46\\U00011a9a-\\U00011a9c\\U00011a9e-\\U00011aa2\\U00011c41-\\U00011c45\\U00011c70-\\U00011c71\\U00011ef7-\\U00011ef8\\U00012470-\\U00012474\\U00016a6e-\\U00016a6f\\U00016af5\\U00016b37-\\U00016b3b\\U00016b44\\U00016e97-\\U00016e9a\\U0001bc9f\\U0001da87-\\U0001da8b\\U0001e95e-\\U0001e95f\"\n\nPs = '(\\\\[{\\u0f3a\\u0f3c\\u169b\\u201a\\u201e\\u2045\\u207d\\u208d\\u2308\\u230a\\u2329\\u2768\\u276a\\u276c\\u276e\\u2770\\u2772\\u2774\\u27c5\\u27e6\\u27e8\\u27ea\\u27ec\\u27ee\\u2983\\u2985\\u2987\\u2989\\u298b\\u298d\\u298f\\u2991\\u2993\\u2995\\u2997\\u29d8\\u29da\\u29fc\\u2e22\\u2e24\\u2e26\\u2e28\\u2e42\\u3008\\u300a\\u300c\\u300e\\u3010\\u3014\\u3016\\u3018\\u301a\\u301d\\ufd3f\\ufe17\\ufe35\\ufe37\\ufe39\\ufe3b\\ufe3d\\ufe3f\\ufe41\\ufe43\\ufe47\\ufe59\\ufe5b\\ufe5d\\uff08\\uff3b\\uff5b\\uff5f\\uff62'\n\nSc = '$\\xa2-\\xa5\\u058f\\u060b\\u07fe-\\u07ff\\u09f2-\\u09f3\\u09fb\\u0af1\\u0bf9\\u0e3f\\u17db\\u20a0-\\u20bf\\ua838\\ufdfc\\ufe69\\uff04\\uffe0-\\uffe1\\uffe5-\\uffe6\\U0001ecb0'\n\nSk = '\\\\^`\\xa8\\xaf\\xb4\\xb8\\u02c2-\\u02c5\\u02d2-\\u02df\\u02e5-\\u02eb\\u02ed\\u02ef-\\u02ff\\u0375\\u0384-\\u0385\\u1fbd\\u1fbf-\\u1fc1\\u1fcd-\\u1fcf\\u1fdd-\\u1fdf\\u1fed-\\u1fef\\u1ffd-\\u1ffe\\u309b-\\u309c\\ua700-\\ua716\\ua720-\\ua721\\ua789-\\ua78a\\uab5b\\ufbb2-\\ufbc1\\uff3e\\uff40\\uffe3\\U0001f3fb-\\U0001f3ff'\n\nSm = '+<->|~\\xac\\xb1\\xd7\\xf7\\u03f6\\u0606-\\u0608\\u2044\\u2052\\u207a-\\u207c\\u208a-\\u208c\\u2118\\u2140-\\u2144\\u214b\\u2190-\\u2194\\u219a-\\u219b\\u21a0\\u21a3\\u21a6\\u21ae\\u21ce-\\u21cf\\u21d2\\u21d4\\u21f4-\\u22ff\\u2320-\\u2321\\u237c\\u239b-\\u23b3\\u23dc-\\u23e1\\u25b7\\u25c1\\u25f8-\\u25ff\\u266f\\u27c0-\\u27c4\\u27c7-\\u27e5\\u27f0-\\u27ff\\u2900-\\u2982\\u2999-\\u29d7\\u29dc-\\u29fb\\u29fe-\\u2aff\\u2b30-\\u2b44\\u2b47-\\u2b4c\\ufb29\\ufe62\\ufe64-\\ufe66\\uff0b\\uff1c-\\uff1e\\uff5c\\uff5e\\uffe2\\uffe9-\\uffec\\U0001d6c1\\U0001d6db\\U0001d6fb\\U0001d715\\U0001d735\\U0001d74f\\U0001d76f\\U0001d789\\U0001d7a9\\U0001d7c3\\U0001eef0-\\U0001eef1'\n\nSo = '\\xa6\\xa9\\xae\\xb0\\u0482\\u058d-\\u058e\\u060e-\\u060f\\u06de\\u06e9\\u06fd-\\u06fe\\u07f6\\u09fa\\u0b70\\u0bf3-\\u0bf8\\u0bfa\\u0c7f\\u0d4f\\u0d79\\u0f01-\\u0f03\\u0f13\\u0f15-\\u0f17\\u0f1a-\\u0f1f\\u0f34\\u0f36\\u0f38\\u0fbe-\\u0fc5\\u0fc7-\\u0fcc\\u0fce-\\u0fcf\\u0fd5-\\u0fd8\\u109e-\\u109f\\u1390-\\u1399\\u1940\\u19de-\\u19ff\\u1b61-\\u1b6a\\u1b74-\\u1b7c\\u2100-\\u2101\\u2103-\\u2106\\u2108-\\u2109\\u2114\\u2116-\\u2117\\u211e-\\u2123\\u2125\\u2127\\u2129\\u212e\\u213a-\\u213b\\u214a\\u214c-\\u214d\\u214f\\u218a-\\u218b\\u2195-\\u2199\\u219c-\\u219f\\u21a1-\\u21a2\\u21a4-\\u21a5\\u21a7-\\u21ad\\u21af-\\u21cd\\u21d0-\\u21d1\\u21d3\\u21d5-\\u21f3\\u2300-\\u2307\\u230c-\\u231f\\u2322-\\u2328\\u232b-\\u237b\\u237d-\\u239a\\u23b4-\\u23db\\u23e2-\\u2426\\u2440-\\u244a\\u249c-\\u24e9\\u2500-\\u25b6\\u25b8-\\u25c0\\u25c2-\\u25f7\\u2600-\\u266e\\u2670-\\u2767\\u2794-\\u27bf\\u2800-\\u28ff\\u2b00-\\u2b2f\\u2b45-\\u2b46\\u2b4d-\\u2b73\\u2b76-\\u2b95\\u2b98-\\u2bc8\\u2bca-\\u2bfe\\u2ce5-\\u2cea\\u2e80-\\u2e99\\u2e9b-\\u2ef3\\u2f00-\\u2fd5\\u2ff0-\\u2ffb\\u3004\\u3012-\\u3013\\u3020\\u3036-\\u3037\\u303e-\\u303f\\u3190-\\u3191\\u3196-\\u319f\\u31c0-\\u31e3\\u3200-\\u321e\\u322a-\\u3247\\u3250\\u3260-\\u327f\\u328a-\\u32b0\\u32c0-\\u32fe\\u3300-\\u33ff\\u4dc0-\\u4dff\\ua490-\\ua4c6\\ua828-\\ua82b\\ua836-\\ua837\\ua839\\uaa77-\\uaa79\\ufdfd\\uffe4\\uffe8\\uffed-\\uffee\\ufffc-\\ufffd\\U00010137-\\U0001013f\\U00010179-\\U00010189\\U0001018c-\\U0001018e\\U00010190-\\U0001019b\\U000101a0\\U000101d0-\\U000101fc\\U00010877-\\U00010878\\U00010ac8\\U0001173f\\U00016b3c-\\U00016b3f\\U00016b45\\U0001bc9c\\U0001d000-\\U0001d0f5\\U0001d100-\\U0001d126\\U0001d129-\\U0001d164\\U0001d16a-\\U0001d16c\\U0001d183-\\U0001d184\\U0001d18c-\\U0001d1a9\\U0001d1ae-\\U0001d1e8\\U0001d200-\\U0001d241\\U0001d245\\U0001d300-\\U0001d356\\U0001d800-\\U0001d9ff\\U0001da37-\\U0001da3a\\U0001da6d-\\U0001da74\\U0001da76-\\U0001da83\\U0001da85-\\U0001da86\\U0001ecac\\U0001f000-\\U0001f02b\\U0001f030-\\U0001f093\\U0001f0a0-\\U0001f0ae\\U0001f0b1-\\U0001f0bf\\U0001f0c1-\\U0001f0cf\\U0001f0d1-\\U0001f0f5\\U0001f110-\\U0001f16b\\U0001f170-\\U0001f1ac\\U0001f1e6-\\U0001f202\\U0001f210-\\U0001f23b\\U0001f240-\\U0001f248\\U0001f250-\\U0001f251\\U0001f260-\\U0001f265\\U0001f300-\\U0001f3fa\\U0001f400-\\U0001f6d4\\U0001f6e0-\\U0001f6ec\\U0001f6f0-\\U0001f6f9\\U0001f700-\\U0001f773\\U0001f780-\\U0001f7d8\\U0001f800-\\U0001f80b\\U0001f810-\\U0001f847\\U0001f850-\\U0001f859\\U0001f860-\\U0001f887\\U0001f890-\\U0001f8ad\\U0001f900-\\U0001f90b\\U0001f910-\\U0001f93e\\U0001f940-\\U0001f970\\U0001f973-\\U0001f976\\U0001f97a\\U0001f97c-\\U0001f9a2\\U0001f9b0-\\U0001f9b9\\U0001f9c0-\\U0001f9c2\\U0001f9d0-\\U0001f9ff\\U0001fa60-\\U0001fa6d'\n\nZl = '\\u2028'\n\nZp = '\\u2029'\n\nZs = ' \\xa0\\u1680\\u2000-\\u200a\\u202f\\u205f\\u3000'\n\nxid_continue = '0-9A-Z_a-z\\xaa\\xb5\\xb7\\xba\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0300-\\u0374\\u0376-\\u0377\\u037b-\\u037d\\u037f\\u0386-\\u038a\\u038c\\u038e-\\u03a1\\u03a3-\\u03f5\\u03f7-\\u0481\\u0483-\\u0487\\u048a-\\u052f\\u0531-\\u0556\\u0559\\u0560-\\u0588\\u0591-\\u05bd\\u05bf\\u05c1-\\u05c2\\u05c4-\\u05c5\\u05c7\\u05d0-\\u05ea\\u05ef-\\u05f2\\u0610-\\u061a\\u0620-\\u0669\\u066e-\\u06d3\\u06d5-\\u06dc\\u06df-\\u06e8\\u06ea-\\u06fc\\u06ff\\u0710-\\u074a\\u074d-\\u07b1\\u07c0-\\u07f5\\u07fa\\u07fd\\u0800-\\u082d\\u0840-\\u085b\\u0860-\\u086a\\u08a0-\\u08b4\\u08b6-\\u08bd\\u08d3-\\u08e1\\u08e3-\\u0963\\u0966-\\u096f\\u0971-\\u0983\\u0985-\\u098c\\u098f-\\u0990\\u0993-\\u09a8\\u09aa-\\u09b0\\u09b2\\u09b6-\\u09b9\\u09bc-\\u09c4\\u09c7-\\u09c8\\u09cb-\\u09ce\\u09d7\\u09dc-\\u09dd\\u09df-\\u09e3\\u09e6-\\u09f1\\u09fc\\u09fe\\u0a01-\\u0a03\\u0a05-\\u0a0a\\u0a0f-\\u0a10\\u0a13-\\u0a28\\u0a2a-\\u0a30\\u0a32-\\u0a33\\u0a35-\\u0a36\\u0a38-\\u0a39\\u0a3c\\u0a3e-\\u0a42\\u0a47-\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a59-\\u0a5c\\u0a5e\\u0a66-\\u0a75\\u0a81-\\u0a83\\u0a85-\\u0a8d\\u0a8f-\\u0a91\\u0a93-\\u0aa8\\u0aaa-\\u0ab0\\u0ab2-\\u0ab3\\u0ab5-\\u0ab9\\u0abc-\\u0ac5\\u0ac7-\\u0ac9\\u0acb-\\u0acd\\u0ad0\\u0ae0-\\u0ae3\\u0ae6-\\u0aef\\u0af9-\\u0aff\\u0b01-\\u0b03\\u0b05-\\u0b0c\\u0b0f-\\u0b10\\u0b13-\\u0b28\\u0b2a-\\u0b30\\u0b32-\\u0b33\\u0b35-\\u0b39\\u0b3c-\\u0b44\\u0b47-\\u0b48\\u0b4b-\\u0b4d\\u0b56-\\u0b57\\u0b5c-\\u0b5d\\u0b5f-\\u0b63\\u0b66-\\u0b6f\\u0b71\\u0b82-\\u0b83\\u0b85-\\u0b8a\\u0b8e-\\u0b90\\u0b92-\\u0b95\\u0b99-\\u0b9a\\u0b9c\\u0b9e-\\u0b9f\\u0ba3-\\u0ba4\\u0ba8-\\u0baa\\u0bae-\\u0bb9\\u0bbe-\\u0bc2\\u0bc6-\\u0bc8\\u0bca-\\u0bcd\\u0bd0\\u0bd7\\u0be6-\\u0bef\\u0c00-\\u0c0c\\u0c0e-\\u0c10\\u0c12-\\u0c28\\u0c2a-\\u0c39\\u0c3d-\\u0c44\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55-\\u0c56\\u0c58-\\u0c5a\\u0c60-\\u0c63\\u0c66-\\u0c6f\\u0c80-\\u0c83\\u0c85-\\u0c8c\\u0c8e-\\u0c90\\u0c92-\\u0ca8\\u0caa-\\u0cb3\\u0cb5-\\u0cb9\\u0cbc-\\u0cc4\\u0cc6-\\u0cc8\\u0cca-\\u0ccd\\u0cd5-\\u0cd6\\u0cde\\u0ce0-\\u0ce3\\u0ce6-\\u0cef\\u0cf1-\\u0cf2\\u0d00-\\u0d03\\u0d05-\\u0d0c\\u0d0e-\\u0d10\\u0d12-\\u0d44\\u0d46-\\u0d48\\u0d4a-\\u0d4e\\u0d54-\\u0d57\\u0d5f-\\u0d63\\u0d66-\\u0d6f\\u0d7a-\\u0d7f\\u0d82-\\u0d83\\u0d85-\\u0d96\\u0d9a-\\u0db1\\u0db3-\\u0dbb\\u0dbd\\u0dc0-\\u0dc6\\u0dca\\u0dcf-\\u0dd4\\u0dd6\\u0dd8-\\u0ddf\\u0de6-\\u0def\\u0df2-\\u0df3\\u0e01-\\u0e3a\\u0e40-\\u0e4e\\u0e50-\\u0e59\\u0e81-\\u0e82\\u0e84\\u0e87-\\u0e88\\u0e8a\\u0e8d\\u0e94-\\u0e97\\u0e99-\\u0e9f\\u0ea1-\\u0ea3\\u0ea5\\u0ea7\\u0eaa-\\u0eab\\u0ead-\\u0eb9\\u0ebb-\\u0ebd\\u0ec0-\\u0ec4\\u0ec6\\u0ec8-\\u0ecd\\u0ed0-\\u0ed9\\u0edc-\\u0edf\\u0f00\\u0f18-\\u0f19\\u0f20-\\u0f29\\u0f35\\u0f37\\u0f39\\u0f3e-\\u0f47\\u0f49-\\u0f6c\\u0f71-\\u0f84\\u0f86-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u1000-\\u1049\\u1050-\\u109d\\u10a0-\\u10c5\\u10c7\\u10cd\\u10d0-\\u10fa\\u10fc-\\u1248\\u124a-\\u124d\\u1250-\\u1256\\u1258\\u125a-\\u125d\\u1260-\\u1288\\u128a-\\u128d\\u1290-\\u12b0\\u12b2-\\u12b5\\u12b8-\\u12be\\u12c0\\u12c2-\\u12c5\\u12c8-\\u12d6\\u12d8-\\u1310\\u1312-\\u1315\\u1318-\\u135a\\u135d-\\u135f\\u1369-\\u1371\\u1380-\\u138f\\u13a0-\\u13f5\\u13f8-\\u13fd\\u1401-\\u166c\\u166f-\\u167f\\u1681-\\u169a\\u16a0-\\u16ea\\u16ee-\\u16f8\\u1700-\\u170c\\u170e-\\u1714\\u1720-\\u1734\\u1740-\\u1753\\u1760-\\u176c\\u176e-\\u1770\\u1772-\\u1773\\u1780-\\u17d3\\u17d7\\u17dc-\\u17dd\\u17e0-\\u17e9\\u180b-\\u180d\\u1810-\\u1819\\u1820-\\u1878\\u1880-\\u18aa\\u18b0-\\u18f5\\u1900-\\u191e\\u1920-\\u192b\\u1930-\\u193b\\u1946-\\u196d\\u1970-\\u1974\\u1980-\\u19ab\\u19b0-\\u19c9\\u19d0-\\u19da\\u1a00-\\u1a1b\\u1a20-\\u1a5e\\u1a60-\\u1a7c\\u1a7f-\\u1a89\\u1a90-\\u1a99\\u1aa7\\u1ab0-\\u1abd\\u1b00-\\u1b4b\\u1b50-\\u1b59\\u1b6b-\\u1b73\\u1b80-\\u1bf3\\u1c00-\\u1c37\\u1c40-\\u1c49\\u1c4d-\\u1c7d\\u1c80-\\u1c88\\u1c90-\\u1cba\\u1cbd-\\u1cbf\\u1cd0-\\u1cd2\\u1cd4-\\u1cf9\\u1d00-\\u1df9\\u1dfb-\\u1f15\\u1f18-\\u1f1d\\u1f20-\\u1f45\\u1f48-\\u1f4d\\u1f50-\\u1f57\\u1f59\\u1f5b\\u1f5d\\u1f5f-\\u1f7d\\u1f80-\\u1fb4\\u1fb6-\\u1fbc\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fcc\\u1fd0-\\u1fd3\\u1fd6-\\u1fdb\\u1fe0-\\u1fec\\u1ff2-\\u1ff4\\u1ff6-\\u1ffc\\u203f-\\u2040\\u2054\\u2071\\u207f\\u2090-\\u209c\\u20d0-\\u20dc\\u20e1\\u20e5-\\u20f0\\u2102\\u2107\\u210a-\\u2113\\u2115\\u2118-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u2139\\u213c-\\u213f\\u2145-\\u2149\\u214e\\u2160-\\u2188\\u2c00-\\u2c2e\\u2c30-\\u2c5e\\u2c60-\\u2ce4\\u2ceb-\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\u2d30-\\u2d67\\u2d6f\\u2d7f-\\u2d96\\u2da0-\\u2da6\\u2da8-\\u2dae\\u2db0-\\u2db6\\u2db8-\\u2dbe\\u2dc0-\\u2dc6\\u2dc8-\\u2dce\\u2dd0-\\u2dd6\\u2dd8-\\u2dde\\u2de0-\\u2dff\\u3005-\\u3007\\u3021-\\u302f\\u3031-\\u3035\\u3038-\\u303c\\u3041-\\u3096\\u3099-\\u309a\\u309d-\\u309f\\u30a1-\\u30fa\\u30fc-\\u30ff\\u3105-\\u312f\\u3131-\\u318e\\u31a0-\\u31ba\\u31f0-\\u31ff\\u3400-\\u4db5\\u4e00-\\u9fef\\ua000-\\ua48c\\ua4d0-\\ua4fd\\ua500-\\ua60c\\ua610-\\ua62b\\ua640-\\ua66f\\ua674-\\ua67d\\ua67f-\\ua6f1\\ua717-\\ua71f\\ua722-\\ua788\\ua78b-\\ua7b9\\ua7f7-\\ua827\\ua840-\\ua873\\ua880-\\ua8c5\\ua8d0-\\ua8d9\\ua8e0-\\ua8f7\\ua8fb\\ua8fd-\\ua92d\\ua930-\\ua953\\ua960-\\ua97c\\ua980-\\ua9c0\\ua9cf-\\ua9d9\\ua9e0-\\ua9fe\\uaa00-\\uaa36\\uaa40-\\uaa4d\\uaa50-\\uaa59\\uaa60-\\uaa76\\uaa7a-\\uaac2\\uaadb-\\uaadd\\uaae0-\\uaaef\\uaaf2-\\uaaf6\\uab01-\\uab06\\uab09-\\uab0e\\uab11-\\uab16\\uab20-\\uab26\\uab28-\\uab2e\\uab30-\\uab5a\\uab5c-\\uab65\\uab70-\\uabea\\uabec-\\uabed\\uabf0-\\uabf9\\uac00-\\ud7a3\\ud7b0-\\ud7c6\\ud7cb-\\ud7fb\\uf900-\\ufa6d\\ufa70-\\ufad9\\ufb00-\\ufb06\\ufb13-\\ufb17\\ufb1d-\\ufb28\\ufb2a-\\ufb36\\ufb38-\\ufb3c\\ufb3e\\ufb40-\\ufb41\\ufb43-\\ufb44\\ufb46-\\ufbb1\\ufbd3-\\ufc5d\\ufc64-\\ufd3d\\ufd50-\\ufd8f\\ufd92-\\ufdc7\\ufdf0-\\ufdf9\\ufe00-\\ufe0f\\ufe20-\\ufe2f\\ufe33-\\ufe34\\ufe4d-\\ufe4f\\ufe71\\ufe73\\ufe77\\ufe79\\ufe7b\\ufe7d\\ufe7f-\\ufefc\\uff10-\\uff19\\uff21-\\uff3a\\uff3f\\uff41-\\uff5a\\uff66-\\uffbe\\uffc2-\\uffc7\\uffca-\\uffcf\\uffd2-\\uffd7\\uffda-\\uffdc\\U00010000-\\U0001000b\\U0001000d-\\U00010026\\U00010028-\\U0001003a\\U0001003c-\\U0001003d\\U0001003f-\\U0001004d\\U00010050-\\U0001005d\\U00010080-\\U000100fa\\U00010140-\\U00010174\\U000101fd\\U00010280-\\U0001029c\\U000102a0-\\U000102d0\\U000102e0\\U00010300-\\U0001031f\\U0001032d-\\U0001034a\\U00010350-\\U0001037a\\U00010380-\\U0001039d\\U000103a0-\\U000103c3\\U000103c8-\\U000103cf\\U000103d1-\\U000103d5\\U00010400-\\U0001049d\\U000104a0-\\U000104a9\\U000104b0-\\U000104d3\\U000104d8-\\U000104fb\\U00010500-\\U00010527\\U00010530-\\U00010563\\U00010600-\\U00010736\\U00010740-\\U00010755\\U00010760-\\U00010767\\U00010800-\\U00010805\\U00010808\\U0001080a-\\U00010835\\U00010837-\\U00010838\\U0001083c\\U0001083f-\\U00010855\\U00010860-\\U00010876\\U00010880-\\U0001089e\\U000108e0-\\U000108f2\\U000108f4-\\U000108f5\\U00010900-\\U00010915\\U00010920-\\U00010939\\U00010980-\\U000109b7\\U000109be-\\U000109bf\\U00010a00-\\U00010a03\\U00010a05-\\U00010a06\\U00010a0c-\\U00010a13\\U00010a15-\\U00010a17\\U00010a19-\\U00010a35\\U00010a38-\\U00010a3a\\U00010a3f\\U00010a60-\\U00010a7c\\U00010a80-\\U00010a9c\\U00010ac0-\\U00010ac7\\U00010ac9-\\U00010ae6\\U00010b00-\\U00010b35\\U00010b40-\\U00010b55\\U00010b60-\\U00010b72\\U00010b80-\\U00010b91\\U00010c00-\\U00010c48\\U00010c80-\\U00010cb2\\U00010cc0-\\U00010cf2\\U00010d00-\\U00010d27\\U00010d30-\\U00010d39\\U00010f00-\\U00010f1c\\U00010f27\\U00010f30-\\U00010f50\\U00011000-\\U00011046\\U00011066-\\U0001106f\\U0001107f-\\U000110ba\\U000110d0-\\U000110e8\\U000110f0-\\U000110f9\\U00011100-\\U00011134\\U00011136-\\U0001113f\\U00011144-\\U00011146\\U00011150-\\U00011173\\U00011176\\U00011180-\\U000111c4\\U000111c9-\\U000111cc\\U000111d0-\\U000111da\\U000111dc\\U00011200-\\U00011211\\U00011213-\\U00011237\\U0001123e\\U00011280-\\U00011286\\U00011288\\U0001128a-\\U0001128d\\U0001128f-\\U0001129d\\U0001129f-\\U000112a8\\U000112b0-\\U000112ea\\U000112f0-\\U000112f9\\U00011300-\\U00011303\\U00011305-\\U0001130c\\U0001130f-\\U00011310\\U00011313-\\U00011328\\U0001132a-\\U00011330\\U00011332-\\U00011333\\U00011335-\\U00011339\\U0001133b-\\U00011344\\U00011347-\\U00011348\\U0001134b-\\U0001134d\\U00011350\\U00011357\\U0001135d-\\U00011363\\U00011366-\\U0001136c\\U00011370-\\U00011374\\U00011400-\\U0001144a\\U00011450-\\U00011459\\U0001145e\\U00011480-\\U000114c5\\U000114c7\\U000114d0-\\U000114d9\\U00011580-\\U000115b5\\U000115b8-\\U000115c0\\U000115d8-\\U000115dd\\U00011600-\\U00011640\\U00011644\\U00011650-\\U00011659\\U00011680-\\U000116b7\\U000116c0-\\U000116c9\\U00011700-\\U0001171a\\U0001171d-\\U0001172b\\U00011730-\\U00011739\\U00011800-\\U0001183a\\U000118a0-\\U000118e9\\U000118ff\\U00011a00-\\U00011a3e\\U00011a47\\U00011a50-\\U00011a83\\U00011a86-\\U00011a99\\U00011a9d\\U00011ac0-\\U00011af8\\U00011c00-\\U00011c08\\U00011c0a-\\U00011c36\\U00011c38-\\U00011c40\\U00011c50-\\U00011c59\\U00011c72-\\U00011c8f\\U00011c92-\\U00011ca7\\U00011ca9-\\U00011cb6\\U00011d00-\\U00011d06\\U00011d08-\\U00011d09\\U00011d0b-\\U00011d36\\U00011d3a\\U00011d3c-\\U00011d3d\\U00011d3f-\\U00011d47\\U00011d50-\\U00011d59\\U00011d60-\\U00011d65\\U00011d67-\\U00011d68\\U00011d6a-\\U00011d8e\\U00011d90-\\U00011d91\\U00011d93-\\U00011d98\\U00011da0-\\U00011da9\\U00011ee0-\\U00011ef6\\U00012000-\\U00012399\\U00012400-\\U0001246e\\U00012480-\\U00012543\\U00013000-\\U0001342e\\U00014400-\\U00014646\\U00016800-\\U00016a38\\U00016a40-\\U00016a5e\\U00016a60-\\U00016a69\\U00016ad0-\\U00016aed\\U00016af0-\\U00016af4\\U00016b00-\\U00016b36\\U00016b40-\\U00016b43\\U00016b50-\\U00016b59\\U00016b63-\\U00016b77\\U00016b7d-\\U00016b8f\\U00016e40-\\U00016e7f\\U00016f00-\\U00016f44\\U00016f50-\\U00016f7e\\U00016f8f-\\U00016f9f\\U00016fe0-\\U00016fe1\\U00017000-\\U000187f1\\U00018800-\\U00018af2\\U0001b000-\\U0001b11e\\U0001b170-\\U0001b2fb\\U0001bc00-\\U0001bc6a\\U0001bc70-\\U0001bc7c\\U0001bc80-\\U0001bc88\\U0001bc90-\\U0001bc99\\U0001bc9d-\\U0001bc9e\\U0001d165-\\U0001d169\\U0001d16d-\\U0001d172\\U0001d17b-\\U0001d182\\U0001d185-\\U0001d18b\\U0001d1aa-\\U0001d1ad\\U0001d242-\\U0001d244\\U0001d400-\\U0001d454\\U0001d456-\\U0001d49c\\U0001d49e-\\U0001d49f\\U0001d4a2\\U0001d4a5-\\U0001d4a6\\U0001d4a9-\\U0001d4ac\\U0001d4ae-\\U0001d4b9\\U0001d4bb\\U0001d4bd-\\U0001d4c3\\U0001d4c5-\\U0001d505\\U0001d507-\\U0001d50a\\U0001d50d-\\U0001d514\\U0001d516-\\U0001d51c\\U0001d51e-\\U0001d539\\U0001d53b-\\U0001d53e\\U0001d540-\\U0001d544\\U0001d546\\U0001d54a-\\U0001d550\\U0001d552-\\U0001d6a5\\U0001d6a8-\\U0001d6c0\\U0001d6c2-\\U0001d6da\\U0001d6dc-\\U0001d6fa\\U0001d6fc-\\U0001d714\\U0001d716-\\U0001d734\\U0001d736-\\U0001d74e\\U0001d750-\\U0001d76e\\U0001d770-\\U0001d788\\U0001d78a-\\U0001d7a8\\U0001d7aa-\\U0001d7c2\\U0001d7c4-\\U0001d7cb\\U0001d7ce-\\U0001d7ff\\U0001da00-\\U0001da36\\U0001da3b-\\U0001da6c\\U0001da75\\U0001da84\\U0001da9b-\\U0001da9f\\U0001daa1-\\U0001daaf\\U0001e000-\\U0001e006\\U0001e008-\\U0001e018\\U0001e01b-\\U0001e021\\U0001e023-\\U0001e024\\U0001e026-\\U0001e02a\\U0001e800-\\U0001e8c4\\U0001e8d0-\\U0001e8d6\\U0001e900-\\U0001e94a\\U0001e950-\\U0001e959\\U0001ee00-\\U0001ee03\\U0001ee05-\\U0001ee1f\\U0001ee21-\\U0001ee22\\U0001ee24\\U0001ee27\\U0001ee29-\\U0001ee32\\U0001ee34-\\U0001ee37\\U0001ee39\\U0001ee3b\\U0001ee42\\U0001ee47\\U0001ee49\\U0001ee4b\\U0001ee4d-\\U0001ee4f\\U0001ee51-\\U0001ee52\\U0001ee54\\U0001ee57\\U0001ee59\\U0001ee5b\\U0001ee5d\\U0001ee5f\\U0001ee61-\\U0001ee62\\U0001ee64\\U0001ee67-\\U0001ee6a\\U0001ee6c-\\U0001ee72\\U0001ee74-\\U0001ee77\\U0001ee79-\\U0001ee7c\\U0001ee7e\\U0001ee80-\\U0001ee89\\U0001ee8b-\\U0001ee9b\\U0001eea1-\\U0001eea3\\U0001eea5-\\U0001eea9\\U0001eeab-\\U0001eebb\\U00020000-\\U0002a6d6\\U0002a700-\\U0002b734\\U0002b740-\\U0002b81d\\U0002b820-\\U0002cea1\\U0002ceb0-\\U0002ebe0\\U0002f800-\\U0002fa1d\\U000e0100-\\U000e01ef'\n\nxid_start = 'A-Z_a-z\\xaa\\xb5\\xba\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0370-\\u0374\\u0376-\\u0377\\u037b-\\u037d\\u037f\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u03a1\\u03a3-\\u03f5\\u03f7-\\u0481\\u048a-\\u052f\\u0531-\\u0556\\u0559\\u0560-\\u0588\\u05d0-\\u05ea\\u05ef-\\u05f2\\u0620-\\u064a\\u066e-\\u066f\\u0671-\\u06d3\\u06d5\\u06e5-\\u06e6\\u06ee-\\u06ef\\u06fa-\\u06fc\\u06ff\\u0710\\u0712-\\u072f\\u074d-\\u07a5\\u07b1\\u07ca-\\u07ea\\u07f4-\\u07f5\\u07fa\\u0800-\\u0815\\u081a\\u0824\\u0828\\u0840-\\u0858\\u0860-\\u086a\\u08a0-\\u08b4\\u08b6-\\u08bd\\u0904-\\u0939\\u093d\\u0950\\u0958-\\u0961\\u0971-\\u0980\\u0985-\\u098c\\u098f-\\u0990\\u0993-\\u09a8\\u09aa-\\u09b0\\u09b2\\u09b6-\\u09b9\\u09bd\\u09ce\\u09dc-\\u09dd\\u09df-\\u09e1\\u09f0-\\u09f1\\u09fc\\u0a05-\\u0a0a\\u0a0f-\\u0a10\\u0a13-\\u0a28\\u0a2a-\\u0a30\\u0a32-\\u0a33\\u0a35-\\u0a36\\u0a38-\\u0a39\\u0a59-\\u0a5c\\u0a5e\\u0a72-\\u0a74\\u0a85-\\u0a8d\\u0a8f-\\u0a91\\u0a93-\\u0aa8\\u0aaa-\\u0ab0\\u0ab2-\\u0ab3\\u0ab5-\\u0ab9\\u0abd\\u0ad0\\u0ae0-\\u0ae1\\u0af9\\u0b05-\\u0b0c\\u0b0f-\\u0b10\\u0b13-\\u0b28\\u0b2a-\\u0b30\\u0b32-\\u0b33\\u0b35-\\u0b39\\u0b3d\\u0b5c-\\u0b5d\\u0b5f-\\u0b61\\u0b71\\u0b83\\u0b85-\\u0b8a\\u0b8e-\\u0b90\\u0b92-\\u0b95\\u0b99-\\u0b9a\\u0b9c\\u0b9e-\\u0b9f\\u0ba3-\\u0ba4\\u0ba8-\\u0baa\\u0bae-\\u0bb9\\u0bd0\\u0c05-\\u0c0c\\u0c0e-\\u0c10\\u0c12-\\u0c28\\u0c2a-\\u0c39\\u0c3d\\u0c58-\\u0c5a\\u0c60-\\u0c61\\u0c80\\u0c85-\\u0c8c\\u0c8e-\\u0c90\\u0c92-\\u0ca8\\u0caa-\\u0cb3\\u0cb5-\\u0cb9\\u0cbd\\u0cde\\u0ce0-\\u0ce1\\u0cf1-\\u0cf2\\u0d05-\\u0d0c\\u0d0e-\\u0d10\\u0d12-\\u0d3a\\u0d3d\\u0d4e\\u0d54-\\u0d56\\u0d5f-\\u0d61\\u0d7a-\\u0d7f\\u0d85-\\u0d96\\u0d9a-\\u0db1\\u0db3-\\u0dbb\\u0dbd\\u0dc0-\\u0dc6\\u0e01-\\u0e30\\u0e32\\u0e40-\\u0e46\\u0e81-\\u0e82\\u0e84\\u0e87-\\u0e88\\u0e8a\\u0e8d\\u0e94-\\u0e97\\u0e99-\\u0e9f\\u0ea1-\\u0ea3\\u0ea5\\u0ea7\\u0eaa-\\u0eab\\u0ead-\\u0eb0\\u0eb2\\u0ebd\\u0ec0-\\u0ec4\\u0ec6\\u0edc-\\u0edf\\u0f00\\u0f40-\\u0f47\\u0f49-\\u0f6c\\u0f88-\\u0f8c\\u1000-\\u102a\\u103f\\u1050-\\u1055\\u105a-\\u105d\\u1061\\u1065-\\u1066\\u106e-\\u1070\\u1075-\\u1081\\u108e\\u10a0-\\u10c5\\u10c7\\u10cd\\u10d0-\\u10fa\\u10fc-\\u1248\\u124a-\\u124d\\u1250-\\u1256\\u1258\\u125a-\\u125d\\u1260-\\u1288\\u128a-\\u128d\\u1290-\\u12b0\\u12b2-\\u12b5\\u12b8-\\u12be\\u12c0\\u12c2-\\u12c5\\u12c8-\\u12d6\\u12d8-\\u1310\\u1312-\\u1315\\u1318-\\u135a\\u1380-\\u138f\\u13a0-\\u13f5\\u13f8-\\u13fd\\u1401-\\u166c\\u166f-\\u167f\\u1681-\\u169a\\u16a0-\\u16ea\\u16ee-\\u16f8\\u1700-\\u170c\\u170e-\\u1711\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u176c\\u176e-\\u1770\\u1780-\\u17b3\\u17d7\\u17dc\\u1820-\\u1878\\u1880-\\u18a8\\u18aa\\u18b0-\\u18f5\\u1900-\\u191e\\u1950-\\u196d\\u1970-\\u1974\\u1980-\\u19ab\\u19b0-\\u19c9\\u1a00-\\u1a16\\u1a20-\\u1a54\\u1aa7\\u1b05-\\u1b33\\u1b45-\\u1b4b\\u1b83-\\u1ba0\\u1bae-\\u1baf\\u1bba-\\u1be5\\u1c00-\\u1c23\\u1c4d-\\u1c4f\\u1c5a-\\u1c7d\\u1c80-\\u1c88\\u1c90-\\u1cba\\u1cbd-\\u1cbf\\u1ce9-\\u1cec\\u1cee-\\u1cf1\\u1cf5-\\u1cf6\\u1d00-\\u1dbf\\u1e00-\\u1f15\\u1f18-\\u1f1d\\u1f20-\\u1f45\\u1f48-\\u1f4d\\u1f50-\\u1f57\\u1f59\\u1f5b\\u1f5d\\u1f5f-\\u1f7d\\u1f80-\\u1fb4\\u1fb6-\\u1fbc\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fcc\\u1fd0-\\u1fd3\\u1fd6-\\u1fdb\\u1fe0-\\u1fec\\u1ff2-\\u1ff4\\u1ff6-\\u1ffc\\u2071\\u207f\\u2090-\\u209c\\u2102\\u2107\\u210a-\\u2113\\u2115\\u2118-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u2139\\u213c-\\u213f\\u2145-\\u2149\\u214e\\u2160-\\u2188\\u2c00-\\u2c2e\\u2c30-\\u2c5e\\u2c60-\\u2ce4\\u2ceb-\\u2cee\\u2cf2-\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\u2d30-\\u2d67\\u2d6f\\u2d80-\\u2d96\\u2da0-\\u2da6\\u2da8-\\u2dae\\u2db0-\\u2db6\\u2db8-\\u2dbe\\u2dc0-\\u2dc6\\u2dc8-\\u2dce\\u2dd0-\\u2dd6\\u2dd8-\\u2dde\\u3005-\\u3007\\u3021-\\u3029\\u3031-\\u3035\\u3038-\\u303c\\u3041-\\u3096\\u309d-\\u309f\\u30a1-\\u30fa\\u30fc-\\u30ff\\u3105-\\u312f\\u3131-\\u318e\\u31a0-\\u31ba\\u31f0-\\u31ff\\u3400-\\u4db5\\u4e00-\\u9fef\\ua000-\\ua48c\\ua4d0-\\ua4fd\\ua500-\\ua60c\\ua610-\\ua61f\\ua62a-\\ua62b\\ua640-\\ua66e\\ua67f-\\ua69d\\ua6a0-\\ua6ef\\ua717-\\ua71f\\ua722-\\ua788\\ua78b-\\ua7b9\\ua7f7-\\ua801\\ua803-\\ua805\\ua807-\\ua80a\\ua80c-\\ua822\\ua840-\\ua873\\ua882-\\ua8b3\\ua8f2-\\ua8f7\\ua8fb\\ua8fd-\\ua8fe\\ua90a-\\ua925\\ua930-\\ua946\\ua960-\\ua97c\\ua984-\\ua9b2\\ua9cf\\ua9e0-\\ua9e4\\ua9e6-\\ua9ef\\ua9fa-\\ua9fe\\uaa00-\\uaa28\\uaa40-\\uaa42\\uaa44-\\uaa4b\\uaa60-\\uaa76\\uaa7a\\uaa7e-\\uaaaf\\uaab1\\uaab5-\\uaab6\\uaab9-\\uaabd\\uaac0\\uaac2\\uaadb-\\uaadd\\uaae0-\\uaaea\\uaaf2-\\uaaf4\\uab01-\\uab06\\uab09-\\uab0e\\uab11-\\uab16\\uab20-\\uab26\\uab28-\\uab2e\\uab30-\\uab5a\\uab5c-\\uab65\\uab70-\\uabe2\\uac00-\\ud7a3\\ud7b0-\\ud7c6\\ud7cb-\\ud7fb\\uf900-\\ufa6d\\ufa70-\\ufad9\\ufb00-\\ufb06\\ufb13-\\ufb17\\ufb1d\\ufb1f-\\ufb28\\ufb2a-\\ufb36\\ufb38-\\ufb3c\\ufb3e\\ufb40-\\ufb41\\ufb43-\\ufb44\\ufb46-\\ufbb1\\ufbd3-\\ufc5d\\ufc64-\\ufd3d\\ufd50-\\ufd8f\\ufd92-\\ufdc7\\ufdf0-\\ufdf9\\ufe71\\ufe73\\ufe77\\ufe79\\ufe7b\\ufe7d\\ufe7f-\\ufefc\\uff21-\\uff3a\\uff41-\\uff5a\\uff66-\\uff9d\\uffa0-\\uffbe\\uffc2-\\uffc7\\uffca-\\uffcf\\uffd2-\\uffd7\\uffda-\\uffdc\\U00010000-\\U0001000b\\U0001000d-\\U00010026\\U00010028-\\U0001003a\\U0001003c-\\U0001003d\\U0001003f-\\U0001004d\\U00010050-\\U0001005d\\U00010080-\\U000100fa\\U00010140-\\U00010174\\U00010280-\\U0001029c\\U000102a0-\\U000102d0\\U00010300-\\U0001031f\\U0001032d-\\U0001034a\\U00010350-\\U00010375\\U00010380-\\U0001039d\\U000103a0-\\U000103c3\\U000103c8-\\U000103cf\\U000103d1-\\U000103d5\\U00010400-\\U0001049d\\U000104b0-\\U000104d3\\U000104d8-\\U000104fb\\U00010500-\\U00010527\\U00010530-\\U00010563\\U00010600-\\U00010736\\U00010740-\\U00010755\\U00010760-\\U00010767\\U00010800-\\U00010805\\U00010808\\U0001080a-\\U00010835\\U00010837-\\U00010838\\U0001083c\\U0001083f-\\U00010855\\U00010860-\\U00010876\\U00010880-\\U0001089e\\U000108e0-\\U000108f2\\U000108f4-\\U000108f5\\U00010900-\\U00010915\\U00010920-\\U00010939\\U00010980-\\U000109b7\\U000109be-\\U000109bf\\U00010a00\\U00010a10-\\U00010a13\\U00010a15-\\U00010a17\\U00010a19-\\U00010a35\\U00010a60-\\U00010a7c\\U00010a80-\\U00010a9c\\U00010ac0-\\U00010ac7\\U00010ac9-\\U00010ae4\\U00010b00-\\U00010b35\\U00010b40-\\U00010b55\\U00010b60-\\U00010b72\\U00010b80-\\U00010b91\\U00010c00-\\U00010c48\\U00010c80-\\U00010cb2\\U00010cc0-\\U00010cf2\\U00010d00-\\U00010d23\\U00010f00-\\U00010f1c\\U00010f27\\U00010f30-\\U00010f45\\U00011003-\\U00011037\\U00011083-\\U000110af\\U000110d0-\\U000110e8\\U00011103-\\U00011126\\U00011144\\U00011150-\\U00011172\\U00011176\\U00011183-\\U000111b2\\U000111c1-\\U000111c4\\U000111da\\U000111dc\\U00011200-\\U00011211\\U00011213-\\U0001122b\\U00011280-\\U00011286\\U00011288\\U0001128a-\\U0001128d\\U0001128f-\\U0001129d\\U0001129f-\\U000112a8\\U000112b0-\\U000112de\\U00011305-\\U0001130c\\U0001130f-\\U00011310\\U00011313-\\U00011328\\U0001132a-\\U00011330\\U00011332-\\U00011333\\U00011335-\\U00011339\\U0001133d\\U00011350\\U0001135d-\\U00011361\\U00011400-\\U00011434\\U00011447-\\U0001144a\\U00011480-\\U000114af\\U000114c4-\\U000114c5\\U000114c7\\U00011580-\\U000115ae\\U000115d8-\\U000115db\\U00011600-\\U0001162f\\U00011644\\U00011680-\\U000116aa\\U00011700-\\U0001171a\\U00011800-\\U0001182b\\U000118a0-\\U000118df\\U000118ff\\U00011a00\\U00011a0b-\\U00011a32\\U00011a3a\\U00011a50\\U00011a5c-\\U00011a83\\U00011a86-\\U00011a89\\U00011a9d\\U00011ac0-\\U00011af8\\U00011c00-\\U00011c08\\U00011c0a-\\U00011c2e\\U00011c40\\U00011c72-\\U00011c8f\\U00011d00-\\U00011d06\\U00011d08-\\U00011d09\\U00011d0b-\\U00011d30\\U00011d46\\U00011d60-\\U00011d65\\U00011d67-\\U00011d68\\U00011d6a-\\U00011d89\\U00011d98\\U00011ee0-\\U00011ef2\\U00012000-\\U00012399\\U00012400-\\U0001246e\\U00012480-\\U00012543\\U00013000-\\U0001342e\\U00014400-\\U00014646\\U00016800-\\U00016a38\\U00016a40-\\U00016a5e\\U00016ad0-\\U00016aed\\U00016b00-\\U00016b2f\\U00016b40-\\U00016b43\\U00016b63-\\U00016b77\\U00016b7d-\\U00016b8f\\U00016e40-\\U00016e7f\\U00016f00-\\U00016f44\\U00016f50\\U00016f93-\\U00016f9f\\U00016fe0-\\U00016fe1\\U00017000-\\U000187f1\\U00018800-\\U00018af2\\U0001b000-\\U0001b11e\\U0001b170-\\U0001b2fb\\U0001bc00-\\U0001bc6a\\U0001bc70-\\U0001bc7c\\U0001bc80-\\U0001bc88\\U0001bc90-\\U0001bc99\\U0001d400-\\U0001d454\\U0001d456-\\U0001d49c\\U0001d49e-\\U0001d49f\\U0001d4a2\\U0001d4a5-\\U0001d4a6\\U0001d4a9-\\U0001d4ac\\U0001d4ae-\\U0001d4b9\\U0001d4bb\\U0001d4bd-\\U0001d4c3\\U0001d4c5-\\U0001d505\\U0001d507-\\U0001d50a\\U0001d50d-\\U0001d514\\U0001d516-\\U0001d51c\\U0001d51e-\\U0001d539\\U0001d53b-\\U0001d53e\\U0001d540-\\U0001d544\\U0001d546\\U0001d54a-\\U0001d550\\U0001d552-\\U0001d6a5\\U0001d6a8-\\U0001d6c0\\U0001d6c2-\\U0001d6da\\U0001d6dc-\\U0001d6fa\\U0001d6fc-\\U0001d714\\U0001d716-\\U0001d734\\U0001d736-\\U0001d74e\\U0001d750-\\U0001d76e\\U0001d770-\\U0001d788\\U0001d78a-\\U0001d7a8\\U0001d7aa-\\U0001d7c2\\U0001d7c4-\\U0001d7cb\\U0001e800-\\U0001e8c4\\U0001e900-\\U0001e943\\U0001ee00-\\U0001ee03\\U0001ee05-\\U0001ee1f\\U0001ee21-\\U0001ee22\\U0001ee24\\U0001ee27\\U0001ee29-\\U0001ee32\\U0001ee34-\\U0001ee37\\U0001ee39\\U0001ee3b\\U0001ee42\\U0001ee47\\U0001ee49\\U0001ee4b\\U0001ee4d-\\U0001ee4f\\U0001ee51-\\U0001ee52\\U0001ee54\\U0001ee57\\U0001ee59\\U0001ee5b\\U0001ee5d\\U0001ee5f\\U0001ee61-\\U0001ee62\\U0001ee64\\U0001ee67-\\U0001ee6a\\U0001ee6c-\\U0001ee72\\U0001ee74-\\U0001ee77\\U0001ee79-\\U0001ee7c\\U0001ee7e\\U0001ee80-\\U0001ee89\\U0001ee8b-\\U0001ee9b\\U0001eea1-\\U0001eea3\\U0001eea5-\\U0001eea9\\U0001eeab-\\U0001eebb\\U00020000-\\U0002a6d6\\U0002a700-\\U0002b734\\U0002b740-\\U0002b81d\\U0002b820-\\U0002cea1\\U0002ceb0-\\U0002ebe0\\U0002f800-\\U0002fa1d'\n\ncats = ['Cc', 'Cf', 'Cn', 'Co', 'Cs', 'Ll', 'Lm', 'Lo', 'Lt', 'Lu', 'Mc', 'Me', 'Mn', 'Nd', 'Nl', 'No', 'Pc', 'Pd', 'Pe', 'Pf', 'Pi', 'Po', 'Ps', 'Sc', 'Sk', 'Sm', 'So', 'Zl', 'Zp', 'Zs']\n\n# Generated from unidata 11.0.0\n\ndef combine(*args):\n    return ''.join(globals()[cat] for cat in args)\n\n\ndef allexcept(*args):\n    newcats = cats[:]\n    for arg in args:\n        newcats.remove(arg)\n    return ''.join(globals()[cat] for cat in newcats)\n\n\ndef _handle_runs(char_list):  # pragma: no cover\n    buf = []\n    for c in char_list:\n        if len(c) == 1:\n            if buf and buf[-1][1] == chr(ord(c)-1):\n                buf[-1] = (buf[-1][0], c)\n            else:\n                buf.append((c, c))\n        else:\n            buf.append((c, c))\n    for a, b in buf:\n        if a == b:\n            yield a\n        else:\n            yield f'{a}-{b}'\n\n\nif __name__ == '__main__':  # pragma: no cover\n    import unicodedata\n\n    categories = {'xid_start': [], 'xid_continue': []}\n\n    with open(__file__, encoding='utf-8') as fp:\n        content = fp.read()\n\n    header = content[:content.find('Cc =')]\n    footer = content[content.find(\"def combine(\"):]\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\util.py": {
      "sha": "79b5ae463e2c",
      "lines": 324,
      "head": "\"\"\"\n    pygments.util\n    ~~~~~~~~~~~~~\n\n    Utility functions.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nfrom io import TextIOWrapper\n\n\nsplit_path_re = re.compile(r'[/\\\\ ]')\ndoctype_lookup_re = re.compile(r'''\n    <!DOCTYPE\\s+(\n     [a-zA-Z_][a-zA-Z0-9]*\n     (?: \\s+      # optional in HTML5\n     [a-zA-Z_][a-zA-Z0-9]*\\s+\n     \"[^\"]*\")?\n     )\n     [^>]*>\n''', re.DOTALL | re.MULTILINE | re.VERBOSE)\ntag_re = re.compile(r'<(.+?)(\\s.*?)?>.*?</.+?>',\n                    re.IGNORECASE | re.DOTALL | re.MULTILINE)\nxml_decl_re = re.compile(r'\\s*<\\?xml[^>]*\\?>', re.I)\n\n\nclass ClassNotFound(ValueError):\n    \"\"\"Raised if one of the lookup functions didn't find a matching class.\"\"\"\n\n\nclass OptionError(Exception):\n    \"\"\"\n    This exception will be raised by all option processing functions if\n    the type or value of the argument is not correct.\n    \"\"\"\n\ndef get_choice_opt(options, optname, allowed, default=None, normcase=False):\n    \"\"\"\n    If the key `optname` from the dictionary is not in the sequence\n    `allowed`, raise an error, otherwise return it.\n    \"\"\"\n    string = options.get(optname, default)\n    if normcase:\n        string = string.lower()\n    if string not in allowed:\n        raise OptionError('Value for option {} must be one of {}'.format(optname, ', '.join(map(str, allowed))))\n    return string\n\n\ndef get_bool_opt(options, optname, default=None):\n    \"\"\"\n    Intuitively, this is `options.get(optname, default)`, but restricted to\n    Boolean value. The Booleans can be represented as string, in order to accept\n    Boolean value from the command line arguments. If the key `optname` is\n    present in the dictionary `options` and is not associated with a Boolean,\n    raise an `OptionError`. If it is absent, `default` is returned instead.\n\n    The valid string values for ``True`` are ``1``, ``yes``, ``true`` and\n    ``on``, the ones for ``False`` are ``0``, ``no``, ``false`` and ``off``\n    (matched case-insensitively).\n    \"\"\"\n    string = options.get(optname, default)\n    if isinstance(string, bool):\n        return string\n    elif isinstance(string, int):\n        return bool(string)\n    elif not isinstance(string, str):\n        raise OptionError(f'Invalid type {string!r} for option {optname}; use '\n                          '1/0, yes/no, true/false, on/off')\n    elif string.lower() in ('1', 'yes', 'true', 'on'):\n        return True\n    elif string.lower() in ('0', 'no', 'false', 'off'):\n        return False\n    else:\n        raise OptionError(f'Invalid value {string!r} for option {optname}; use '\n                          '1/0, yes/no, true/false, on/off')\n\n\ndef get_int_opt(options, optname, default=None):\n    \"\"\"As :func:`get_bool_opt`, but interpret the value as an integer.\"\"\"\n    string = options.get(optname, default)\n    try:\n        return int(string)\n    except TypeError:\n        raise OptionError(f'Invalid type {string!r} for option {optname}; you '\n                          'must give an integer value')\n    except ValueError:\n        raise OptionError(f'Invalid value {string!r} for option {optname}; you '\n                          'must give an integer value')\n\ndef get_list_opt(options, optname, default=None):\n    \"\"\"\n    If the key `optname` from the dictionary `options` is a string,\n    split it at whitespace and return it. If it is already a list\n    or a tuple, it is returned as a list.\n    \"\"\"\n    val = options.get(optname, default)\n    if isinstance(val, str):\n        return val.split()\n    elif isinstance(val, (list, tuple)):\n        return list(val)\n    else:\n        raise OptionError(f'Invalid type {val!r} for option {optname}; you '\n                          'must give a list value')\n\n\ndef docstring_headline(obj):\n    if not obj.__doc__:\n        return ''\n    res = []\n    for line in obj.__doc__.strip().splitlines():\n        if line.strip():\n            res.append(\" \" + line.strip())\n        else:\n            break\n    return ''.join(res).lstrip()\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\__init__.py": {
      "sha": "d5169f4a4b45",
      "lines": 82,
      "head": "\"\"\"\n    Pygments\n    ~~~~~~~~\n\n    Pygments is a syntax highlighting package written in Python.\n\n    It is a generic syntax highlighter for general use in all kinds of software\n    such as forum systems, wikis or other applications that need to prettify\n    source code. Highlights are:\n\n    * a wide range of common languages and markup formats is supported\n    * special attention is paid to details, increasing quality by a fair amount\n    * support for new languages and formats are added easily\n    * a number of output formats, presently HTML, LaTeX, RTF, SVG, all image\n      formats that PIL supports, and ANSI sequences\n    * it is usable as a command-line tool and as a library\n    * ... and it highlights even Brainfuck!\n\n    The `Pygments master branch`_ is installable with ``easy_install Pygments==dev``.\n\n    .. _Pygments master branch:\n       https://github.com/pygments/pygments/archive/master.zip#egg=Pygments-dev\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\nfrom io import StringIO, BytesIO\n\n__version__ = '2.19.1'\n__docformat__ = 'restructuredtext'\n\n__all__ = ['lex', 'format', 'highlight']\n\n\ndef lex(code, lexer):\n    \"\"\"\n    Lex `code` with the `lexer` (must be a `Lexer` instance)\n    and return an iterable of tokens. Currently, this only calls\n    `lexer.get_tokens()`.\n    \"\"\"\n    try:\n        return lexer.get_tokens(code)\n    except TypeError:\n        # Heuristic to catch a common mistake.\n        from pip._vendor.pygments.lexer import RegexLexer\n        if isinstance(lexer, type) and issubclass(lexer, RegexLexer):\n            raise TypeError('lex() argument must be a lexer instance, '\n                            'not a class')\n        raise\n\n\ndef format(tokens, formatter, outfile=None):  # pylint: disable=redefined-builtin\n    \"\"\"\n    Format ``tokens`` (an iterable of tokens) with the formatter ``formatter``\n    (a `Formatter` instance).\n\n    If ``outfile`` is given and a valid file object (an object with a\n    ``write`` method), the result will be written to it, otherwise it\n    is returned as a string.\n    \"\"\"\n    try:\n        if not outfile:\n            realoutfile = getattr(formatter, 'encoding', None) and BytesIO() or StringIO()\n            formatter.format(tokens, realoutfile)\n            return realoutfile.getvalue()\n        else:\n            formatter.format(tokens, outfile)\n    except TypeError:\n        # Heuristic to catch a common mistake.\n        from pip._vendor.pygments.formatter import Formatter\n        if isinstance(formatter, type) and issubclass(formatter, Formatter):\n            raise TypeError('format() argument must be a formatter instance, '\n                            'not a class')\n        raise\n\n\ndef highlight(code, lexer, formatter, outfile=None):\n    \"\"\"\n    This is the most high-level highlighting function. It combines `lex` and\n    `format` in one function.\n    \"\"\"\n    return format(lex(code, lexer), formatter, outfile)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\__main__.py": {
      "sha": "35345eb02c0a",
      "lines": 17,
      "head": "\"\"\"\n    pygments.__main__\n    ~~~~~~~~~~~~~~~~~\n\n    Main entry point for ``python -m pygments``.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport sys\nfrom pip._vendor.pygments.cmdline import main\n\ntry:\n    sys.exit(main(sys.argv))\nexcept KeyboardInterrupt:\n    sys.exit(1)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\filters\\__init__.py": {
      "sha": "4098541433e5",
      "lines": 940,
      "head": "\"\"\"\n    pygments.filters\n    ~~~~~~~~~~~~~~~~\n\n    Module containing filter lookup functions and default\n    filters.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\n\nfrom pip._vendor.pygments.token import String, Comment, Keyword, Name, Error, Whitespace, \\\n    string_to_tokentype\nfrom pip._vendor.pygments.filter import Filter\nfrom pip._vendor.pygments.util import get_list_opt, get_int_opt, get_bool_opt, \\\n    get_choice_opt, ClassNotFound, OptionError\nfrom pip._vendor.pygments.plugin import find_plugin_filters\n\n\ndef find_filter_class(filtername):\n    \"\"\"Lookup a filter by name. Return None if not found.\"\"\"\n    if filtername in FILTERS:\n        return FILTERS[filtername]\n    for name, cls in find_plugin_filters():\n        if name == filtername:\n            return cls\n    return None\n\n\ndef get_filter_by_name(filtername, **options):\n    \"\"\"Return an instantiated filter.\n\n    Options are passed to the filter initializer if wanted.\n    Raise a ClassNotFound if not found.\n    \"\"\"\n    cls = find_filter_class(filtername)\n    if cls:\n        return cls(**options)\n    else:\n        raise ClassNotFound(f'filter {filtername!r} not found')\n\n\ndef get_all_filters():\n    \"\"\"Return a generator of all filter names.\"\"\"\n    yield from FILTERS\n    for name, _ in find_plugin_filters():\n        yield name\n\n\ndef _replace_special(ttype, value, regex, specialttype,\n                     replacefunc=lambda x: x):\n    last = 0\n    for match in regex.finditer(value):\n        start, end = match.start(), match.end()\n        if start != last:\n            yield ttype, value[last:start]\n        yield specialttype, replacefunc(value[start:end])\n        last = end\n    if last != len(value):\n        yield ttype, value[last:]\n\n\nclass CodeTagFilter(Filter):\n    \"\"\"Highlight special code tags in comments and docstrings.\n\n    Options accepted:\n\n    `codetags` : list of strings\n       A list of strings that are flagged as code tags.  The default is to\n       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.\n\n    .. versionchanged:: 2.13\n       Now recognizes ``FIXME`` by default.\n    \"\"\"\n\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        tags = get_list_opt(options, 'codetags',\n                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])\n        self.tag_re = re.compile(r'\\b({})\\b'.format('|'.join([\n            re.escape(tag) for tag in tags if tag\n        ])))\n\n    def filter(self, lexer, stream):\n        regex = self.tag_re\n        for ttype, value in stream:\n            if ttype in String.Doc or \\\n               ttype in Comment and \\\n               ttype not in Comment.Preproc:\n                yield from _replace_special(ttype, value, regex, Comment.Special)\n            else:\n                yield ttype, value\n\n\nclass SymbolFilter(Filter):\n    \"\"\"Convert mathematical symbols such as \\\\<longrightarrow> in Isabelle\n    or \\\\longrightarrow in LaTeX into Unicode characters.\n\n    This is mostly useful for HTML or console output when you want to\n    approximate the source rendering you'd see in an IDE.\n\n    Options accepted:\n\n    `lang` : string\n       The symbol language. Must be one of ``'isabelle'`` or\n       ``'latex'``.  The default is ``'isabelle'``.\n    \"\"\"\n\n    latex_symbols = {\n        '\\\\alpha'                : '\\U000003b1',\n        '\\\\beta'                 : '\\U000003b2',\n        '\\\\gamma'                : '\\U000003b3',\n        '\\\\delta'                : '\\U000003b4',\n        '\\\\varepsilon'           : '\\U000003b5',\n        '\\\\zeta'                 : '\\U000003b6',\n        '\\\\eta'                  : '\\U000003b7',\n        '\\\\vartheta'             : '\\U000003b8',\n        '\\\\iota'                 : '\\U000003b9',\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\formatters\\_mapping.py": {
      "sha": "70c2241423f1",
      "lines": 23,
      "head": "# Automatically generated by scripts/gen_mapfiles.py.\n# DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.\n\nFORMATTERS = {\n    'BBCodeFormatter': ('pygments.formatters.bbcode', 'BBCode', ('bbcode', 'bb'), (), 'Format tokens with BBcodes. These formatting codes are used by many bulletin boards, so you can highlight your sourcecode with pygments before posting it there.'),\n    'BmpImageFormatter': ('pygments.formatters.img', 'img_bmp', ('bmp', 'bitmap'), ('*.bmp',), 'Create a bitmap image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),\n    'GifImageFormatter': ('pygments.formatters.img', 'img_gif', ('gif',), ('*.gif',), 'Create a GIF image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),\n    'GroffFormatter': ('pygments.formatters.groff', 'groff', ('groff', 'troff', 'roff'), (), 'Format tokens with groff escapes to change their color and font style.'),\n    'HtmlFormatter': ('pygments.formatters.html', 'HTML', ('html',), ('*.html', '*.htm'), \"Format tokens as HTML 4 ``<span>`` tags. By default, the content is enclosed in a ``<pre>`` tag, itself wrapped in a ``<div>`` tag (but see the `nowrap` option). The ``<div>``'s CSS class can be set by the `cssclass` option.\"),\n    'IRCFormatter': ('pygments.formatters.irc', 'IRC', ('irc', 'IRC'), (), 'Format tokens with IRC color sequences'),\n    'ImageFormatter': ('pygments.formatters.img', 'img', ('img', 'IMG', 'png'), ('*.png',), 'Create a PNG image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),\n    'JpgImageFormatter': ('pygments.formatters.img', 'img_jpg', ('jpg', 'jpeg'), ('*.jpg',), 'Create a JPEG image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),\n    'LatexFormatter': ('pygments.formatters.latex', 'LaTeX', ('latex', 'tex'), ('*.tex',), 'Format tokens as LaTeX code. This needs the `fancyvrb` and `color` standard packages.'),\n    'NullFormatter': ('pygments.formatters.other', 'Text only', ('text', 'null'), ('*.txt',), 'Output the text unchanged without any formatting.'),\n    'PangoMarkupFormatter': ('pygments.formatters.pangomarkup', 'Pango Markup', ('pango', 'pangomarkup'), (), 'Format tokens as Pango Markup code. It can then be rendered to an SVG.'),\n    'RawTokenFormatter': ('pygments.formatters.other', 'Raw tokens', ('raw', 'tokens'), ('*.raw',), 'Format tokens as a raw representation for storing token streams.'),\n    'RtfFormatter': ('pygments.formatters.rtf', 'RTF', ('rtf',), ('*.rtf',), 'Format tokens as RTF markup. This formatter automatically outputs full RTF documents with color information and other useful stuff. Perfect for Copy and Paste into Microsoft(R) Word(R) documents.'),\n    'SvgFormatter': ('pygments.formatters.svg', 'SVG', ('svg',), ('*.svg',), 'Format tokens as an SVG graphics file.  This formatter is still experimental. Each line of code is a ``<text>`` element with explicit ``x`` and ``y`` coordinates containing ``<tspan>`` elements with the individual token styles.'),\n    'Terminal256Formatter': ('pygments.formatters.terminal256', 'Terminal256', ('terminal256', 'console256', '256'), (), 'Format tokens with ANSI color sequences, for output in a 256-color terminal or console.  Like in `TerminalFormatter` color sequences are terminated at newlines, so that paging the output works correctly.'),\n    'TerminalFormatter': ('pygments.formatters.terminal', 'Terminal', ('terminal', 'console'), (), 'Format tokens with ANSI color sequences, for output in a text console. Color sequences are terminated at newlines, so that paging the output works correctly.'),\n    'TerminalTrueColorFormatter': ('pygments.formatters.terminal256', 'TerminalTrueColor', ('terminal16m', 'console16m', '16m'), (), 'Format tokens with ANSI color sequences, for output in a true-color terminal or console.  Like in `TerminalFormatter` color sequences are terminated at newlines, so that paging the output works correctly.'),\n    'TestcaseFormatter': ('pygments.formatters.other', 'Testcase', ('testcase',), (), 'Format tokens as appropriate for a new testcase.'),\n}\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\formatters\\__init__.py": {
      "sha": "8826cfc9d482",
      "lines": 157,
      "head": "\"\"\"\n    pygments.formatters\n    ~~~~~~~~~~~~~~~~~~~\n\n    Pygments formatters.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nimport sys\nimport types\nimport fnmatch\nfrom os.path import basename\n\nfrom pip._vendor.pygments.formatters._mapping import FORMATTERS\nfrom pip._vendor.pygments.plugin import find_plugin_formatters\nfrom pip._vendor.pygments.util import ClassNotFound\n\n__all__ = ['get_formatter_by_name', 'get_formatter_for_filename',\n           'get_all_formatters', 'load_formatter_from_file'] + list(FORMATTERS)\n\n_formatter_cache = {}  # classes by name\n_pattern_cache = {}\n\n\ndef _fn_matches(fn, glob):\n    \"\"\"Return whether the supplied file name fn matches pattern filename.\"\"\"\n    if glob not in _pattern_cache:\n        pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))\n        return pattern.match(fn)\n    return _pattern_cache[glob].match(fn)\n\n\ndef _load_formatters(module_name):\n    \"\"\"Load a formatter (and all others in the module too).\"\"\"\n    mod = __import__(module_name, None, None, ['__all__'])\n    for formatter_name in mod.__all__:\n        cls = getattr(mod, formatter_name)\n        _formatter_cache[cls.name] = cls\n\n\ndef get_all_formatters():\n    \"\"\"Return a generator for all formatter classes.\"\"\"\n    # NB: this returns formatter classes, not info like get_all_lexers().\n    for info in FORMATTERS.values():\n        if info[1] not in _formatter_cache:\n            _load_formatters(info[0])\n        yield _formatter_cache[info[1]]\n    for _, formatter in find_plugin_formatters():\n        yield formatter\n\n\ndef find_formatter_class(alias):\n    \"\"\"Lookup a formatter by alias.\n\n    Returns None if not found.\n    \"\"\"\n    for module_name, name, aliases, _, _ in FORMATTERS.values():\n        if alias in aliases:\n            if name not in _formatter_cache:\n                _load_formatters(module_name)\n            return _formatter_cache[name]\n    for _, cls in find_plugin_formatters():\n        if alias in cls.aliases:\n            return cls\n\n\ndef get_formatter_by_name(_alias, **options):\n    \"\"\"\n    Return an instance of a :class:`.Formatter` subclass that has `alias` in its\n    aliases list. The formatter is given the `options` at its instantiation.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no formatter with that\n    alias is found.\n    \"\"\"\n    cls = find_formatter_class(_alias)\n    if cls is None:\n        raise ClassNotFound(f\"no formatter found for name {_alias!r}\")\n    return cls(**options)\n\n\ndef load_formatter_from_file(filename, formattername=\"CustomFormatter\", **options):\n    \"\"\"\n    Return a `Formatter` subclass instance loaded from the provided file, relative\n    to the current directory.\n\n    The file is expected to contain a Formatter class named ``formattername``\n    (by default, CustomFormatter). Users should be very careful with the input, because\n    this method is equivalent to running ``eval()`` on the input file. The formatter is\n    given the `options` at its instantiation.\n\n    :exc:`pygments.util.ClassNotFound` is raised if there are any errors loading\n    the formatter.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    try:\n        # This empty dict will contain the namespace for the exec'd file\n        custom_namespace = {}\n        with open(filename, 'rb') as f:\n            exec(f.read(), custom_namespace)\n        # Retrieve the class `formattername` from that namespace\n        if formattername not in custom_namespace:\n            raise ClassNotFound(f'no valid {formattername} class found in {filename}')\n        formatter_class = custom_namespace[formattername]\n        # And finally instantiate it with the options\n        return formatter_class(**options)\n    except OSError as err:\n        raise ClassNotFound(f'cannot read {filename}: {err}')\n    except ClassNotFound:\n        raise\n    except Exception as err:\n        raise ClassNotFound(f'error when loading custom formatter: {err}')\n\n\ndef get_formatter_for_filename(fn, **options):\n    \"\"\"\n    Return a :class:`.Formatter` subclass instance that has a filename pattern\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\lexers\\python.py": {
      "sha": "001ca57d1107",
      "lines": 1201,
      "head": "\"\"\"\n    pygments.lexers.python\n    ~~~~~~~~~~~~~~~~~~~~~~\n\n    Lexers for Python and related languages.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport keyword\n\nfrom pip._vendor.pygments.lexer import DelegatingLexer, RegexLexer, include, \\\n    bygroups, using, default, words, combined, this\nfrom pip._vendor.pygments.util import get_bool_opt, shebang_matches\nfrom pip._vendor.pygments.token import Text, Comment, Operator, Keyword, Name, String, \\\n    Number, Punctuation, Generic, Other, Error, Whitespace\nfrom pip._vendor.pygments import unistring as uni\n\n__all__ = ['PythonLexer', 'PythonConsoleLexer', 'PythonTracebackLexer',\n           'Python2Lexer', 'Python2TracebackLexer',\n           'CythonLexer', 'DgLexer', 'NumPyLexer']\n\n\nclass PythonLexer(RegexLexer):\n    \"\"\"\n    For Python source code (version 3.x).\n\n    .. versionchanged:: 2.5\n       This is now the default ``PythonLexer``.  It is still available as the\n       alias ``Python3Lexer``.\n    \"\"\"\n\n    name = 'Python'\n    url = 'https://www.python.org'\n    aliases = ['python', 'py', 'sage', 'python3', 'py3', 'bazel', 'starlark', 'pyi']\n    filenames = [\n        '*.py',\n        '*.pyw',\n        # Type stubs\n        '*.pyi',\n        # Jython\n        '*.jy',\n        # Sage\n        '*.sage',\n        # SCons\n        '*.sc',\n        'SConstruct',\n        'SConscript',\n        # Skylark/Starlark (used by Bazel, Buck, and Pants)\n        '*.bzl',\n        'BUCK',\n        'BUILD',\n        'BUILD.bazel',\n        'WORKSPACE',\n        # Twisted Application infrastructure\n        '*.tac',\n    ]\n    mimetypes = ['text/x-python', 'application/x-python',\n                 'text/x-python3', 'application/x-python3']\n    version_added = '0.10'\n\n    uni_name = f\"[{uni.xid_start}][{uni.xid_continue}]*\"\n\n    def innerstring_rules(ttype):\n        return [\n            # the old style '%s' % (...) string formatting (still valid in Py3)\n            (r'%(\\(\\w+\\))?[-#0 +]*([0-9]+|[*])?(\\.([0-9]+|[*]))?'\n             '[hlL]?[E-GXc-giorsaux%]', String.Interpol),\n            # the new style '{}'.format(...) string formatting\n            (r'\\{'\n             r'((\\w+)((\\.\\w+)|(\\[[^\\]]+\\]))*)?'  # field name\n             r'(\\![sra])?'                       # conversion\n             r'(\\:(.?[<>=\\^])?[-+ ]?#?0?(\\d+)?,?(\\.\\d+)?[E-GXb-gnosx%]?)?'\n             r'\\}', String.Interpol),\n\n            # backslashes, quotes and formatting signs must be parsed one at a time\n            (r'[^\\\\\\'\"%{\\n]+', ttype),\n            (r'[\\'\"\\\\]', ttype),\n            # unhandled string formatting sign\n            (r'%|(\\{{1,2})', ttype)\n            # newlines are an error (use \"nl\" state)\n        ]\n\n    def fstring_rules(ttype):\n        return [\n            # Assuming that a '}' is the closing brace after format specifier.\n            # Sadly, this means that we won't detect syntax error. But it's\n            # more important to parse correct syntax correctly, than to\n            # highlight invalid syntax.\n            (r'\\}', String.Interpol),\n            (r'\\{', String.Interpol, 'expr-inside-fstring'),\n            # backslashes, quotes and formatting signs must be parsed one at a time\n            (r'[^\\\\\\'\"{}\\n]+', ttype),\n            (r'[\\'\"\\\\]', ttype),\n            # newlines are an error (use \"nl\" state)\n        ]\n\n    tokens = {\n        'root': [\n            (r'\\n', Whitespace),\n            (r'^(\\s*)([rRuUbB]{,2})(\"\"\"(?:.|\\n)*?\"\"\")',\n             bygroups(Whitespace, String.Affix, String.Doc)),\n            (r\"^(\\s*)([rRuUbB]{,2})('''(?:.|\\n)*?''')\",\n             bygroups(Whitespace, String.Affix, String.Doc)),\n            (r'\\A#!.+$', Comment.Hashbang),\n            (r'#.*$', Comment.Single),\n            (r'\\\\\\n', Text),\n            (r'\\\\', Text),\n            include('keywords'),\n            include('soft-keywords'),\n            (r'(def)((?:\\s|\\\\\\s)+)', bygroups(Keyword, Whitespace), 'funcname'),\n            (r'(class)((?:\\s|\\\\\\s)+)', bygroups(Keyword, Whitespace), 'classname'),\n            (r'(from)((?:\\s|\\\\\\s)+)', bygroups(Keyword.Namespace, Whitespace),\n             'fromimport'),\n            (r'(import)((?:\\s|\\\\\\s)+)', bygroups(Keyword.Namespace, Whitespace),\n             'import'),\n            include('expr'),\n        ],\n        'expr': [\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\lexers\\_mapping.py": {
      "sha": "1d215390f8b6",
      "lines": 602,
      "head": "# Automatically generated by scripts/gen_mapfiles.py.\n# DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.\n\nLEXERS = {\n    'ABAPLexer': ('pip._vendor.pygments.lexers.business', 'ABAP', ('abap',), ('*.abap', '*.ABAP'), ('text/x-abap',)),\n    'AMDGPULexer': ('pip._vendor.pygments.lexers.amdgpu', 'AMDGPU', ('amdgpu',), ('*.isa',), ()),\n    'APLLexer': ('pip._vendor.pygments.lexers.apl', 'APL', ('apl',), ('*.apl', '*.aplf', '*.aplo', '*.apln', '*.aplc', '*.apli', '*.dyalog'), ()),\n    'AbnfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'ABNF', ('abnf',), ('*.abnf',), ('text/x-abnf',)),\n    'ActionScript3Lexer': ('pip._vendor.pygments.lexers.actionscript', 'ActionScript 3', ('actionscript3', 'as3'), ('*.as',), ('application/x-actionscript3', 'text/x-actionscript3', 'text/actionscript3')),\n    'ActionScriptLexer': ('pip._vendor.pygments.lexers.actionscript', 'ActionScript', ('actionscript', 'as'), ('*.as',), ('application/x-actionscript', 'text/x-actionscript', 'text/actionscript')),\n    'AdaLexer': ('pip._vendor.pygments.lexers.ada', 'Ada', ('ada', 'ada95', 'ada2005'), ('*.adb', '*.ads', '*.ada'), ('text/x-ada',)),\n    'AdlLexer': ('pip._vendor.pygments.lexers.archetype', 'ADL', ('adl',), ('*.adl', '*.adls', '*.adlf', '*.adlx'), ()),\n    'AgdaLexer': ('pip._vendor.pygments.lexers.haskell', 'Agda', ('agda',), ('*.agda',), ('text/x-agda',)),\n    'AheuiLexer': ('pip._vendor.pygments.lexers.esoteric', 'Aheui', ('aheui',), ('*.aheui',), ()),\n    'AlloyLexer': ('pip._vendor.pygments.lexers.dsls', 'Alloy', ('alloy',), ('*.als',), ('text/x-alloy',)),\n    'AmbientTalkLexer': ('pip._vendor.pygments.lexers.ambient', 'AmbientTalk', ('ambienttalk', 'ambienttalk/2', 'at'), ('*.at',), ('text/x-ambienttalk',)),\n    'AmplLexer': ('pip._vendor.pygments.lexers.ampl', 'Ampl', ('ampl',), ('*.run',), ()),\n    'Angular2HtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML + Angular2', ('html+ng2',), ('*.ng2',), ()),\n    'Angular2Lexer': ('pip._vendor.pygments.lexers.templates', 'Angular2', ('ng2',), (), ()),\n    'AntlrActionScriptLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With ActionScript Target', ('antlr-actionscript', 'antlr-as'), ('*.G', '*.g'), ()),\n    'AntlrCSharpLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With C# Target', ('antlr-csharp', 'antlr-c#'), ('*.G', '*.g'), ()),\n    'AntlrCppLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With CPP Target', ('antlr-cpp',), ('*.G', '*.g'), ()),\n    'AntlrJavaLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Java Target', ('antlr-java',), ('*.G', '*.g'), ()),\n    'AntlrLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR', ('antlr',), (), ()),\n    'AntlrObjectiveCLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With ObjectiveC Target', ('antlr-objc',), ('*.G', '*.g'), ()),\n    'AntlrPerlLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Perl Target', ('antlr-perl',), ('*.G', '*.g'), ()),\n    'AntlrPythonLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Python Target', ('antlr-python',), ('*.G', '*.g'), ()),\n    'AntlrRubyLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Ruby Target', ('antlr-ruby', 'antlr-rb'), ('*.G', '*.g'), ()),\n    'ApacheConfLexer': ('pip._vendor.pygments.lexers.configs', 'ApacheConf', ('apacheconf', 'aconf', 'apache'), ('.htaccess', 'apache.conf', 'apache2.conf'), ('text/x-apacheconf',)),\n    'AppleScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'AppleScript', ('applescript',), ('*.applescript',), ()),\n    'ArduinoLexer': ('pip._vendor.pygments.lexers.c_like', 'Arduino', ('arduino',), ('*.ino',), ('text/x-arduino',)),\n    'ArrowLexer': ('pip._vendor.pygments.lexers.arrow', 'Arrow', ('arrow',), ('*.arw',), ()),\n    'ArturoLexer': ('pip._vendor.pygments.lexers.arturo', 'Arturo', ('arturo', 'art'), ('*.art',), ()),\n    'AscLexer': ('pip._vendor.pygments.lexers.asc', 'ASCII armored', ('asc', 'pem'), ('*.asc', '*.pem', 'id_dsa', 'id_ecdsa', 'id_ecdsa_sk', 'id_ed25519', 'id_ed25519_sk', 'id_rsa'), ('application/pgp-keys', 'application/pgp-encrypted', 'application/pgp-signature', 'application/pem-certificate-chain')),\n    'Asn1Lexer': ('pip._vendor.pygments.lexers.asn1', 'ASN.1', ('asn1',), ('*.asn1',), ()),\n    'AspectJLexer': ('pip._vendor.pygments.lexers.jvm', 'AspectJ', ('aspectj',), ('*.aj',), ('text/x-aspectj',)),\n    'AsymptoteLexer': ('pip._vendor.pygments.lexers.graphics', 'Asymptote', ('asymptote', 'asy'), ('*.asy',), ('text/x-asymptote',)),\n    'AugeasLexer': ('pip._vendor.pygments.lexers.configs', 'Augeas', ('augeas',), ('*.aug',), ()),\n    'AutoItLexer': ('pip._vendor.pygments.lexers.automation', 'AutoIt', ('autoit',), ('*.au3',), ('text/x-autoit',)),\n    'AutohotkeyLexer': ('pip._vendor.pygments.lexers.automation', 'autohotkey', ('autohotkey', 'ahk'), ('*.ahk', '*.ahkl'), ('text/x-autohotkey',)),\n    'AwkLexer': ('pip._vendor.pygments.lexers.textedit', 'Awk', ('awk', 'gawk', 'mawk', 'nawk'), ('*.awk',), ('application/x-awk',)),\n    'BBCBasicLexer': ('pip._vendor.pygments.lexers.basic', 'BBC Basic', ('bbcbasic',), ('*.bbc',), ()),\n    'BBCodeLexer': ('pip._vendor.pygments.lexers.markup', 'BBCode', ('bbcode',), (), ('text/x-bbcode',)),\n    'BCLexer': ('pip._vendor.pygments.lexers.algebra', 'BC', ('bc',), ('*.bc',), ()),\n    'BQNLexer': ('pip._vendor.pygments.lexers.bqn', 'BQN', ('bqn',), ('*.bqn',), ()),\n    'BSTLexer': ('pip._vendor.pygments.lexers.bibtex', 'BST', ('bst', 'bst-pybtex'), ('*.bst',), ()),\n    'BareLexer': ('pip._vendor.pygments.lexers.bare', 'BARE', ('bare',), ('*.bare',), ()),\n    'BaseMakefileLexer': ('pip._vendor.pygments.lexers.make', 'Base Makefile', ('basemake',), (), ()),\n    'BashLexer': ('pip._vendor.pygments.lexers.shell', 'Bash', ('bash', 'sh', 'ksh', 'zsh', 'shell', 'openrc'), ('*.sh', '*.ksh', '*.bash', '*.ebuild', '*.eclass', '*.exheres-0', '*.exlib', '*.zsh', '.bashrc', 'bashrc', '.bash_*', 'bash_*', 'zshrc', '.zshrc', '.kshrc', 'kshrc', 'PKGBUILD'), ('application/x-sh', 'application/x-shellscript', 'text/x-shellscript')),\n    'BashSessionLexer': ('pip._vendor.pygments.lexers.shell', 'Bash Session', ('console', 'shell-session'), ('*.sh-session', '*.shell-session'), ('application/x-shell-session', 'application/x-sh-session')),\n    'BatchLexer': ('pip._vendor.pygments.lexers.shell', 'Batchfile', ('batch', 'bat', 'dosbatch', 'winbatch'), ('*.bat', '*.cmd'), ('application/x-dos-batch',)),\n    'BddLexer': ('pip._vendor.pygments.lexers.bdd', 'Bdd', ('bdd',), ('*.feature',), ('text/x-bdd',)),\n    'BefungeLexer': ('pip._vendor.pygments.lexers.esoteric', 'Befunge', ('befunge',), ('*.befunge',), ('application/x-befunge',)),\n    'BerryLexer': ('pip._vendor.pygments.lexers.berry', 'Berry', ('berry', 'be'), ('*.be',), ('text/x-berry', 'application/x-berry')),\n    'BibTeXLexer': ('pip._vendor.pygments.lexers.bibtex', 'BibTeX', ('bibtex', 'bib'), ('*.bib',), ('text/x-bibtex',)),\n    'BlitzBasicLexer': ('pip._vendor.pygments.lexers.basic', 'BlitzBasic', ('blitzbasic', 'b3d', 'bplus'), ('*.bb', '*.decls'), ('text/x-bb',)),\n    'BlitzMaxLexer': ('pip._vendor.pygments.lexers.basic', 'BlitzMax', ('blitzmax', 'bmax'), ('*.bmx',), ('text/x-bmx',)),\n    'BlueprintLexer': ('pip._vendor.pygments.lexers.blueprint', 'Blueprint', ('blueprint',), ('*.blp',), ('text/x-blueprint',)),\n    'BnfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'BNF', ('bnf',), ('*.bnf',), ('text/x-bnf',)),\n    'BoaLexer': ('pip._vendor.pygments.lexers.boa', 'Boa', ('boa',), ('*.boa',), ()),\n    'BooLexer': ('pip._vendor.pygments.lexers.dotnet', 'Boo', ('boo',), ('*.boo',), ('text/x-boo',)),\n    'BoogieLexer': ('pip._vendor.pygments.lexers.verification', 'Boogie', ('boogie',), ('*.bpl',), ()),\n    'BrainfuckLexer': ('pip._vendor.pygments.lexers.esoteric', 'Brainfuck', ('brainfuck', 'bf'), ('*.bf', '*.b'), ('application/x-brainfuck',)),\n    'BugsLexer': ('pip._vendor.pygments.lexers.modeling', 'BUGS', ('bugs', 'winbugs', 'openbugs'), ('*.bug',), ()),\n    'CAmkESLexer': ('pip._vendor.pygments.lexers.esoteric', 'CAmkES', ('camkes', 'idl4'), ('*.camkes', '*.idl4'), ()),\n    'CLexer': ('pip._vendor.pygments.lexers.c_cpp', 'C', ('c',), ('*.c', '*.h', '*.idc', '*.x[bp]m'), ('text/x-chdr', 'text/x-csrc', 'image/x-xbitmap', 'image/x-xpixmap')),\n    'CMakeLexer': ('pip._vendor.pygments.lexers.make', 'CMake', ('cmake',), ('*.cmake', 'CMakeLists.txt'), ('text/x-cmake',)),\n    'CObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'c-objdump', ('c-objdump',), ('*.c-objdump',), ('text/x-c-objdump',)),\n    'CPSALexer': ('pip._vendor.pygments.lexers.lisp', 'CPSA', ('cpsa',), ('*.cpsa',), ()),\n    'CSSUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'CSS+UL4', ('css+ul4',), ('*.cssul4',), ()),\n    'CSharpAspxLexer': ('pip._vendor.pygments.lexers.dotnet', 'aspx-cs', ('aspx-cs',), ('*.aspx', '*.asax', '*.ascx', '*.ashx', '*.asmx', '*.axd'), ()),\n    'CSharpLexer': ('pip._vendor.pygments.lexers.dotnet', 'C#', ('csharp', 'c#', 'cs'), ('*.cs',), ('text/x-csharp',)),\n    'Ca65Lexer': ('pip._vendor.pygments.lexers.asm', 'ca65 assembler', ('ca65',), ('*.s',), ()),\n    'CadlLexer': ('pip._vendor.pygments.lexers.archetype', 'cADL', ('cadl',), ('*.cadl',), ()),\n    'CapDLLexer': ('pip._vendor.pygments.lexers.esoteric', 'CapDL', ('capdl',), ('*.cdl',), ()),\n    'CapnProtoLexer': ('pip._vendor.pygments.lexers.capnproto', \"Cap'n Proto\", ('capnp',), ('*.capnp',), ()),\n    'CarbonLexer': ('pip._vendor.pygments.lexers.carbon', 'Carbon', ('carbon',), ('*.carbon',), ('text/x-carbon',)),\n    'CbmBasicV2Lexer': ('pip._vendor.pygments.lexers.basic', 'CBM BASIC V2', ('cbmbas',), ('*.bas',), ()),\n    'CddlLexer': ('pip._vendor.pygments.lexers.cddl', 'CDDL', ('cddl',), ('*.cddl',), ('text/x-cddl',)),\n    'CeylonLexer': ('pip._vendor.pygments.lexers.jvm', 'Ceylon', ('ceylon',), ('*.ceylon',), ('text/x-ceylon',)),\n    'Cfengine3Lexer': ('pip._vendor.pygments.lexers.configs', 'CFEngine3', ('cfengine3', 'cf3'), ('*.cf',), ()),\n    'ChaiscriptLexer': ('pip._vendor.pygments.lexers.scripting', 'ChaiScript', ('chaiscript', 'chai'), ('*.chai',), ('text/x-chaiscript', 'application/x-chaiscript')),\n    'ChapelLexer': ('pip._vendor.pygments.lexers.chapel', 'Chapel', ('chapel', 'chpl'), ('*.chpl',), ()),\n    'CharmciLexer': ('pip._vendor.pygments.lexers.c_like', 'Charmci', ('charmci',), ('*.ci',), ()),\n    'CheetahHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Cheetah', ('html+cheetah', 'html+spitfire', 'htmlcheetah'), (), ('text/html+cheetah', 'text/html+spitfire')),\n    'CheetahJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Cheetah', ('javascript+cheetah', 'js+cheetah', 'javascript+spitfire', 'js+spitfire'), (), ('application/x-javascript+cheetah', 'text/x-javascript+cheetah', 'text/javascript+cheetah', 'application/x-javascript+spitfire', 'text/x-javascript+spitfire', 'text/javascript+spitfire')),\n    'CheetahLexer': ('pip._vendor.pygments.lexers.templates', 'Cheetah', ('cheetah', 'spitfire'), ('*.tmpl', '*.spt'), ('application/x-cheetah', 'application/x-spitfire')),\n    'CheetahXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Cheetah', ('xml+cheetah', 'xml+spitfire'), (), ('application/xml+cheetah', 'application/xml+spitfire')),\n    'CirruLexer': ('pip._vendor.pygments.lexers.webmisc', 'Cirru', ('cirru',), ('*.cirru',), ('text/x-cirru',)),\n    'ClayLexer': ('pip._vendor.pygments.lexers.c_like', 'Clay', ('clay',), ('*.clay',), ('text/x-clay',)),\n    'CleanLexer': ('pip._vendor.pygments.lexers.clean', 'Clean', ('clean',), ('*.icl', '*.dcl'), ()),\n    'ClojureLexer': ('pip._vendor.pygments.lexers.jvm', 'Clojure', ('clojure', 'clj'), ('*.clj', '*.cljc'), ('text/x-clojure', 'application/x-clojure')),\n    'ClojureScriptLexer': ('pip._vendor.pygments.lexers.jvm', 'ClojureScript', ('clojurescript', 'cljs'), ('*.cljs',), ('text/x-clojurescript', 'application/x-clojurescript')),\n    'CobolFreeformatLexer': ('pip._vendor.pygments.lexers.business', 'COBOLFree', ('cobolfree',), ('*.cbl', '*.CBL'), ()),\n    'CobolLexer': ('pip._vendor.pygments.lexers.business', 'COBOL', ('cobol',), ('*.cob', '*.COB', '*.cpy', '*.CPY'), ('text/x-cobol',)),\n    'CodeQLLexer': ('pip._vendor.pygments.lexers.codeql', 'CodeQL', ('codeql', 'ql'), ('*.ql', '*.qll'), ()),\n    'CoffeeScriptLexer': ('pip._vendor.pygments.lexers.javascript', 'CoffeeScript', ('coffeescript', 'coffee-script', 'coffee'), ('*.coffee',), ('text/coffeescript',)),\n    'ColdfusionCFCLexer': ('pip._vendor.pygments.lexers.templates', 'Coldfusion CFC', ('cfc',), ('*.cfc',), ()),\n    'ColdfusionHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'Coldfusion HTML', ('cfm',), ('*.cfm', '*.cfml'), ('application/x-coldfusion',)),\n    'ColdfusionLexer': ('pip._vendor.pygments.lexers.templates', 'cfstatement', ('cfs',), (), ()),\n    'Comal80Lexer': ('pip._vendor.pygments.lexers.comal', 'COMAL-80', ('comal', 'comal80'), ('*.cml', '*.comal'), ()),\n    'CommonLispLexer': ('pip._vendor.pygments.lexers.lisp', 'Common Lisp', ('common-lisp', 'cl', 'lisp'), ('*.cl', '*.lisp'), ('text/x-common-lisp',)),\n    'ComponentPascalLexer': ('pip._vendor.pygments.lexers.oberon', 'Component Pascal', ('componentpascal', 'cp'), ('*.cp', '*.cps'), ('text/x-component-pascal',)),\n    'CoqLexer': ('pip._vendor.pygments.lexers.theorem', 'Coq', ('coq',), ('*.v',), ('text/x-coq',)),\n    'CplintLexer': ('pip._vendor.pygments.lexers.cplint', 'cplint', ('cplint',), ('*.ecl', '*.prolog', '*.pro', '*.pl', '*.P', '*.lpad', '*.cpl'), ('text/x-cplint',)),\n    'CppLexer': ('pip._vendor.pygments.lexers.c_cpp', 'C++', ('cpp', 'c++'), ('*.cpp', '*.hpp', '*.c++', '*.h++', '*.cc', '*.hh', '*.cxx', '*.hxx', '*.C', '*.H', '*.cp', '*.CPP', '*.tpp'), ('text/x-c++hdr', 'text/x-c++src')),\n    'CppObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'cpp-objdump', ('cpp-objdump', 'c++-objdumb', 'cxx-objdump'), ('*.cpp-objdump', '*.c++-objdump', '*.cxx-objdump'), ('text/x-cpp-objdump',)),\n    'CrmshLexer': ('pip._vendor.pygments.lexers.dsls', 'Crmsh', ('crmsh', 'pcmk'), ('*.crmsh', '*.pcmk'), ()),\n    'CrocLexer': ('pip._vendor.pygments.lexers.d', 'Croc', ('croc',), ('*.croc',), ('text/x-crocsrc',)),\n    'CryptolLexer': ('pip._vendor.pygments.lexers.haskell', 'Cryptol', ('cryptol', 'cry'), ('*.cry',), ('text/x-cryptol',)),\n    'CrystalLexer': ('pip._vendor.pygments.lexers.crystal', 'Crystal', ('cr', 'crystal'), ('*.cr',), ('text/x-crystal',)),\n    'CsoundDocumentLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Document', ('csound-document', 'csound-csd'), ('*.csd',), ()),\n    'CsoundOrchestraLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Orchestra', ('csound', 'csound-orc'), ('*.orc', '*.udo'), ()),\n    'CsoundScoreLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Score', ('csound-score', 'csound-sco'), ('*.sco',), ()),\n    'CssDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Django/Jinja', ('css+django', 'css+jinja'), ('*.css.j2', '*.css.jinja2'), ('text/css+django', 'text/css+jinja')),\n    'CssErbLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Ruby', ('css+ruby', 'css+erb'), (), ('text/css+ruby',)),\n    'CssGenshiLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Genshi Text', ('css+genshitext', 'css+genshi'), (), ('text/css+genshi',)),\n    'CssLexer': ('pip._vendor.pygments.lexers.css', 'CSS', ('css',), ('*.css',), ('text/css',)),\n    'CssPhpLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+PHP', ('css+php',), (), ('text/css+php',)),\n    'CssSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Smarty', ('css+smarty',), (), ('text/css+smarty',)),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\lexers\\__init__.py": {
      "sha": "b607f075d7ee",
      "lines": 362,
      "head": "\"\"\"\n    pygments.lexers\n    ~~~~~~~~~~~~~~~\n\n    Pygments lexers.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nimport sys\nimport types\nimport fnmatch\nfrom os.path import basename\n\nfrom pip._vendor.pygments.lexers._mapping import LEXERS\nfrom pip._vendor.pygments.modeline import get_filetype_from_buffer\nfrom pip._vendor.pygments.plugin import find_plugin_lexers\nfrom pip._vendor.pygments.util import ClassNotFound, guess_decode\n\nCOMPAT = {\n    'Python3Lexer': 'PythonLexer',\n    'Python3TracebackLexer': 'PythonTracebackLexer',\n    'LeanLexer': 'Lean3Lexer',\n}\n\n__all__ = ['get_lexer_by_name', 'get_lexer_for_filename', 'find_lexer_class',\n           'guess_lexer', 'load_lexer_from_file'] + list(LEXERS) + list(COMPAT)\n\n_lexer_cache = {}\n_pattern_cache = {}\n\n\ndef _fn_matches(fn, glob):\n    \"\"\"Return whether the supplied file name fn matches pattern filename.\"\"\"\n    if glob not in _pattern_cache:\n        pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))\n        return pattern.match(fn)\n    return _pattern_cache[glob].match(fn)\n\n\ndef _load_lexers(module_name):\n    \"\"\"Load a lexer (and all others in the module too).\"\"\"\n    mod = __import__(module_name, None, None, ['__all__'])\n    for lexer_name in mod.__all__:\n        cls = getattr(mod, lexer_name)\n        _lexer_cache[cls.name] = cls\n\n\ndef get_all_lexers(plugins=True):\n    \"\"\"Return a generator of tuples in the form ``(name, aliases,\n    filenames, mimetypes)`` of all know lexers.\n\n    If *plugins* is true (the default), plugin lexers supplied by entrypoints\n    are also returned.  Otherwise, only builtin ones are considered.\n    \"\"\"\n    for item in LEXERS.values():\n        yield item[1:]\n    if plugins:\n        for lexer in find_plugin_lexers():\n            yield lexer.name, lexer.aliases, lexer.filenames, lexer.mimetypes\n\n\ndef find_lexer_class(name):\n    \"\"\"\n    Return the `Lexer` subclass that with the *name* attribute as given by\n    the *name* argument.\n    \"\"\"\n    if name in _lexer_cache:\n        return _lexer_cache[name]\n    # lookup builtin lexers\n    for module_name, lname, aliases, _, _ in LEXERS.values():\n        if name == lname:\n            _load_lexers(module_name)\n            return _lexer_cache[name]\n    # continue with lexers from setuptools entrypoints\n    for cls in find_plugin_lexers():\n        if cls.name == name:\n            return cls\n\n\ndef find_lexer_class_by_name(_alias):\n    \"\"\"\n    Return the `Lexer` subclass that has `alias` in its aliases list, without\n    instantiating it.\n\n    Like `get_lexer_by_name`, but does not instantiate the class.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is\n    found.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if not _alias:\n        raise ClassNotFound(f'no lexer for alias {_alias!r} found')\n    # lookup builtin lexers\n    for module_name, name, aliases, _, _ in LEXERS.values():\n        if _alias.lower() in aliases:\n            if name not in _lexer_cache:\n                _load_lexers(module_name)\n            return _lexer_cache[name]\n    # continue with lexers from setuptools entrypoints\n    for cls in find_plugin_lexers():\n        if _alias.lower() in cls.aliases:\n            return cls\n    raise ClassNotFound(f'no lexer for alias {_alias!r} found')\n\n\ndef get_lexer_by_name(_alias, **options):\n    \"\"\"\n    Return an instance of a `Lexer` subclass that has `alias` in its\n    aliases list. The lexer is given the `options` at its\n    instantiation.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is\n    found.\n    \"\"\"\n    if not _alias:\n        raise ClassNotFound(f'no lexer for alias {_alias!r} found')\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\styles\\_mapping.py": {
      "sha": "651359ef16bc",
      "lines": 54,
      "head": "# Automatically generated by scripts/gen_mapfiles.py.\n# DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.\n\nSTYLES = {\n    'AbapStyle': ('pygments.styles.abap', 'abap', ()),\n    'AlgolStyle': ('pygments.styles.algol', 'algol', ()),\n    'Algol_NuStyle': ('pygments.styles.algol_nu', 'algol_nu', ()),\n    'ArduinoStyle': ('pygments.styles.arduino', 'arduino', ()),\n    'AutumnStyle': ('pygments.styles.autumn', 'autumn', ()),\n    'BlackWhiteStyle': ('pygments.styles.bw', 'bw', ()),\n    'BorlandStyle': ('pygments.styles.borland', 'borland', ()),\n    'CoffeeStyle': ('pygments.styles.coffee', 'coffee', ()),\n    'ColorfulStyle': ('pygments.styles.colorful', 'colorful', ()),\n    'DefaultStyle': ('pygments.styles.default', 'default', ()),\n    'DraculaStyle': ('pygments.styles.dracula', 'dracula', ()),\n    'EmacsStyle': ('pygments.styles.emacs', 'emacs', ()),\n    'FriendlyGrayscaleStyle': ('pygments.styles.friendly_grayscale', 'friendly_grayscale', ()),\n    'FriendlyStyle': ('pygments.styles.friendly', 'friendly', ()),\n    'FruityStyle': ('pygments.styles.fruity', 'fruity', ()),\n    'GhDarkStyle': ('pygments.styles.gh_dark', 'github-dark', ()),\n    'GruvboxDarkStyle': ('pygments.styles.gruvbox', 'gruvbox-dark', ()),\n    'GruvboxLightStyle': ('pygments.styles.gruvbox', 'gruvbox-light', ()),\n    'IgorStyle': ('pygments.styles.igor', 'igor', ()),\n    'InkPotStyle': ('pygments.styles.inkpot', 'inkpot', ()),\n    'LightbulbStyle': ('pygments.styles.lightbulb', 'lightbulb', ()),\n    'LilyPondStyle': ('pygments.styles.lilypond', 'lilypond', ()),\n    'LovelaceStyle': ('pygments.styles.lovelace', 'lovelace', ()),\n    'ManniStyle': ('pygments.styles.manni', 'manni', ()),\n    'MaterialStyle': ('pygments.styles.material', 'material', ()),\n    'MonokaiStyle': ('pygments.styles.monokai', 'monokai', ()),\n    'MurphyStyle': ('pygments.styles.murphy', 'murphy', ()),\n    'NativeStyle': ('pygments.styles.native', 'native', ()),\n    'NordDarkerStyle': ('pygments.styles.nord', 'nord-darker', ()),\n    'NordStyle': ('pygments.styles.nord', 'nord', ()),\n    'OneDarkStyle': ('pygments.styles.onedark', 'one-dark', ()),\n    'ParaisoDarkStyle': ('pygments.styles.paraiso_dark', 'paraiso-dark', ()),\n    'ParaisoLightStyle': ('pygments.styles.paraiso_light', 'paraiso-light', ()),\n    'PastieStyle': ('pygments.styles.pastie', 'pastie', ()),\n    'PerldocStyle': ('pygments.styles.perldoc', 'perldoc', ()),\n    'RainbowDashStyle': ('pygments.styles.rainbow_dash', 'rainbow_dash', ()),\n    'RrtStyle': ('pygments.styles.rrt', 'rrt', ()),\n    'SasStyle': ('pygments.styles.sas', 'sas', ()),\n    'SolarizedDarkStyle': ('pygments.styles.solarized', 'solarized-dark', ()),\n    'SolarizedLightStyle': ('pygments.styles.solarized', 'solarized-light', ()),\n    'StarofficeStyle': ('pygments.styles.staroffice', 'staroffice', ()),\n    'StataDarkStyle': ('pygments.styles.stata_dark', 'stata-dark', ()),\n    'StataLightStyle': ('pygments.styles.stata_light', 'stata-light', ()),\n    'TangoStyle': ('pygments.styles.tango', 'tango', ()),\n    'TracStyle': ('pygments.styles.trac', 'trac', ()),\n    'VimStyle': ('pygments.styles.vim', 'vim', ()),\n    'VisualStudioStyle': ('pygments.styles.vs', 'vs', ()),\n    'XcodeStyle': ('pygments.styles.xcode', 'xcode', ()),\n    'ZenburnStyle': ('pygments.styles.zenburn', 'zenburn', ()),\n}\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pygments\\styles\\__init__.py": {
      "sha": "5f74c006a2bf",
      "lines": 61,
      "head": "\"\"\"\n    pygments.styles\n    ~~~~~~~~~~~~~~~\n\n    Contains built-in styles.\n\n    :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.plugin import find_plugin_styles\nfrom pip._vendor.pygments.util import ClassNotFound\nfrom pip._vendor.pygments.styles._mapping import STYLES\n\n#: A dictionary of built-in styles, mapping style names to\n#: ``'submodule::classname'`` strings.\n#: This list is deprecated. Use `pygments.styles.STYLES` instead\nSTYLE_MAP = {v[1]: v[0].split('.')[-1] + '::' + k for k, v in STYLES.items()}\n\n#: Internal reverse mapping to make `get_style_by_name` more efficient\n_STYLE_NAME_TO_MODULE_MAP = {v[1]: (v[0], k) for k, v in STYLES.items()}\n\n\ndef get_style_by_name(name):\n    \"\"\"\n    Return a style class by its short name. The names of the builtin styles\n    are listed in :data:`pygments.styles.STYLE_MAP`.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no style of that name is\n    found.\n    \"\"\"\n    if name in _STYLE_NAME_TO_MODULE_MAP:\n        mod, cls = _STYLE_NAME_TO_MODULE_MAP[name]\n        builtin = \"yes\"\n    else:\n        for found_name, style in find_plugin_styles():\n            if name == found_name:\n                return style\n        # perhaps it got dropped into our styles package\n        builtin = \"\"\n        mod = 'pygments.styles.' + name\n        cls = name.title() + \"Style\"\n\n    try:\n        mod = __import__(mod, None, None, [cls])\n    except ImportError:\n        raise ClassNotFound(f\"Could not find style module {mod!r}\" +\n                            (builtin and \", though it should be builtin\")\n                            + \".\")\n    try:\n        return getattr(mod, cls)\n    except AttributeError:\n        raise ClassNotFound(f\"Could not find style class {cls!r} in style module.\")\n\n\ndef get_all_styles():\n    \"\"\"Return a generator for all styles by name, both builtin and plugin.\"\"\"\n    for v in STYLES.values():\n        yield v[1]\n    for name, _ in find_plugin_styles():\n        yield name\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py": {
      "sha": "823d53ff5e06",
      "lines": 410,
      "head": "import json\nimport os\nimport sys\nimport tempfile\nfrom contextlib import contextmanager\nfrom os.path import abspath\nfrom os.path import join as pjoin\nfrom subprocess import STDOUT, check_call, check_output\nfrom typing import TYPE_CHECKING, Any, Iterator, Mapping, Optional, Sequence\n\nfrom ._in_process import _in_proc_script_path\n\nif TYPE_CHECKING:\n    from typing import Protocol\n\n    class SubprocessRunner(Protocol):\n        \"\"\"A protocol for the subprocess runner.\"\"\"\n\n        def __call__(\n            self,\n            cmd: Sequence[str],\n            cwd: Optional[str] = None,\n            extra_environ: Optional[Mapping[str, str]] = None,\n        ) -> None:\n            ...\n\n\ndef write_json(obj: Mapping[str, Any], path: str, **kwargs) -> None:\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(obj, f, **kwargs)\n\n\ndef read_json(path: str) -> Mapping[str, Any]:\n    with open(path, encoding=\"utf-8\") as f:\n        return json.load(f)\n\n\nclass BackendUnavailable(Exception):\n    \"\"\"Will be raised if the backend cannot be imported in the hook process.\"\"\"\n\n    def __init__(\n        self,\n        traceback: str,\n        message: Optional[str] = None,\n        backend_name: Optional[str] = None,\n        backend_path: Optional[Sequence[str]] = None,\n    ) -> None:\n        # Preserving arg order for the sake of API backward compatibility.\n        self.backend_name = backend_name\n        self.backend_path = backend_path\n        self.traceback = traceback\n        super().__init__(message or \"Error while importing backend\")\n\n\nclass HookMissing(Exception):\n    \"\"\"Will be raised on missing hooks (if a fallback can't be used).\"\"\"\n\n    def __init__(self, hook_name: str) -> None:\n        super().__init__(hook_name)\n        self.hook_name = hook_name\n\n\nclass UnsupportedOperation(Exception):\n    \"\"\"May be raised by build_sdist if the backend indicates that it can't.\"\"\"\n\n    def __init__(self, traceback: str) -> None:\n        self.traceback = traceback\n\n\ndef default_subprocess_runner(\n    cmd: Sequence[str],\n    cwd: Optional[str] = None,\n    extra_environ: Optional[Mapping[str, str]] = None,\n) -> None:\n    \"\"\"The default method of calling the wrapper subprocess.\n\n    This uses :func:`subprocess.check_call` under the hood.\n    \"\"\"\n    env = os.environ.copy()\n    if extra_environ:\n        env.update(extra_environ)\n\n    check_call(cmd, cwd=cwd, env=env)\n\n\ndef quiet_subprocess_runner(\n    cmd: Sequence[str],\n    cwd: Optional[str] = None,\n    extra_environ: Optional[Mapping[str, str]] = None,\n) -> None:\n    \"\"\"Call the subprocess while suppressing output.\n\n    This uses :func:`subprocess.check_output` under the hood.\n    \"\"\"\n    env = os.environ.copy()\n    if extra_environ:\n        env.update(extra_environ)\n\n    check_output(cmd, cwd=cwd, env=env, stderr=STDOUT)\n\n\ndef norm_and_check(source_tree: str, requested: str) -> str:\n    \"\"\"Normalise and check a backend path.\n\n    Ensure that the requested backend path is specified as a relative path,\n    and resolves to a location under the given source tree.\n\n    Return an absolute version of the requested path.\n    \"\"\"\n    if os.path.isabs(requested):\n        raise ValueError(\"paths must be relative\")\n\n    abs_source = os.path.abspath(source_tree)\n    abs_requested = os.path.normpath(os.path.join(abs_source, requested))\n    # We have to use commonprefix for Python 2.7 compatibility. So we\n    # normalise case to avoid problems because commonprefix is a character\n    # based comparison :-(\n    norm_source = os.path.normcase(abs_source)\n    norm_requested = os.path.normcase(abs_requested)\n    if os.path.commonprefix([norm_source, norm_requested]) != norm_source:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\__init__.py": {
      "sha": "bf82c531b8de",
      "lines": 31,
      "head": "\"\"\"Wrappers to call pyproject.toml-based build backend hooks.\n\"\"\"\n\nfrom typing import TYPE_CHECKING\n\nfrom ._impl import (\n    BackendUnavailable,\n    BuildBackendHookCaller,\n    HookMissing,\n    UnsupportedOperation,\n    default_subprocess_runner,\n    quiet_subprocess_runner,\n)\n\n__version__ = \"1.2.0\"\n__all__ = [\n    \"BackendUnavailable\",\n    \"BackendInvalid\",\n    \"HookMissing\",\n    \"UnsupportedOperation\",\n    \"default_subprocess_runner\",\n    \"quiet_subprocess_runner\",\n    \"BuildBackendHookCaller\",\n]\n\nBackendInvalid = BackendUnavailable  # Deprecated alias, previously a separate exception\n\nif TYPE_CHECKING:\n    from ._impl import SubprocessRunner\n\n    __all__ += [\"SubprocessRunner\"]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py": {
      "sha": "6cf78aa27d0c",
      "lines": 389,
      "head": "\"\"\"This is invoked in a subprocess to call the build backend hooks.\n\nIt expects:\n- Command line args: hook_name, control_dir\n- Environment variables:\n      _PYPROJECT_HOOKS_BUILD_BACKEND=entry.point:spec\n      _PYPROJECT_HOOKS_BACKEND_PATH=paths (separated with os.pathsep)\n- control_dir/input.json:\n  - {\"kwargs\": {...}}\n\nResults:\n- control_dir/output.json\n  - {\"return_val\": ...}\n\"\"\"\nimport json\nimport os\nimport os.path\nimport re\nimport shutil\nimport sys\nimport traceback\nfrom glob import glob\nfrom importlib import import_module\nfrom importlib.machinery import PathFinder\nfrom os.path import join as pjoin\n\n# This file is run as a script, and `import wrappers` is not zip-safe, so we\n# include write_json() and read_json() from wrappers.py.\n\n\ndef write_json(obj, path, **kwargs):\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(obj, f, **kwargs)\n\n\ndef read_json(path):\n    with open(path, encoding=\"utf-8\") as f:\n        return json.load(f)\n\n\nclass BackendUnavailable(Exception):\n    \"\"\"Raised if we cannot import the backend\"\"\"\n\n    def __init__(self, message, traceback=None):\n        super().__init__(message)\n        self.message = message\n        self.traceback = traceback\n\n\nclass HookMissing(Exception):\n    \"\"\"Raised if a hook is missing and we are not executing the fallback\"\"\"\n\n    def __init__(self, hook_name=None):\n        super().__init__(hook_name)\n        self.hook_name = hook_name\n\n\ndef _build_backend():\n    \"\"\"Find and load the build backend\"\"\"\n    backend_path = os.environ.get(\"_PYPROJECT_HOOKS_BACKEND_PATH\")\n    ep = os.environ[\"_PYPROJECT_HOOKS_BUILD_BACKEND\"]\n    mod_path, _, obj_path = ep.partition(\":\")\n\n    if backend_path:\n        # Ensure in-tree backend directories have the highest priority when importing.\n        extra_pathitems = backend_path.split(os.pathsep)\n        sys.meta_path.insert(0, _BackendPathFinder(extra_pathitems, mod_path))\n\n    try:\n        obj = import_module(mod_path)\n    except ImportError:\n        msg = f\"Cannot import {mod_path!r}\"\n        raise BackendUnavailable(msg, traceback.format_exc())\n\n    if obj_path:\n        for path_part in obj_path.split(\".\"):\n            obj = getattr(obj, path_part)\n    return obj\n\n\nclass _BackendPathFinder:\n    \"\"\"Implements the MetaPathFinder interface to locate modules in ``backend-path``.\n\n    Since the environment provided by the frontend can contain all sorts of\n    MetaPathFinders, the only way to ensure the backend is loaded from the\n    right place is to prepend our own.\n    \"\"\"\n\n    def __init__(self, backend_path, backend_module):\n        self.backend_path = backend_path\n        self.backend_module = backend_module\n        self.backend_parent, _, _ = backend_module.partition(\".\")\n\n    def find_spec(self, fullname, _path, _target=None):\n        if \".\" in fullname:\n            # Rely on importlib to find nested modules based on parent's path\n            return None\n\n        # Ignore other items in _path or sys.path and use backend_path instead:\n        spec = PathFinder.find_spec(fullname, path=self.backend_path)\n        if spec is None and fullname == self.backend_parent:\n            # According to the spec, the backend MUST be loaded from backend-path.\n            # Therefore, we can halt the import machinery and raise a clean error.\n            msg = f\"Cannot find module {self.backend_module!r} in {self.backend_path!r}\"\n            raise BackendUnavailable(msg)\n\n        return spec\n\n    if sys.version_info >= (3, 8):\n\n        def find_distributions(self, context=None):\n            # Delayed import: Python 3.7 does not contain importlib.metadata\n            from importlib.metadata import DistributionFinder, MetadataPathFinder\n\n            context = DistributionFinder.Context(path=self.backend_path)\n            return MetadataPathFinder.find_distributions(context=context)\n\n\ndef _supported_features():\n    \"\"\"Return the list of options features supported by the backend.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\__init__.py": {
      "sha": "f3d8f7bc5567",
      "lines": 21,
      "head": "\"\"\"This is a subpackage because the directory is on sys.path for _in_process.py\n\nThe subpackage should stay as empty as possible to avoid shadowing modules that\nthe backend might import.\n\"\"\"\n\nimport importlib.resources as resources\n\ntry:\n    resources.files\nexcept AttributeError:\n    # Python 3.8 compatibility\n    def _in_proc_script_path():\n        return resources.path(__package__, \"_in_process.py\")\n\nelse:\n\n    def _in_proc_script_path():\n        return resources.as_file(\n            resources.files(__package__).joinpath(\"_in_process.py\")\n        )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\adapters.py": {
      "sha": "1d9144b5df49",
      "lines": 719,
      "head": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom pip._vendor.urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom pip._vendor.urllib3.exceptions import HTTPError as _HTTPError\nfrom pip._vendor.urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom pip._vendor.urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom pip._vendor.urllib3.exceptions import ProxyError as _ProxyError\nfrom pip._vendor.urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom pip._vendor.urllib3.exceptions import SSLError as _SSLError\nfrom pip._vendor.urllib3.poolmanager import PoolManager, proxy_from_url\nfrom pip._vendor.urllib3.util import Timeout as TimeoutSauce\nfrom pip._vendor.urllib3.util import parse_url\nfrom pip._vendor.urllib3.util.retry import Retry\nfrom pip._vendor.urllib3.util.ssl_ import create_urllib3_context\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from pip._vendor.urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ntry:\n    import ssl  # noqa: F401\n\n    _preloaded_ssl_context = create_urllib3_context()\n    _preloaded_ssl_context.load_verify_locations(\n        extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)\n    )\nexcept ImportError:\n    # Bypass default SSLContext creation when Python\n    # interpreter isn't built with the ssl module.\n    _preloaded_ssl_context = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    poolmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    # Determine if we have and should use our default SSLContext\n    # to optimize performance on standard requests.\n    poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n    has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n    should_use_default_ssl_context = (\n        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n    )\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif verify is True and should_use_default_ssl_context:\n        pool_kwargs[\"ssl_context\"] = _preloaded_ssl_context\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\api.py": {
      "sha": "e2acc6d4ace7",
      "lines": 157,
      "head": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    kwargs.setdefault(\"allow_redirects\", False)\n    return request(\"head\", url, **kwargs)\n\n\ndef post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"post\", url, data=data, json=json, **kwargs)\n\n\ndef put(url, data=None, **kwargs):\n    r\"\"\"Sends a PUT request.\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\auth.py": {
      "sha": "bd96146ba418",
      "lines": 314,
      "head": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, password))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\certs.py": {
      "sha": "21c177768e83",
      "lines": 17,
      "head": "#!/usr/bin/env python\n\n\"\"\"\nrequests.certs\n~~~~~~~~~~~~~~\n\nThis module returns the preferred default CA certificate bundle. There is\nonly one \u2014 the one from the certifi package.\n\nIf you are packaging Requests, e.g., for a Linux distribution or a managed\nenvironment, you can change the definition of where() to return a separately\npackaged CA bundle.\n\"\"\"\nfrom pip._vendor.certifi import where\n\nif __name__ == \"__main__\":\n    print(where())\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\compat.py": {
      "sha": "bce2e637b167",
      "lines": 78,
      "head": "\"\"\"\nrequests.compat\n~~~~~~~~~~~~~~~\n\nThis module previously handled import compatibility issues\nbetween Python 2 and Python 3. It remains for backwards\ncompatibility until the next major version.\n\"\"\"\n\nimport sys\n\n# -------------------\n# Character Detection\n# -------------------\n\n\ndef _resolve_char_detection():\n    \"\"\"Find supported character detection libraries.\"\"\"\n    chardet = None\n    return chardet\n\n\nchardet = _resolve_char_detection()\n\n# -------\n# Pythons\n# -------\n\n# Syntax sugar.\n_ver = sys.version_info\n\n#: Python 2.x?\nis_py2 = _ver[0] == 2\n\n#: Python 3.x?\nis_py3 = _ver[0] == 3\n\n# Note: We've patched out simplejson support in pip because it prevents\n#       upgrading simplejson on Windows.\nimport json\nfrom json import JSONDecodeError\n\n# Keep OrderedDict for backwards compatibility.\nfrom collections import OrderedDict\nfrom collections.abc import Callable, Mapping, MutableMapping\nfrom http import cookiejar as cookielib\nfrom http.cookies import Morsel\nfrom io import StringIO\n\n# --------------\n# Legacy Imports\n# --------------\nfrom urllib.parse import (\n    quote,\n    quote_plus,\n    unquote,\n    unquote_plus,\n    urldefrag,\n    urlencode,\n    urljoin,\n    urlparse,\n    urlsplit,\n    urlunparse,\n)\nfrom urllib.request import (\n    getproxies,\n    getproxies_environment,\n    parse_http_list,\n    proxy_bypass,\n    proxy_bypass_environment,\n)\n\nbuiltin_str = str\nstr = str\nbytes = bytes\nbasestring = (str, bytes)\nnumeric_types = (int, float)\ninteger_types = (int,)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\cookies.py": {
      "sha": "904a118f4c9b",
      "lines": 561,
      "head": "\"\"\"\nrequests.cookies\n~~~~~~~~~~~~~~~~\n\nCompatibility code to be able to use `http.cookiejar.CookieJar` with requests.\n\nrequests.utils imports from here, so be careful with imports.\n\"\"\"\n\nimport calendar\nimport copy\nimport time\n\nfrom ._internal_utils import to_native_string\nfrom .compat import Morsel, MutableMapping, cookielib, urlparse, urlunparse\n\ntry:\n    import threading\nexcept ImportError:\n    import dummy_threading as threading\n\n\nclass MockRequest:\n    \"\"\"Wraps a `requests.Request` to mimic a `urllib2.Request`.\n\n    The code in `http.cookiejar.CookieJar` expects this interface in order to correctly\n    manage cookie policies, i.e., determine whether a cookie can be set, given the\n    domains of the request and the cookie.\n\n    The original request object is read-only. The client is responsible for collecting\n    the new headers via `get_new_headers()` and interpreting them appropriately. You\n    probably want `get_cookie_header`, defined below.\n    \"\"\"\n\n    def __init__(self, request):\n        self._r = request\n        self._new_headers = {}\n        self.type = urlparse(self._r.url).scheme\n\n    def get_type(self):\n        return self.type\n\n    def get_host(self):\n        return urlparse(self._r.url).netloc\n\n    def get_origin_req_host(self):\n        return self.get_host()\n\n    def get_full_url(self):\n        # Only return the response's URL if the user hadn't set the Host\n        # header\n        if not self._r.headers.get(\"Host\"):\n            return self._r.url\n        # If they did set it, retrieve it and reconstruct the expected domain\n        host = to_native_string(self._r.headers[\"Host\"], encoding=\"utf-8\")\n        parsed = urlparse(self._r.url)\n        # Reconstruct the URL as we expect it\n        return urlunparse(\n            [\n                parsed.scheme,\n                host,\n                parsed.path,\n                parsed.params,\n                parsed.query,\n                parsed.fragment,\n            ]\n        )\n\n    def is_unverifiable(self):\n        return True\n\n    def has_header(self, name):\n        return name in self._r.headers or name in self._new_headers\n\n    def get_header(self, name, default=None):\n        return self._r.headers.get(name, self._new_headers.get(name, default))\n\n    def add_header(self, key, val):\n        \"\"\"cookiejar has no legitimate use for this method; add it back if you find one.\"\"\"\n        raise NotImplementedError(\n            \"Cookie headers should be added with add_unredirected_header()\"\n        )\n\n    def add_unredirected_header(self, name, value):\n        self._new_headers[name] = value\n\n    def get_new_headers(self):\n        return self._new_headers\n\n    @property\n    def unverifiable(self):\n        return self.is_unverifiable()\n\n    @property\n    def origin_req_host(self):\n        return self.get_origin_req_host()\n\n    @property\n    def host(self):\n        return self.get_host()\n\n\nclass MockResponse:\n    \"\"\"Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.\n\n    ...what? Basically, expose the parsed HTTP headers from the server response\n    the way `http.cookiejar` expects to see them.\n    \"\"\"\n\n    def __init__(self, headers):\n        \"\"\"Make a MockResponse for `cookiejar` to read.\n\n        :param headers: a httplib.HTTPMessage or analogous carrying the headers\n        \"\"\"\n        self._headers = headers\n\n    def info(self):\n        return self._headers\n\n    def getheaders(self, name):\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\exceptions.py": {
      "sha": "34d85bda13b6",
      "lines": 151,
      "head": "\"\"\"\nrequests.exceptions\n~~~~~~~~~~~~~~~~~~~\n\nThis module contains the set of Requests' exceptions.\n\"\"\"\nfrom pip._vendor.urllib3.exceptions import HTTPError as BaseHTTPError\n\nfrom .compat import JSONDecodeError as CompatJSONDecodeError\n\n\nclass RequestException(IOError):\n    \"\"\"There was an ambiguous exception that occurred while handling your\n    request.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"Initialize RequestException with `request` and `response` objects.\"\"\"\n        response = kwargs.pop(\"response\", None)\n        self.response = response\n        self.request = kwargs.pop(\"request\", None)\n        if response is not None and not self.request and hasattr(response, \"request\"):\n            self.request = self.response.request\n        super().__init__(*args, **kwargs)\n\n\nclass InvalidJSONError(RequestException):\n    \"\"\"A JSON error occurred.\"\"\"\n\n\nclass JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n    \"\"\"Couldn't decode the text into json\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Construct the JSONDecodeError instance first with all\n        args. Then use it's args to construct the IOError so that\n        the json specific args aren't used as IOError specific args\n        and the error message from JSONDecodeError is preserved.\n        \"\"\"\n        CompatJSONDecodeError.__init__(self, *args)\n        InvalidJSONError.__init__(self, *self.args, **kwargs)\n\n    def __reduce__(self):\n        \"\"\"\n        The __reduce__ method called when pickling the object must\n        be the one from the JSONDecodeError (be it json/simplejson)\n        as it expects all the arguments for instantiation, not just\n        one like the IOError, and the MRO would by default call the\n        __reduce__ method from the IOError due to the inheritance order.\n        \"\"\"\n        return CompatJSONDecodeError.__reduce__(self)\n\n\nclass HTTPError(RequestException):\n    \"\"\"An HTTP error occurred.\"\"\"\n\n\nclass ConnectionError(RequestException):\n    \"\"\"A Connection error occurred.\"\"\"\n\n\nclass ProxyError(ConnectionError):\n    \"\"\"A proxy error occurred.\"\"\"\n\n\nclass SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\n\n\nclass Timeout(RequestException):\n    \"\"\"The request timed out.\n\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and\n    :exc:`~requests.exceptions.ReadTimeout` errors.\n    \"\"\"\n\n\nclass ConnectTimeout(ConnectionError, Timeout):\n    \"\"\"The request timed out while trying to connect to the remote server.\n\n    Requests that produced this error are safe to retry.\n    \"\"\"\n\n\nclass ReadTimeout(Timeout):\n    \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\n\n\nclass URLRequired(RequestException):\n    \"\"\"A valid URL is required to make a request.\"\"\"\n\n\nclass TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"\n\n\nclass MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\n\n\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\n\n\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\n\n\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\n\n\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\n\n\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\help.py": {
      "sha": "bb23ad839cb6",
      "lines": 127,
      "head": "\"\"\"Module containing bug report helper(s).\"\"\"\n\nimport json\nimport platform\nimport ssl\nimport sys\n\nfrom pip._vendor import idna\nfrom pip._vendor import urllib3\n\nfrom . import __version__ as requests_version\n\ncharset_normalizer = None\nchardet = None\n\ntry:\n    from pip._vendor.urllib3.contrib import pyopenssl\nexcept ImportError:\n    pyopenssl = None\n    OpenSSL = None\n    cryptography = None\nelse:\n    import cryptography\n    import OpenSSL\n\n\ndef _implementation():\n    \"\"\"Return a dict with the Python implementation and version.\n\n    Provide both the name and the version of the Python implementation\n    currently running. For example, on CPython 3.10.3 it will return\n    {'name': 'CPython', 'version': '3.10.3'}.\n\n    This function works best on CPython and PyPy: in particular, it probably\n    doesn't work for Jython or IronPython. Future investigation should be done\n    to work out the correct shape of the code for those platforms.\n    \"\"\"\n    implementation = platform.python_implementation()\n\n    if implementation == \"CPython\":\n        implementation_version = platform.python_version()\n    elif implementation == \"PyPy\":\n        implementation_version = \"{}.{}.{}\".format(\n            sys.pypy_version_info.major,\n            sys.pypy_version_info.minor,\n            sys.pypy_version_info.micro,\n        )\n        if sys.pypy_version_info.releaselevel != \"final\":\n            implementation_version = \"\".join(\n                [implementation_version, sys.pypy_version_info.releaselevel]\n            )\n    elif implementation == \"Jython\":\n        implementation_version = platform.python_version()  # Complete Guess\n    elif implementation == \"IronPython\":\n        implementation_version = platform.python_version()  # Complete Guess\n    else:\n        implementation_version = \"Unknown\"\n\n    return {\"name\": implementation, \"version\": implementation_version}\n\n\ndef info():\n    \"\"\"Generate information for a bug report.\"\"\"\n    try:\n        platform_info = {\n            \"system\": platform.system(),\n            \"release\": platform.release(),\n        }\n    except OSError:\n        platform_info = {\n            \"system\": \"Unknown\",\n            \"release\": \"Unknown\",\n        }\n\n    implementation_info = _implementation()\n    urllib3_info = {\"version\": urllib3.__version__}\n    charset_normalizer_info = {\"version\": None}\n    chardet_info = {\"version\": None}\n    if charset_normalizer:\n        charset_normalizer_info = {\"version\": charset_normalizer.__version__}\n    if chardet:\n        chardet_info = {\"version\": chardet.__version__}\n\n    pyopenssl_info = {\n        \"version\": None,\n        \"openssl_version\": \"\",\n    }\n    if OpenSSL:\n        pyopenssl_info = {\n            \"version\": OpenSSL.__version__,\n            \"openssl_version\": f\"{OpenSSL.SSL.OPENSSL_VERSION_NUMBER:x}\",\n        }\n    cryptography_info = {\n        \"version\": getattr(cryptography, \"__version__\", \"\"),\n    }\n    idna_info = {\n        \"version\": getattr(idna, \"__version__\", \"\"),\n    }\n\n    system_ssl = ssl.OPENSSL_VERSION_NUMBER\n    system_ssl_info = {\"version\": f\"{system_ssl:x}\" if system_ssl is not None else \"\"}\n\n    return {\n        \"platform\": platform_info,\n        \"implementation\": implementation_info,\n        \"system_ssl\": system_ssl_info,\n        \"using_pyopenssl\": pyopenssl is not None,\n        \"using_charset_normalizer\": chardet is None,\n        \"pyOpenSSL\": pyopenssl_info,\n        \"urllib3\": urllib3_info,\n        \"chardet\": chardet_info,\n        \"charset_normalizer\": charset_normalizer_info,\n        \"cryptography\": cryptography_info,\n        \"idna\": idna_info,\n        \"requests\": {\n            \"version\": requests_version,\n        },\n    }\n\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\hooks.py": {
      "sha": "6c2aebe642d6",
      "lines": 33,
      "head": "\"\"\"\nrequests.hooks\n~~~~~~~~~~~~~~\n\nThis module provides the capabilities for the Requests hooks system.\n\nAvailable hooks:\n\n``response``:\n    The response generated from a Request.\n\"\"\"\nHOOKS = [\"response\"]\n\n\ndef default_hooks():\n    return {event: [] for event in HOOKS}\n\n\n# TODO: response is the only one\n\n\ndef dispatch_hook(key, hooks, hook_data, **kwargs):\n    \"\"\"Dispatches a hook dictionary on a given piece of data.\"\"\"\n    hooks = hooks or {}\n    hooks = hooks.get(key)\n    if hooks:\n        if hasattr(hooks, \"__call__\"):\n            hooks = [hooks]\n        for hook in hooks:\n            _hook_data = hook(hook_data, **kwargs)\n            if _hook_data is not None:\n                hook_data = _hook_data\n    return hook_data\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\models.py": {
      "sha": "43d0af325a93",
      "lines": 1037,
      "head": "\"\"\"\nrequests.models\n~~~~~~~~~~~~~~~\n\nThis module contains the primary objects that power Requests.\n\"\"\"\n\nimport datetime\n\n# Import encoding now, to avoid implicit import later.\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\nimport encodings.idna  # noqa: F401\nfrom io import UnsupportedOperation\n\nfrom pip._vendor.urllib3.exceptions import (\n    DecodeError,\n    LocationParseError,\n    ProtocolError,\n    ReadTimeoutError,\n    SSLError,\n)\nfrom pip._vendor.urllib3.fields import RequestField\nfrom pip._vendor.urllib3.filepost import encode_multipart_formdata\nfrom pip._vendor.urllib3.util import parse_url\n\nfrom ._internal_utils import to_native_string, unicode_is_ascii\nfrom .auth import HTTPBasicAuth\nfrom .compat import (\n    Callable,\n    JSONDecodeError,\n    Mapping,\n    basestring,\n    builtin_str,\n    chardet,\n    cookielib,\n)\nfrom .compat import json as complexjson\nfrom .compat import urlencode, urlsplit, urlunparse\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ContentDecodingError,\n    HTTPError,\n    InvalidJSONError,\n    InvalidURL,\n)\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\nfrom .exceptions import MissingSchema\nfrom .exceptions import SSLError as RequestsSSLError\nfrom .exceptions import StreamConsumedError\nfrom .hooks import default_hooks\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    check_header_validity,\n    get_auth_from_url,\n    guess_filename,\n    guess_json_utf,\n    iter_slices,\n    parse_header_links,\n    requote_uri,\n    stream_decode_response_unicode,\n    super_len,\n    to_key_val_list,\n)\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = \"/\"\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append(\"?\")\n            url.append(query)\n\n        return \"\".join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, \"read\"):\n            return data\n        elif hasattr(data, \"__iter__\"):\n            result = []\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\packages.py": {
      "sha": "954cabd8a950",
      "lines": 25,
      "head": "import sys\n\nfrom .compat import chardet\n\n# This code exists for backwards compatibility reasons.\n# I don't like it either. Just look the other way. :)\n\nfor package in (\"urllib3\", \"idna\"):\n    vendored_package = \"pip._vendor.\" + package\n    locals()[package] = __import__(vendored_package)\n    # This traversal is apparently necessary such that the identities are\n    # preserved (requests.packages.urllib3.* is urllib3.*)\n    for mod in list(sys.modules):\n        if mod == vendored_package or mod.startswith(vendored_package + '.'):\n            unprefixed_mod = mod[len(\"pip._vendor.\"):]\n            sys.modules['pip._vendor.requests.packages.' + unprefixed_mod] = sys.modules[mod]\n\nif chardet is not None:\n    target = chardet.__name__\n    for mod in list(sys.modules):\n        if mod == target or mod.startswith(f\"{target}.\"):\n            imported_mod = sys.modules[mod]\n            sys.modules[f\"requests.packages.{mod}\"] = imported_mod\n            mod = mod.replace(target, \"chardet\")\n            sys.modules[f\"requests.packages.{mod}\"] = imported_mod\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\sessions.py": {
      "sha": "93881c774ba8",
      "lines": 831,
      "head": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)\n    ):\n        return request_setting\n\n    merged_setting = dict_class(to_key_val_list(session_setting))\n    merged_setting.update(to_key_val_list(request_setting))\n\n    # Remove keys that are set to None. Extract keys first to avoid altering\n    # the dictionary during iteration.\n    none_keys = [k for (k, v) in merged_setting.items() if v is None]\n    for key in none_keys:\n        del merged_setting[key]\n\n    return merged_setting\n\n\ndef merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n    \"\"\"Properly merges both requests and session hooks.\n\n    This is necessary because when request_hooks == {'response': []}, the\n    merge breaks Session hooks entirely.\n    \"\"\"\n    if session_hooks is None or session_hooks.get(\"response\") == []:\n        return request_hooks\n\n    if request_hooks is None or request_hooks.get(\"response\") == []:\n        return session_hooks\n\n    return merge_setting(request_hooks, session_hooks, dict_class)\n\n\nclass SessionRedirectMixin:\n    def get_redirect_target(self, resp):\n        \"\"\"Receives a Response. Returns a redirect URI or ``None``\"\"\"\n        # Due to the nature of how requests processes redirects this method will\n        # be called at least once upon the original response and at least twice\n        # on each subsequent redirect response (if any).\n        # If a custom mixin is used to handle this logic, it may be advantageous\n        # to cache the redirect location onto the response object as a private\n        # attribute.\n        if resp.is_redirect:\n            location = resp.headers[\"location\"]\n            # Currently the underlying http module on py3 decode headers\n            # in latin1, but empirical evidence suggests that latin1 is very\n            # rarely used with non-ASCII characters in HTTP headers.\n            # It is more likely to get UTF8 header rather than latin1.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\status_codes.py": {
      "sha": "cf59c07d2dfa",
      "lines": 128,
      "head": "r\"\"\"\nThe ``codes`` object defines a mapping from common names for HTTP statuses\nto their numerical codes, accessible either as attributes or as dictionary\nitems.\n\nExample::\n\n    >>> import requests\n    >>> requests.codes['temporary_redirect']\n    307\n    >>> requests.codes.teapot\n    418\n    >>> requests.codes['\\o/']\n    200\n\nSome codes have multiple names, and both upper- and lower-case versions of\nthe names are allowed. For example, ``codes.ok``, ``codes.OK``, and\n``codes.okay`` all correspond to the HTTP status code 200.\n\"\"\"\n\nfrom .structures import LookupDict\n\n_codes = {\n    # Informational.\n    100: (\"continue\",),\n    101: (\"switching_protocols\",),\n    102: (\"processing\", \"early-hints\"),\n    103: (\"checkpoint\",),\n    122: (\"uri_too_long\", \"request_uri_too_long\"),\n    200: (\"ok\", \"okay\", \"all_ok\", \"all_okay\", \"all_good\", \"\\\\o/\", \"\u2713\"),\n    201: (\"created\",),\n    202: (\"accepted\",),\n    203: (\"non_authoritative_info\", \"non_authoritative_information\"),\n    204: (\"no_content\",),\n    205: (\"reset_content\", \"reset\"),\n    206: (\"partial_content\", \"partial\"),\n    207: (\"multi_status\", \"multiple_status\", \"multi_stati\", \"multiple_stati\"),\n    208: (\"already_reported\",),\n    226: (\"im_used\",),\n    # Redirection.\n    300: (\"multiple_choices\",),\n    301: (\"moved_permanently\", \"moved\", \"\\\\o-\"),\n    302: (\"found\",),\n    303: (\"see_other\", \"other\"),\n    304: (\"not_modified\",),\n    305: (\"use_proxy\",),\n    306: (\"switch_proxy\",),\n    307: (\"temporary_redirect\", \"temporary_moved\", \"temporary\"),\n    308: (\n        \"permanent_redirect\",\n        \"resume_incomplete\",\n        \"resume\",\n    ),  # \"resume\" and \"resume_incomplete\" to be removed in 3.0\n    # Client Error.\n    400: (\"bad_request\", \"bad\"),\n    401: (\"unauthorized\",),\n    402: (\"payment_required\", \"payment\"),\n    403: (\"forbidden\",),\n    404: (\"not_found\", \"-o-\"),\n    405: (\"method_not_allowed\", \"not_allowed\"),\n    406: (\"not_acceptable\",),\n    407: (\"proxy_authentication_required\", \"proxy_auth\", \"proxy_authentication\"),\n    408: (\"request_timeout\", \"timeout\"),\n    409: (\"conflict\",),\n    410: (\"gone\",),\n    411: (\"length_required\",),\n    412: (\"precondition_failed\", \"precondition\"),\n    413: (\"request_entity_too_large\", \"content_too_large\"),\n    414: (\"request_uri_too_large\", \"uri_too_long\"),\n    415: (\"unsupported_media_type\", \"unsupported_media\", \"media_type\"),\n    416: (\n        \"requested_range_not_satisfiable\",\n        \"requested_range\",\n        \"range_not_satisfiable\",\n    ),\n    417: (\"expectation_failed\",),\n    418: (\"im_a_teapot\", \"teapot\", \"i_am_a_teapot\"),\n    421: (\"misdirected_request\",),\n    422: (\"unprocessable_entity\", \"unprocessable\", \"unprocessable_content\"),\n    423: (\"locked\",),\n    424: (\"failed_dependency\", \"dependency\"),\n    425: (\"unordered_collection\", \"unordered\", \"too_early\"),\n    426: (\"upgrade_required\", \"upgrade\"),\n    428: (\"precondition_required\", \"precondition\"),\n    429: (\"too_many_requests\", \"too_many\"),\n    431: (\"header_fields_too_large\", \"fields_too_large\"),\n    444: (\"no_response\", \"none\"),\n    449: (\"retry_with\", \"retry\"),\n    450: (\"blocked_by_windows_parental_controls\", \"parental_controls\"),\n    451: (\"unavailable_for_legal_reasons\", \"legal_reasons\"),\n    499: (\"client_closed_request\",),\n    # Server Error.\n    500: (\"internal_server_error\", \"server_error\", \"/o\\\\\", \"\u2717\"),\n    501: (\"not_implemented\",),\n    502: (\"bad_gateway\",),\n    503: (\"service_unavailable\", \"unavailable\"),\n    504: (\"gateway_timeout\",),\n    505: (\"http_version_not_supported\", \"http_version\"),\n    506: (\"variant_also_negotiates\",),\n    507: (\"insufficient_storage\",),\n    509: (\"bandwidth_limit_exceeded\", \"bandwidth\"),\n    510: (\"not_extended\",),\n    511: (\"network_authentication_required\", \"network_auth\", \"network_authentication\"),\n}\n\ncodes = LookupDict(name=\"status_codes\")\n\n\ndef _init():\n    for code, titles in _codes.items():\n        for title in titles:\n            setattr(codes, title, code)\n            if not title.startswith((\"\\\\\", \"/\")):\n                setattr(codes, title.upper(), code)\n\n    def doc(code):\n        names = \", \".join(f\"``{n}``\" for n in _codes[code])\n        return \"* %d: %s\" % (code, names)\n\n    global __doc__\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\structures.py": {
      "sha": "b5c2c740b9ff",
      "lines": 99,
      "head": "\"\"\"\nrequests.structures\n~~~~~~~~~~~~~~~~~~~\n\nData structures that power Requests.\n\"\"\"\n\nfrom collections import OrderedDict\n\nfrom .compat import Mapping, MutableMapping\n\n\nclass CaseInsensitiveDict(MutableMapping):\n    \"\"\"A case-insensitive ``dict``-like object.\n\n    Implements all methods and operations of\n    ``MutableMapping`` as well as dict's ``copy``. Also\n    provides ``lower_items``.\n\n    All keys are expected to be strings. The structure remembers the\n    case of the last key to be set, and ``iter(instance)``,\n    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``\n    will contain case-sensitive keys. However, querying and contains\n    testing is case insensitive::\n\n        cid = CaseInsensitiveDict()\n        cid['Accept'] = 'application/json'\n        cid['aCCEPT'] == 'application/json'  # True\n        list(cid) == ['Accept']  # True\n\n    For example, ``headers['content-encoding']`` will return the\n    value of a ``'Content-Encoding'`` response header, regardless\n    of how the header name was originally stored.\n\n    If the constructor, ``.update``, or equality comparison\n    operations are given keys that have equal ``.lower()``s, the\n    behavior is undefined.\n    \"\"\"\n\n    def __init__(self, data=None, **kwargs):\n        self._store = OrderedDict()\n        if data is None:\n            data = {}\n        self.update(data, **kwargs)\n\n    def __setitem__(self, key, value):\n        # Use the lowercased key for lookups, but store the actual\n        # key alongside the value.\n        self._store[key.lower()] = (key, value)\n\n    def __getitem__(self, key):\n        return self._store[key.lower()][1]\n\n    def __delitem__(self, key):\n        del self._store[key.lower()]\n\n    def __iter__(self):\n        return (casedkey for casedkey, mappedvalue in self._store.values())\n\n    def __len__(self):\n        return len(self._store)\n\n    def lower_items(self):\n        \"\"\"Like iteritems(), but with all lowercase keys.\"\"\"\n        return ((lowerkey, keyval[1]) for (lowerkey, keyval) in self._store.items())\n\n    def __eq__(self, other):\n        if isinstance(other, Mapping):\n            other = CaseInsensitiveDict(other)\n        else:\n            return NotImplemented\n        # Compare insensitively\n        return dict(self.lower_items()) == dict(other.lower_items())\n\n    # Copy is required\n    def copy(self):\n        return CaseInsensitiveDict(self._store.values())\n\n    def __repr__(self):\n        return str(dict(self.items()))\n\n\nclass LookupDict(dict):\n    \"\"\"Dictionary lookup object.\"\"\"\n\n    def __init__(self, name=None):\n        self.name = name\n        super().__init__()\n\n    def __repr__(self):\n        return f\"<lookup '{self.name}'>\"\n\n    def __getitem__(self, key):\n        # We allow fall-through here, so values default to None\n\n        return self.__dict__.get(key, None)\n\n    def get(self, key, default=None):\n        return self.__dict__.get(key, default)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\utils.py": {
      "sha": "735f3ef3c60d",
      "lines": 1096,
      "head": "\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom pip._vendor.urllib3.util import make_headers, parse_url\n\nfrom . import certs\nfrom .__version__ import __version__\n\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import (  # noqa: F401\n    _HEADER_VALIDATORS_BYTE,\n    _HEADER_VALIDATORS_STR,\n    HEADER_VALIDATORS,\n    to_native_string,\n)\nfrom .compat import (\n    Mapping,\n    basestring,\n    bytes,\n    getproxies,\n    getproxies_environment,\n    integer_types,\n)\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    proxy_bypass,\n    proxy_bypass_environment,\n    quote,\n    str,\n    unquote,\n    urlparse,\n    urlunparse,\n)\nfrom .cookies import cookiejar_from_dict\nfrom .exceptions import (\n    FileModeWarning,\n    InvalidHeader,\n    InvalidURL,\n    UnrewindableBodyError,\n)\nfrom .structures import CaseInsensitiveDict\n\nNETRC_FILES = (\".netrc\", \"_netrc\")\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(\n                winreg.HKEY_CURRENT_USER,\n                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n            )\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n        except (OSError, ValueError):\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(\";\")\n        # filter out empty strings to avoid re.match return true in the following code.\n        proxyOverride = filter(None, proxyOverride)\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == \"<local>\":\n                if \".\" not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")  # mask dots\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\n            test = test.replace(\"?\", r\".\")  # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\_internal_utils.py": {
      "sha": "83a8612a7fe6",
      "lines": 50,
      "head": "\"\"\"\nrequests._internal_utils\n~~~~~~~~~~~~~~\n\nProvides utility functions that are consumed internally by Requests\nwhich depend on extremely few external helpers (such as compat)\n\"\"\"\nimport re\n\nfrom .compat import builtin_str\n\n_VALID_HEADER_NAME_RE_BYTE = re.compile(rb\"^[^:\\s][^:\\r\\n]*$\")\n_VALID_HEADER_NAME_RE_STR = re.compile(r\"^[^:\\s][^:\\r\\n]*$\")\n_VALID_HEADER_VALUE_RE_BYTE = re.compile(rb\"^\\S[^\\r\\n]*$|^$\")\n_VALID_HEADER_VALUE_RE_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n\n_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)\n_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\nHEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}\n\n\ndef to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of\n    that string in the native string type, encoding and decoding where\n    necessary. This assumes ASCII unless told otherwise.\n    \"\"\"\n    if isinstance(string, builtin_str):\n        out = string\n    else:\n        out = string.decode(encoding)\n\n    return out\n\n\ndef unicode_is_ascii(u_string):\n    \"\"\"Determine if unicode string only contains ASCII characters.\n\n    :param str u_string: unicode string to check. Must be unicode\n        and not Python 2 `str`.\n    :rtype: bool\n    \"\"\"\n    assert isinstance(u_string, str)\n    try:\n        u_string.encode(\"ascii\")\n        return True\n    except UnicodeEncodeError:\n        return False\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\__init__.py": {
      "sha": "bf0ac9f844a5",
      "lines": 179,
      "head": "#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nfrom pip._vendor import urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ncharset_normalizer_version = None\nchardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # chardet_version >= 3.0.2, < 6.0.0\n        assert (3, 0, 2) <= (major, minor, patch) < (6, 0, 0)\n    elif charset_normalizer_version:\n        major, minor, patch = charset_normalizer_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charset_normalizer >= 2.0.0 < 4.0.0\n        assert (2, 0, 0) <= (major, minor, patch) < (4, 0, 0)\n    else:\n        # pip does not need or use character detection\n        pass\n\n\ndef _check_cryptography(cryptography_version):\n    # cryptography < 1.3.4\n    try:\n        cryptography_version = list(map(int, cryptography_version.split(\".\")))\n    except ValueError:\n        return\n\n    if cryptography_version < [1, 3, 4]:\n        warning = \"Old version of cryptography ({}) may cause slowdown.\".format(\n            cryptography_version\n        )\n        warnings.warn(warning, RequestsDependencyWarning)\n\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    # Note: This logic prevents upgrading cryptography on Windows, if imported\n    #       as part of pip.\n    from pip._internal.utils.compat import WINDOWS\n    if not WINDOWS:\n        raise ImportError(\"pip internals: don't import cryptography on Windows\")\n    try:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\requests\\__version__.py": {
      "sha": "c4d5e1c3654e",
      "lines": 14,
      "head": "# .-. .-. .-. . . .-. .-. .-. .-.\n# |(  |-  |.| | | |-  `-.  |  `-.\n# ' ' `-' `-`.`-' `-' `-'  '  `-'\n\n__title__ = \"requests\"\n__description__ = \"Python HTTP for Humans.\"\n__url__ = \"https://requests.readthedocs.io\"\n__version__ = \"2.32.3\"\n__build__ = 0x023203\n__author__ = \"Kenneth Reitz\"\n__author_email__ = \"me@kennethreitz.org\"\n__license__ = \"Apache-2.0\"\n__copyright__ = \"Copyright Kenneth Reitz\"\n__cake__ = \"\\u2728 \\U0001f370 \\u2728\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\providers.py": {
      "sha": "46623caff501",
      "lines": 196,
      "head": "from __future__ import annotations\n\nfrom typing import (\n    TYPE_CHECKING,\n    Generic,\n    Iterable,\n    Iterator,\n    Mapping,\n    Sequence,\n)\n\nfrom .structs import CT, KT, RT, Matches, RequirementInformation\n\nif TYPE_CHECKING:\n    from typing import Any, Protocol\n\n    class Preference(Protocol):\n        def __lt__(self, __other: Any) -> bool: ...\n\n\nclass AbstractProvider(Generic[RT, CT, KT]):\n    \"\"\"Delegate class to provide the required interface for the resolver.\"\"\"\n\n    def identify(self, requirement_or_candidate: RT | CT) -> KT:\n        \"\"\"Given a requirement or candidate, return an identifier for it.\n\n        This is used to identify, e.g. whether two requirements\n        should have their specifier parts merged or a candidate matches a\n        requirement via ``find_matches()``.\n        \"\"\"\n        raise NotImplementedError\n\n    def get_preference(\n        self,\n        identifier: KT,\n        resolutions: Mapping[KT, CT],\n        candidates: Mapping[KT, Iterator[CT]],\n        information: Mapping[KT, Iterator[RequirementInformation[RT, CT]]],\n        backtrack_causes: Sequence[RequirementInformation[RT, CT]],\n    ) -> Preference:\n        \"\"\"Produce a sort key for given requirement based on preference.\n\n        As this is a sort key it will be called O(n) times per backtrack\n        step, where n is the number of `identifier`s, if you have a check\n        which is expensive in some sense. E.g. It needs to make O(n) checks\n        per call or takes significant wall clock time, consider using\n        `narrow_requirement_selection` to filter the `identifier`s, which\n        is applied before this sort key is called.\n\n        The preference is defined as \"I think this requirement should be\n        resolved first\". The lower the return value is, the more preferred\n        this group of arguments is.\n\n        :param identifier: An identifier as returned by ``identify()``. This\n            identifies the requirement being considered.\n        :param resolutions: Mapping of candidates currently pinned by the\n            resolver. Each key is an identifier, and the value is a candidate.\n            The candidate may conflict with requirements from ``information``.\n        :param candidates: Mapping of each dependency's possible candidates.\n            Each value is an iterator of candidates.\n        :param information: Mapping of requirement information of each package.\n            Each value is an iterator of *requirement information*.\n        :param backtrack_causes: Sequence of *requirement information* that are\n            the requirements that caused the resolver to most recently\n            backtrack.\n\n        A *requirement information* instance is a named tuple with two members:\n\n        * ``requirement`` specifies a requirement contributing to the current\n          list of candidates.\n        * ``parent`` specifies the candidate that provides (depended on) the\n          requirement, or ``None`` to indicate a root requirement.\n\n        The preference could depend on various issues, including (not\n        necessarily in this order):\n\n        * Is this package pinned in the current resolution result?\n        * How relaxed is the requirement? Stricter ones should probably be\n          worked on first? (I don't know, actually.)\n        * How many possibilities are there to satisfy this requirement? Those\n          with few left should likely be worked on first, I guess?\n        * Are there any known conflicts for this requirement? We should\n          probably work on those with the most known conflicts.\n\n        A sortable value should be returned (this will be used as the ``key``\n        parameter of the built-in sorting function). The smaller the value is,\n        the more preferred this requirement is (i.e. the sorting function\n        is called with ``reverse=False``).\n        \"\"\"\n        raise NotImplementedError\n\n    def find_matches(\n        self,\n        identifier: KT,\n        requirements: Mapping[KT, Iterator[RT]],\n        incompatibilities: Mapping[KT, Iterator[CT]],\n    ) -> Matches[CT]:\n        \"\"\"Find all possible candidates that satisfy the given constraints.\n\n        :param identifier: An identifier as returned by ``identify()``. All\n            candidates returned by this method should produce the same\n            identifier.\n        :param requirements: A mapping of requirements that all returned\n            candidates must satisfy. Each key is an identifier, and the value\n            an iterator of requirements for that dependency.\n        :param incompatibilities: A mapping of known incompatibile candidates of\n            each dependency. Each key is an identifier, and the value an\n            iterator of incompatibilities known to the resolver. All\n            incompatibilities *must* be excluded from the return value.\n\n        This should try to get candidates based on the requirements' types.\n        For VCS, local, and archive requirements, the one-and-only match is\n        returned, and for a \"named\" requirement, the index(es) should be\n        consulted to find concrete candidates for this requirement.\n\n        The return value should produce candidates ordered by preference; the\n        most preferred candidate should come first. The return type may be one\n        of the following:\n\n        * A callable that returns an iterator that yields candidates.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\reporters.py": {
      "sha": "cdf9b9610834",
      "lines": 55,
      "head": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Collection, Generic\n\nfrom .structs import CT, KT, RT, RequirementInformation, State\n\nif TYPE_CHECKING:\n    from .resolvers import Criterion\n\n\nclass BaseReporter(Generic[RT, CT, KT]):\n    \"\"\"Delegate class to provider progress reporting for the resolver.\"\"\"\n\n    def starting(self) -> None:\n        \"\"\"Called before the resolution actually starts.\"\"\"\n\n    def starting_round(self, index: int) -> None:\n        \"\"\"Called before each round of resolution starts.\n\n        The index is zero-based.\n        \"\"\"\n\n    def ending_round(self, index: int, state: State[RT, CT, KT]) -> None:\n        \"\"\"Called before each round of resolution ends.\n\n        This is NOT called if the resolution ends at this round. Use `ending`\n        if you want to report finalization. The index is zero-based.\n        \"\"\"\n\n    def ending(self, state: State[RT, CT, KT]) -> None:\n        \"\"\"Called before the resolution ends successfully.\"\"\"\n\n    def adding_requirement(self, requirement: RT, parent: CT | None) -> None:\n        \"\"\"Called when adding a new requirement into the resolve criteria.\n\n        :param requirement: The additional requirement to be applied to filter\n            the available candidaites.\n        :param parent: The candidate that requires ``requirement`` as a\n            dependency, or None if ``requirement`` is one of the root\n            requirements passed in from ``Resolver.resolve()``.\n        \"\"\"\n\n    def resolving_conflicts(\n        self, causes: Collection[RequirementInformation[RT, CT]]\n    ) -> None:\n        \"\"\"Called when starting to attempt requirement conflict resolution.\n\n        :param causes: The information on the collision that caused the backtracking.\n        \"\"\"\n\n    def rejecting_candidate(self, criterion: Criterion[RT, CT], candidate: CT) -> None:\n        \"\"\"Called when rejecting a candidate during backtracking.\"\"\"\n\n    def pinning(self, candidate: CT) -> None:\n        \"\"\"Called when adding a candidate to the potential solution.\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py": {
      "sha": "54b57d147484",
      "lines": 209,
      "head": "from __future__ import annotations\n\nimport itertools\nfrom collections import namedtuple\nfrom typing import (\n    TYPE_CHECKING,\n    Callable,\n    Generic,\n    Iterable,\n    Iterator,\n    Mapping,\n    NamedTuple,\n    Sequence,\n    TypeVar,\n    Union,\n)\n\nKT = TypeVar(\"KT\")  # Identifier.\nRT = TypeVar(\"RT\")  # Requirement.\nCT = TypeVar(\"CT\")  # Candidate.\n\nMatches = Union[Iterable[CT], Callable[[], Iterable[CT]]]\n\nif TYPE_CHECKING:\n    from .resolvers.criterion import Criterion\n\n    class RequirementInformation(NamedTuple, Generic[RT, CT]):\n        requirement: RT\n        parent: CT | None\n\n    class State(NamedTuple, Generic[RT, CT, KT]):\n        \"\"\"Resolution state in a round.\"\"\"\n\n        mapping: dict[KT, CT]\n        criteria: dict[KT, Criterion[RT, CT]]\n        backtrack_causes: list[RequirementInformation[RT, CT]]\n\nelse:\n    RequirementInformation = namedtuple(\n        \"RequirementInformation\", [\"requirement\", \"parent\"]\n    )\n    State = namedtuple(\"State\", [\"mapping\", \"criteria\", \"backtrack_causes\"])\n\n\nclass DirectedGraph(Generic[KT]):\n    \"\"\"A graph structure with directed edges.\"\"\"\n\n    def __init__(self) -> None:\n        self._vertices: set[KT] = set()\n        self._forwards: dict[KT, set[KT]] = {}  # <key> -> Set[<key>]\n        self._backwards: dict[KT, set[KT]] = {}  # <key> -> Set[<key>]\n\n    def __iter__(self) -> Iterator[KT]:\n        return iter(self._vertices)\n\n    def __len__(self) -> int:\n        return len(self._vertices)\n\n    def __contains__(self, key: KT) -> bool:\n        return key in self._vertices\n\n    def copy(self) -> DirectedGraph[KT]:\n        \"\"\"Return a shallow copy of this graph.\"\"\"\n        other = type(self)()\n        other._vertices = set(self._vertices)\n        other._forwards = {k: set(v) for k, v in self._forwards.items()}\n        other._backwards = {k: set(v) for k, v in self._backwards.items()}\n        return other\n\n    def add(self, key: KT) -> None:\n        \"\"\"Add a new vertex to the graph.\"\"\"\n        if key in self._vertices:\n            raise ValueError(\"vertex exists\")\n        self._vertices.add(key)\n        self._forwards[key] = set()\n        self._backwards[key] = set()\n\n    def remove(self, key: KT) -> None:\n        \"\"\"Remove a vertex from the graph, disconnecting all edges from/to it.\"\"\"\n        self._vertices.remove(key)\n        for f in self._forwards.pop(key):\n            self._backwards[f].remove(key)\n        for t in self._backwards.pop(key):\n            self._forwards[t].remove(key)\n\n    def connected(self, f: KT, t: KT) -> bool:\n        return f in self._backwards[t] and t in self._forwards[f]\n\n    def connect(self, f: KT, t: KT) -> None:\n        \"\"\"Connect two existing vertices.\n\n        Nothing happens if the vertices are already connected.\n        \"\"\"\n        if t not in self._vertices:\n            raise KeyError(t)\n        self._forwards[f].add(t)\n        self._backwards[t].add(f)\n\n    def iter_edges(self) -> Iterator[tuple[KT, KT]]:\n        for f, children in self._forwards.items():\n            for t in children:\n                yield f, t\n\n    def iter_children(self, key: KT) -> Iterator[KT]:\n        return iter(self._forwards[key])\n\n    def iter_parents(self, key: KT) -> Iterator[KT]:\n        return iter(self._backwards[key])\n\n\nclass IteratorMapping(Mapping[KT, Iterator[CT]], Generic[RT, CT, KT]):\n    def __init__(\n        self,\n        mapping: Mapping[KT, RT],\n        accessor: Callable[[RT], Iterable[CT]],\n        appends: Mapping[KT, Iterable[CT]] | None = None,\n    ) -> None:\n        self._mapping = mapping\n        self._accessor = accessor\n        self._appends: Mapping[KT, Iterable[CT]] = appends or {}\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\__init__.py": {
      "sha": "e21458be17a0",
      "lines": 27,
      "head": "__all__ = [\n    \"__version__\",\n    \"AbstractProvider\",\n    \"AbstractResolver\",\n    \"BaseReporter\",\n    \"InconsistentCandidate\",\n    \"Resolver\",\n    \"RequirementsConflicted\",\n    \"ResolutionError\",\n    \"ResolutionImpossible\",\n    \"ResolutionTooDeep\",\n]\n\n__version__ = \"1.1.0\"\n\n\nfrom .providers import AbstractProvider\nfrom .reporters import BaseReporter\nfrom .resolvers import (\n    AbstractResolver,\n    InconsistentCandidate,\n    RequirementsConflicted,\n    ResolutionError,\n    ResolutionImpossible,\n    ResolutionTooDeep,\n    Resolver,\n)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\abstract.py": {
      "sha": "d783d3f040b7",
      "lines": 47,
      "head": "from __future__ import annotations\n\nimport collections\nfrom typing import TYPE_CHECKING, Any, Generic, Iterable, Mapping, NamedTuple\n\nfrom ..structs import CT, KT, RT, DirectedGraph\n\nif TYPE_CHECKING:\n    from ..providers import AbstractProvider\n    from ..reporters import BaseReporter\n    from .criterion import Criterion\n\n    class Result(NamedTuple, Generic[RT, CT, KT]):\n        mapping: Mapping[KT, CT]\n        graph: DirectedGraph[KT | None]\n        criteria: Mapping[KT, Criterion[RT, CT]]\n\nelse:\n    Result = collections.namedtuple(\"Result\", [\"mapping\", \"graph\", \"criteria\"])\n\n\nclass AbstractResolver(Generic[RT, CT, KT]):\n    \"\"\"The thing that performs the actual resolution work.\"\"\"\n\n    base_exception = Exception\n\n    def __init__(\n        self,\n        provider: AbstractProvider[RT, CT, KT],\n        reporter: BaseReporter[RT, CT, KT],\n    ) -> None:\n        self.provider = provider\n        self.reporter = reporter\n\n    def resolve(self, requirements: Iterable[RT], **kwargs: Any) -> Result[RT, CT, KT]:\n        \"\"\"Take a collection of constraints, spit out the resolution result.\n\n        This returns a representation of the final resolution state, with one\n        guarenteed attribute ``mapping`` that contains resolved candidates as\n        values. The keys are their respective identifiers.\n\n        :param requirements: A collection of constraints.\n        :param kwargs: Additional keyword arguments that subclasses may accept.\n\n        :raises: ``self.base_exception`` or its subclass.\n        \"\"\"\n        raise NotImplementedError\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\criterion.py": {
      "sha": "f51ba2b176d5",
      "lines": 48,
      "head": "from __future__ import annotations\n\nfrom typing import Collection, Generic, Iterable, Iterator\n\nfrom ..structs import CT, RT, RequirementInformation\n\n\nclass Criterion(Generic[RT, CT]):\n    \"\"\"Representation of possible resolution results of a package.\n\n    This holds three attributes:\n\n    * `information` is a collection of `RequirementInformation` pairs.\n      Each pair is a requirement contributing to this criterion, and the\n      candidate that provides the requirement.\n    * `incompatibilities` is a collection of all known not-to-work candidates\n      to exclude from consideration.\n    * `candidates` is a collection containing all possible candidates deducted\n      from the union of contributing requirements and known incompatibilities.\n      It should never be empty, except when the criterion is an attribute of a\n      raised `RequirementsConflicted` (in which case it is always empty).\n\n    .. note::\n        This class is intended to be externally immutable. **Do not** mutate\n        any of its attribute containers.\n    \"\"\"\n\n    def __init__(\n        self,\n        candidates: Iterable[CT],\n        information: Collection[RequirementInformation[RT, CT]],\n        incompatibilities: Collection[CT],\n    ) -> None:\n        self.candidates = candidates\n        self.information = information\n        self.incompatibilities = incompatibilities\n\n    def __repr__(self) -> str:\n        requirements = \", \".join(\n            f\"({req!r}, via={parent!r})\" for req, parent in self.information\n        )\n        return f\"Criterion({requirements})\"\n\n    def iter_requirement(self) -> Iterator[RT]:\n        return (i.requirement for i in self.information)\n\n    def iter_parent(self) -> Iterator[CT | None]:\n        return (i.parent for i in self.information)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\exceptions.py": {
      "sha": "00b959a48700",
      "lines": 57,
      "head": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Collection, Generic\n\nfrom ..structs import CT, RT, RequirementInformation\n\nif TYPE_CHECKING:\n    from .criterion import Criterion\n\n\nclass ResolverException(Exception):\n    \"\"\"A base class for all exceptions raised by this module.\n\n    Exceptions derived by this class should all be handled in this module. Any\n    bubbling pass the resolver should be treated as a bug.\n    \"\"\"\n\n\nclass RequirementsConflicted(ResolverException, Generic[RT, CT]):\n    def __init__(self, criterion: Criterion[RT, CT]) -> None:\n        super().__init__(criterion)\n        self.criterion = criterion\n\n    def __str__(self) -> str:\n        return \"Requirements conflict: {}\".format(\n            \", \".join(repr(r) for r in self.criterion.iter_requirement()),\n        )\n\n\nclass InconsistentCandidate(ResolverException, Generic[RT, CT]):\n    def __init__(self, candidate: CT, criterion: Criterion[RT, CT]):\n        super().__init__(candidate, criterion)\n        self.candidate = candidate\n        self.criterion = criterion\n\n    def __str__(self) -> str:\n        return \"Provided candidate {!r} does not satisfy {}\".format(\n            self.candidate,\n            \", \".join(repr(r) for r in self.criterion.iter_requirement()),\n        )\n\n\nclass ResolutionError(ResolverException):\n    pass\n\n\nclass ResolutionImpossible(ResolutionError, Generic[RT, CT]):\n    def __init__(self, causes: Collection[RequirementInformation[RT, CT]]):\n        super().__init__(causes)\n        # causes is a list of RequirementInformation objects\n        self.causes = causes\n\n\nclass ResolutionTooDeep(ResolutionError):\n    def __init__(self, round_count: int) -> None:\n        super().__init__(round_count)\n        self.round_count = round_count\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py": {
      "sha": "73c637ee6b40",
      "lines": 541,
      "head": "from __future__ import annotations\n\nimport collections\nimport itertools\nimport operator\nfrom typing import TYPE_CHECKING, Collection, Generic, Iterable, Mapping\n\nfrom ..structs import (\n    CT,\n    KT,\n    RT,\n    DirectedGraph,\n    IterableView,\n    IteratorMapping,\n    RequirementInformation,\n    State,\n    build_iter_view,\n)\nfrom .abstract import AbstractResolver, Result\nfrom .criterion import Criterion\nfrom .exceptions import (\n    InconsistentCandidate,\n    RequirementsConflicted,\n    ResolutionImpossible,\n    ResolutionTooDeep,\n    ResolverException,\n)\n\nif TYPE_CHECKING:\n    from ..providers import AbstractProvider, Preference\n    from ..reporters import BaseReporter\n\n\ndef _build_result(state: State[RT, CT, KT]) -> Result[RT, CT, KT]:\n    mapping = state.mapping\n    all_keys: dict[int, KT | None] = {id(v): k for k, v in mapping.items()}\n    all_keys[id(None)] = None\n\n    graph: DirectedGraph[KT | None] = DirectedGraph()\n    graph.add(None)  # Sentinel as root dependencies' parent.\n\n    connected: set[KT | None] = {None}\n    for key, criterion in state.criteria.items():\n        if not _has_route_to_root(state.criteria, key, all_keys, connected):\n            continue\n        if key not in graph:\n            graph.add(key)\n        for p in criterion.iter_parent():\n            try:\n                pkey = all_keys[id(p)]\n            except KeyError:\n                continue\n            if pkey not in graph:\n                graph.add(pkey)\n            graph.connect(pkey, key)\n\n    return Result(\n        mapping={k: v for k, v in mapping.items() if k in connected},\n        graph=graph,\n        criteria=state.criteria,\n    )\n\n\nclass Resolution(Generic[RT, CT, KT]):\n    \"\"\"Stateful resolution object.\n\n    This is designed as a one-off object that holds information to kick start\n    the resolution process, and holds the results afterwards.\n    \"\"\"\n\n    def __init__(\n        self,\n        provider: AbstractProvider[RT, CT, KT],\n        reporter: BaseReporter[RT, CT, KT],\n    ) -> None:\n        self._p = provider\n        self._r = reporter\n        self._states: list[State[RT, CT, KT]] = []\n\n    @property\n    def state(self) -> State[RT, CT, KT]:\n        try:\n            return self._states[-1]\n        except IndexError as e:\n            raise AttributeError(\"state\") from e\n\n    def _push_new_state(self) -> None:\n        \"\"\"Push a new state into history.\n\n        This new state will be used to hold resolution results of the next\n        coming round.\n        \"\"\"\n        base = self._states[-1]\n        state = State(\n            mapping=base.mapping.copy(),\n            criteria=base.criteria.copy(),\n            backtrack_causes=base.backtrack_causes[:],\n        )\n        self._states.append(state)\n\n    def _add_to_criteria(\n        self,\n        criteria: dict[KT, Criterion[RT, CT]],\n        requirement: RT,\n        parent: CT | None,\n    ) -> None:\n        self._r.adding_requirement(requirement=requirement, parent=parent)\n\n        identifier = self._p.identify(requirement_or_candidate=requirement)\n        criterion = criteria.get(identifier)\n        if criterion:\n            incompatibilities = list(criterion.incompatibilities)\n        else:\n            incompatibilities = []\n\n        matches = self._p.find_matches(\n            identifier=identifier,\n            requirements=IteratorMapping(\n                criteria,\n                operator.methodcaller(\"iter_requirement\"),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\__init__.py": {
      "sha": "9949388cfe1a",
      "lines": 27,
      "head": "from ..structs import RequirementInformation\nfrom .abstract import AbstractResolver, Result\nfrom .criterion import Criterion\nfrom .exceptions import (\n    InconsistentCandidate,\n    RequirementsConflicted,\n    ResolutionError,\n    ResolutionImpossible,\n    ResolutionTooDeep,\n    ResolverException,\n)\nfrom .resolution import Resolution, Resolver\n\n__all__ = [\n    \"AbstractResolver\",\n    \"InconsistentCandidate\",\n    \"Resolver\",\n    \"Resolution\",\n    \"RequirementsConflicted\",\n    \"ResolutionError\",\n    \"ResolutionImpossible\",\n    \"ResolutionTooDeep\",\n    \"RequirementInformation\",\n    \"ResolverException\",\n    \"Result\",\n    \"Criterion\",\n]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\abc.py": {
      "sha": "9e5742f6c5e2",
      "lines": 33,
      "head": "from abc import ABC\n\n\nclass RichRenderable(ABC):\n    \"\"\"An abstract base class for Rich renderables.\n\n    Note that there is no need to extend this class, the intended use is to check if an\n    object supports the Rich renderable protocol. For example::\n\n        if isinstance(my_object, RichRenderable):\n            console.print(my_object)\n\n    \"\"\"\n\n    @classmethod\n    def __subclasshook__(cls, other: type) -> bool:\n        \"\"\"Check if this class supports the rich render protocol.\"\"\"\n        return hasattr(other, \"__rich_console__\") or hasattr(other, \"__rich__\")\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from pip._vendor.rich.text import Text\n\n    t = Text()\n    print(isinstance(Text, RichRenderable))\n    print(isinstance(t, RichRenderable))\n\n    class Foo:\n        pass\n\n    f = Foo()\n    print(isinstance(f, RichRenderable))\n    print(isinstance(\"\", RichRenderable))\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\align.py": {
      "sha": "891b51135b4f",
      "lines": 312,
      "head": "import sys\nfrom itertools import chain\nfrom typing import TYPE_CHECKING, Iterable, Optional\n\nif sys.version_info >= (3, 8):\n    from typing import Literal\nelse:\n    from pip._vendor.typing_extensions import Literal  # pragma: no cover\n\nfrom .constrain import Constrain\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .segment import Segment\nfrom .style import StyleType\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n\nAlignMethod = Literal[\"left\", \"center\", \"right\"]\nVerticalAlignMethod = Literal[\"top\", \"middle\", \"bottom\"]\n\n\nclass Align(JupyterMixin):\n    \"\"\"Align a renderable by adding spaces if necessary.\n\n    Args:\n        renderable (RenderableType): A console renderable.\n        align (AlignMethod): One of \"left\", \"center\", or \"right\"\"\n        style (StyleType, optional): An optional style to apply to the background.\n        vertical (Optional[VerticalAlignMethod], optional): Optional vertical align, one of \"top\", \"middle\", or \"bottom\". Defaults to None.\n        pad (bool, optional): Pad the right with spaces. Defaults to True.\n        width (int, optional): Restrict contents to given width, or None to use default width. Defaults to None.\n        height (int, optional): Set height of align renderable, or None to fit to contents. Defaults to None.\n\n    Raises:\n        ValueError: if ``align`` is not one of the expected values.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: \"RenderableType\",\n        align: AlignMethod = \"left\",\n        style: Optional[StyleType] = None,\n        *,\n        vertical: Optional[VerticalAlignMethod] = None,\n        pad: bool = True,\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n    ) -> None:\n        if align not in (\"left\", \"center\", \"right\"):\n            raise ValueError(\n                f'invalid value for align, expected \"left\", \"center\", or \"right\" (not {align!r})'\n            )\n        if vertical is not None and vertical not in (\"top\", \"middle\", \"bottom\"):\n            raise ValueError(\n                f'invalid value for vertical, expected \"top\", \"middle\", or \"bottom\" (not {vertical!r})'\n            )\n        self.renderable = renderable\n        self.align = align\n        self.style = style\n        self.vertical = vertical\n        self.pad = pad\n        self.width = width\n        self.height = height\n\n    def __repr__(self) -> str:\n        return f\"Align({self.renderable!r}, {self.align!r})\"\n\n    @classmethod\n    def left(\n        cls,\n        renderable: \"RenderableType\",\n        style: Optional[StyleType] = None,\n        *,\n        vertical: Optional[VerticalAlignMethod] = None,\n        pad: bool = True,\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n    ) -> \"Align\":\n        \"\"\"Align a renderable to the left.\"\"\"\n        return cls(\n            renderable,\n            \"left\",\n            style=style,\n            vertical=vertical,\n            pad=pad,\n            width=width,\n            height=height,\n        )\n\n    @classmethod\n    def center(\n        cls,\n        renderable: \"RenderableType\",\n        style: Optional[StyleType] = None,\n        *,\n        vertical: Optional[VerticalAlignMethod] = None,\n        pad: bool = True,\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n    ) -> \"Align\":\n        \"\"\"Align a renderable to the center.\"\"\"\n        return cls(\n            renderable,\n            \"center\",\n            style=style,\n            vertical=vertical,\n            pad=pad,\n            width=width,\n            height=height,\n        )\n\n    @classmethod\n    def right(\n        cls,\n        renderable: \"RenderableType\",\n        style: Optional[StyleType] = None,\n        *,\n        vertical: Optional[VerticalAlignMethod] = None,\n        pad: bool = True,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\ansi.py": {
      "sha": "127e8fa3efd6",
      "lines": 241,
      "head": "import re\nimport sys\nfrom contextlib import suppress\nfrom typing import Iterable, NamedTuple, Optional\n\nfrom .color import Color\nfrom .style import Style\nfrom .text import Text\n\nre_ansi = re.compile(\n    r\"\"\"\n(?:\\x1b[0-?])|\n(?:\\x1b\\](.*?)\\x1b\\\\)|\n(?:\\x1b([(@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~]))\n\"\"\",\n    re.VERBOSE,\n)\n\n\nclass _AnsiToken(NamedTuple):\n    \"\"\"Result of ansi tokenized string.\"\"\"\n\n    plain: str = \"\"\n    sgr: Optional[str] = \"\"\n    osc: Optional[str] = \"\"\n\n\ndef _ansi_tokenize(ansi_text: str) -> Iterable[_AnsiToken]:\n    \"\"\"Tokenize a string in to plain text and ANSI codes.\n\n    Args:\n        ansi_text (str): A String containing ANSI codes.\n\n    Yields:\n        AnsiToken: A named tuple of (plain, sgr, osc)\n    \"\"\"\n\n    position = 0\n    sgr: Optional[str]\n    osc: Optional[str]\n    for match in re_ansi.finditer(ansi_text):\n        start, end = match.span(0)\n        osc, sgr = match.groups()\n        if start > position:\n            yield _AnsiToken(ansi_text[position:start])\n        if sgr:\n            if sgr == \"(\":\n                position = end + 1\n                continue\n            if sgr.endswith(\"m\"):\n                yield _AnsiToken(\"\", sgr[1:-1], osc)\n        else:\n            yield _AnsiToken(\"\", sgr, osc)\n        position = end\n    if position < len(ansi_text):\n        yield _AnsiToken(ansi_text[position:])\n\n\nSGR_STYLE_MAP = {\n    1: \"bold\",\n    2: \"dim\",\n    3: \"italic\",\n    4: \"underline\",\n    5: \"blink\",\n    6: \"blink2\",\n    7: \"reverse\",\n    8: \"conceal\",\n    9: \"strike\",\n    21: \"underline2\",\n    22: \"not dim not bold\",\n    23: \"not italic\",\n    24: \"not underline\",\n    25: \"not blink\",\n    26: \"not blink2\",\n    27: \"not reverse\",\n    28: \"not conceal\",\n    29: \"not strike\",\n    30: \"color(0)\",\n    31: \"color(1)\",\n    32: \"color(2)\",\n    33: \"color(3)\",\n    34: \"color(4)\",\n    35: \"color(5)\",\n    36: \"color(6)\",\n    37: \"color(7)\",\n    39: \"default\",\n    40: \"on color(0)\",\n    41: \"on color(1)\",\n    42: \"on color(2)\",\n    43: \"on color(3)\",\n    44: \"on color(4)\",\n    45: \"on color(5)\",\n    46: \"on color(6)\",\n    47: \"on color(7)\",\n    49: \"on default\",\n    51: \"frame\",\n    52: \"encircle\",\n    53: \"overline\",\n    54: \"not frame not encircle\",\n    55: \"not overline\",\n    90: \"color(8)\",\n    91: \"color(9)\",\n    92: \"color(10)\",\n    93: \"color(11)\",\n    94: \"color(12)\",\n    95: \"color(13)\",\n    96: \"color(14)\",\n    97: \"color(15)\",\n    100: \"on color(8)\",\n    101: \"on color(9)\",\n    102: \"on color(10)\",\n    103: \"on color(11)\",\n    104: \"on color(12)\",\n    105: \"on color(13)\",\n    106: \"on color(14)\",\n    107: \"on color(15)\",\n}\n\n\nclass AnsiDecoder:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\bar.py": {
      "sha": "a55869f0a6fc",
      "lines": 93,
      "head": "from typing import Optional, Union\n\nfrom .color import Color\nfrom .console import Console, ConsoleOptions, RenderResult\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .segment import Segment\nfrom .style import Style\n\n# There are left-aligned characters for 1/8 to 7/8, but\n# the right-aligned characters exist only for 1/8 and 4/8.\nBEGIN_BLOCK_ELEMENTS = [\"\u2588\", \"\u2588\", \"\u2588\", \"\u2590\", \"\u2590\", \"\u2590\", \"\u2595\", \"\u2595\"]\nEND_BLOCK_ELEMENTS = [\" \", \"\u258f\", \"\u258e\", \"\u258d\", \"\u258c\", \"\u258b\", \"\u258a\", \"\u2589\"]\nFULL_BLOCK = \"\u2588\"\n\n\nclass Bar(JupyterMixin):\n    \"\"\"Renders a solid block bar.\n\n    Args:\n        size (float): Value for the end of the bar.\n        begin (float): Begin point (between 0 and size, inclusive).\n        end (float): End point (between 0 and size, inclusive).\n        width (int, optional): Width of the bar, or ``None`` for maximum width. Defaults to None.\n        color (Union[Color, str], optional): Color of the bar. Defaults to \"default\".\n        bgcolor (Union[Color, str], optional): Color of bar background. Defaults to \"default\".\n    \"\"\"\n\n    def __init__(\n        self,\n        size: float,\n        begin: float,\n        end: float,\n        *,\n        width: Optional[int] = None,\n        color: Union[Color, str] = \"default\",\n        bgcolor: Union[Color, str] = \"default\",\n    ):\n        self.size = size\n        self.begin = max(begin, 0)\n        self.end = min(end, size)\n        self.width = width\n        self.style = Style(color=color, bgcolor=bgcolor)\n\n    def __repr__(self) -> str:\n        return f\"Bar({self.size}, {self.begin}, {self.end})\"\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        width = min(\n            self.width if self.width is not None else options.max_width,\n            options.max_width,\n        )\n\n        if self.begin >= self.end:\n            yield Segment(\" \" * width, self.style)\n            yield Segment.line()\n            return\n\n        prefix_complete_eights = int(width * 8 * self.begin / self.size)\n        prefix_bar_count = prefix_complete_eights // 8\n        prefix_eights_count = prefix_complete_eights % 8\n\n        body_complete_eights = int(width * 8 * self.end / self.size)\n        body_bar_count = body_complete_eights // 8\n        body_eights_count = body_complete_eights % 8\n\n        # When start and end fall into the same cell, we ideally should render\n        # a symbol that's \"center-aligned\", but there is no good symbol in Unicode.\n        # In this case, we fall back to right-aligned block symbol for simplicity.\n\n        prefix = \" \" * prefix_bar_count\n        if prefix_eights_count:\n            prefix += BEGIN_BLOCK_ELEMENTS[prefix_eights_count]\n\n        body = FULL_BLOCK * body_bar_count\n        if body_eights_count:\n            body += END_BLOCK_ELEMENTS[body_eights_count]\n\n        suffix = \" \" * (width - len(body))\n\n        yield Segment(prefix + body[len(prefix) :] + suffix, self.style)\n        yield Segment.line()\n\n    def __rich_measure__(\n        self, console: Console, options: ConsoleOptions\n    ) -> Measurement:\n        return (\n            Measurement(self.width, self.width)\n            if self.width is not None\n            else Measurement(4, options.max_width)\n        )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\box.py": {
      "sha": "b5786aadcb6a",
      "lines": 480,
      "head": "import sys\nfrom typing import TYPE_CHECKING, Iterable, List\n\nif sys.version_info >= (3, 8):\n    from typing import Literal\nelse:\n    from pip._vendor.typing_extensions import Literal  # pragma: no cover\n\n\nfrom ._loop import loop_last\n\nif TYPE_CHECKING:\n    from pip._vendor.rich.console import ConsoleOptions\n\n\nclass Box:\n    \"\"\"Defines characters to render boxes.\n\n    \u250c\u2500\u252c\u2510 top\n    \u2502 \u2502\u2502 head\n    \u251c\u2500\u253c\u2524 head_row\n    \u2502 \u2502\u2502 mid\n    \u251c\u2500\u253c\u2524 row\n    \u251c\u2500\u253c\u2524 foot_row\n    \u2502 \u2502\u2502 foot\n    \u2514\u2500\u2534\u2518 bottom\n\n    Args:\n        box (str): Characters making up box.\n        ascii (bool, optional): True if this box uses ascii characters only. Default is False.\n    \"\"\"\n\n    def __init__(self, box: str, *, ascii: bool = False) -> None:\n        self._box = box\n        self.ascii = ascii\n        line1, line2, line3, line4, line5, line6, line7, line8 = box.splitlines()\n        # top\n        self.top_left, self.top, self.top_divider, self.top_right = iter(line1)\n        # head\n        self.head_left, _, self.head_vertical, self.head_right = iter(line2)\n        # head_row\n        (\n            self.head_row_left,\n            self.head_row_horizontal,\n            self.head_row_cross,\n            self.head_row_right,\n        ) = iter(line3)\n\n        # mid\n        self.mid_left, _, self.mid_vertical, self.mid_right = iter(line4)\n        # row\n        self.row_left, self.row_horizontal, self.row_cross, self.row_right = iter(line5)\n        # foot_row\n        (\n            self.foot_row_left,\n            self.foot_row_horizontal,\n            self.foot_row_cross,\n            self.foot_row_right,\n        ) = iter(line6)\n        # foot\n        self.foot_left, _, self.foot_vertical, self.foot_right = iter(line7)\n        # bottom\n        self.bottom_left, self.bottom, self.bottom_divider, self.bottom_right = iter(\n            line8\n        )\n\n    def __repr__(self) -> str:\n        return \"Box(...)\"\n\n    def __str__(self) -> str:\n        return self._box\n\n    def substitute(self, options: \"ConsoleOptions\", safe: bool = True) -> \"Box\":\n        \"\"\"Substitute this box for another if it won't render due to platform issues.\n\n        Args:\n            options (ConsoleOptions): Console options used in rendering.\n            safe (bool, optional): Substitute this for another Box if there are known problems\n                displaying on the platform (currently only relevant on Windows). Default is True.\n\n        Returns:\n            Box: A different Box or the same Box.\n        \"\"\"\n        box = self\n        if options.legacy_windows and safe:\n            box = LEGACY_WINDOWS_SUBSTITUTIONS.get(box, box)\n        if options.ascii_only and not box.ascii:\n            box = ASCII\n        return box\n\n    def get_plain_headed_box(self) -> \"Box\":\n        \"\"\"If this box uses special characters for the borders of the header, then\n        return the equivalent box that does not.\n\n        Returns:\n            Box: The most similar Box that doesn't use header-specific box characters.\n                If the current Box already satisfies this criterion, then it's returned.\n        \"\"\"\n        return PLAIN_HEADED_SUBSTITUTIONS.get(self, self)\n\n    def get_top(self, widths: Iterable[int]) -> str:\n        \"\"\"Get the top of a simple box.\n\n        Args:\n            widths (List[int]): Widths of columns.\n\n        Returns:\n            str: A string of box characters.\n        \"\"\"\n\n        parts: List[str] = []\n        append = parts.append\n        append(self.top_left)\n        for last, width in loop_last(widths):\n            append(self.top * width)\n            if not last:\n                append(self.top_divider)\n        append(self.top_right)\n        return \"\".join(parts)\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\cells.py": {
      "sha": "f0bdec5436ed",
      "lines": 174,
      "head": "from __future__ import annotations\n\nfrom functools import lru_cache\nfrom typing import Callable\n\nfrom ._cell_widths import CELL_WIDTHS\n\n# Ranges of unicode ordinals that produce a 1-cell wide character\n# This is non-exhaustive, but covers most common Western characters\n_SINGLE_CELL_UNICODE_RANGES: list[tuple[int, int]] = [\n    (0x20, 0x7E),  # Latin (excluding non-printable)\n    (0xA0, 0xAC),\n    (0xAE, 0x002FF),\n    (0x00370, 0x00482),  # Greek / Cyrillic\n    (0x02500, 0x025FC),  # Box drawing, box elements, geometric shapes\n    (0x02800, 0x028FF),  # Braille\n]\n\n# A set of characters that are a single cell wide\n_SINGLE_CELLS = frozenset(\n    [\n        character\n        for _start, _end in _SINGLE_CELL_UNICODE_RANGES\n        for character in map(chr, range(_start, _end + 1))\n    ]\n)\n\n# When called with a string this will return True if all\n# characters are single-cell, otherwise False\n_is_single_cell_widths: Callable[[str], bool] = _SINGLE_CELLS.issuperset\n\n\n@lru_cache(4096)\ndef cached_cell_len(text: str) -> int:\n    \"\"\"Get the number of cells required to display text.\n\n    This method always caches, which may use up a lot of memory. It is recommended to use\n    `cell_len` over this method.\n\n    Args:\n        text (str): Text to display.\n\n    Returns:\n        int: Get the number of cells required to display text.\n    \"\"\"\n    if _is_single_cell_widths(text):\n        return len(text)\n    return sum(map(get_character_cell_size, text))\n\n\ndef cell_len(text: str, _cell_len: Callable[[str], int] = cached_cell_len) -> int:\n    \"\"\"Get the number of cells required to display text.\n\n    Args:\n        text (str): Text to display.\n\n    Returns:\n        int: Get the number of cells required to display text.\n    \"\"\"\n    if len(text) < 512:\n        return _cell_len(text)\n    if _is_single_cell_widths(text):\n        return len(text)\n    return sum(map(get_character_cell_size, text))\n\n\n@lru_cache(maxsize=4096)\ndef get_character_cell_size(character: str) -> int:\n    \"\"\"Get the cell size of a character.\n\n    Args:\n        character (str): A single character.\n\n    Returns:\n        int: Number of cells (0, 1 or 2) occupied by that character.\n    \"\"\"\n    codepoint = ord(character)\n    _table = CELL_WIDTHS\n    lower_bound = 0\n    upper_bound = len(_table) - 1\n    index = (lower_bound + upper_bound) // 2\n    while True:\n        start, end, width = _table[index]\n        if codepoint < start:\n            upper_bound = index - 1\n        elif codepoint > end:\n            lower_bound = index + 1\n        else:\n            return 0 if width == -1 else width\n        if upper_bound < lower_bound:\n            break\n        index = (lower_bound + upper_bound) // 2\n    return 1\n\n\ndef set_cell_size(text: str, total: int) -> str:\n    \"\"\"Set the length of a string to fit within given number of cells.\"\"\"\n\n    if _is_single_cell_widths(text):\n        size = len(text)\n        if size < total:\n            return text + \" \" * (total - size)\n        return text[:total]\n\n    if total <= 0:\n        return \"\"\n    cell_size = cell_len(text)\n    if cell_size == total:\n        return text\n    if cell_size < total:\n        return text + \" \" * (total - cell_size)\n\n    start = 0\n    end = len(text)\n\n    # Binary search until we find the right size\n    while True:\n        pos = (start + end) // 2\n        before = text[: pos + 1]\n        before_len = cell_len(before)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\color.py": {
      "sha": "a4cb4dba1139",
      "lines": 621,
      "head": "import re\nimport sys\nfrom colorsys import rgb_to_hls\nfrom enum import IntEnum\nfrom functools import lru_cache\nfrom typing import TYPE_CHECKING, NamedTuple, Optional, Tuple\n\nfrom ._palettes import EIGHT_BIT_PALETTE, STANDARD_PALETTE, WINDOWS_PALETTE\nfrom .color_triplet import ColorTriplet\nfrom .repr import Result, rich_repr\nfrom .terminal_theme import DEFAULT_TERMINAL_THEME\n\nif TYPE_CHECKING:  # pragma: no cover\n    from .terminal_theme import TerminalTheme\n    from .text import Text\n\n\nWINDOWS = sys.platform == \"win32\"\n\n\nclass ColorSystem(IntEnum):\n    \"\"\"One of the 3 color system supported by terminals.\"\"\"\n\n    STANDARD = 1\n    EIGHT_BIT = 2\n    TRUECOLOR = 3\n    WINDOWS = 4\n\n    def __repr__(self) -> str:\n        return f\"ColorSystem.{self.name}\"\n\n    def __str__(self) -> str:\n        return repr(self)\n\n\nclass ColorType(IntEnum):\n    \"\"\"Type of color stored in Color class.\"\"\"\n\n    DEFAULT = 0\n    STANDARD = 1\n    EIGHT_BIT = 2\n    TRUECOLOR = 3\n    WINDOWS = 4\n\n    def __repr__(self) -> str:\n        return f\"ColorType.{self.name}\"\n\n\nANSI_COLOR_NAMES = {\n    \"black\": 0,\n    \"red\": 1,\n    \"green\": 2,\n    \"yellow\": 3,\n    \"blue\": 4,\n    \"magenta\": 5,\n    \"cyan\": 6,\n    \"white\": 7,\n    \"bright_black\": 8,\n    \"bright_red\": 9,\n    \"bright_green\": 10,\n    \"bright_yellow\": 11,\n    \"bright_blue\": 12,\n    \"bright_magenta\": 13,\n    \"bright_cyan\": 14,\n    \"bright_white\": 15,\n    \"grey0\": 16,\n    \"gray0\": 16,\n    \"navy_blue\": 17,\n    \"dark_blue\": 18,\n    \"blue3\": 20,\n    \"blue1\": 21,\n    \"dark_green\": 22,\n    \"deep_sky_blue4\": 25,\n    \"dodger_blue3\": 26,\n    \"dodger_blue2\": 27,\n    \"green4\": 28,\n    \"spring_green4\": 29,\n    \"turquoise4\": 30,\n    \"deep_sky_blue3\": 32,\n    \"dodger_blue1\": 33,\n    \"green3\": 40,\n    \"spring_green3\": 41,\n    \"dark_cyan\": 36,\n    \"light_sea_green\": 37,\n    \"deep_sky_blue2\": 38,\n    \"deep_sky_blue1\": 39,\n    \"spring_green2\": 47,\n    \"cyan3\": 43,\n    \"dark_turquoise\": 44,\n    \"turquoise2\": 45,\n    \"green1\": 46,\n    \"spring_green1\": 48,\n    \"medium_spring_green\": 49,\n    \"cyan2\": 50,\n    \"cyan1\": 51,\n    \"dark_red\": 88,\n    \"deep_pink4\": 125,\n    \"purple4\": 55,\n    \"purple3\": 56,\n    \"blue_violet\": 57,\n    \"orange4\": 94,\n    \"grey37\": 59,\n    \"gray37\": 59,\n    \"medium_purple4\": 60,\n    \"slate_blue3\": 62,\n    \"royal_blue1\": 63,\n    \"chartreuse4\": 64,\n    \"dark_sea_green4\": 71,\n    \"pale_turquoise4\": 66,\n    \"steel_blue\": 67,\n    \"steel_blue3\": 68,\n    \"cornflower_blue\": 69,\n    \"chartreuse3\": 76,\n    \"cadet_blue\": 73,\n    \"sky_blue3\": 74,\n    \"steel_blue1\": 81,\n    \"pale_green3\": 114,\n    \"sea_green3\": 78,\n    \"aquamarine3\": 79,\n    \"medium_turquoise\": 80,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\color_triplet.py": {
      "sha": "fa44f6511c7b",
      "lines": 38,
      "head": "from typing import NamedTuple, Tuple\n\n\nclass ColorTriplet(NamedTuple):\n    \"\"\"The red, green, and blue components of a color.\"\"\"\n\n    red: int\n    \"\"\"Red component in 0 to 255 range.\"\"\"\n    green: int\n    \"\"\"Green component in 0 to 255 range.\"\"\"\n    blue: int\n    \"\"\"Blue component in 0 to 255 range.\"\"\"\n\n    @property\n    def hex(self) -> str:\n        \"\"\"get the color triplet in CSS style.\"\"\"\n        red, green, blue = self\n        return f\"#{red:02x}{green:02x}{blue:02x}\"\n\n    @property\n    def rgb(self) -> str:\n        \"\"\"The color in RGB format.\n\n        Returns:\n            str: An rgb color, e.g. ``\"rgb(100,23,255)\"``.\n        \"\"\"\n        red, green, blue = self\n        return f\"rgb({red},{green},{blue})\"\n\n    @property\n    def normalized(self) -> Tuple[float, float, float]:\n        \"\"\"Convert components into floats between 0 and 1.\n\n        Returns:\n            Tuple[float, float, float]: A tuple of three normalized colour components.\n        \"\"\"\n        red, green, blue = self\n        return red / 255.0, green / 255.0, blue / 255.0\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\columns.py": {
      "sha": "556f2bdd1c73",
      "lines": 187,
      "head": "from collections import defaultdict\nfrom itertools import chain\nfrom operator import itemgetter\nfrom typing import Dict, Iterable, List, Optional, Tuple\n\nfrom .align import Align, AlignMethod\nfrom .console import Console, ConsoleOptions, RenderableType, RenderResult\nfrom .constrain import Constrain\nfrom .measure import Measurement\nfrom .padding import Padding, PaddingDimensions\nfrom .table import Table\nfrom .text import TextType\nfrom .jupyter import JupyterMixin\n\n\nclass Columns(JupyterMixin):\n    \"\"\"Display renderables in neat columns.\n\n    Args:\n        renderables (Iterable[RenderableType]): Any number of Rich renderables (including str).\n        width (int, optional): The desired width of the columns, or None to auto detect. Defaults to None.\n        padding (PaddingDimensions, optional): Optional padding around cells. Defaults to (0, 1).\n        expand (bool, optional): Expand columns to full width. Defaults to False.\n        equal (bool, optional): Arrange in to equal sized columns. Defaults to False.\n        column_first (bool, optional): Align items from top to bottom (rather than left to right). Defaults to False.\n        right_to_left (bool, optional): Start column from right hand side. Defaults to False.\n        align (str, optional): Align value (\"left\", \"right\", or \"center\") or None for default. Defaults to None.\n        title (TextType, optional): Optional title for Columns.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderables: Optional[Iterable[RenderableType]] = None,\n        padding: PaddingDimensions = (0, 1),\n        *,\n        width: Optional[int] = None,\n        expand: bool = False,\n        equal: bool = False,\n        column_first: bool = False,\n        right_to_left: bool = False,\n        align: Optional[AlignMethod] = None,\n        title: Optional[TextType] = None,\n    ) -> None:\n        self.renderables = list(renderables or [])\n        self.width = width\n        self.padding = padding\n        self.expand = expand\n        self.equal = equal\n        self.column_first = column_first\n        self.right_to_left = right_to_left\n        self.align: Optional[AlignMethod] = align\n        self.title = title\n\n    def add_renderable(self, renderable: RenderableType) -> None:\n        \"\"\"Add a renderable to the columns.\n\n        Args:\n            renderable (RenderableType): Any renderable object.\n        \"\"\"\n        self.renderables.append(renderable)\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        render_str = console.render_str\n        renderables = [\n            render_str(renderable) if isinstance(renderable, str) else renderable\n            for renderable in self.renderables\n        ]\n        if not renderables:\n            return\n        _top, right, _bottom, left = Padding.unpack(self.padding)\n        width_padding = max(left, right)\n        max_width = options.max_width\n        widths: Dict[int, int] = defaultdict(int)\n        column_count = len(renderables)\n\n        get_measurement = Measurement.get\n        renderable_widths = [\n            get_measurement(console, options, renderable).maximum\n            for renderable in renderables\n        ]\n        if self.equal:\n            renderable_widths = [max(renderable_widths)] * len(renderable_widths)\n\n        def iter_renderables(\n            column_count: int,\n        ) -> Iterable[Tuple[int, Optional[RenderableType]]]:\n            item_count = len(renderables)\n            if self.column_first:\n                width_renderables = list(zip(renderable_widths, renderables))\n\n                column_lengths: List[int] = [item_count // column_count] * column_count\n                for col_no in range(item_count % column_count):\n                    column_lengths[col_no] += 1\n\n                row_count = (item_count + column_count - 1) // column_count\n                cells = [[-1] * column_count for _ in range(row_count)]\n                row = col = 0\n                for index in range(item_count):\n                    cells[row][col] = index\n                    column_lengths[col] -= 1\n                    if column_lengths[col]:\n                        row += 1\n                    else:\n                        col += 1\n                        row = 0\n                for index in chain.from_iterable(cells):\n                    if index == -1:\n                        break\n                    yield width_renderables[index]\n            else:\n                yield from zip(renderable_widths, renderables)\n            # Pad odd elements with spaces\n            if item_count % column_count:\n                for _ in range(column_count - (item_count % column_count)):\n                    yield 0, None\n\n        table = Table.grid(padding=self.padding, collapse_padding=True, pad_edge=False)\n        table.expand = self.expand\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\console.py": {
      "sha": "dd8f43e19d90",
      "lines": 2675,
      "head": "import inspect\nimport os\nimport sys\nimport threading\nimport zlib\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom functools import wraps\nfrom getpass import getpass\nfrom html import escape\nfrom inspect import isclass\nfrom itertools import islice\nfrom math import ceil\nfrom time import monotonic\nfrom types import FrameType, ModuleType, TracebackType\nfrom typing import (\n    IO,\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Mapping,\n    NamedTuple,\n    Optional,\n    TextIO,\n    Tuple,\n    Type,\n    Union,\n    cast,\n)\n\nfrom pip._vendor.rich._null_file import NULL_FILE\n\nif sys.version_info >= (3, 8):\n    from typing import Literal, Protocol, runtime_checkable\nelse:\n    from pip._vendor.typing_extensions import (\n        Literal,\n        Protocol,\n        runtime_checkable,\n    )  # pragma: no cover\n\nfrom . import errors, themes\nfrom ._emoji_replace import _emoji_replace\nfrom ._export_format import CONSOLE_HTML_FORMAT, CONSOLE_SVG_FORMAT\nfrom ._fileno import get_fileno\nfrom ._log_render import FormatTimeCallable, LogRender\nfrom .align import Align, AlignMethod\nfrom .color import ColorSystem, blend_rgb\nfrom .control import Control\nfrom .emoji import EmojiVariant\nfrom .highlighter import NullHighlighter, ReprHighlighter\nfrom .markup import render as render_markup\nfrom .measure import Measurement, measure_renderables\nfrom .pager import Pager, SystemPager\nfrom .pretty import Pretty, is_expandable\nfrom .protocol import rich_cast\nfrom .region import Region\nfrom .scope import render_scope\nfrom .screen import Screen\nfrom .segment import Segment\nfrom .style import Style, StyleType\nfrom .styled import Styled\nfrom .terminal_theme import DEFAULT_TERMINAL_THEME, SVG_EXPORT_THEME, TerminalTheme\nfrom .text import Text, TextType\nfrom .theme import Theme, ThemeStack\n\nif TYPE_CHECKING:\n    from ._windows import WindowsConsoleFeatures\n    from .live import Live\n    from .status import Status\n\nJUPYTER_DEFAULT_COLUMNS = 115\nJUPYTER_DEFAULT_LINES = 100\nWINDOWS = sys.platform == \"win32\"\n\nHighlighterType = Callable[[Union[str, \"Text\"]], \"Text\"]\nJustifyMethod = Literal[\"default\", \"left\", \"center\", \"right\", \"full\"]\nOverflowMethod = Literal[\"fold\", \"crop\", \"ellipsis\", \"ignore\"]\n\n\nclass NoChange:\n    pass\n\n\nNO_CHANGE = NoChange()\n\ntry:\n    _STDIN_FILENO = sys.__stdin__.fileno()  # type: ignore[union-attr]\nexcept Exception:\n    _STDIN_FILENO = 0\ntry:\n    _STDOUT_FILENO = sys.__stdout__.fileno()  # type: ignore[union-attr]\nexcept Exception:\n    _STDOUT_FILENO = 1\ntry:\n    _STDERR_FILENO = sys.__stderr__.fileno()  # type: ignore[union-attr]\nexcept Exception:\n    _STDERR_FILENO = 2\n\n_STD_STREAMS = (_STDIN_FILENO, _STDOUT_FILENO, _STDERR_FILENO)\n_STD_STREAMS_OUTPUT = (_STDOUT_FILENO, _STDERR_FILENO)\n\n\n_TERM_COLORS = {\n    \"kitty\": ColorSystem.EIGHT_BIT,\n    \"256color\": ColorSystem.EIGHT_BIT,\n    \"16color\": ColorSystem.STANDARD,\n}\n\n\nclass ConsoleDimensions(NamedTuple):\n    \"\"\"Size of the terminal.\"\"\"\n\n    width: int\n    \"\"\"The width of the console in 'cells'.\"\"\"\n    height: int\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\constrain.py": {
      "sha": "97d8b90ab5f8",
      "lines": 37,
      "head": "from typing import Optional, TYPE_CHECKING\n\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n\n\nclass Constrain(JupyterMixin):\n    \"\"\"Constrain the width of a renderable to a given number of characters.\n\n    Args:\n        renderable (RenderableType): A renderable object.\n        width (int, optional): The maximum width (in characters) to render. Defaults to 80.\n    \"\"\"\n\n    def __init__(self, renderable: \"RenderableType\", width: Optional[int] = 80) -> None:\n        self.renderable = renderable\n        self.width = width\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        if self.width is None:\n            yield self.renderable\n        else:\n            child_options = options.update_width(min(self.width, options.max_width))\n            yield from console.render(self.renderable, child_options)\n\n    def __rich_measure__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"Measurement\":\n        if self.width is not None:\n            options = options.update_width(self.width)\n        measurement = Measurement.get(console, options, self.renderable)\n        return measurement\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\containers.py": {
      "sha": "e78906a601db",
      "lines": 167,
      "head": "from itertools import zip_longest\nfrom typing import (\n    TYPE_CHECKING,\n    Iterable,\n    Iterator,\n    List,\n    Optional,\n    TypeVar,\n    Union,\n    overload,\n)\n\nif TYPE_CHECKING:\n    from .console import (\n        Console,\n        ConsoleOptions,\n        JustifyMethod,\n        OverflowMethod,\n        RenderResult,\n        RenderableType,\n    )\n    from .text import Text\n\nfrom .cells import cell_len\nfrom .measure import Measurement\n\nT = TypeVar(\"T\")\n\n\nclass Renderables:\n    \"\"\"A list subclass which renders its contents to the console.\"\"\"\n\n    def __init__(\n        self, renderables: Optional[Iterable[\"RenderableType\"]] = None\n    ) -> None:\n        self._renderables: List[\"RenderableType\"] = (\n            list(renderables) if renderables is not None else []\n        )\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        \"\"\"Console render method to insert line-breaks.\"\"\"\n        yield from self._renderables\n\n    def __rich_measure__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"Measurement\":\n        dimensions = [\n            Measurement.get(console, options, renderable)\n            for renderable in self._renderables\n        ]\n        if not dimensions:\n            return Measurement(1, 1)\n        _min = max(dimension.minimum for dimension in dimensions)\n        _max = max(dimension.maximum for dimension in dimensions)\n        return Measurement(_min, _max)\n\n    def append(self, renderable: \"RenderableType\") -> None:\n        self._renderables.append(renderable)\n\n    def __iter__(self) -> Iterable[\"RenderableType\"]:\n        return iter(self._renderables)\n\n\nclass Lines:\n    \"\"\"A list subclass which can render to the console.\"\"\"\n\n    def __init__(self, lines: Iterable[\"Text\"] = ()) -> None:\n        self._lines: List[\"Text\"] = list(lines)\n\n    def __repr__(self) -> str:\n        return f\"Lines({self._lines!r})\"\n\n    def __iter__(self) -> Iterator[\"Text\"]:\n        return iter(self._lines)\n\n    @overload\n    def __getitem__(self, index: int) -> \"Text\":\n        ...\n\n    @overload\n    def __getitem__(self, index: slice) -> List[\"Text\"]:\n        ...\n\n    def __getitem__(self, index: Union[slice, int]) -> Union[\"Text\", List[\"Text\"]]:\n        return self._lines[index]\n\n    def __setitem__(self, index: int, value: \"Text\") -> \"Lines\":\n        self._lines[index] = value\n        return self\n\n    def __len__(self) -> int:\n        return self._lines.__len__()\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        \"\"\"Console render method to insert line-breaks.\"\"\"\n        yield from self._lines\n\n    def append(self, line: \"Text\") -> None:\n        self._lines.append(line)\n\n    def extend(self, lines: Iterable[\"Text\"]) -> None:\n        self._lines.extend(lines)\n\n    def pop(self, index: int = -1) -> \"Text\":\n        return self._lines.pop(index)\n\n    def justify(\n        self,\n        console: \"Console\",\n        width: int,\n        justify: \"JustifyMethod\" = \"left\",\n        overflow: \"OverflowMethod\" = \"fold\",\n    ) -> None:\n        \"\"\"Justify and overflow text to a given width.\n\n        Args:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\control.py": {
      "sha": "59d7c1fb1c7d",
      "lines": 225,
      "head": "import sys\nimport time\nfrom typing import TYPE_CHECKING, Callable, Dict, Iterable, List, Union\n\nif sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from pip._vendor.typing_extensions import Final  # pragma: no cover\n\nfrom .segment import ControlCode, ControlType, Segment\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderResult\n\nSTRIP_CONTROL_CODES: Final = [\n    7,  # Bell\n    8,  # Backspace\n    11,  # Vertical tab\n    12,  # Form feed\n    13,  # Carriage return\n]\n_CONTROL_STRIP_TRANSLATE: Final = {\n    _codepoint: None for _codepoint in STRIP_CONTROL_CODES\n}\n\nCONTROL_ESCAPE: Final = {\n    7: \"\\\\a\",\n    8: \"\\\\b\",\n    11: \"\\\\v\",\n    12: \"\\\\f\",\n    13: \"\\\\r\",\n}\n\nCONTROL_CODES_FORMAT: Dict[int, Callable[..., str]] = {\n    ControlType.BELL: lambda: \"\\x07\",\n    ControlType.CARRIAGE_RETURN: lambda: \"\\r\",\n    ControlType.HOME: lambda: \"\\x1b[H\",\n    ControlType.CLEAR: lambda: \"\\x1b[2J\",\n    ControlType.ENABLE_ALT_SCREEN: lambda: \"\\x1b[?1049h\",\n    ControlType.DISABLE_ALT_SCREEN: lambda: \"\\x1b[?1049l\",\n    ControlType.SHOW_CURSOR: lambda: \"\\x1b[?25h\",\n    ControlType.HIDE_CURSOR: lambda: \"\\x1b[?25l\",\n    ControlType.CURSOR_UP: lambda param: f\"\\x1b[{param}A\",\n    ControlType.CURSOR_DOWN: lambda param: f\"\\x1b[{param}B\",\n    ControlType.CURSOR_FORWARD: lambda param: f\"\\x1b[{param}C\",\n    ControlType.CURSOR_BACKWARD: lambda param: f\"\\x1b[{param}D\",\n    ControlType.CURSOR_MOVE_TO_COLUMN: lambda param: f\"\\x1b[{param+1}G\",\n    ControlType.ERASE_IN_LINE: lambda param: f\"\\x1b[{param}K\",\n    ControlType.CURSOR_MOVE_TO: lambda x, y: f\"\\x1b[{y+1};{x+1}H\",\n    ControlType.SET_WINDOW_TITLE: lambda title: f\"\\x1b]0;{title}\\x07\",\n}\n\n\nclass Control:\n    \"\"\"A renderable that inserts a control code (non printable but may move cursor).\n\n    Args:\n        *codes (str): Positional arguments are either a :class:`~rich.segment.ControlType` enum or a\n            tuple of ControlType and an integer parameter\n    \"\"\"\n\n    __slots__ = [\"segment\"]\n\n    def __init__(self, *codes: Union[ControlType, ControlCode]) -> None:\n        control_codes: List[ControlCode] = [\n            (code,) if isinstance(code, ControlType) else code for code in codes\n        ]\n        _format_map = CONTROL_CODES_FORMAT\n        rendered_codes = \"\".join(\n            _format_map[code](*parameters) for code, *parameters in control_codes\n        )\n        self.segment = Segment(rendered_codes, None, control_codes)\n\n    @classmethod\n    def bell(cls) -> \"Control\":\n        \"\"\"Ring the 'bell'.\"\"\"\n        return cls(ControlType.BELL)\n\n    @classmethod\n    def home(cls) -> \"Control\":\n        \"\"\"Move cursor to 'home' position.\"\"\"\n        return cls(ControlType.HOME)\n\n    @classmethod\n    def move(cls, x: int = 0, y: int = 0) -> \"Control\":\n        \"\"\"Move cursor relative to current position.\n\n        Args:\n            x (int): X offset.\n            y (int): Y offset.\n\n        Returns:\n            ~Control: Control object.\n\n        \"\"\"\n\n        def get_codes() -> Iterable[ControlCode]:\n            control = ControlType\n            if x:\n                yield (\n                    control.CURSOR_FORWARD if x > 0 else control.CURSOR_BACKWARD,\n                    abs(x),\n                )\n            if y:\n                yield (\n                    control.CURSOR_DOWN if y > 0 else control.CURSOR_UP,\n                    abs(y),\n                )\n\n        control = cls(*get_codes())\n        return control\n\n    @classmethod\n    def move_to_column(cls, x: int, y: int = 0) -> \"Control\":\n        \"\"\"Move to the given column, optionally add offset to row.\n\n        Returns:\n            x (int): absolute x (column)\n            y (int): optional y offset (row)\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\default_styles.py": {
      "sha": "232f38c571a6",
      "lines": 193,
      "head": "from typing import Dict\n\nfrom .style import Style\n\nDEFAULT_STYLES: Dict[str, Style] = {\n    \"none\": Style.null(),\n    \"reset\": Style(\n        color=\"default\",\n        bgcolor=\"default\",\n        dim=False,\n        bold=False,\n        italic=False,\n        underline=False,\n        blink=False,\n        blink2=False,\n        reverse=False,\n        conceal=False,\n        strike=False,\n    ),\n    \"dim\": Style(dim=True),\n    \"bright\": Style(dim=False),\n    \"bold\": Style(bold=True),\n    \"strong\": Style(bold=True),\n    \"code\": Style(reverse=True, bold=True),\n    \"italic\": Style(italic=True),\n    \"emphasize\": Style(italic=True),\n    \"underline\": Style(underline=True),\n    \"blink\": Style(blink=True),\n    \"blink2\": Style(blink2=True),\n    \"reverse\": Style(reverse=True),\n    \"strike\": Style(strike=True),\n    \"black\": Style(color=\"black\"),\n    \"red\": Style(color=\"red\"),\n    \"green\": Style(color=\"green\"),\n    \"yellow\": Style(color=\"yellow\"),\n    \"magenta\": Style(color=\"magenta\"),\n    \"cyan\": Style(color=\"cyan\"),\n    \"white\": Style(color=\"white\"),\n    \"inspect.attr\": Style(color=\"yellow\", italic=True),\n    \"inspect.attr.dunder\": Style(color=\"yellow\", italic=True, dim=True),\n    \"inspect.callable\": Style(bold=True, color=\"red\"),\n    \"inspect.async_def\": Style(italic=True, color=\"bright_cyan\"),\n    \"inspect.def\": Style(italic=True, color=\"bright_cyan\"),\n    \"inspect.class\": Style(italic=True, color=\"bright_cyan\"),\n    \"inspect.error\": Style(bold=True, color=\"red\"),\n    \"inspect.equals\": Style(),\n    \"inspect.help\": Style(color=\"cyan\"),\n    \"inspect.doc\": Style(dim=True),\n    \"inspect.value.border\": Style(color=\"green\"),\n    \"live.ellipsis\": Style(bold=True, color=\"red\"),\n    \"layout.tree.row\": Style(dim=False, color=\"red\"),\n    \"layout.tree.column\": Style(dim=False, color=\"blue\"),\n    \"logging.keyword\": Style(bold=True, color=\"yellow\"),\n    \"logging.level.notset\": Style(dim=True),\n    \"logging.level.debug\": Style(color=\"green\"),\n    \"logging.level.info\": Style(color=\"blue\"),\n    \"logging.level.warning\": Style(color=\"yellow\"),\n    \"logging.level.error\": Style(color=\"red\", bold=True),\n    \"logging.level.critical\": Style(color=\"red\", bold=True, reverse=True),\n    \"log.level\": Style.null(),\n    \"log.time\": Style(color=\"cyan\", dim=True),\n    \"log.message\": Style.null(),\n    \"log.path\": Style(dim=True),\n    \"repr.ellipsis\": Style(color=\"yellow\"),\n    \"repr.indent\": Style(color=\"green\", dim=True),\n    \"repr.error\": Style(color=\"red\", bold=True),\n    \"repr.str\": Style(color=\"green\", italic=False, bold=False),\n    \"repr.brace\": Style(bold=True),\n    \"repr.comma\": Style(bold=True),\n    \"repr.ipv4\": Style(bold=True, color=\"bright_green\"),\n    \"repr.ipv6\": Style(bold=True, color=\"bright_green\"),\n    \"repr.eui48\": Style(bold=True, color=\"bright_green\"),\n    \"repr.eui64\": Style(bold=True, color=\"bright_green\"),\n    \"repr.tag_start\": Style(bold=True),\n    \"repr.tag_name\": Style(color=\"bright_magenta\", bold=True),\n    \"repr.tag_contents\": Style(color=\"default\"),\n    \"repr.tag_end\": Style(bold=True),\n    \"repr.attrib_name\": Style(color=\"yellow\", italic=False),\n    \"repr.attrib_equal\": Style(bold=True),\n    \"repr.attrib_value\": Style(color=\"magenta\", italic=False),\n    \"repr.number\": Style(color=\"cyan\", bold=True, italic=False),\n    \"repr.number_complex\": Style(color=\"cyan\", bold=True, italic=False),  # same\n    \"repr.bool_true\": Style(color=\"bright_green\", italic=True),\n    \"repr.bool_false\": Style(color=\"bright_red\", italic=True),\n    \"repr.none\": Style(color=\"magenta\", italic=True),\n    \"repr.url\": Style(underline=True, color=\"bright_blue\", italic=False, bold=False),\n    \"repr.uuid\": Style(color=\"bright_yellow\", bold=False),\n    \"repr.call\": Style(color=\"magenta\", bold=True),\n    \"repr.path\": Style(color=\"magenta\"),\n    \"repr.filename\": Style(color=\"bright_magenta\"),\n    \"rule.line\": Style(color=\"bright_green\"),\n    \"rule.text\": Style.null(),\n    \"json.brace\": Style(bold=True),\n    \"json.bool_true\": Style(color=\"bright_green\", italic=True),\n    \"json.bool_false\": Style(color=\"bright_red\", italic=True),\n    \"json.null\": Style(color=\"magenta\", italic=True),\n    \"json.number\": Style(color=\"cyan\", bold=True, italic=False),\n    \"json.str\": Style(color=\"green\", italic=False, bold=False),\n    \"json.key\": Style(color=\"blue\", bold=True),\n    \"prompt\": Style.null(),\n    \"prompt.choices\": Style(color=\"magenta\", bold=True),\n    \"prompt.default\": Style(color=\"cyan\", bold=True),\n    \"prompt.invalid\": Style(color=\"red\"),\n    \"prompt.invalid.choice\": Style(color=\"red\"),\n    \"pretty\": Style.null(),\n    \"scope.border\": Style(color=\"blue\"),\n    \"scope.key\": Style(color=\"yellow\", italic=True),\n    \"scope.key.special\": Style(color=\"yellow\", italic=True, dim=True),\n    \"scope.equals\": Style(color=\"red\"),\n    \"table.header\": Style(bold=True),\n    \"table.footer\": Style(bold=True),\n    \"table.cell\": Style.null(),\n    \"table.title\": Style(italic=True),\n    \"table.caption\": Style(italic=True, dim=True),\n    \"traceback.error\": Style(color=\"red\", italic=True),\n    \"traceback.border.syntax_error\": Style(color=\"bright_red\"),\n    \"traceback.border\": Style(color=\"red\"),\n    \"traceback.text\": Style.null(),\n    \"traceback.title\": Style(color=\"red\", bold=True),\n    \"traceback.exc_type\": Style(color=\"bright_red\", bold=True),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\diagnose.py": {
      "sha": "6bb8acf2d7c2",
      "lines": 38,
      "head": "import os\nimport platform\n\nfrom pip._vendor.rich import inspect\nfrom pip._vendor.rich.console import Console, get_windows_console_features\nfrom pip._vendor.rich.panel import Panel\nfrom pip._vendor.rich.pretty import Pretty\n\n\ndef report() -> None:  # pragma: no cover\n    \"\"\"Print a report to the terminal with debugging information\"\"\"\n    console = Console()\n    inspect(console)\n    features = get_windows_console_features()\n    inspect(features)\n\n    env_names = (\n        \"CLICOLOR\",\n        \"COLORTERM\",\n        \"COLUMNS\",\n        \"JPY_PARENT_PID\",\n        \"JUPYTER_COLUMNS\",\n        \"JUPYTER_LINES\",\n        \"LINES\",\n        \"NO_COLOR\",\n        \"TERM_PROGRAM\",\n        \"TERM\",\n        \"TTY_COMPATIBLE\",\n        \"VSCODE_VERBOSE_LOGGING\",\n    )\n    env = {name: os.getenv(name) for name in env_names}\n    console.print(Panel.fit((Pretty(env)), title=\"[b]Environment Variables\"))\n\n    console.print(f'platform=\"{platform.system()}\"')\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    report()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\emoji.py": {
      "sha": "23a65b3dc99d",
      "lines": 96,
      "head": "import sys\nfrom typing import TYPE_CHECKING, Optional, Union\n\nfrom .jupyter import JupyterMixin\nfrom .segment import Segment\nfrom .style import Style\nfrom ._emoji_codes import EMOJI\nfrom ._emoji_replace import _emoji_replace\n\nif sys.version_info >= (3, 8):\n    from typing import Literal\nelse:\n    from pip._vendor.typing_extensions import Literal  # pragma: no cover\n\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderResult\n\n\nEmojiVariant = Literal[\"emoji\", \"text\"]\n\n\nclass NoEmoji(Exception):\n    \"\"\"No emoji by that name.\"\"\"\n\n\nclass Emoji(JupyterMixin):\n    __slots__ = [\"name\", \"style\", \"_char\", \"variant\"]\n\n    VARIANTS = {\"text\": \"\\uFE0E\", \"emoji\": \"\\uFE0F\"}\n\n    def __init__(\n        self,\n        name: str,\n        style: Union[str, Style] = \"none\",\n        variant: Optional[EmojiVariant] = None,\n    ) -> None:\n        \"\"\"A single emoji character.\n\n        Args:\n            name (str): Name of emoji.\n            style (Union[str, Style], optional): Optional style. Defaults to None.\n\n        Raises:\n            NoEmoji: If the emoji doesn't exist.\n        \"\"\"\n        self.name = name\n        self.style = style\n        self.variant = variant\n        try:\n            self._char = EMOJI[name]\n        except KeyError:\n            raise NoEmoji(f\"No emoji called {name!r}\")\n        if variant is not None:\n            self._char += self.VARIANTS.get(variant, \"\")\n\n    @classmethod\n    def replace(cls, text: str) -> str:\n        \"\"\"Replace emoji markup with corresponding unicode characters.\n\n        Args:\n            text (str): A string with emojis codes, e.g. \"Hello :smiley:!\"\n\n        Returns:\n            str: A string with emoji codes replaces with actual emoji.\n        \"\"\"\n        return _emoji_replace(text)\n\n    def __repr__(self) -> str:\n        return f\"<emoji {self.name!r}>\"\n\n    def __str__(self) -> str:\n        return self._char\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        yield Segment(self._char, console.get_style(self.style))\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import sys\n\n    from pip._vendor.rich.columns import Columns\n    from pip._vendor.rich.console import Console\n\n    console = Console(record=True)\n\n    columns = Columns(\n        (f\":{name}: {name}\" for name in sorted(EMOJI.keys()) if \"\\u200D\" not in name),\n        column_first=True,\n    )\n\n    console.print(columns)\n    if len(sys.argv) > 1:\n        console.save_html(sys.argv[1])\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\errors.py": {
      "sha": "cfd7926adb4a",
      "lines": 34,
      "head": "class ConsoleError(Exception):\n    \"\"\"An error in console operation.\"\"\"\n\n\nclass StyleError(Exception):\n    \"\"\"An error in styles.\"\"\"\n\n\nclass StyleSyntaxError(ConsoleError):\n    \"\"\"Style was badly formatted.\"\"\"\n\n\nclass MissingStyle(StyleError):\n    \"\"\"No such style.\"\"\"\n\n\nclass StyleStackError(ConsoleError):\n    \"\"\"Style stack is invalid.\"\"\"\n\n\nclass NotRenderableError(ConsoleError):\n    \"\"\"Object is not renderable.\"\"\"\n\n\nclass MarkupError(ConsoleError):\n    \"\"\"Markup was badly formatted.\"\"\"\n\n\nclass LiveError(ConsoleError):\n    \"\"\"Error related to Live display.\"\"\"\n\n\nclass NoAltScreen(ConsoleError):\n    \"\"\"Alt screen mode was required.\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\filesize.py": {
      "sha": "161b8e1ee81d",
      "lines": 88,
      "head": "\"\"\"Functions for reporting filesizes. Borrowed from https://github.com/PyFilesystem/pyfilesystem2\n\nThe functions declared in this module should cover the different\nuse cases needed to generate a string representation of a file size\nusing several different units. Since there are many standards regarding\nfile size units, three different functions have been implemented.\n\nSee Also:\n    * `Wikipedia: Binary prefix <https://en.wikipedia.org/wiki/Binary_prefix>`_\n\n\"\"\"\n\n__all__ = [\"decimal\"]\n\nfrom typing import Iterable, List, Optional, Tuple\n\n\ndef _to_str(\n    size: int,\n    suffixes: Iterable[str],\n    base: int,\n    *,\n    precision: Optional[int] = 1,\n    separator: Optional[str] = \" \",\n) -> str:\n    if size == 1:\n        return \"1 byte\"\n    elif size < base:\n        return f\"{size:,} bytes\"\n\n    for i, suffix in enumerate(suffixes, 2):  # noqa: B007\n        unit = base**i\n        if size < unit:\n            break\n    return \"{:,.{precision}f}{separator}{}\".format(\n        (base * size / unit),\n        suffix,\n        precision=precision,\n        separator=separator,\n    )\n\n\ndef pick_unit_and_suffix(size: int, suffixes: List[str], base: int) -> Tuple[int, str]:\n    \"\"\"Pick a suffix and base for the given size.\"\"\"\n    for i, suffix in enumerate(suffixes):\n        unit = base**i\n        if size < unit * base:\n            break\n    return unit, suffix\n\n\ndef decimal(\n    size: int,\n    *,\n    precision: Optional[int] = 1,\n    separator: Optional[str] = \" \",\n) -> str:\n    \"\"\"Convert a filesize in to a string (powers of 1000, SI prefixes).\n\n    In this convention, ``1000 B = 1 kB``.\n\n    This is typically the format used to advertise the storage\n    capacity of USB flash drives and the like (*256 MB* meaning\n    actually a storage capacity of more than *256 000 000 B*),\n    or used by **Mac OS X** since v10.6 to report file sizes.\n\n    Arguments:\n        int (size): A file size.\n        int (precision): The number of decimal places to include (default = 1).\n        str (separator): The string to separate the value from the units (default = \" \").\n\n    Returns:\n        `str`: A string containing a abbreviated file size and units.\n\n    Example:\n        >>> filesize.decimal(30000)\n        '30.0 kB'\n        >>> filesize.decimal(30000, precision=2, separator=\"\")\n        '30.00kB'\n\n    \"\"\"\n    return _to_str(\n        size,\n        (\"kB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\"),\n        1000,\n        precision=precision,\n        separator=separator,\n    )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\file_proxy.py": {
      "sha": "5f7dee3ccc5b",
      "lines": 57,
      "head": "import io\nfrom typing import IO, TYPE_CHECKING, Any, List\n\nfrom .ansi import AnsiDecoder\nfrom .text import Text\n\nif TYPE_CHECKING:\n    from .console import Console\n\n\nclass FileProxy(io.TextIOBase):\n    \"\"\"Wraps a file (e.g. sys.stdout) and redirects writes to a console.\"\"\"\n\n    def __init__(self, console: \"Console\", file: IO[str]) -> None:\n        self.__console = console\n        self.__file = file\n        self.__buffer: List[str] = []\n        self.__ansi_decoder = AnsiDecoder()\n\n    @property\n    def rich_proxied_file(self) -> IO[str]:\n        \"\"\"Get proxied file.\"\"\"\n        return self.__file\n\n    def __getattr__(self, name: str) -> Any:\n        return getattr(self.__file, name)\n\n    def write(self, text: str) -> int:\n        if not isinstance(text, str):\n            raise TypeError(f\"write() argument must be str, not {type(text).__name__}\")\n        buffer = self.__buffer\n        lines: List[str] = []\n        while text:\n            line, new_line, text = text.partition(\"\\n\")\n            if new_line:\n                lines.append(\"\".join(buffer) + line)\n                buffer.clear()\n            else:\n                buffer.append(line)\n                break\n        if lines:\n            console = self.__console\n            with console:\n                output = Text(\"\\n\").join(\n                    self.__ansi_decoder.decode_line(line) for line in lines\n                )\n                console.print(output)\n        return len(text)\n\n    def flush(self) -> None:\n        output = \"\".join(self.__buffer)\n        if output:\n            self.__console.print(output)\n        del self.__buffer[:]\n\n    def fileno(self) -> int:\n        return self.__file.fileno()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\highlighter.py": {
      "sha": "e5d86b4c15c5",
      "lines": 232,
      "head": "import re\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union\n\nfrom .text import Span, Text\n\n\ndef _combine_regex(*regexes: str) -> str:\n    \"\"\"Combine a number of regexes in to a single regex.\n\n    Returns:\n        str: New regex with all regexes ORed together.\n    \"\"\"\n    return \"|\".join(regexes)\n\n\nclass Highlighter(ABC):\n    \"\"\"Abstract base class for highlighters.\"\"\"\n\n    def __call__(self, text: Union[str, Text]) -> Text:\n        \"\"\"Highlight a str or Text instance.\n\n        Args:\n            text (Union[str, ~Text]): Text to highlight.\n\n        Raises:\n            TypeError: If not called with text or str.\n\n        Returns:\n            Text: A test instance with highlighting applied.\n        \"\"\"\n        if isinstance(text, str):\n            highlight_text = Text(text)\n        elif isinstance(text, Text):\n            highlight_text = text.copy()\n        else:\n            raise TypeError(f\"str or Text instance required, not {text!r}\")\n        self.highlight(highlight_text)\n        return highlight_text\n\n    @abstractmethod\n    def highlight(self, text: Text) -> None:\n        \"\"\"Apply highlighting in place to text.\n\n        Args:\n            text (~Text): A text object highlight.\n        \"\"\"\n\n\nclass NullHighlighter(Highlighter):\n    \"\"\"A highlighter object that doesn't highlight.\n\n    May be used to disable highlighting entirely.\n\n    \"\"\"\n\n    def highlight(self, text: Text) -> None:\n        \"\"\"Nothing to do\"\"\"\n\n\nclass RegexHighlighter(Highlighter):\n    \"\"\"Applies highlighting from a list of regular expressions.\"\"\"\n\n    highlights: List[str] = []\n    base_style: str = \"\"\n\n    def highlight(self, text: Text) -> None:\n        \"\"\"Highlight :class:`rich.text.Text` using regular expressions.\n\n        Args:\n            text (~Text): Text to highlighted.\n\n        \"\"\"\n\n        highlight_regex = text.highlight_regex\n        for re_highlight in self.highlights:\n            highlight_regex(re_highlight, style_prefix=self.base_style)\n\n\nclass ReprHighlighter(RegexHighlighter):\n    \"\"\"Highlights the text typically produced from ``__repr__`` methods.\"\"\"\n\n    base_style = \"repr.\"\n    highlights = [\n        r\"(?P<tag_start><)(?P<tag_name>[-\\w.:|]*)(?P<tag_contents>[\\w\\W]*)(?P<tag_end>>)\",\n        r'(?P<attrib_name>[\\w_]{1,50})=(?P<attrib_value>\"?[\\w_]+\"?)?',\n        r\"(?P<brace>[][{}()])\",\n        _combine_regex(\n            r\"(?P<ipv4>[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3})\",\n            r\"(?P<ipv6>([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})\",\n            r\"(?P<eui64>(?:[0-9A-Fa-f]{1,2}-){7}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{1,2}:){7}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{4}\\.){3}[0-9A-Fa-f]{4})\",\n            r\"(?P<eui48>(?:[0-9A-Fa-f]{1,2}-){5}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{1,2}:){5}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{4}\\.){2}[0-9A-Fa-f]{4})\",\n            r\"(?P<uuid>[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12})\",\n            r\"(?P<call>[\\w.]*?)\\(\",\n            r\"\\b(?P<bool_true>True)\\b|\\b(?P<bool_false>False)\\b|\\b(?P<none>None)\\b\",\n            r\"(?P<ellipsis>\\.\\.\\.)\",\n            r\"(?P<number_complex>(?<!\\w)(?:\\-?[0-9]+\\.?[0-9]*(?:e[-+]?\\d+?)?)(?:[-+](?:[0-9]+\\.?[0-9]*(?:e[-+]?\\d+)?))?j)\",\n            r\"(?P<number>(?<!\\w)\\-?[0-9]+\\.?[0-9]*(e[-+]?\\d+?)?\\b|0x[0-9a-fA-F]*)\",\n            r\"(?P<path>\\B(/[-\\w._+]+)*\\/)(?P<filename>[-\\w._+]*)?\",\n            r\"(?<![\\\\\\w])(?P<str>b?'''.*?(?<!\\\\)'''|b?'.*?(?<!\\\\)'|b?\\\"\\\"\\\".*?(?<!\\\\)\\\"\\\"\\\"|b?\\\".*?(?<!\\\\)\\\")\",\n            r\"(?P<url>(file|https|http|ws|wss)://[-0-9a-zA-Z$_+!`(),.?/;:&=%#~@]*)\",\n        ),\n    ]\n\n\nclass JSONHighlighter(RegexHighlighter):\n    \"\"\"Highlights JSON\"\"\"\n\n    # Captures the start and end of JSON strings, handling escaped quotes\n    JSON_STR = r\"(?<![\\\\\\w])(?P<str>b?\\\".*?(?<!\\\\)\\\")\"\n    JSON_WHITESPACE = {\" \", \"\\n\", \"\\r\", \"\\t\"}\n\n    base_style = \"json.\"\n    highlights = [\n        _combine_regex(\n            r\"(?P<brace>[\\{\\[\\(\\)\\]\\}])\",\n            r\"\\b(?P<bool_true>true)\\b|\\b(?P<bool_false>false)\\b|\\b(?P<null>null)\\b\",\n            r\"(?P<number>(?<!\\w)\\-?[0-9]+\\.?[0-9]*(e[\\-\\+]?\\d+?)?\\b|0x[0-9a-fA-F]*)\",\n            JSON_STR,\n        ),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\json.py": {
      "sha": "bdfcfcf46497",
      "lines": 139,
      "head": "from pathlib import Path\nfrom json import loads, dumps\nfrom typing import Any, Callable, Optional, Union\n\nfrom .text import Text\nfrom .highlighter import JSONHighlighter, NullHighlighter\n\n\nclass JSON:\n    \"\"\"A renderable which pretty prints JSON.\n\n    Args:\n        json (str): JSON encoded data.\n        indent (Union[None, int, str], optional): Number of characters to indent by. Defaults to 2.\n        highlight (bool, optional): Enable highlighting. Defaults to True.\n        skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.\n        ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.\n        check_circular (bool, optional): Check for circular references. Defaults to True.\n        allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.\n        default (Callable, optional): A callable that converts values that can not be encoded\n            in to something that can be JSON encoded. Defaults to None.\n        sort_keys (bool, optional): Sort dictionary keys. Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        json: str,\n        indent: Union[None, int, str] = 2,\n        highlight: bool = True,\n        skip_keys: bool = False,\n        ensure_ascii: bool = False,\n        check_circular: bool = True,\n        allow_nan: bool = True,\n        default: Optional[Callable[[Any], Any]] = None,\n        sort_keys: bool = False,\n    ) -> None:\n        data = loads(json)\n        json = dumps(\n            data,\n            indent=indent,\n            skipkeys=skip_keys,\n            ensure_ascii=ensure_ascii,\n            check_circular=check_circular,\n            allow_nan=allow_nan,\n            default=default,\n            sort_keys=sort_keys,\n        )\n        highlighter = JSONHighlighter() if highlight else NullHighlighter()\n        self.text = highlighter(json)\n        self.text.no_wrap = True\n        self.text.overflow = None\n\n    @classmethod\n    def from_data(\n        cls,\n        data: Any,\n        indent: Union[None, int, str] = 2,\n        highlight: bool = True,\n        skip_keys: bool = False,\n        ensure_ascii: bool = False,\n        check_circular: bool = True,\n        allow_nan: bool = True,\n        default: Optional[Callable[[Any], Any]] = None,\n        sort_keys: bool = False,\n    ) -> \"JSON\":\n        \"\"\"Encodes a JSON object from arbitrary data.\n\n        Args:\n            data (Any): An object that may be encoded in to JSON\n            indent (Union[None, int, str], optional): Number of characters to indent by. Defaults to 2.\n            highlight (bool, optional): Enable highlighting. Defaults to True.\n            default (Callable, optional): Optional callable which will be called for objects that cannot be serialized. Defaults to None.\n            skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.\n            ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.\n            check_circular (bool, optional): Check for circular references. Defaults to True.\n            allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.\n            default (Callable, optional): A callable that converts values that can not be encoded\n                in to something that can be JSON encoded. Defaults to None.\n            sort_keys (bool, optional): Sort dictionary keys. Defaults to False.\n\n        Returns:\n            JSON: New JSON object from the given data.\n        \"\"\"\n        json_instance: \"JSON\" = cls.__new__(cls)\n        json = dumps(\n            data,\n            indent=indent,\n            skipkeys=skip_keys,\n            ensure_ascii=ensure_ascii,\n            check_circular=check_circular,\n            allow_nan=allow_nan,\n            default=default,\n            sort_keys=sort_keys,\n        )\n        highlighter = JSONHighlighter() if highlight else NullHighlighter()\n        json_instance.text = highlighter(json)\n        json_instance.text.no_wrap = True\n        json_instance.text.overflow = None\n        return json_instance\n\n    def __rich__(self) -> Text:\n        return self.text\n\n\nif __name__ == \"__main__\":\n    import argparse\n    import sys\n\n    parser = argparse.ArgumentParser(description=\"Pretty print json\")\n    parser.add_argument(\n        \"path\",\n        metavar=\"PATH\",\n        help=\"path to file, or - for stdin\",\n    )\n    parser.add_argument(\n        \"-i\",\n        \"--indent\",\n        metavar=\"SPACES\",\n        type=int,\n        help=\"Number of spaces in an indent\",\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\jupyter.py": {
      "sha": "4ccdab192573",
      "lines": 101,
      "head": "from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Sequence\n\nif TYPE_CHECKING:\n    from pip._vendor.rich.console import ConsoleRenderable\n\nfrom . import get_console\nfrom .segment import Segment\nfrom .terminal_theme import DEFAULT_TERMINAL_THEME\n\nif TYPE_CHECKING:\n    from pip._vendor.rich.console import ConsoleRenderable\n\nJUPYTER_HTML_FORMAT = \"\"\"\\\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">{code}</pre>\n\"\"\"\n\n\nclass JupyterRenderable:\n    \"\"\"A shim to write html to Jupyter notebook.\"\"\"\n\n    def __init__(self, html: str, text: str) -> None:\n        self.html = html\n        self.text = text\n\n    def _repr_mimebundle_(\n        self, include: Sequence[str], exclude: Sequence[str], **kwargs: Any\n    ) -> Dict[str, str]:\n        data = {\"text/plain\": self.text, \"text/html\": self.html}\n        if include:\n            data = {k: v for (k, v) in data.items() if k in include}\n        if exclude:\n            data = {k: v for (k, v) in data.items() if k not in exclude}\n        return data\n\n\nclass JupyterMixin:\n    \"\"\"Add to an Rich renderable to make it render in Jupyter notebook.\"\"\"\n\n    __slots__ = ()\n\n    def _repr_mimebundle_(\n        self: \"ConsoleRenderable\",\n        include: Sequence[str],\n        exclude: Sequence[str],\n        **kwargs: Any,\n    ) -> Dict[str, str]:\n        console = get_console()\n        segments = list(console.render(self, console.options))\n        html = _render_segments(segments)\n        text = console._render_buffer(segments)\n        data = {\"text/plain\": text, \"text/html\": html}\n        if include:\n            data = {k: v for (k, v) in data.items() if k in include}\n        if exclude:\n            data = {k: v for (k, v) in data.items() if k not in exclude}\n        return data\n\n\ndef _render_segments(segments: Iterable[Segment]) -> str:\n    def escape(text: str) -> str:\n        \"\"\"Escape html.\"\"\"\n        return text.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n\n    fragments: List[str] = []\n    append_fragment = fragments.append\n    theme = DEFAULT_TERMINAL_THEME\n    for text, style, control in Segment.simplify(segments):\n        if control:\n            continue\n        text = escape(text)\n        if style:\n            rule = style.get_html_style(theme)\n            text = f'<span style=\"{rule}\">{text}</span>' if rule else text\n            if style.link:\n                text = f'<a href=\"{style.link}\" target=\"_blank\">{text}</a>'\n        append_fragment(text)\n\n    code = \"\".join(fragments)\n    html = JUPYTER_HTML_FORMAT.format(code=code)\n\n    return html\n\n\ndef display(segments: Iterable[Segment], text: str) -> None:\n    \"\"\"Render segments to Jupyter.\"\"\"\n    html = _render_segments(segments)\n    jupyter_renderable = JupyterRenderable(html, text)\n    try:\n        from IPython.display import display as ipython_display\n\n        ipython_display(jupyter_renderable)\n    except ModuleNotFoundError:\n        # Handle the case where the Console has force_jupyter=True,\n        # but IPython is not installed.\n        pass\n\n\ndef print(*args: Any, **kwargs: Any) -> None:\n    \"\"\"Proxy for Console print.\"\"\"\n    console = get_console()\n    return console.print(*args, **kwargs)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\layout.py": {
      "sha": "9b64aec34492",
      "lines": 442,
      "head": "from abc import ABC, abstractmethod\nfrom itertools import islice\nfrom operator import itemgetter\nfrom threading import RLock\nfrom typing import (\n    TYPE_CHECKING,\n    Dict,\n    Iterable,\n    List,\n    NamedTuple,\n    Optional,\n    Sequence,\n    Tuple,\n    Union,\n)\n\nfrom ._ratio import ratio_resolve\nfrom .align import Align\nfrom .console import Console, ConsoleOptions, RenderableType, RenderResult\nfrom .highlighter import ReprHighlighter\nfrom .panel import Panel\nfrom .pretty import Pretty\nfrom .region import Region\nfrom .repr import Result, rich_repr\nfrom .segment import Segment\nfrom .style import StyleType\n\nif TYPE_CHECKING:\n    from pip._vendor.rich.tree import Tree\n\n\nclass LayoutRender(NamedTuple):\n    \"\"\"An individual layout render.\"\"\"\n\n    region: Region\n    render: List[List[Segment]]\n\n\nRegionMap = Dict[\"Layout\", Region]\nRenderMap = Dict[\"Layout\", LayoutRender]\n\n\nclass LayoutError(Exception):\n    \"\"\"Layout related error.\"\"\"\n\n\nclass NoSplitter(LayoutError):\n    \"\"\"Requested splitter does not exist.\"\"\"\n\n\nclass _Placeholder:\n    \"\"\"An internal renderable used as a Layout placeholder.\"\"\"\n\n    highlighter = ReprHighlighter()\n\n    def __init__(self, layout: \"Layout\", style: StyleType = \"\") -> None:\n        self.layout = layout\n        self.style = style\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        width = options.max_width\n        height = options.height or options.size.height\n        layout = self.layout\n        title = (\n            f\"{layout.name!r} ({width} x {height})\"\n            if layout.name\n            else f\"({width} x {height})\"\n        )\n        yield Panel(\n            Align.center(Pretty(layout), vertical=\"middle\"),\n            style=self.style,\n            title=self.highlighter(title),\n            border_style=\"blue\",\n            height=height,\n        )\n\n\nclass Splitter(ABC):\n    \"\"\"Base class for a splitter.\"\"\"\n\n    name: str = \"\"\n\n    @abstractmethod\n    def get_tree_icon(self) -> str:\n        \"\"\"Get the icon (emoji) used in layout.tree\"\"\"\n\n    @abstractmethod\n    def divide(\n        self, children: Sequence[\"Layout\"], region: Region\n    ) -> Iterable[Tuple[\"Layout\", Region]]:\n        \"\"\"Divide a region amongst several child layouts.\n\n        Args:\n            children (Sequence(Layout)): A number of child layouts.\n            region (Region): A rectangular region to divide.\n        \"\"\"\n\n\nclass RowSplitter(Splitter):\n    \"\"\"Split a layout region in to rows.\"\"\"\n\n    name = \"row\"\n\n    def get_tree_icon(self) -> str:\n        return \"[layout.tree.row]\u2b0c\"\n\n    def divide(\n        self, children: Sequence[\"Layout\"], region: Region\n    ) -> Iterable[Tuple[\"Layout\", Region]]:\n        x, y, width, height = region\n        render_widths = ratio_resolve(width, children)\n        offset = 0\n        _Region = Region\n        for child, child_width in zip(children, render_widths):\n            yield child, _Region(x + offset, y, child_width, height)\n            offset += child_width\n\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\live.py": {
      "sha": "0b57f5e5a818",
      "lines": 375,
      "head": "import sys\nfrom threading import Event, RLock, Thread\nfrom types import TracebackType\nfrom typing import IO, Any, Callable, List, Optional, TextIO, Type, cast\n\nfrom . import get_console\nfrom .console import Console, ConsoleRenderable, RenderableType, RenderHook\nfrom .control import Control\nfrom .file_proxy import FileProxy\nfrom .jupyter import JupyterMixin\nfrom .live_render import LiveRender, VerticalOverflowMethod\nfrom .screen import Screen\nfrom .text import Text\n\n\nclass _RefreshThread(Thread):\n    \"\"\"A thread that calls refresh() at regular intervals.\"\"\"\n\n    def __init__(self, live: \"Live\", refresh_per_second: float) -> None:\n        self.live = live\n        self.refresh_per_second = refresh_per_second\n        self.done = Event()\n        super().__init__(daemon=True)\n\n    def stop(self) -> None:\n        self.done.set()\n\n    def run(self) -> None:\n        while not self.done.wait(1 / self.refresh_per_second):\n            with self.live._lock:\n                if not self.done.is_set():\n                    self.live.refresh()\n\n\nclass Live(JupyterMixin, RenderHook):\n    \"\"\"Renders an auto-updating live display of any given renderable.\n\n    Args:\n        renderable (RenderableType, optional): The renderable to live display. Defaults to displaying nothing.\n        console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.\n        screen (bool, optional): Enable alternate screen mode. Defaults to False.\n        auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()` or `update()` with refresh flag. Defaults to True\n        refresh_per_second (float, optional): Number of times per second to refresh the live display. Defaults to 4.\n        transient (bool, optional): Clear the renderable on exit (has no effect when screen=True). Defaults to False.\n        redirect_stdout (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.\n        redirect_stderr (bool, optional): Enable redirection of stderr. Defaults to True.\n        vertical_overflow (VerticalOverflowMethod, optional): How to handle renderable when it is too tall for the console. Defaults to \"ellipsis\".\n        get_renderable (Callable[[], RenderableType], optional): Optional callable to get renderable. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: Optional[RenderableType] = None,\n        *,\n        console: Optional[Console] = None,\n        screen: bool = False,\n        auto_refresh: bool = True,\n        refresh_per_second: float = 4,\n        transient: bool = False,\n        redirect_stdout: bool = True,\n        redirect_stderr: bool = True,\n        vertical_overflow: VerticalOverflowMethod = \"ellipsis\",\n        get_renderable: Optional[Callable[[], RenderableType]] = None,\n    ) -> None:\n        assert refresh_per_second > 0, \"refresh_per_second must be > 0\"\n        self._renderable = renderable\n        self.console = console if console is not None else get_console()\n        self._screen = screen\n        self._alt_screen = False\n\n        self._redirect_stdout = redirect_stdout\n        self._redirect_stderr = redirect_stderr\n        self._restore_stdout: Optional[IO[str]] = None\n        self._restore_stderr: Optional[IO[str]] = None\n\n        self._lock = RLock()\n        self.ipy_widget: Optional[Any] = None\n        self.auto_refresh = auto_refresh\n        self._started: bool = False\n        self.transient = True if screen else transient\n\n        self._refresh_thread: Optional[_RefreshThread] = None\n        self.refresh_per_second = refresh_per_second\n\n        self.vertical_overflow = vertical_overflow\n        self._get_renderable = get_renderable\n        self._live_render = LiveRender(\n            self.get_renderable(), vertical_overflow=vertical_overflow\n        )\n\n    @property\n    def is_started(self) -> bool:\n        \"\"\"Check if live display has been started.\"\"\"\n        return self._started\n\n    def get_renderable(self) -> RenderableType:\n        renderable = (\n            self._get_renderable()\n            if self._get_renderable is not None\n            else self._renderable\n        )\n        return renderable or \"\"\n\n    def start(self, refresh: bool = False) -> None:\n        \"\"\"Start live rendering display.\n\n        Args:\n            refresh (bool, optional): Also refresh. Defaults to False.\n        \"\"\"\n        with self._lock:\n            if self._started:\n                return\n            self.console.set_live(self)\n            self._started = True\n            if self._screen:\n                self._alt_screen = self.console.set_alt_screen(True)\n            self.console.show_cursor(False)\n            self._enable_redirect_io()\n            self.console.push_render_hook(self)\n            if refresh:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\live_render.py": {
      "sha": "89bf548e4fa1",
      "lines": 112,
      "head": "import sys\nfrom typing import Optional, Tuple\n\nif sys.version_info >= (3, 8):\n    from typing import Literal\nelse:\n    from pip._vendor.typing_extensions import Literal  # pragma: no cover\n\n\nfrom ._loop import loop_last\nfrom .console import Console, ConsoleOptions, RenderableType, RenderResult\nfrom .control import Control\nfrom .segment import ControlType, Segment\nfrom .style import StyleType\nfrom .text import Text\n\nVerticalOverflowMethod = Literal[\"crop\", \"ellipsis\", \"visible\"]\n\n\nclass LiveRender:\n    \"\"\"Creates a renderable that may be updated.\n\n    Args:\n        renderable (RenderableType): Any renderable object.\n        style (StyleType, optional): An optional style to apply to the renderable. Defaults to \"\".\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: RenderableType,\n        style: StyleType = \"\",\n        vertical_overflow: VerticalOverflowMethod = \"ellipsis\",\n    ) -> None:\n        self.renderable = renderable\n        self.style = style\n        self.vertical_overflow = vertical_overflow\n        self._shape: Optional[Tuple[int, int]] = None\n\n    def set_renderable(self, renderable: RenderableType) -> None:\n        \"\"\"Set a new renderable.\n\n        Args:\n            renderable (RenderableType): Any renderable object, including str.\n        \"\"\"\n        self.renderable = renderable\n\n    def position_cursor(self) -> Control:\n        \"\"\"Get control codes to move cursor to beginning of live render.\n\n        Returns:\n            Control: A control instance that may be printed.\n        \"\"\"\n        if self._shape is not None:\n            _, height = self._shape\n            return Control(\n                ControlType.CARRIAGE_RETURN,\n                (ControlType.ERASE_IN_LINE, 2),\n                *(\n                    (\n                        (ControlType.CURSOR_UP, 1),\n                        (ControlType.ERASE_IN_LINE, 2),\n                    )\n                    * (height - 1)\n                )\n            )\n        return Control()\n\n    def restore_cursor(self) -> Control:\n        \"\"\"Get control codes to clear the render and restore the cursor to its previous position.\n\n        Returns:\n            Control: A Control instance that may be printed.\n        \"\"\"\n        if self._shape is not None:\n            _, height = self._shape\n            return Control(\n                ControlType.CARRIAGE_RETURN,\n                *((ControlType.CURSOR_UP, 1), (ControlType.ERASE_IN_LINE, 2)) * height\n            )\n        return Control()\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        renderable = self.renderable\n        style = console.get_style(self.style)\n        lines = console.render_lines(renderable, options, style=style, pad=False)\n        shape = Segment.get_shape(lines)\n\n        _, height = shape\n        if height > options.size.height:\n            if self.vertical_overflow == \"crop\":\n                lines = lines[: options.size.height]\n                shape = Segment.get_shape(lines)\n            elif self.vertical_overflow == \"ellipsis\":\n                lines = lines[: (options.size.height - 1)]\n                overflow_text = Text(\n                    \"...\",\n                    overflow=\"crop\",\n                    justify=\"center\",\n                    end=\"\",\n                    style=\"live.ellipsis\",\n                )\n                lines.append(list(console.render(overflow_text)))\n                shape = Segment.get_shape(lines)\n        self._shape = shape\n\n        new_line = Segment.line()\n        for last, line in loop_last(lines):\n            yield from line\n            if not last:\n                yield new_line\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\logging.py": {
      "sha": "a5e0c8e8c7da",
      "lines": 297,
      "head": "import logging\nfrom datetime import datetime\nfrom logging import Handler, LogRecord\nfrom pathlib import Path\nfrom types import ModuleType\nfrom typing import ClassVar, Iterable, List, Optional, Type, Union\n\nfrom pip._vendor.rich._null_file import NullFile\n\nfrom . import get_console\nfrom ._log_render import FormatTimeCallable, LogRender\nfrom .console import Console, ConsoleRenderable\nfrom .highlighter import Highlighter, ReprHighlighter\nfrom .text import Text\nfrom .traceback import Traceback\n\n\nclass RichHandler(Handler):\n    \"\"\"A logging handler that renders output with Rich. The time / level / message and file are displayed in columns.\n    The level is color coded, and the message is syntax highlighted.\n\n    Note:\n        Be careful when enabling console markup in log messages if you have configured logging for libraries not\n        under your control. If a dependency writes messages containing square brackets, it may not produce the intended output.\n\n    Args:\n        level (Union[int, str], optional): Log level. Defaults to logging.NOTSET.\n        console (:class:`~rich.console.Console`, optional): Optional console instance to write logs.\n            Default will use a global console instance writing to stdout.\n        show_time (bool, optional): Show a column for the time. Defaults to True.\n        omit_repeated_times (bool, optional): Omit repetition of the same time. Defaults to True.\n        show_level (bool, optional): Show a column for the level. Defaults to True.\n        show_path (bool, optional): Show the path to the original log call. Defaults to True.\n        enable_link_path (bool, optional): Enable terminal link of path column to file. Defaults to True.\n        highlighter (Highlighter, optional): Highlighter to style log messages, or None to use ReprHighlighter. Defaults to None.\n        markup (bool, optional): Enable console markup in log messages. Defaults to False.\n        rich_tracebacks (bool, optional): Enable rich tracebacks with syntax highlighting and formatting. Defaults to False.\n        tracebacks_width (Optional[int], optional): Number of characters used to render tracebacks, or None for full width. Defaults to None.\n        tracebacks_code_width (int, optional): Number of code characters used to render tracebacks, or None for full width. Defaults to 88.\n        tracebacks_extra_lines (int, optional): Additional lines of code to render tracebacks, or None for full width. Defaults to None.\n        tracebacks_theme (str, optional): Override pygments theme used in traceback.\n        tracebacks_word_wrap (bool, optional): Enable word wrapping of long tracebacks lines. Defaults to True.\n        tracebacks_show_locals (bool, optional): Enable display of locals in tracebacks. Defaults to False.\n        tracebacks_suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        tracebacks_max_frames (int, optional): Optional maximum number of frames returned by traceback.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        log_time_format (Union[str, TimeFormatterCallable], optional): If ``log_time`` is enabled, either string for strftime or callable that formats the time. Defaults to \"[%x %X] \".\n        keywords (List[str], optional): List of words to highlight instead of ``RichHandler.KEYWORDS``.\n    \"\"\"\n\n    KEYWORDS: ClassVar[Optional[List[str]]] = [\n        \"GET\",\n        \"POST\",\n        \"HEAD\",\n        \"PUT\",\n        \"DELETE\",\n        \"OPTIONS\",\n        \"TRACE\",\n        \"PATCH\",\n    ]\n    HIGHLIGHTER_CLASS: ClassVar[Type[Highlighter]] = ReprHighlighter\n\n    def __init__(\n        self,\n        level: Union[int, str] = logging.NOTSET,\n        console: Optional[Console] = None,\n        *,\n        show_time: bool = True,\n        omit_repeated_times: bool = True,\n        show_level: bool = True,\n        show_path: bool = True,\n        enable_link_path: bool = True,\n        highlighter: Optional[Highlighter] = None,\n        markup: bool = False,\n        rich_tracebacks: bool = False,\n        tracebacks_width: Optional[int] = None,\n        tracebacks_code_width: int = 88,\n        tracebacks_extra_lines: int = 3,\n        tracebacks_theme: Optional[str] = None,\n        tracebacks_word_wrap: bool = True,\n        tracebacks_show_locals: bool = False,\n        tracebacks_suppress: Iterable[Union[str, ModuleType]] = (),\n        tracebacks_max_frames: int = 100,\n        locals_max_length: int = 10,\n        locals_max_string: int = 80,\n        log_time_format: Union[str, FormatTimeCallable] = \"[%x %X]\",\n        keywords: Optional[List[str]] = None,\n    ) -> None:\n        super().__init__(level=level)\n        self.console = console or get_console()\n        self.highlighter = highlighter or self.HIGHLIGHTER_CLASS()\n        self._log_render = LogRender(\n            show_time=show_time,\n            show_level=show_level,\n            show_path=show_path,\n            time_format=log_time_format,\n            omit_repeated_times=omit_repeated_times,\n            level_width=None,\n        )\n        self.enable_link_path = enable_link_path\n        self.markup = markup\n        self.rich_tracebacks = rich_tracebacks\n        self.tracebacks_width = tracebacks_width\n        self.tracebacks_extra_lines = tracebacks_extra_lines\n        self.tracebacks_theme = tracebacks_theme\n        self.tracebacks_word_wrap = tracebacks_word_wrap\n        self.tracebacks_show_locals = tracebacks_show_locals\n        self.tracebacks_suppress = tracebacks_suppress\n        self.tracebacks_max_frames = tracebacks_max_frames\n        self.tracebacks_code_width = tracebacks_code_width\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.keywords = keywords\n\n    def get_level_text(self, record: LogRecord) -> Text:\n        \"\"\"Get the level name from the record.\n\n        Args:\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\markup.py": {
      "sha": "203e0225a128",
      "lines": 251,
      "head": "import re\nfrom ast import literal_eval\nfrom operator import attrgetter\nfrom typing import Callable, Iterable, List, Match, NamedTuple, Optional, Tuple, Union\n\nfrom ._emoji_replace import _emoji_replace\nfrom .emoji import EmojiVariant\nfrom .errors import MarkupError\nfrom .style import Style\nfrom .text import Span, Text\n\nRE_TAGS = re.compile(\n    r\"\"\"((\\\\*)\\[([a-z#/@][^[]*?)])\"\"\",\n    re.VERBOSE,\n)\n\nRE_HANDLER = re.compile(r\"^([\\w.]*?)(\\(.*?\\))?$\")\n\n\nclass Tag(NamedTuple):\n    \"\"\"A tag in console markup.\"\"\"\n\n    name: str\n    \"\"\"The tag name. e.g. 'bold'.\"\"\"\n    parameters: Optional[str]\n    \"\"\"Any additional parameters after the name.\"\"\"\n\n    def __str__(self) -> str:\n        return (\n            self.name if self.parameters is None else f\"{self.name} {self.parameters}\"\n        )\n\n    @property\n    def markup(self) -> str:\n        \"\"\"Get the string representation of this tag.\"\"\"\n        return (\n            f\"[{self.name}]\"\n            if self.parameters is None\n            else f\"[{self.name}={self.parameters}]\"\n        )\n\n\n_ReStringMatch = Match[str]  # regex match object\n_ReSubCallable = Callable[[_ReStringMatch], str]  # Callable invoked by re.sub\n_EscapeSubMethod = Callable[[_ReSubCallable, str], str]  # Sub method of a compiled re\n\n\ndef escape(\n    markup: str,\n    _escape: _EscapeSubMethod = re.compile(r\"(\\\\*)(\\[[a-z#/@][^[]*?])\").sub,\n) -> str:\n    \"\"\"Escapes text so that it won't be interpreted as markup.\n\n    Args:\n        markup (str): Content to be inserted in to markup.\n\n    Returns:\n        str: Markup with square brackets escaped.\n    \"\"\"\n\n    def escape_backslashes(match: Match[str]) -> str:\n        \"\"\"Called by re.sub replace matches.\"\"\"\n        backslashes, text = match.groups()\n        return f\"{backslashes}{backslashes}\\\\{text}\"\n\n    markup = _escape(escape_backslashes, markup)\n    if markup.endswith(\"\\\\\") and not markup.endswith(\"\\\\\\\\\"):\n        return markup + \"\\\\\"\n\n    return markup\n\n\ndef _parse(markup: str) -> Iterable[Tuple[int, Optional[str], Optional[Tag]]]:\n    \"\"\"Parse markup in to an iterable of tuples of (position, text, tag).\n\n    Args:\n        markup (str): A string containing console markup\n\n    \"\"\"\n    position = 0\n    _divmod = divmod\n    _Tag = Tag\n    for match in RE_TAGS.finditer(markup):\n        full_text, escapes, tag_text = match.groups()\n        start, end = match.span()\n        if start > position:\n            yield start, markup[position:start], None\n        if escapes:\n            backslashes, escaped = _divmod(len(escapes), 2)\n            if backslashes:\n                # Literal backslashes\n                yield start, \"\\\\\" * backslashes, None\n                start += backslashes * 2\n            if escaped:\n                # Escape of tag\n                yield start, full_text[len(escapes) :], None\n                position = end\n                continue\n        text, equals, parameters = tag_text.partition(\"=\")\n        yield start, None, _Tag(text, parameters if equals else None)\n        position = end\n    if position < len(markup):\n        yield position, markup[position:], None\n\n\ndef render(\n    markup: str,\n    style: Union[str, Style] = \"\",\n    emoji: bool = True,\n    emoji_variant: Optional[EmojiVariant] = None,\n) -> Text:\n    \"\"\"Render console markup in to a Text instance.\n\n    Args:\n        markup (str): A string containing console markup.\n        style: (Union[str, Style]): The style to use.\n        emoji (bool, optional): Also render emoji code. Defaults to True.\n        emoji_variant (str, optional): Optional emoji variant, either \"text\" or \"emoji\". Defaults to None.\n\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\measure.py": {
      "sha": "cecfbef0e10c",
      "lines": 151,
      "head": "from operator import itemgetter\nfrom typing import TYPE_CHECKING, Callable, NamedTuple, Optional, Sequence\n\nfrom . import errors\nfrom .protocol import is_renderable, rich_cast\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderableType\n\n\nclass Measurement(NamedTuple):\n    \"\"\"Stores the minimum and maximum widths (in characters) required to render an object.\"\"\"\n\n    minimum: int\n    \"\"\"Minimum number of cells required to render.\"\"\"\n    maximum: int\n    \"\"\"Maximum number of cells required to render.\"\"\"\n\n    @property\n    def span(self) -> int:\n        \"\"\"Get difference between maximum and minimum.\"\"\"\n        return self.maximum - self.minimum\n\n    def normalize(self) -> \"Measurement\":\n        \"\"\"Get measurement that ensures that minimum <= maximum and minimum >= 0\n\n        Returns:\n            Measurement: A normalized measurement.\n        \"\"\"\n        minimum, maximum = self\n        minimum = min(max(0, minimum), maximum)\n        return Measurement(max(0, minimum), max(0, max(minimum, maximum)))\n\n    def with_maximum(self, width: int) -> \"Measurement\":\n        \"\"\"Get a RenderableWith where the widths are <= width.\n\n        Args:\n            width (int): Maximum desired width.\n\n        Returns:\n            Measurement: New Measurement object.\n        \"\"\"\n        minimum, maximum = self\n        return Measurement(min(minimum, width), min(maximum, width))\n\n    def with_minimum(self, width: int) -> \"Measurement\":\n        \"\"\"Get a RenderableWith where the widths are >= width.\n\n        Args:\n            width (int): Minimum desired width.\n\n        Returns:\n            Measurement: New Measurement object.\n        \"\"\"\n        minimum, maximum = self\n        width = max(0, width)\n        return Measurement(max(minimum, width), max(maximum, width))\n\n    def clamp(\n        self, min_width: Optional[int] = None, max_width: Optional[int] = None\n    ) -> \"Measurement\":\n        \"\"\"Clamp a measurement within the specified range.\n\n        Args:\n            min_width (int): Minimum desired width, or ``None`` for no minimum. Defaults to None.\n            max_width (int): Maximum desired width, or ``None`` for no maximum. Defaults to None.\n\n        Returns:\n            Measurement: New Measurement object.\n        \"\"\"\n        measurement = self\n        if min_width is not None:\n            measurement = measurement.with_minimum(min_width)\n        if max_width is not None:\n            measurement = measurement.with_maximum(max_width)\n        return measurement\n\n    @classmethod\n    def get(\n        cls, console: \"Console\", options: \"ConsoleOptions\", renderable: \"RenderableType\"\n    ) -> \"Measurement\":\n        \"\"\"Get a measurement for a renderable.\n\n        Args:\n            console (~rich.console.Console): Console instance.\n            options (~rich.console.ConsoleOptions): Console options.\n            renderable (RenderableType): An object that may be rendered with Rich.\n\n        Raises:\n            errors.NotRenderableError: If the object is not renderable.\n\n        Returns:\n            Measurement: Measurement object containing range of character widths required to render the object.\n        \"\"\"\n        _max_width = options.max_width\n        if _max_width < 1:\n            return Measurement(0, 0)\n        if isinstance(renderable, str):\n            renderable = console.render_str(\n                renderable, markup=options.markup, highlight=False\n            )\n        renderable = rich_cast(renderable)\n        if is_renderable(renderable):\n            get_console_width: Optional[\n                Callable[[\"Console\", \"ConsoleOptions\"], \"Measurement\"]\n            ] = getattr(renderable, \"__rich_measure__\", None)\n            if get_console_width is not None:\n                render_width = (\n                    get_console_width(console, options)\n                    .normalize()\n                    .with_maximum(_max_width)\n                )\n                if render_width.maximum < 1:\n                    return Measurement(0, 0)\n                return render_width.normalize()\n            else:\n                return Measurement(0, _max_width)\n        else:\n            raise errors.NotRenderableError(\n                f\"Unable to get render width for {renderable!r}; \"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\padding.py": {
      "sha": "2a3db7368ecf",
      "lines": 141,
      "head": "from typing import TYPE_CHECKING, List, Optional, Tuple, Union\n\nif TYPE_CHECKING:\n    from .console import (\n        Console,\n        ConsoleOptions,\n        RenderableType,\n        RenderResult,\n    )\n\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .segment import Segment\nfrom .style import Style\n\nPaddingDimensions = Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int, int]]\n\n\nclass Padding(JupyterMixin):\n    \"\"\"Draw space around content.\n\n    Example:\n        >>> print(Padding(\"Hello\", (2, 4), style=\"on blue\"))\n\n    Args:\n        renderable (RenderableType): String or other renderable.\n        pad (Union[int, Tuple[int]]): Padding for top, right, bottom, and left borders.\n            May be specified with 1, 2, or 4 integers (CSS style).\n        style (Union[str, Style], optional): Style for padding characters. Defaults to \"none\".\n        expand (bool, optional): Expand padding to fit available width. Defaults to True.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: \"RenderableType\",\n        pad: \"PaddingDimensions\" = (0, 0, 0, 0),\n        *,\n        style: Union[str, Style] = \"none\",\n        expand: bool = True,\n    ):\n        self.renderable = renderable\n        self.top, self.right, self.bottom, self.left = self.unpack(pad)\n        self.style = style\n        self.expand = expand\n\n    @classmethod\n    def indent(cls, renderable: \"RenderableType\", level: int) -> \"Padding\":\n        \"\"\"Make padding instance to render an indent.\n\n        Args:\n            renderable (RenderableType): String or other renderable.\n            level (int): Number of characters to indent.\n\n        Returns:\n            Padding: A Padding instance.\n        \"\"\"\n\n        return Padding(renderable, pad=(0, 0, 0, level), expand=False)\n\n    @staticmethod\n    def unpack(pad: \"PaddingDimensions\") -> Tuple[int, int, int, int]:\n        \"\"\"Unpack padding specified in CSS style.\"\"\"\n        if isinstance(pad, int):\n            return (pad, pad, pad, pad)\n        if len(pad) == 1:\n            _pad = pad[0]\n            return (_pad, _pad, _pad, _pad)\n        if len(pad) == 2:\n            pad_top, pad_right = pad\n            return (pad_top, pad_right, pad_top, pad_right)\n        if len(pad) == 4:\n            top, right, bottom, left = pad\n            return (top, right, bottom, left)\n        raise ValueError(f\"1, 2 or 4 integers required for padding; {len(pad)} given\")\n\n    def __repr__(self) -> str:\n        return f\"Padding({self.renderable!r}, ({self.top},{self.right},{self.bottom},{self.left}))\"\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        style = console.get_style(self.style)\n        if self.expand:\n            width = options.max_width\n        else:\n            width = min(\n                Measurement.get(console, options, self.renderable).maximum\n                + self.left\n                + self.right,\n                options.max_width,\n            )\n        render_options = options.update_width(width - self.left - self.right)\n        if render_options.height is not None:\n            render_options = render_options.update_height(\n                height=render_options.height - self.top - self.bottom\n            )\n        lines = console.render_lines(\n            self.renderable, render_options, style=style, pad=True\n        )\n        _Segment = Segment\n\n        left = _Segment(\" \" * self.left, style) if self.left else None\n        right = (\n            [_Segment(f'{\" \" * self.right}', style), _Segment.line()]\n            if self.right\n            else [_Segment.line()]\n        )\n        blank_line: Optional[List[Segment]] = None\n        if self.top:\n            blank_line = [_Segment(f'{\" \" * width}\\n', style)]\n            yield from blank_line * self.top\n        if left:\n            for line in lines:\n                yield left\n                yield from line\n                yield from right\n        else:\n            for line in lines:\n                yield from line\n                yield from right\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\pager.py": {
      "sha": "66a01aaa2f82",
      "lines": 34,
      "head": "from abc import ABC, abstractmethod\nfrom typing import Any\n\n\nclass Pager(ABC):\n    \"\"\"Base class for a pager.\"\"\"\n\n    @abstractmethod\n    def show(self, content: str) -> None:\n        \"\"\"Show content in pager.\n\n        Args:\n            content (str): Content to be displayed.\n        \"\"\"\n\n\nclass SystemPager(Pager):\n    \"\"\"Uses the pager installed on the system.\"\"\"\n\n    def _pager(self, content: str) -> Any:  # \u00a0pragma: no cover\n        return __import__(\"pydoc\").pager(content)\n\n    def show(self, content: str) -> None:\n        \"\"\"Use the same pager used by pydoc.\"\"\"\n        self._pager(content)\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from .__main__ import make_test_card\n    from .console import Console\n\n    console = Console()\n    with console.pager(styles=True):\n        console.print(make_test_card())\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\palette.py": {
      "sha": "30f805997188",
      "lines": 100,
      "head": "from math import sqrt\nfrom functools import lru_cache\nfrom typing import Sequence, Tuple, TYPE_CHECKING\n\nfrom .color_triplet import ColorTriplet\n\nif TYPE_CHECKING:\n    from pip._vendor.rich.table import Table\n\n\nclass Palette:\n    \"\"\"A palette of available colors.\"\"\"\n\n    def __init__(self, colors: Sequence[Tuple[int, int, int]]):\n        self._colors = colors\n\n    def __getitem__(self, number: int) -> ColorTriplet:\n        return ColorTriplet(*self._colors[number])\n\n    def __rich__(self) -> \"Table\":\n        from pip._vendor.rich.color import Color\n        from pip._vendor.rich.style import Style\n        from pip._vendor.rich.text import Text\n        from pip._vendor.rich.table import Table\n\n        table = Table(\n            \"index\",\n            \"RGB\",\n            \"Color\",\n            title=\"Palette\",\n            caption=f\"{len(self._colors)} colors\",\n            highlight=True,\n            caption_justify=\"right\",\n        )\n        for index, color in enumerate(self._colors):\n            table.add_row(\n                str(index),\n                repr(color),\n                Text(\" \" * 16, style=Style(bgcolor=Color.from_rgb(*color))),\n            )\n        return table\n\n    # This is somewhat inefficient and needs caching\n    @lru_cache(maxsize=1024)\n    def match(self, color: Tuple[int, int, int]) -> int:\n        \"\"\"Find a color from a palette that most closely matches a given color.\n\n        Args:\n            color (Tuple[int, int, int]): RGB components in range 0 > 255.\n\n        Returns:\n            int: Index of closes matching color.\n        \"\"\"\n        red1, green1, blue1 = color\n        _sqrt = sqrt\n        get_color = self._colors.__getitem__\n\n        def get_color_distance(index: int) -> float:\n            \"\"\"Get the distance to a color.\"\"\"\n            red2, green2, blue2 = get_color(index)\n            red_mean = (red1 + red2) // 2\n            red = red1 - red2\n            green = green1 - green2\n            blue = blue1 - blue2\n            return _sqrt(\n                (((512 + red_mean) * red * red) >> 8)\n                + 4 * green * green\n                + (((767 - red_mean) * blue * blue) >> 8)\n            )\n\n        min_index = min(range(len(self._colors)), key=get_color_distance)\n        return min_index\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import colorsys\n    from typing import Iterable\n    from pip._vendor.rich.color import Color\n    from pip._vendor.rich.console import Console, ConsoleOptions\n    from pip._vendor.rich.segment import Segment\n    from pip._vendor.rich.style import Style\n\n    class ColorBox:\n        def __rich_console__(\n            self, console: Console, options: ConsoleOptions\n        ) -> Iterable[Segment]:\n            height = console.size.height - 3\n            for y in range(0, height):\n                for x in range(options.max_width):\n                    h = x / options.max_width\n                    l = y / (height + 1)\n                    r1, g1, b1 = colorsys.hls_to_rgb(h, l, 1.0)\n                    r2, g2, b2 = colorsys.hls_to_rgb(h, l + (1 / height / 2), 1.0)\n                    bgcolor = Color.from_rgb(r1 * 255, g1 * 255, b1 * 255)\n                    color = Color.from_rgb(r2 * 255, g2 * 255, b2 * 255)\n                    yield Segment(\"\u2584\", Style(color=color, bgcolor=bgcolor))\n                yield Segment.line()\n\n    console = Console()\n    console.print(ColorBox())\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\panel.py": {
      "sha": "e0a79d0f1dac",
      "lines": 318,
      "head": "from typing import TYPE_CHECKING, Optional\n\nfrom .align import AlignMethod\nfrom .box import ROUNDED, Box\nfrom .cells import cell_len\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement, measure_renderables\nfrom .padding import Padding, PaddingDimensions\nfrom .segment import Segment\nfrom .style import Style, StyleType\nfrom .text import Text, TextType\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n\n\nclass Panel(JupyterMixin):\n    \"\"\"A console renderable that draws a border around its contents.\n\n    Example:\n        >>> console.print(Panel(\"Hello, World!\"))\n\n    Args:\n        renderable (RenderableType): A console renderable object.\n        box (Box): A Box instance that defines the look of the border (see :ref:`appendix_box`. Defaults to box.ROUNDED.\n        title (Optional[TextType], optional): Optional title displayed in panel header. Defaults to None.\n        title_align (AlignMethod, optional): Alignment of title. Defaults to \"center\".\n        subtitle (Optional[TextType], optional): Optional subtitle displayed in panel footer. Defaults to None.\n        subtitle_align (AlignMethod, optional): Alignment of subtitle. Defaults to \"center\".\n        safe_box (bool, optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.\n        expand (bool, optional): If True the panel will stretch to fill the console width, otherwise it will be sized to fit the contents. Defaults to True.\n        style (str, optional): The style of the panel (border and contents). Defaults to \"none\".\n        border_style (str, optional): The style of the border. Defaults to \"none\".\n        width (Optional[int], optional): Optional width of panel. Defaults to None to auto-detect.\n        height (Optional[int], optional): Optional height of panel. Defaults to None to auto-detect.\n        padding (Optional[PaddingDimensions]): Optional padding around renderable. Defaults to 0.\n        highlight (bool, optional): Enable automatic highlighting of panel title (if str). Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: \"RenderableType\",\n        box: Box = ROUNDED,\n        *,\n        title: Optional[TextType] = None,\n        title_align: AlignMethod = \"center\",\n        subtitle: Optional[TextType] = None,\n        subtitle_align: AlignMethod = \"center\",\n        safe_box: Optional[bool] = None,\n        expand: bool = True,\n        style: StyleType = \"none\",\n        border_style: StyleType = \"none\",\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n        padding: PaddingDimensions = (0, 1),\n        highlight: bool = False,\n    ) -> None:\n        self.renderable = renderable\n        self.box = box\n        self.title = title\n        self.title_align: AlignMethod = title_align\n        self.subtitle = subtitle\n        self.subtitle_align = subtitle_align\n        self.safe_box = safe_box\n        self.expand = expand\n        self.style = style\n        self.border_style = border_style\n        self.width = width\n        self.height = height\n        self.padding = padding\n        self.highlight = highlight\n\n    @classmethod\n    def fit(\n        cls,\n        renderable: \"RenderableType\",\n        box: Box = ROUNDED,\n        *,\n        title: Optional[TextType] = None,\n        title_align: AlignMethod = \"center\",\n        subtitle: Optional[TextType] = None,\n        subtitle_align: AlignMethod = \"center\",\n        safe_box: Optional[bool] = None,\n        style: StyleType = \"none\",\n        border_style: StyleType = \"none\",\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n        padding: PaddingDimensions = (0, 1),\n        highlight: bool = False,\n    ) -> \"Panel\":\n        \"\"\"An alternative constructor that sets expand=False.\"\"\"\n        return cls(\n            renderable,\n            box,\n            title=title,\n            title_align=title_align,\n            subtitle=subtitle,\n            subtitle_align=subtitle_align,\n            safe_box=safe_box,\n            style=style,\n            border_style=border_style,\n            width=width,\n            height=height,\n            padding=padding,\n            highlight=highlight,\n            expand=False,\n        )\n\n    @property\n    def _title(self) -> Optional[Text]:\n        if self.title:\n            title_text = (\n                Text.from_markup(self.title)\n                if isinstance(self.title, str)\n                else self.title.copy()\n            )\n            title_text.end = \"\"\n            title_text.plain = title_text.plain.replace(\"\\n\", \" \")\n            title_text.no_wrap = True\n            title_text.expand_tabs()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\pretty.py": {
      "sha": "f62af39f4c8d",
      "lines": 1016,
      "head": "import builtins\nimport collections\nimport dataclasses\nimport inspect\nimport os\nimport reprlib\nimport sys\nfrom array import array\nfrom collections import Counter, UserDict, UserList, defaultdict, deque\nfrom dataclasses import dataclass, fields, is_dataclass\nfrom inspect import isclass\nfrom itertools import islice\nfrom types import MappingProxyType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    DefaultDict,\n    Deque,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    Union,\n)\n\nfrom pip._vendor.rich.repr import RichReprResult\n\ntry:\n    import attr as _attr_module\n\n    _has_attrs = hasattr(_attr_module, \"ib\")\nexcept ImportError:  # pragma: no cover\n    _has_attrs = False\n\nfrom . import get_console\nfrom ._loop import loop_last\nfrom ._pick import pick_bool\nfrom .abc import RichRenderable\nfrom .cells import cell_len\nfrom .highlighter import ReprHighlighter\nfrom .jupyter import JupyterMixin, JupyterRenderable\nfrom .measure import Measurement\nfrom .text import Text\n\nif TYPE_CHECKING:\n    from .console import (\n        Console,\n        ConsoleOptions,\n        HighlighterType,\n        JustifyMethod,\n        OverflowMethod,\n        RenderResult,\n    )\n\n\ndef _is_attr_object(obj: Any) -> bool:\n    \"\"\"Check if an object was created with attrs module.\"\"\"\n    return _has_attrs and _attr_module.has(type(obj))\n\n\ndef _get_attr_fields(obj: Any) -> Sequence[\"_attr_module.Attribute[Any]\"]:\n    \"\"\"Get fields for an attrs object.\"\"\"\n    return _attr_module.fields(type(obj)) if _has_attrs else []\n\n\ndef _is_dataclass_repr(obj: object) -> bool:\n    \"\"\"Check if an instance of a dataclass contains the default repr.\n\n    Args:\n        obj (object): A dataclass instance.\n\n    Returns:\n        bool: True if the default repr is used, False if there is a custom repr.\n    \"\"\"\n    # Digging in to a lot of internals here\n    # Catching all exceptions in case something is missing on a non CPython implementation\n    try:\n        return obj.__repr__.__code__.co_filename in (\n            dataclasses.__file__,\n            reprlib.__file__,\n        )\n    except Exception:  # pragma: no coverage\n        return False\n\n\n_dummy_namedtuple = collections.namedtuple(\"_dummy_namedtuple\", [])\n\n\ndef _has_default_namedtuple_repr(obj: object) -> bool:\n    \"\"\"Check if an instance of namedtuple contains the default repr\n\n    Args:\n        obj (object): A namedtuple\n\n    Returns:\n        bool: True if the default repr is used, False if there's a custom repr.\n    \"\"\"\n    obj_file = None\n    try:\n        obj_file = inspect.getfile(obj.__repr__)\n    except (OSError, TypeError):\n        # OSError handles case where object is defined in __main__ scope, e.g. REPL - no filename available.\n        # TypeError trapped defensively, in case of object without filename slips through.\n        pass\n    default_repr_file = inspect.getfile(_dummy_namedtuple.__repr__)\n    return obj_file == default_repr_file\n\n\ndef _ipy_display_hook(\n    value: Any,\n    console: Optional[\"Console\"] = None,\n    overflow: \"OverflowMethod\" = \"ignore\",\n    crop: bool = False,\n    indent_guides: bool = False,\n    max_length: Optional[int] = None,\n    max_string: Optional[int] = None,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\progress.py": {
      "sha": "a4db842800f0",
      "lines": 1715,
      "head": "import io\nimport sys\nimport typing\nimport warnings\nfrom abc import ABC, abstractmethod\nfrom collections import deque\nfrom dataclasses import dataclass, field\nfrom datetime import timedelta\nfrom io import RawIOBase, UnsupportedOperation\nfrom math import ceil\nfrom mmap import mmap\nfrom operator import length_hint\nfrom os import PathLike, stat\nfrom threading import Event, RLock, Thread\nfrom types import TracebackType\nfrom typing import (\n    Any,\n    BinaryIO,\n    Callable,\n    ContextManager,\n    Deque,\n    Dict,\n    Generic,\n    Iterable,\n    List,\n    NamedTuple,\n    NewType,\n    Optional,\n    Sequence,\n    TextIO,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n)\n\nif sys.version_info >= (3, 8):\n    from typing import Literal\nelse:\n    from pip._vendor.typing_extensions import Literal  # pragma: no cover\n\nif sys.version_info >= (3, 11):\n    from typing import Self\nelse:\n    from pip._vendor.typing_extensions import Self  # pragma: no cover\n\nfrom . import filesize, get_console\nfrom .console import Console, Group, JustifyMethod, RenderableType\nfrom .highlighter import Highlighter\nfrom .jupyter import JupyterMixin\nfrom .live import Live\nfrom .progress_bar import ProgressBar\nfrom .spinner import Spinner\nfrom .style import StyleType\nfrom .table import Column, Table\nfrom .text import Text, TextType\n\nTaskID = NewType(\"TaskID\", int)\n\nProgressType = TypeVar(\"ProgressType\")\n\nGetTimeCallable = Callable[[], float]\n\n\n_I = typing.TypeVar(\"_I\", TextIO, BinaryIO)\n\n\nclass _TrackThread(Thread):\n    \"\"\"A thread to periodically update progress.\"\"\"\n\n    def __init__(self, progress: \"Progress\", task_id: \"TaskID\", update_period: float):\n        self.progress = progress\n        self.task_id = task_id\n        self.update_period = update_period\n        self.done = Event()\n\n        self.completed = 0\n        super().__init__(daemon=True)\n\n    def run(self) -> None:\n        task_id = self.task_id\n        advance = self.progress.advance\n        update_period = self.update_period\n        last_completed = 0\n        wait = self.done.wait\n        while not wait(update_period) and self.progress.live.is_started:\n            completed = self.completed\n            if last_completed != completed:\n                advance(task_id, completed - last_completed)\n                last_completed = completed\n\n        self.progress.update(self.task_id, completed=self.completed, refresh=True)\n\n    def __enter__(self) -> \"_TrackThread\":\n        self.start()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        self.done.set()\n        self.join()\n\n\ndef track(\n    sequence: Union[Sequence[ProgressType], Iterable[ProgressType]],\n    description: str = \"Working...\",\n    total: Optional[float] = None,\n    completed: int = 0,\n    auto_refresh: bool = True,\n    console: Optional[Console] = None,\n    transient: bool = False,\n    get_time: Optional[Callable[[], float]] = None,\n    refresh_per_second: float = 10,\n    style: StyleType = \"bar.back\",\n    complete_style: StyleType = \"bar.complete\",\n    finished_style: StyleType = \"bar.finished\",\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\progress_bar.py": {
      "sha": "67d2ad11833c",
      "lines": 223,
      "head": "import math\nfrom functools import lru_cache\nfrom time import monotonic\nfrom typing import Iterable, List, Optional\n\nfrom .color import Color, blend_rgb\nfrom .color_triplet import ColorTriplet\nfrom .console import Console, ConsoleOptions, RenderResult\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .segment import Segment\nfrom .style import Style, StyleType\n\n# Number of characters before 'pulse' animation repeats\nPULSE_SIZE = 20\n\n\nclass ProgressBar(JupyterMixin):\n    \"\"\"Renders a (progress) bar. Used by rich.progress.\n\n    Args:\n        total (float, optional): Number of steps in the bar. Defaults to 100. Set to None to render a pulsing animation.\n        completed (float, optional): Number of steps completed. Defaults to 0.\n        width (int, optional): Width of the bar, or ``None`` for maximum width. Defaults to None.\n        pulse (bool, optional): Enable pulse effect. Defaults to False. Will pulse if a None total was passed.\n        style (StyleType, optional): Style for the bar background. Defaults to \"bar.back\".\n        complete_style (StyleType, optional): Style for the completed bar. Defaults to \"bar.complete\".\n        finished_style (StyleType, optional): Style for a finished bar. Defaults to \"bar.finished\".\n        pulse_style (StyleType, optional): Style for pulsing bars. Defaults to \"bar.pulse\".\n        animation_time (Optional[float], optional): Time in seconds to use for animation, or None to use system time.\n    \"\"\"\n\n    def __init__(\n        self,\n        total: Optional[float] = 100.0,\n        completed: float = 0,\n        width: Optional[int] = None,\n        pulse: bool = False,\n        style: StyleType = \"bar.back\",\n        complete_style: StyleType = \"bar.complete\",\n        finished_style: StyleType = \"bar.finished\",\n        pulse_style: StyleType = \"bar.pulse\",\n        animation_time: Optional[float] = None,\n    ):\n        self.total = total\n        self.completed = completed\n        self.width = width\n        self.pulse = pulse\n        self.style = style\n        self.complete_style = complete_style\n        self.finished_style = finished_style\n        self.pulse_style = pulse_style\n        self.animation_time = animation_time\n\n        self._pulse_segments: Optional[List[Segment]] = None\n\n    def __repr__(self) -> str:\n        return f\"<Bar {self.completed!r} of {self.total!r}>\"\n\n    @property\n    def percentage_completed(self) -> Optional[float]:\n        \"\"\"Calculate percentage complete.\"\"\"\n        if self.total is None:\n            return None\n        completed = (self.completed / self.total) * 100.0\n        completed = min(100, max(0.0, completed))\n        return completed\n\n    @lru_cache(maxsize=16)\n    def _get_pulse_segments(\n        self,\n        fore_style: Style,\n        back_style: Style,\n        color_system: str,\n        no_color: bool,\n        ascii: bool = False,\n    ) -> List[Segment]:\n        \"\"\"Get a list of segments to render a pulse animation.\n\n        Returns:\n            List[Segment]: A list of segments, one segment per character.\n        \"\"\"\n        bar = \"-\" if ascii else \"\u2501\"\n        segments: List[Segment] = []\n        if color_system not in (\"standard\", \"eight_bit\", \"truecolor\") or no_color:\n            segments += [Segment(bar, fore_style)] * (PULSE_SIZE // 2)\n            segments += [Segment(\" \" if no_color else bar, back_style)] * (\n                PULSE_SIZE - (PULSE_SIZE // 2)\n            )\n            return segments\n\n        append = segments.append\n        fore_color = (\n            fore_style.color.get_truecolor()\n            if fore_style.color\n            else ColorTriplet(255, 0, 255)\n        )\n        back_color = (\n            back_style.color.get_truecolor()\n            if back_style.color\n            else ColorTriplet(0, 0, 0)\n        )\n        cos = math.cos\n        pi = math.pi\n        _Segment = Segment\n        _Style = Style\n        from_triplet = Color.from_triplet\n\n        for index in range(PULSE_SIZE):\n            position = index / PULSE_SIZE\n            fade = 0.5 + cos(position * pi * 2) / 2.0\n            color = blend_rgb(fore_color, back_color, cross_fade=fade)\n            append(_Segment(bar, _Style(color=from_triplet(color))))\n        return segments\n\n    def update(self, completed: float, total: Optional[float] = None) -> None:\n        \"\"\"Update progress with new values.\n\n        Args:\n            completed (float): Number of steps completed.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\prompt.py": {
      "sha": "4ec3638d1879",
      "lines": 400,
      "head": "from typing import Any, Generic, List, Optional, TextIO, TypeVar, Union, overload\n\nfrom . import get_console\nfrom .console import Console\nfrom .text import Text, TextType\n\nPromptType = TypeVar(\"PromptType\")\nDefaultType = TypeVar(\"DefaultType\")\n\n\nclass PromptError(Exception):\n    \"\"\"Exception base class for prompt related errors.\"\"\"\n\n\nclass InvalidResponse(PromptError):\n    \"\"\"Exception to indicate a response was invalid. Raise this within process_response() to indicate an error\n    and provide an error message.\n\n    Args:\n        message (Union[str, Text]): Error message.\n    \"\"\"\n\n    def __init__(self, message: TextType) -> None:\n        self.message = message\n\n    def __rich__(self) -> TextType:\n        return self.message\n\n\nclass PromptBase(Generic[PromptType]):\n    \"\"\"Ask the user for input until a valid response is received. This is the base class, see one of\n    the concrete classes for examples.\n\n    Args:\n        prompt (TextType, optional): Prompt text. Defaults to \"\".\n        console (Console, optional): A Console instance or None to use global console. Defaults to None.\n        password (bool, optional): Enable password input. Defaults to False.\n        choices (List[str], optional): A list of valid choices. Defaults to None.\n        case_sensitive (bool, optional): Matching of choices should be case-sensitive. Defaults to True.\n        show_default (bool, optional): Show default in prompt. Defaults to True.\n        show_choices (bool, optional): Show choices in prompt. Defaults to True.\n    \"\"\"\n\n    response_type: type = str\n\n    validate_error_message = \"[prompt.invalid]Please enter a valid value\"\n    illegal_choice_message = (\n        \"[prompt.invalid.choice]Please select one of the available options\"\n    )\n    prompt_suffix = \": \"\n\n    choices: Optional[List[str]] = None\n\n    def __init__(\n        self,\n        prompt: TextType = \"\",\n        *,\n        console: Optional[Console] = None,\n        password: bool = False,\n        choices: Optional[List[str]] = None,\n        case_sensitive: bool = True,\n        show_default: bool = True,\n        show_choices: bool = True,\n    ) -> None:\n        self.console = console or get_console()\n        self.prompt = (\n            Text.from_markup(prompt, style=\"prompt\")\n            if isinstance(prompt, str)\n            else prompt\n        )\n        self.password = password\n        if choices is not None:\n            self.choices = choices\n        self.case_sensitive = case_sensitive\n        self.show_default = show_default\n        self.show_choices = show_choices\n\n    @classmethod\n    @overload\n    def ask(\n        cls,\n        prompt: TextType = \"\",\n        *,\n        console: Optional[Console] = None,\n        password: bool = False,\n        choices: Optional[List[str]] = None,\n        case_sensitive: bool = True,\n        show_default: bool = True,\n        show_choices: bool = True,\n        default: DefaultType,\n        stream: Optional[TextIO] = None,\n    ) -> Union[DefaultType, PromptType]:\n        ...\n\n    @classmethod\n    @overload\n    def ask(\n        cls,\n        prompt: TextType = \"\",\n        *,\n        console: Optional[Console] = None,\n        password: bool = False,\n        choices: Optional[List[str]] = None,\n        case_sensitive: bool = True,\n        show_default: bool = True,\n        show_choices: bool = True,\n        stream: Optional[TextIO] = None,\n    ) -> PromptType:\n        ...\n\n    @classmethod\n    def ask(\n        cls,\n        prompt: TextType = \"\",\n        *,\n        console: Optional[Console] = None,\n        password: bool = False,\n        choices: Optional[List[str]] = None,\n        case_sensitive: bool = True,\n        show_default: bool = True,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\protocol.py": {
      "sha": "a2dca9d46365",
      "lines": 42,
      "head": "from typing import Any, cast, Set, TYPE_CHECKING\nfrom inspect import isclass\n\nif TYPE_CHECKING:\n    from pip._vendor.rich.console import RenderableType\n\n_GIBBERISH = \"\"\"aihwerij235234ljsdnp34ksodfipwoe234234jlskjdf\"\"\"\n\n\ndef is_renderable(check_object: Any) -> bool:\n    \"\"\"Check if an object may be rendered by Rich.\"\"\"\n    return (\n        isinstance(check_object, str)\n        or hasattr(check_object, \"__rich__\")\n        or hasattr(check_object, \"__rich_console__\")\n    )\n\n\ndef rich_cast(renderable: object) -> \"RenderableType\":\n    \"\"\"Cast an object to a renderable by calling __rich__ if present.\n\n    Args:\n        renderable (object): A potentially renderable object\n\n    Returns:\n        object: The result of recursively calling __rich__.\n    \"\"\"\n    from pip._vendor.rich.console import RenderableType\n\n    rich_visited_set: Set[type] = set()  # Prevent potential infinite loop\n    while hasattr(renderable, \"__rich__\") and not isclass(renderable):\n        # Detect object which claim to have all the attributes\n        if hasattr(renderable, _GIBBERISH):\n            return repr(renderable)\n        cast_method = getattr(renderable, \"__rich__\")\n        renderable = cast_method()\n        renderable_type = type(renderable)\n        if renderable_type in rich_visited_set:\n            break\n        rich_visited_set.add(renderable_type)\n\n    return cast(RenderableType, renderable)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\region.py": {
      "sha": "f38fc0db54d1",
      "lines": 10,
      "head": "from typing import NamedTuple\n\n\nclass Region(NamedTuple):\n    \"\"\"Defines a rectangular region of the screen.\"\"\"\n\n    x: int\n    y: int\n    width: int\n    height: int\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\repr.py": {
      "sha": "bce66f8d6512",
      "lines": 149,
      "head": "import inspect\nfrom functools import partial\nfrom typing import (\n    Any,\n    Callable,\n    Iterable,\n    List,\n    Optional,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    overload,\n)\n\nT = TypeVar(\"T\")\n\n\nResult = Iterable[Union[Any, Tuple[Any], Tuple[str, Any], Tuple[str, Any, Any]]]\nRichReprResult = Result\n\n\nclass ReprError(Exception):\n    \"\"\"An error occurred when attempting to build a repr.\"\"\"\n\n\n@overload\ndef auto(cls: Optional[Type[T]]) -> Type[T]:\n    ...\n\n\n@overload\ndef auto(*, angular: bool = False) -> Callable[[Type[T]], Type[T]]:\n    ...\n\n\ndef auto(\n    cls: Optional[Type[T]] = None, *, angular: Optional[bool] = None\n) -> Union[Type[T], Callable[[Type[T]], Type[T]]]:\n    \"\"\"Class decorator to create __repr__ from __rich_repr__\"\"\"\n\n    def do_replace(cls: Type[T], angular: Optional[bool] = None) -> Type[T]:\n        def auto_repr(self: T) -> str:\n            \"\"\"Create repr string from __rich_repr__\"\"\"\n            repr_str: List[str] = []\n            append = repr_str.append\n\n            angular: bool = getattr(self.__rich_repr__, \"angular\", False)  # type: ignore[attr-defined]\n            for arg in self.__rich_repr__():  # type: ignore[attr-defined]\n                if isinstance(arg, tuple):\n                    if len(arg) == 1:\n                        append(repr(arg[0]))\n                    else:\n                        key, value, *default = arg\n                        if key is None:\n                            append(repr(value))\n                        else:\n                            if default and default[0] == value:\n                                continue\n                            append(f\"{key}={value!r}\")\n                else:\n                    append(repr(arg))\n            if angular:\n                return f\"<{self.__class__.__name__} {' '.join(repr_str)}>\"\n            else:\n                return f\"{self.__class__.__name__}({', '.join(repr_str)})\"\n\n        def auto_rich_repr(self: Type[T]) -> Result:\n            \"\"\"Auto generate __rich_rep__ from signature of __init__\"\"\"\n            try:\n                signature = inspect.signature(self.__init__)\n                for name, param in signature.parameters.items():\n                    if param.kind == param.POSITIONAL_ONLY:\n                        yield getattr(self, name)\n                    elif param.kind in (\n                        param.POSITIONAL_OR_KEYWORD,\n                        param.KEYWORD_ONLY,\n                    ):\n                        if param.default is param.empty:\n                            yield getattr(self, param.name)\n                        else:\n                            yield param.name, getattr(self, param.name), param.default\n            except Exception as error:\n                raise ReprError(\n                    f\"Failed to auto generate __rich_repr__; {error}\"\n                ) from None\n\n        if not hasattr(cls, \"__rich_repr__\"):\n            auto_rich_repr.__doc__ = \"Build a rich repr\"\n            cls.__rich_repr__ = auto_rich_repr  # type: ignore[attr-defined]\n\n        auto_repr.__doc__ = \"Return repr(self)\"\n        cls.__repr__ = auto_repr  # type: ignore[assignment]\n        if angular is not None:\n            cls.__rich_repr__.angular = angular  # type: ignore[attr-defined]\n        return cls\n\n    if cls is None:\n        return partial(do_replace, angular=angular)\n    else:\n        return do_replace(cls, angular=angular)\n\n\n@overload\ndef rich_repr(cls: Optional[Type[T]]) -> Type[T]:\n    ...\n\n\n@overload\ndef rich_repr(*, angular: bool = False) -> Callable[[Type[T]], Type[T]]:\n    ...\n\n\ndef rich_repr(\n    cls: Optional[Type[T]] = None, *, angular: bool = False\n) -> Union[Type[T], Callable[[Type[T]], Type[T]]]:\n    if cls is None:\n        return auto(angular=angular)\n    else:\n        return auto(cls)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\rule.py": {
      "sha": "7749aef099cb",
      "lines": 130,
      "head": "from typing import Union\n\nfrom .align import AlignMethod\nfrom .cells import cell_len, set_cell_size\nfrom .console import Console, ConsoleOptions, RenderResult\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .style import Style\nfrom .text import Text\n\n\nclass Rule(JupyterMixin):\n    \"\"\"A console renderable to draw a horizontal rule (line).\n\n    Args:\n        title (Union[str, Text], optional): Text to render in the rule. Defaults to \"\".\n        characters (str, optional): Character(s) used to draw the line. Defaults to \"\u2500\".\n        style (StyleType, optional): Style of Rule. Defaults to \"rule.line\".\n        end (str, optional): Character at end of Rule. defaults to \"\\\\\\\\n\"\n        align (str, optional): How to align the title, one of \"left\", \"center\", or \"right\". Defaults to \"center\".\n    \"\"\"\n\n    def __init__(\n        self,\n        title: Union[str, Text] = \"\",\n        *,\n        characters: str = \"\u2500\",\n        style: Union[str, Style] = \"rule.line\",\n        end: str = \"\\n\",\n        align: AlignMethod = \"center\",\n    ) -> None:\n        if cell_len(characters) < 1:\n            raise ValueError(\n                \"'characters' argument must have a cell width of at least 1\"\n            )\n        if align not in (\"left\", \"center\", \"right\"):\n            raise ValueError(\n                f'invalid value for align, expected \"left\", \"center\", \"right\" (not {align!r})'\n            )\n        self.title = title\n        self.characters = characters\n        self.style = style\n        self.end = end\n        self.align = align\n\n    def __repr__(self) -> str:\n        return f\"Rule({self.title!r}, {self.characters!r})\"\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        width = options.max_width\n\n        characters = (\n            \"-\"\n            if (options.ascii_only and not self.characters.isascii())\n            else self.characters\n        )\n\n        chars_len = cell_len(characters)\n        if not self.title:\n            yield self._rule_line(chars_len, width)\n            return\n\n        if isinstance(self.title, Text):\n            title_text = self.title\n        else:\n            title_text = console.render_str(self.title, style=\"rule.text\")\n\n        title_text.plain = title_text.plain.replace(\"\\n\", \" \")\n        title_text.expand_tabs()\n\n        required_space = 4 if self.align == \"center\" else 2\n        truncate_width = max(0, width - required_space)\n        if not truncate_width:\n            yield self._rule_line(chars_len, width)\n            return\n\n        rule_text = Text(end=self.end)\n        if self.align == \"center\":\n            title_text.truncate(truncate_width, overflow=\"ellipsis\")\n            side_width = (width - cell_len(title_text.plain)) // 2\n            left = Text(characters * (side_width // chars_len + 1))\n            left.truncate(side_width - 1)\n            right_length = width - cell_len(left.plain) - cell_len(title_text.plain)\n            right = Text(characters * (side_width // chars_len + 1))\n            right.truncate(right_length)\n            rule_text.append(left.plain + \" \", self.style)\n            rule_text.append(title_text)\n            rule_text.append(\" \" + right.plain, self.style)\n        elif self.align == \"left\":\n            title_text.truncate(truncate_width, overflow=\"ellipsis\")\n            rule_text.append(title_text)\n            rule_text.append(\" \")\n            rule_text.append(characters * (width - rule_text.cell_len), self.style)\n        elif self.align == \"right\":\n            title_text.truncate(truncate_width, overflow=\"ellipsis\")\n            rule_text.append(characters * (width - title_text.cell_len - 1), self.style)\n            rule_text.append(\" \")\n            rule_text.append(title_text)\n\n        rule_text.plain = set_cell_size(rule_text.plain, width)\n        yield rule_text\n\n    def _rule_line(self, chars_len: int, width: int) -> Text:\n        rule_text = Text(self.characters * ((width // chars_len) + 1), self.style)\n        rule_text.truncate(width)\n        rule_text.plain = set_cell_size(rule_text.plain, width)\n        return rule_text\n\n    def __rich_measure__(\n        self, console: Console, options: ConsoleOptions\n    ) -> Measurement:\n        return Measurement(1, 1)\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import sys\n\n    from pip._vendor.rich.console import Console\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\scope.py": {
      "sha": "5aec0581ed1c",
      "lines": 86,
      "head": "from collections.abc import Mapping\nfrom typing import TYPE_CHECKING, Any, Optional, Tuple\n\nfrom .highlighter import ReprHighlighter\nfrom .panel import Panel\nfrom .pretty import Pretty\nfrom .table import Table\nfrom .text import Text, TextType\n\nif TYPE_CHECKING:\n    from .console import ConsoleRenderable\n\n\ndef render_scope(\n    scope: \"Mapping[str, Any]\",\n    *,\n    title: Optional[TextType] = None,\n    sort_keys: bool = True,\n    indent_guides: bool = False,\n    max_length: Optional[int] = None,\n    max_string: Optional[int] = None,\n) -> \"ConsoleRenderable\":\n    \"\"\"Render python variables in a given scope.\n\n    Args:\n        scope (Mapping): A mapping containing variable names and values.\n        title (str, optional): Optional title. Defaults to None.\n        sort_keys (bool, optional): Enable sorting of items. Defaults to True.\n        indent_guides (bool, optional): Enable indentation guides. Defaults to False.\n        max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to None.\n        max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.\n\n    Returns:\n        ConsoleRenderable: A renderable object.\n    \"\"\"\n    highlighter = ReprHighlighter()\n    items_table = Table.grid(padding=(0, 1), expand=False)\n    items_table.add_column(justify=\"right\")\n\n    def sort_items(item: Tuple[str, Any]) -> Tuple[bool, str]:\n        \"\"\"Sort special variables first, then alphabetically.\"\"\"\n        key, _ = item\n        return (not key.startswith(\"__\"), key.lower())\n\n    items = sorted(scope.items(), key=sort_items) if sort_keys else scope.items()\n    for key, value in items:\n        key_text = Text.assemble(\n            (key, \"scope.key.special\" if key.startswith(\"__\") else \"scope.key\"),\n            (\" =\", \"scope.equals\"),\n        )\n        items_table.add_row(\n            key_text,\n            Pretty(\n                value,\n                highlighter=highlighter,\n                indent_guides=indent_guides,\n                max_length=max_length,\n                max_string=max_string,\n            ),\n        )\n    return Panel.fit(\n        items_table,\n        title=title,\n        border_style=\"scope.border\",\n        padding=(0, 1),\n    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from pip._vendor.rich import print\n\n    print()\n\n    def test(foo: float, bar: float) -> None:\n        list_of_things = [1, 2, 3, None, 4, True, False, \"Hello World\"]\n        dict_of_things = {\n            \"version\": \"1.1\",\n            \"method\": \"confirmFruitPurchase\",\n            \"params\": [[\"apple\", \"orange\", \"mangoes\", \"pomelo\"], 1.123],\n            \"id\": \"194521489\",\n        }\n        print(render_scope(locals(), title=\"[i]locals\", sort_keys=False))\n\n    test(20.3423, 3.1427)\n    print()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\screen.py": {
      "sha": "4f0802d8391d",
      "lines": 54,
      "head": "from typing import Optional, TYPE_CHECKING\n\nfrom .segment import Segment\nfrom .style import StyleType\nfrom ._loop import loop_last\n\n\nif TYPE_CHECKING:\n    from .console import (\n        Console,\n        ConsoleOptions,\n        RenderResult,\n        RenderableType,\n        Group,\n    )\n\n\nclass Screen:\n    \"\"\"A renderable that fills the terminal screen and crops excess.\n\n    Args:\n        renderable (RenderableType): Child renderable.\n        style (StyleType, optional): Optional background style. Defaults to None.\n    \"\"\"\n\n    renderable: \"RenderableType\"\n\n    def __init__(\n        self,\n        *renderables: \"RenderableType\",\n        style: Optional[StyleType] = None,\n        application_mode: bool = False,\n    ) -> None:\n        from pip._vendor.rich.console import Group\n\n        self.renderable = Group(*renderables)\n        self.style = style\n        self.application_mode = application_mode\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        width, height = options.size\n        style = console.get_style(self.style) if self.style else None\n        render_options = options.update(width=width, height=height)\n        lines = console.render_lines(\n            self.renderable or \"\", render_options, style=style, pad=True\n        )\n        lines = Segment.set_shape(lines, width, height, style=style)\n        new_line = Segment(\"\\n\\r\") if self.application_mode else Segment.line()\n        for last, line in loop_last(lines):\n            yield from line\n            if not last:\n                yield new_line\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\segment.py": {
      "sha": "e138b6fd2ee0",
      "lines": 752,
      "head": "from enum import IntEnum\nfrom functools import lru_cache\nfrom itertools import filterfalse\nfrom logging import getLogger\nfrom operator import attrgetter\nfrom typing import (\n    TYPE_CHECKING,\n    Dict,\n    Iterable,\n    List,\n    NamedTuple,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom .cells import (\n    _is_single_cell_widths,\n    cached_cell_len,\n    cell_len,\n    get_character_cell_size,\n    set_cell_size,\n)\nfrom .repr import Result, rich_repr\nfrom .style import Style\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderResult\n\nlog = getLogger(\"rich\")\n\n\nclass ControlType(IntEnum):\n    \"\"\"Non-printable control codes which typically translate to ANSI codes.\"\"\"\n\n    BELL = 1\n    CARRIAGE_RETURN = 2\n    HOME = 3\n    CLEAR = 4\n    SHOW_CURSOR = 5\n    HIDE_CURSOR = 6\n    ENABLE_ALT_SCREEN = 7\n    DISABLE_ALT_SCREEN = 8\n    CURSOR_UP = 9\n    CURSOR_DOWN = 10\n    CURSOR_FORWARD = 11\n    CURSOR_BACKWARD = 12\n    CURSOR_MOVE_TO_COLUMN = 13\n    CURSOR_MOVE_TO = 14\n    ERASE_IN_LINE = 15\n    SET_WINDOW_TITLE = 16\n\n\nControlCode = Union[\n    Tuple[ControlType],\n    Tuple[ControlType, Union[int, str]],\n    Tuple[ControlType, int, int],\n]\n\n\n@rich_repr()\nclass Segment(NamedTuple):\n    \"\"\"A piece of text with associated style. Segments are produced by the Console render process and\n    are ultimately converted in to strings to be written to the terminal.\n\n    Args:\n        text (str): A piece of text.\n        style (:class:`~rich.style.Style`, optional): An optional style to apply to the text.\n        control (Tuple[ControlCode], optional): Optional sequence of control codes.\n\n    Attributes:\n        cell_length (int): The cell length of this Segment.\n    \"\"\"\n\n    text: str\n    style: Optional[Style] = None\n    control: Optional[Sequence[ControlCode]] = None\n\n    @property\n    def cell_length(self) -> int:\n        \"\"\"The number of terminal cells required to display self.text.\n\n        Returns:\n            int: A number of cells.\n        \"\"\"\n        text, _style, control = self\n        return 0 if control else cell_len(text)\n\n    def __rich_repr__(self) -> Result:\n        yield self.text\n        if self.control is None:\n            if self.style is not None:\n                yield self.style\n        else:\n            yield self.style\n            yield self.control\n\n    def __bool__(self) -> bool:\n        \"\"\"Check if the segment contains text.\"\"\"\n        return bool(self.text)\n\n    @property\n    def is_control(self) -> bool:\n        \"\"\"Check if the segment contains control codes.\"\"\"\n        return self.control is not None\n\n    @classmethod\n    @lru_cache(1024 * 16)\n    def _split_cells(cls, segment: \"Segment\", cut: int) -> Tuple[\"Segment\", \"Segment\"]:\n        \"\"\"Split a segment in to two at a given cell position.\n\n        Note that splitting a double-width character, may result in that character turning\n        into two spaces.\n\n        Args:\n            segment (Segment): A segment to split.\n            cut (int): A cell position to cut on.\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\spinner.py": {
      "sha": "3969fca0a134",
      "lines": 138,
      "head": "from typing import cast, List, Optional, TYPE_CHECKING, Union\n\nfrom ._spinners import SPINNERS\nfrom .measure import Measurement\nfrom .table import Table\nfrom .text import Text\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderResult, RenderableType\n    from .style import StyleType\n\n\nclass Spinner:\n    \"\"\"A spinner animation.\n\n    Args:\n        name (str): Name of spinner (run python -m rich.spinner).\n        text (RenderableType, optional): A renderable to display at the right of the spinner (str or Text typically). Defaults to \"\".\n        style (StyleType, optional): Style for spinner animation. Defaults to None.\n        speed (float, optional): Speed factor for animation. Defaults to 1.0.\n\n    Raises:\n        KeyError: If name isn't one of the supported spinner animations.\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        text: \"RenderableType\" = \"\",\n        *,\n        style: Optional[\"StyleType\"] = None,\n        speed: float = 1.0,\n    ) -> None:\n        try:\n            spinner = SPINNERS[name]\n        except KeyError:\n            raise KeyError(f\"no spinner called {name!r}\")\n        self.text: \"Union[RenderableType, Text]\" = (\n            Text.from_markup(text) if isinstance(text, str) else text\n        )\n        self.name = name\n        self.frames = cast(List[str], spinner[\"frames\"])[:]\n        self.interval = cast(float, spinner[\"interval\"])\n        self.start_time: Optional[float] = None\n        self.style = style\n        self.speed = speed\n        self.frame_no_offset: float = 0.0\n        self._update_speed = 0.0\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        yield self.render(console.get_time())\n\n    def __rich_measure__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> Measurement:\n        text = self.render(0)\n        return Measurement.get(console, options, text)\n\n    def render(self, time: float) -> \"RenderableType\":\n        \"\"\"Render the spinner for a given time.\n\n        Args:\n            time (float): Time in seconds.\n\n        Returns:\n            RenderableType: A renderable containing animation frame.\n        \"\"\"\n        if self.start_time is None:\n            self.start_time = time\n\n        frame_no = ((time - self.start_time) * self.speed) / (\n            self.interval / 1000.0\n        ) + self.frame_no_offset\n        frame = Text(\n            self.frames[int(frame_no) % len(self.frames)], style=self.style or \"\"\n        )\n\n        if self._update_speed:\n            self.frame_no_offset = frame_no\n            self.start_time = time\n            self.speed = self._update_speed\n            self._update_speed = 0.0\n\n        if not self.text:\n            return frame\n        elif isinstance(self.text, (str, Text)):\n            return Text.assemble(frame, \" \", self.text)\n        else:\n            table = Table.grid(padding=1)\n            table.add_row(frame, self.text)\n            return table\n\n    def update(\n        self,\n        *,\n        text: \"RenderableType\" = \"\",\n        style: Optional[\"StyleType\"] = None,\n        speed: Optional[float] = None,\n    ) -> None:\n        \"\"\"Updates attributes of a spinner after it has been started.\n\n        Args:\n            text (RenderableType, optional): A renderable to display at the right of the spinner (str or Text typically). Defaults to \"\".\n            style (StyleType, optional): Style for spinner animation. Defaults to None.\n            speed (float, optional): Speed factor for animation. Defaults to None.\n        \"\"\"\n        if text:\n            self.text = Text.from_markup(text) if isinstance(text, str) else text\n        if style:\n            self.style = style\n        if speed:\n            self._update_speed = speed\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from time import sleep\n\n    from .columns import Columns\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\status.py": {
      "sha": "50b0610610fe",
      "lines": 131,
      "head": "from types import TracebackType\nfrom typing import Optional, Type\n\nfrom .console import Console, RenderableType\nfrom .jupyter import JupyterMixin\nfrom .live import Live\nfrom .spinner import Spinner\nfrom .style import StyleType\n\n\nclass Status(JupyterMixin):\n    \"\"\"Displays a status indicator with a 'spinner' animation.\n\n    Args:\n        status (RenderableType): A status renderable (str or Text typically).\n        console (Console, optional): Console instance to use, or None for global console. Defaults to None.\n        spinner (str, optional): Name of spinner animation (see python -m rich.spinner). Defaults to \"dots\".\n        spinner_style (StyleType, optional): Style of spinner. Defaults to \"status.spinner\".\n        speed (float, optional): Speed factor for spinner animation. Defaults to 1.0.\n        refresh_per_second (float, optional): Number of refreshes per second. Defaults to 12.5.\n    \"\"\"\n\n    def __init__(\n        self,\n        status: RenderableType,\n        *,\n        console: Optional[Console] = None,\n        spinner: str = \"dots\",\n        spinner_style: StyleType = \"status.spinner\",\n        speed: float = 1.0,\n        refresh_per_second: float = 12.5,\n    ):\n        self.status = status\n        self.spinner_style = spinner_style\n        self.speed = speed\n        self._spinner = Spinner(spinner, text=status, style=spinner_style, speed=speed)\n        self._live = Live(\n            self.renderable,\n            console=console,\n            refresh_per_second=refresh_per_second,\n            transient=True,\n        )\n\n    @property\n    def renderable(self) -> Spinner:\n        return self._spinner\n\n    @property\n    def console(self) -> \"Console\":\n        \"\"\"Get the Console used by the Status objects.\"\"\"\n        return self._live.console\n\n    def update(\n        self,\n        status: Optional[RenderableType] = None,\n        *,\n        spinner: Optional[str] = None,\n        spinner_style: Optional[StyleType] = None,\n        speed: Optional[float] = None,\n    ) -> None:\n        \"\"\"Update status.\n\n        Args:\n            status (Optional[RenderableType], optional): New status renderable or None for no change. Defaults to None.\n            spinner (Optional[str], optional): New spinner or None for no change. Defaults to None.\n            spinner_style (Optional[StyleType], optional): New spinner style or None for no change. Defaults to None.\n            speed (Optional[float], optional): Speed factor for spinner animation or None for no change. Defaults to None.\n        \"\"\"\n        if status is not None:\n            self.status = status\n        if spinner_style is not None:\n            self.spinner_style = spinner_style\n        if speed is not None:\n            self.speed = speed\n        if spinner is not None:\n            self._spinner = Spinner(\n                spinner, text=self.status, style=self.spinner_style, speed=self.speed\n            )\n            self._live.update(self.renderable, refresh=True)\n        else:\n            self._spinner.update(\n                text=self.status, style=self.spinner_style, speed=self.speed\n            )\n\n    def start(self) -> None:\n        \"\"\"Start the status animation.\"\"\"\n        self._live.start()\n\n    def stop(self) -> None:\n        \"\"\"Stop the spinner animation.\"\"\"\n        self._live.stop()\n\n    def __rich__(self) -> RenderableType:\n        return self.renderable\n\n    def __enter__(self) -> \"Status\":\n        self.start()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        self.stop()\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from time import sleep\n\n    from .console import Console\n\n    console = Console()\n    with console.status(\"[magenta]Covid detector booting up\") as status:\n        sleep(3)\n        console.log(\"Importing advanced AI\")\n        sleep(3)\n        console.log(\"Advanced Covid AI Ready\")\n        sleep(3)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\style.py": {
      "sha": "eff5f4616ebb",
      "lines": 796,
      "head": "import sys\nfrom functools import lru_cache\nfrom marshal import dumps, loads\nfrom random import randint\nfrom typing import Any, Dict, Iterable, List, Optional, Type, Union, cast\n\nfrom . import errors\nfrom .color import Color, ColorParseError, ColorSystem, blend_rgb\nfrom .repr import Result, rich_repr\nfrom .terminal_theme import DEFAULT_TERMINAL_THEME, TerminalTheme\n\n# Style instances and style definitions are often interchangeable\nStyleType = Union[str, \"Style\"]\n\n\nclass _Bit:\n    \"\"\"A descriptor to get/set a style attribute bit.\"\"\"\n\n    __slots__ = [\"bit\"]\n\n    def __init__(self, bit_no: int) -> None:\n        self.bit = 1 << bit_no\n\n    def __get__(self, obj: \"Style\", objtype: Type[\"Style\"]) -> Optional[bool]:\n        if obj._set_attributes & self.bit:\n            return obj._attributes & self.bit != 0\n        return None\n\n\n@rich_repr\nclass Style:\n    \"\"\"A terminal style.\n\n    A terminal style consists of a color (`color`), a background color (`bgcolor`), and a number of attributes, such\n    as bold, italic etc. The attributes have 3 states: they can either be on\n    (``True``), off (``False``), or not set (``None``).\n\n    Args:\n        color (Union[Color, str], optional): Color of terminal text. Defaults to None.\n        bgcolor (Union[Color, str], optional): Color of terminal background. Defaults to None.\n        bold (bool, optional): Enable bold text. Defaults to None.\n        dim (bool, optional): Enable dim text. Defaults to None.\n        italic (bool, optional): Enable italic text. Defaults to None.\n        underline (bool, optional): Enable underlined text. Defaults to None.\n        blink (bool, optional): Enabled blinking text. Defaults to None.\n        blink2 (bool, optional): Enable fast blinking text. Defaults to None.\n        reverse (bool, optional): Enabled reverse text. Defaults to None.\n        conceal (bool, optional): Enable concealed text. Defaults to None.\n        strike (bool, optional): Enable strikethrough text. Defaults to None.\n        underline2 (bool, optional): Enable doubly underlined text. Defaults to None.\n        frame (bool, optional): Enable framed text. Defaults to None.\n        encircle (bool, optional): Enable encircled text. Defaults to None.\n        overline (bool, optional): Enable overlined text. Defaults to None.\n        link (str, link): Link URL. Defaults to None.\n\n    \"\"\"\n\n    _color: Optional[Color]\n    _bgcolor: Optional[Color]\n    _attributes: int\n    _set_attributes: int\n    _hash: Optional[int]\n    _null: bool\n    _meta: Optional[bytes]\n\n    __slots__ = [\n        \"_color\",\n        \"_bgcolor\",\n        \"_attributes\",\n        \"_set_attributes\",\n        \"_link\",\n        \"_link_id\",\n        \"_ansi\",\n        \"_style_definition\",\n        \"_hash\",\n        \"_null\",\n        \"_meta\",\n    ]\n\n    # maps bits on to SGR parameter\n    _style_map = {\n        0: \"1\",\n        1: \"2\",\n        2: \"3\",\n        3: \"4\",\n        4: \"5\",\n        5: \"6\",\n        6: \"7\",\n        7: \"8\",\n        8: \"9\",\n        9: \"21\",\n        10: \"51\",\n        11: \"52\",\n        12: \"53\",\n    }\n\n    STYLE_ATTRIBUTES = {\n        \"dim\": \"dim\",\n        \"d\": \"dim\",\n        \"bold\": \"bold\",\n        \"b\": \"bold\",\n        \"italic\": \"italic\",\n        \"i\": \"italic\",\n        \"underline\": \"underline\",\n        \"u\": \"underline\",\n        \"blink\": \"blink\",\n        \"blink2\": \"blink2\",\n        \"reverse\": \"reverse\",\n        \"r\": \"reverse\",\n        \"conceal\": \"conceal\",\n        \"c\": \"conceal\",\n        \"strike\": \"strike\",\n        \"s\": \"strike\",\n        \"underline2\": \"underline2\",\n        \"uu\": \"underline2\",\n        \"frame\": \"frame\",\n        \"encircle\": \"encircle\",\n        \"overline\": \"overline\",\n        \"o\": \"overline\",\n    }\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\styled.py": {
      "sha": "6fd170ba37f8",
      "lines": 42,
      "head": "from typing import TYPE_CHECKING\n\nfrom .measure import Measurement\nfrom .segment import Segment\nfrom .style import StyleType\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderResult, RenderableType\n\n\nclass Styled:\n    \"\"\"Apply a style to a renderable.\n\n    Args:\n        renderable (RenderableType): Any renderable.\n        style (StyleType): A style to apply across the entire renderable.\n    \"\"\"\n\n    def __init__(self, renderable: \"RenderableType\", style: \"StyleType\") -> None:\n        self.renderable = renderable\n        self.style = style\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        style = console.get_style(self.style)\n        rendered_segments = console.render(self.renderable, options)\n        segments = Segment.apply_style(rendered_segments, style)\n        return segments\n\n    def __rich_measure__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> Measurement:\n        return Measurement.get(console, options, self.renderable)\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from pip._vendor.rich import print\n    from pip._vendor.rich.panel import Panel\n\n    panel = Styled(Panel(\"hello\"), \"on blue\")\n    print(panel)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\syntax.py": {
      "sha": "570693d1b647",
      "lines": 966,
      "head": "import os.path\nimport re\nimport sys\nimport textwrap\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Dict,\n    Iterable,\n    List,\n    NamedTuple,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pip._vendor.pygments.lexer import Lexer\nfrom pip._vendor.pygments.lexers import get_lexer_by_name, guess_lexer_for_filename\nfrom pip._vendor.pygments.style import Style as PygmentsStyle\nfrom pip._vendor.pygments.styles import get_style_by_name\nfrom pip._vendor.pygments.token import (\n    Comment,\n    Error,\n    Generic,\n    Keyword,\n    Name,\n    Number,\n    Operator,\n    String,\n    Token,\n    Whitespace,\n)\nfrom pip._vendor.pygments.util import ClassNotFound\n\nfrom pip._vendor.rich.containers import Lines\nfrom pip._vendor.rich.padding import Padding, PaddingDimensions\n\nfrom ._loop import loop_first\nfrom .cells import cell_len\nfrom .color import Color, blend_rgb\nfrom .console import Console, ConsoleOptions, JustifyMethod, RenderResult\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .segment import Segment, Segments\nfrom .style import Style, StyleType\nfrom .text import Text\n\nTokenType = Tuple[str, ...]\n\nWINDOWS = sys.platform == \"win32\"\nDEFAULT_THEME = \"monokai\"\n\n# The following styles are based on https://github.com/pygments/pygments/blob/master/pygments/formatters/terminal.py\n# A few modifications were made\n\nANSI_LIGHT: Dict[TokenType, Style] = {\n    Token: Style(),\n    Whitespace: Style(color=\"white\"),\n    Comment: Style(dim=True),\n    Comment.Preproc: Style(color=\"cyan\"),\n    Keyword: Style(color=\"blue\"),\n    Keyword.Type: Style(color=\"cyan\"),\n    Operator.Word: Style(color=\"magenta\"),\n    Name.Builtin: Style(color=\"cyan\"),\n    Name.Function: Style(color=\"green\"),\n    Name.Namespace: Style(color=\"cyan\", underline=True),\n    Name.Class: Style(color=\"green\", underline=True),\n    Name.Exception: Style(color=\"cyan\"),\n    Name.Decorator: Style(color=\"magenta\", bold=True),\n    Name.Variable: Style(color=\"red\"),\n    Name.Constant: Style(color=\"red\"),\n    Name.Attribute: Style(color=\"cyan\"),\n    Name.Tag: Style(color=\"bright_blue\"),\n    String: Style(color=\"yellow\"),\n    Number: Style(color=\"blue\"),\n    Generic.Deleted: Style(color=\"bright_red\"),\n    Generic.Inserted: Style(color=\"green\"),\n    Generic.Heading: Style(bold=True),\n    Generic.Subheading: Style(color=\"magenta\", bold=True),\n    Generic.Prompt: Style(bold=True),\n    Generic.Error: Style(color=\"bright_red\"),\n    Error: Style(color=\"red\", underline=True),\n}\n\nANSI_DARK: Dict[TokenType, Style] = {\n    Token: Style(),\n    Whitespace: Style(color=\"bright_black\"),\n    Comment: Style(dim=True),\n    Comment.Preproc: Style(color=\"bright_cyan\"),\n    Keyword: Style(color=\"bright_blue\"),\n    Keyword.Type: Style(color=\"bright_cyan\"),\n    Operator.Word: Style(color=\"bright_magenta\"),\n    Name.Builtin: Style(color=\"bright_cyan\"),\n    Name.Function: Style(color=\"bright_green\"),\n    Name.Namespace: Style(color=\"bright_cyan\", underline=True),\n    Name.Class: Style(color=\"bright_green\", underline=True),\n    Name.Exception: Style(color=\"bright_cyan\"),\n    Name.Decorator: Style(color=\"bright_magenta\", bold=True),\n    Name.Variable: Style(color=\"bright_red\"),\n    Name.Constant: Style(color=\"bright_red\"),\n    Name.Attribute: Style(color=\"bright_cyan\"),\n    Name.Tag: Style(color=\"bright_blue\"),\n    String: Style(color=\"yellow\"),\n    Number: Style(color=\"bright_blue\"),\n    Generic.Deleted: Style(color=\"bright_red\"),\n    Generic.Inserted: Style(color=\"bright_green\"),\n    Generic.Heading: Style(bold=True),\n    Generic.Subheading: Style(color=\"bright_magenta\", bold=True),\n    Generic.Prompt: Style(bold=True),\n    Generic.Error: Style(color=\"bright_red\"),\n    Error: Style(color=\"red\", underline=True),\n}\n\nRICH_SYNTAX_THEMES = {\"ansi_light\": ANSI_LIGHT, \"ansi_dark\": ANSI_DARK}\nNUMBERS_COLUMN_DEFAULT_PADDING = 2\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\table.py": {
      "sha": "a562f8fbaf0f",
      "lines": 1006,
      "head": "from dataclasses import dataclass, field, replace\nfrom typing import (\n    TYPE_CHECKING,\n    Dict,\n    Iterable,\n    List,\n    NamedTuple,\n    Optional,\n    Sequence,\n    Tuple,\n    Union,\n)\n\nfrom . import box, errors\nfrom ._loop import loop_first_last, loop_last\nfrom ._pick import pick_bool\nfrom ._ratio import ratio_distribute, ratio_reduce\nfrom .align import VerticalAlignMethod\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .padding import Padding, PaddingDimensions\nfrom .protocol import is_renderable\nfrom .segment import Segment\nfrom .style import Style, StyleType\nfrom .text import Text, TextType\n\nif TYPE_CHECKING:\n    from .console import (\n        Console,\n        ConsoleOptions,\n        JustifyMethod,\n        OverflowMethod,\n        RenderableType,\n        RenderResult,\n    )\n\n\n@dataclass\nclass Column:\n    \"\"\"Defines a column within a ~Table.\n\n    Args:\n        title (Union[str, Text], optional): The title of the table rendered at the top. Defaults to None.\n        caption (Union[str, Text], optional): The table caption rendered below. Defaults to None.\n        width (int, optional): The width in characters of the table, or ``None`` to automatically fit. Defaults to None.\n        min_width (Optional[int], optional): The minimum width of the table, or ``None`` for no minimum. Defaults to None.\n        box (box.Box, optional): One of the constants in box.py used to draw the edges (see :ref:`appendix_box`), or ``None`` for no box lines. Defaults to box.HEAVY_HEAD.\n        safe_box (Optional[bool], optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.\n        padding (PaddingDimensions, optional): Padding for cells (top, right, bottom, left). Defaults to (0, 1).\n        collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to False.\n        pad_edge (bool, optional): Enable padding of edge cells. Defaults to True.\n        expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.\n        show_header (bool, optional): Show a header row. Defaults to True.\n        show_footer (bool, optional): Show a footer row. Defaults to False.\n        show_edge (bool, optional): Draw a box around the outside of the table. Defaults to True.\n        show_lines (bool, optional): Draw lines between every row. Defaults to False.\n        leading (int, optional): Number of blank lines between rows (precludes ``show_lines``). Defaults to 0.\n        style (Union[str, Style], optional): Default style for the table. Defaults to \"none\".\n        row_styles (List[Union, str], optional): Optional list of row styles, if more than one style is given then the styles will alternate. Defaults to None.\n        header_style (Union[str, Style], optional): Style of the header. Defaults to \"table.header\".\n        footer_style (Union[str, Style], optional): Style of the footer. Defaults to \"table.footer\".\n        border_style (Union[str, Style], optional): Style of the border. Defaults to None.\n        title_style (Union[str, Style], optional): Style of the title. Defaults to None.\n        caption_style (Union[str, Style], optional): Style of the caption. Defaults to None.\n        title_justify (str, optional): Justify method for title. Defaults to \"center\".\n        caption_justify (str, optional): Justify method for caption. Defaults to \"center\".\n        highlight (bool, optional): Highlight cell contents (if str). Defaults to False.\n    \"\"\"\n\n    header: \"RenderableType\" = \"\"\n    \"\"\"RenderableType: Renderable for the header (typically a string)\"\"\"\n\n    footer: \"RenderableType\" = \"\"\n    \"\"\"RenderableType: Renderable for the footer (typically a string)\"\"\"\n\n    header_style: StyleType = \"\"\n    \"\"\"StyleType: The style of the header.\"\"\"\n\n    footer_style: StyleType = \"\"\n    \"\"\"StyleType: The style of the footer.\"\"\"\n\n    style: StyleType = \"\"\n    \"\"\"StyleType: The style of the column.\"\"\"\n\n    justify: \"JustifyMethod\" = \"left\"\n    \"\"\"str: How to justify text within the column (\"left\", \"center\", \"right\", or \"full\")\"\"\"\n\n    vertical: \"VerticalAlignMethod\" = \"top\"\n    \"\"\"str: How to vertically align content (\"top\", \"middle\", or \"bottom\")\"\"\"\n\n    overflow: \"OverflowMethod\" = \"ellipsis\"\n    \"\"\"str: Overflow method.\"\"\"\n\n    width: Optional[int] = None\n    \"\"\"Optional[int]: Width of the column, or ``None`` (default) to auto calculate width.\"\"\"\n\n    min_width: Optional[int] = None\n    \"\"\"Optional[int]: Minimum width of column, or ``None`` for no minimum. Defaults to None.\"\"\"\n\n    max_width: Optional[int] = None\n    \"\"\"Optional[int]: Maximum width of column, or ``None`` for no maximum. Defaults to None.\"\"\"\n\n    ratio: Optional[int] = None\n    \"\"\"Optional[int]: Ratio to use when calculating column width, or ``None`` (default) to adapt to column contents.\"\"\"\n\n    no_wrap: bool = False\n    \"\"\"bool: Prevent wrapping of text within the column. Defaults to ``False``.\"\"\"\n\n    highlight: bool = False\n    \"\"\"bool: Apply highlighter to column. Defaults to ``False``.\"\"\"\n\n    _index: int = 0\n    \"\"\"Index of column.\"\"\"\n\n    _cells: List[\"RenderableType\"] = field(default_factory=list)\n\n    def copy(self) -> \"Column\":\n        \"\"\"Return a copy of this Column.\"\"\"\n        return replace(self, _cells=[])\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\terminal_theme.py": {
      "sha": "006b559781a4",
      "lines": 153,
      "head": "from typing import List, Optional, Tuple\n\nfrom .color_triplet import ColorTriplet\nfrom .palette import Palette\n\n_ColorTuple = Tuple[int, int, int]\n\n\nclass TerminalTheme:\n    \"\"\"A color theme used when exporting console content.\n\n    Args:\n        background (Tuple[int, int, int]): The background color.\n        foreground (Tuple[int, int, int]): The foreground (text) color.\n        normal (List[Tuple[int, int, int]]): A list of 8 normal intensity colors.\n        bright (List[Tuple[int, int, int]], optional): A list of 8 bright colors, or None\n            to repeat normal intensity. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        background: _ColorTuple,\n        foreground: _ColorTuple,\n        normal: List[_ColorTuple],\n        bright: Optional[List[_ColorTuple]] = None,\n    ) -> None:\n        self.background_color = ColorTriplet(*background)\n        self.foreground_color = ColorTriplet(*foreground)\n        self.ansi_colors = Palette(normal + (bright or normal))\n\n\nDEFAULT_TERMINAL_THEME = TerminalTheme(\n    (255, 255, 255),\n    (0, 0, 0),\n    [\n        (0, 0, 0),\n        (128, 0, 0),\n        (0, 128, 0),\n        (128, 128, 0),\n        (0, 0, 128),\n        (128, 0, 128),\n        (0, 128, 128),\n        (192, 192, 192),\n    ],\n    [\n        (128, 128, 128),\n        (255, 0, 0),\n        (0, 255, 0),\n        (255, 255, 0),\n        (0, 0, 255),\n        (255, 0, 255),\n        (0, 255, 255),\n        (255, 255, 255),\n    ],\n)\n\nMONOKAI = TerminalTheme(\n    (12, 12, 12),\n    (217, 217, 217),\n    [\n        (26, 26, 26),\n        (244, 0, 95),\n        (152, 224, 36),\n        (253, 151, 31),\n        (157, 101, 255),\n        (244, 0, 95),\n        (88, 209, 235),\n        (196, 197, 181),\n        (98, 94, 76),\n    ],\n    [\n        (244, 0, 95),\n        (152, 224, 36),\n        (224, 213, 97),\n        (157, 101, 255),\n        (244, 0, 95),\n        (88, 209, 235),\n        (246, 246, 239),\n    ],\n)\nDIMMED_MONOKAI = TerminalTheme(\n    (25, 25, 25),\n    (185, 188, 186),\n    [\n        (58, 61, 67),\n        (190, 63, 72),\n        (135, 154, 59),\n        (197, 166, 53),\n        (79, 118, 161),\n        (133, 92, 141),\n        (87, 143, 164),\n        (185, 188, 186),\n        (136, 137, 135),\n    ],\n    [\n        (251, 0, 31),\n        (15, 114, 47),\n        (196, 112, 51),\n        (24, 109, 227),\n        (251, 0, 103),\n        (46, 112, 109),\n        (253, 255, 185),\n    ],\n)\nNIGHT_OWLISH = TerminalTheme(\n    (255, 255, 255),\n    (64, 63, 83),\n    [\n        (1, 22, 39),\n        (211, 66, 62),\n        (42, 162, 152),\n        (218, 170, 1),\n        (72, 118, 214),\n        (64, 63, 83),\n        (8, 145, 106),\n        (122, 129, 129),\n        (122, 129, 129),\n    ],\n    [\n        (247, 110, 110),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\text.py": {
      "sha": "c20db1a8a45f",
      "lines": 1361,
      "head": "import re\nfrom functools import partial, reduce\nfrom math import gcd\nfrom operator import itemgetter\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    NamedTuple,\n    Optional,\n    Pattern,\n    Tuple,\n    Union,\n)\n\nfrom ._loop import loop_last\nfrom ._pick import pick_bool\nfrom ._wrap import divide_line\nfrom .align import AlignMethod\nfrom .cells import cell_len, set_cell_size\nfrom .containers import Lines\nfrom .control import strip_control_codes\nfrom .emoji import EmojiVariant\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .segment import Segment\nfrom .style import Style, StyleType\n\nif TYPE_CHECKING:  # pragma: no cover\n    from .console import Console, ConsoleOptions, JustifyMethod, OverflowMethod\n\nDEFAULT_JUSTIFY: \"JustifyMethod\" = \"default\"\nDEFAULT_OVERFLOW: \"OverflowMethod\" = \"fold\"\n\n\n_re_whitespace = re.compile(r\"\\s+$\")\n\nTextType = Union[str, \"Text\"]\n\"\"\"A plain string or a :class:`Text` instance.\"\"\"\n\nGetStyleCallable = Callable[[str], Optional[StyleType]]\n\n\nclass Span(NamedTuple):\n    \"\"\"A marked up region in some text.\"\"\"\n\n    start: int\n    \"\"\"Span start index.\"\"\"\n    end: int\n    \"\"\"Span end index.\"\"\"\n    style: Union[str, Style]\n    \"\"\"Style associated with the span.\"\"\"\n\n    def __repr__(self) -> str:\n        return f\"Span({self.start}, {self.end}, {self.style!r})\"\n\n    def __bool__(self) -> bool:\n        return self.end > self.start\n\n    def split(self, offset: int) -> Tuple[\"Span\", Optional[\"Span\"]]:\n        \"\"\"Split a span in to 2 from a given offset.\"\"\"\n\n        if offset < self.start:\n            return self, None\n        if offset >= self.end:\n            return self, None\n\n        start, end, style = self\n        span1 = Span(start, min(end, offset), style)\n        span2 = Span(span1.end, end, style)\n        return span1, span2\n\n    def move(self, offset: int) -> \"Span\":\n        \"\"\"Move start and end by a given offset.\n\n        Args:\n            offset (int): Number of characters to add to start and end.\n\n        Returns:\n            TextSpan: A new TextSpan with adjusted position.\n        \"\"\"\n        start, end, style = self\n        return Span(start + offset, end + offset, style)\n\n    def right_crop(self, offset: int) -> \"Span\":\n        \"\"\"Crop the span at the given offset.\n\n        Args:\n            offset (int): A value between start and end.\n\n        Returns:\n            Span: A new (possibly smaller) span.\n        \"\"\"\n        start, end, style = self\n        if offset >= end:\n            return self\n        return Span(start, min(offset, end), style)\n\n    def extend(self, cells: int) -> \"Span\":\n        \"\"\"Extend the span by the given number of cells.\n\n        Args:\n            cells (int): Additional space to add to end of span.\n\n        Returns:\n            Span: A span.\n        \"\"\"\n        if cells:\n            start, end, style = self\n            return Span(start, end + cells, style)\n        else:\n            return self\n\n\nclass Text(JupyterMixin):\n    \"\"\"Text with color / style.\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\theme.py": {
      "sha": "7791b0b57ea4",
      "lines": 115,
      "head": "import configparser\nfrom typing import IO, Dict, List, Mapping, Optional\n\nfrom .default_styles import DEFAULT_STYLES\nfrom .style import Style, StyleType\n\n\nclass Theme:\n    \"\"\"A container for style information, used by :class:`~rich.console.Console`.\n\n    Args:\n        styles (Dict[str, Style], optional): A mapping of style names on to styles. Defaults to None for a theme with no styles.\n        inherit (bool, optional): Inherit default styles. Defaults to True.\n    \"\"\"\n\n    styles: Dict[str, Style]\n\n    def __init__(\n        self, styles: Optional[Mapping[str, StyleType]] = None, inherit: bool = True\n    ):\n        self.styles = DEFAULT_STYLES.copy() if inherit else {}\n        if styles is not None:\n            self.styles.update(\n                {\n                    name: style if isinstance(style, Style) else Style.parse(style)\n                    for name, style in styles.items()\n                }\n            )\n\n    @property\n    def config(self) -> str:\n        \"\"\"Get contents of a config file for this theme.\"\"\"\n        config = \"[styles]\\n\" + \"\\n\".join(\n            f\"{name} = {style}\" for name, style in sorted(self.styles.items())\n        )\n        return config\n\n    @classmethod\n    def from_file(\n        cls, config_file: IO[str], source: Optional[str] = None, inherit: bool = True\n    ) -> \"Theme\":\n        \"\"\"Load a theme from a text mode file.\n\n        Args:\n            config_file (IO[str]): An open conf file.\n            source (str, optional): The filename of the open file. Defaults to None.\n            inherit (bool, optional): Inherit default styles. Defaults to True.\n\n        Returns:\n            Theme: A New theme instance.\n        \"\"\"\n        config = configparser.ConfigParser()\n        config.read_file(config_file, source=source)\n        styles = {name: Style.parse(value) for name, value in config.items(\"styles\")}\n        theme = Theme(styles, inherit=inherit)\n        return theme\n\n    @classmethod\n    def read(\n        cls, path: str, inherit: bool = True, encoding: Optional[str] = None\n    ) -> \"Theme\":\n        \"\"\"Read a theme from a path.\n\n        Args:\n            path (str): Path to a config file readable by Python configparser module.\n            inherit (bool, optional): Inherit default styles. Defaults to True.\n            encoding (str, optional): Encoding of the config file. Defaults to None.\n\n        Returns:\n            Theme: A new theme instance.\n        \"\"\"\n        with open(path, encoding=encoding) as config_file:\n            return cls.from_file(config_file, source=path, inherit=inherit)\n\n\nclass ThemeStackError(Exception):\n    \"\"\"Base exception for errors related to the theme stack.\"\"\"\n\n\nclass ThemeStack:\n    \"\"\"A stack of themes.\n\n    Args:\n        theme (Theme): A theme instance\n    \"\"\"\n\n    def __init__(self, theme: Theme) -> None:\n        self._entries: List[Dict[str, Style]] = [theme.styles]\n        self.get = self._entries[-1].get\n\n    def push_theme(self, theme: Theme, inherit: bool = True) -> None:\n        \"\"\"Push a theme on the top of the stack.\n\n        Args:\n            theme (Theme): A Theme instance.\n            inherit (boolean, optional): Inherit styles from current top of stack.\n        \"\"\"\n        styles: Dict[str, Style]\n        styles = (\n            {**self._entries[-1], **theme.styles} if inherit else theme.styles.copy()\n        )\n        self._entries.append(styles)\n        self.get = self._entries[-1].get\n\n    def pop_theme(self) -> None:\n        \"\"\"Pop (and discard) the top-most theme.\"\"\"\n        if len(self._entries) == 1:\n            raise ThemeStackError(\"Unable to pop base theme\")\n        self._entries.pop()\n        self.get = self._entries[-1].get\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    theme = Theme()\n    print(theme.config)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\themes.py": {
      "sha": "5962944738f3",
      "lines": 5,
      "head": "from .default_styles import DEFAULT_STYLES\nfrom .theme import Theme\n\n\nDEFAULT = Theme(DEFAULT_STYLES)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\traceback.py": {
      "sha": "5700846766b4",
      "lines": 884,
      "head": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pip._vendor.pygments.lexers import guess_lexer_for_filename\nfrom pip._vendor.pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pip._vendor.pygments.token import Text as TextToken\nfrom pip._vendor.pygments.token import Token\nfrom pip._vendor.pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_first_last, loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax, SyntaxPosition\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef _iter_syntax_lines(\n    start: SyntaxPosition, end: SyntaxPosition\n) -> Iterable[Tuple[int, int, int]]:\n    \"\"\"Yield start and end positions per line.\n\n    Args:\n        start: Start position.\n        end: End position.\n\n    Returns:\n        Iterable of (LINE, COLUMN1, COLUMN2).\n    \"\"\"\n\n    line1, column1 = start\n    line2, column2 = end\n\n    if line1 == line2:\n        yield line1, column1, column2\n    else:\n        for first, last, line_no in loop_first_last(range(line1, line2 + 1)):\n            if first:\n                yield line_no, column1, -1\n            elif last:\n                yield line_no, 0, column2\n            else:\n                yield line_no, 0, -1\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\tree.py": {
      "sha": "29c6bd433940",
      "lines": 257,
      "head": "from typing import Iterator, List, Optional, Tuple\n\nfrom ._loop import loop_first, loop_last\nfrom .console import Console, ConsoleOptions, RenderableType, RenderResult\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement\nfrom .segment import Segment\nfrom .style import Style, StyleStack, StyleType\nfrom .styled import Styled\n\nGuideType = Tuple[str, str, str, str]\n\n\nclass Tree(JupyterMixin):\n    \"\"\"A renderable for a tree structure.\n\n    Attributes:\n        ASCII_GUIDES (GuideType): Guide lines used when Console.ascii_only is True.\n        TREE_GUIDES (List[GuideType, GuideType, GuideType]): Default guide lines.\n\n    Args:\n        label (RenderableType): The renderable or str for the tree label.\n        style (StyleType, optional): Style of this tree. Defaults to \"tree\".\n        guide_style (StyleType, optional): Style of the guide lines. Defaults to \"tree.line\".\n        expanded (bool, optional): Also display children. Defaults to True.\n        highlight (bool, optional): Highlight renderable (if str). Defaults to False.\n        hide_root (bool, optional): Hide the root node. Defaults to False.\n    \"\"\"\n\n    ASCII_GUIDES = (\"    \", \"|   \", \"+-- \", \"`-- \")\n    TREE_GUIDES = [\n        (\"    \", \"\u2502   \", \"\u251c\u2500\u2500 \", \"\u2514\u2500\u2500 \"),\n        (\"    \", \"\u2503   \", \"\u2523\u2501\u2501 \", \"\u2517\u2501\u2501 \"),\n        (\"    \", \"\u2551   \", \"\u2560\u2550\u2550 \", \"\u255a\u2550\u2550 \"),\n    ]\n\n    def __init__(\n        self,\n        label: RenderableType,\n        *,\n        style: StyleType = \"tree\",\n        guide_style: StyleType = \"tree.line\",\n        expanded: bool = True,\n        highlight: bool = False,\n        hide_root: bool = False,\n    ) -> None:\n        self.label = label\n        self.style = style\n        self.guide_style = guide_style\n        self.children: List[Tree] = []\n        self.expanded = expanded\n        self.highlight = highlight\n        self.hide_root = hide_root\n\n    def add(\n        self,\n        label: RenderableType,\n        *,\n        style: Optional[StyleType] = None,\n        guide_style: Optional[StyleType] = None,\n        expanded: bool = True,\n        highlight: Optional[bool] = False,\n    ) -> \"Tree\":\n        \"\"\"Add a child tree.\n\n        Args:\n            label (RenderableType): The renderable or str for the tree label.\n            style (StyleType, optional): Style of this tree. Defaults to \"tree\".\n            guide_style (StyleType, optional): Style of the guide lines. Defaults to \"tree.line\".\n            expanded (bool, optional): Also display children. Defaults to True.\n            highlight (Optional[bool], optional): Highlight renderable (if str). Defaults to False.\n\n        Returns:\n            Tree: A new child Tree, which may be further modified.\n        \"\"\"\n        node = Tree(\n            label,\n            style=self.style if style is None else style,\n            guide_style=self.guide_style if guide_style is None else guide_style,\n            expanded=expanded,\n            highlight=self.highlight if highlight is None else highlight,\n        )\n        self.children.append(node)\n        return node\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        stack: List[Iterator[Tuple[bool, Tree]]] = []\n        pop = stack.pop\n        push = stack.append\n        new_line = Segment.line()\n\n        get_style = console.get_style\n        null_style = Style.null()\n        guide_style = get_style(self.guide_style, default=\"\") or null_style\n        SPACE, CONTINUE, FORK, END = range(4)\n\n        _Segment = Segment\n\n        def make_guide(index: int, style: Style) -> Segment:\n            \"\"\"Make a Segment for a level of the guide lines.\"\"\"\n            if options.ascii_only:\n                line = self.ASCII_GUIDES[index]\n            else:\n                guide = 1 if style.bold else (2 if style.underline2 else 0)\n                line = self.TREE_GUIDES[0 if options.legacy_windows else guide][index]\n            return _Segment(line, style)\n\n        levels: List[Segment] = [make_guide(CONTINUE, guide_style)]\n        push(iter(loop_last([self])))\n\n        guide_style_stack = StyleStack(get_style(self.guide_style))\n        style_stack = StyleStack(get_style(self.style))\n        remove_guide_styles = Style(bold=False, underline2=False)\n\n        depth = 0\n\n        while stack:\n            stack_node = pop()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_cell_widths.py": {
      "sha": "320031d770fc",
      "lines": 454,
      "head": "# Auto generated by make_terminal_widths.py\n\nCELL_WIDTHS = [\n    (0, 0, 0),\n    (1, 31, -1),\n    (127, 159, -1),\n    (173, 173, 0),\n    (768, 879, 0),\n    (1155, 1161, 0),\n    (1425, 1469, 0),\n    (1471, 1471, 0),\n    (1473, 1474, 0),\n    (1476, 1477, 0),\n    (1479, 1479, 0),\n    (1536, 1541, 0),\n    (1552, 1562, 0),\n    (1564, 1564, 0),\n    (1611, 1631, 0),\n    (1648, 1648, 0),\n    (1750, 1757, 0),\n    (1759, 1764, 0),\n    (1767, 1768, 0),\n    (1770, 1773, 0),\n    (1807, 1807, 0),\n    (1809, 1809, 0),\n    (1840, 1866, 0),\n    (1958, 1968, 0),\n    (2027, 2035, 0),\n    (2045, 2045, 0),\n    (2070, 2073, 0),\n    (2075, 2083, 0),\n    (2085, 2087, 0),\n    (2089, 2093, 0),\n    (2137, 2139, 0),\n    (2192, 2193, 0),\n    (2200, 2207, 0),\n    (2250, 2307, 0),\n    (2362, 2364, 0),\n    (2366, 2383, 0),\n    (2385, 2391, 0),\n    (2402, 2403, 0),\n    (2433, 2435, 0),\n    (2492, 2492, 0),\n    (2494, 2500, 0),\n    (2503, 2504, 0),\n    (2507, 2509, 0),\n    (2519, 2519, 0),\n    (2530, 2531, 0),\n    (2558, 2558, 0),\n    (2561, 2563, 0),\n    (2620, 2620, 0),\n    (2622, 2626, 0),\n    (2631, 2632, 0),\n    (2635, 2637, 0),\n    (2641, 2641, 0),\n    (2672, 2673, 0),\n    (2677, 2677, 0),\n    (2689, 2691, 0),\n    (2748, 2748, 0),\n    (2750, 2757, 0),\n    (2759, 2761, 0),\n    (2763, 2765, 0),\n    (2786, 2787, 0),\n    (2810, 2815, 0),\n    (2817, 2819, 0),\n    (2876, 2876, 0),\n    (2878, 2884, 0),\n    (2887, 2888, 0),\n    (2891, 2893, 0),\n    (2901, 2903, 0),\n    (2914, 2915, 0),\n    (2946, 2946, 0),\n    (3006, 3010, 0),\n    (3014, 3016, 0),\n    (3018, 3021, 0),\n    (3031, 3031, 0),\n    (3072, 3076, 0),\n    (3132, 3132, 0),\n    (3134, 3140, 0),\n    (3142, 3144, 0),\n    (3146, 3149, 0),\n    (3157, 3158, 0),\n    (3170, 3171, 0),\n    (3201, 3203, 0),\n    (3260, 3260, 0),\n    (3262, 3268, 0),\n    (3270, 3272, 0),\n    (3274, 3277, 0),\n    (3285, 3286, 0),\n    (3298, 3299, 0),\n    (3315, 3315, 0),\n    (3328, 3331, 0),\n    (3387, 3388, 0),\n    (3390, 3396, 0),\n    (3398, 3400, 0),\n    (3402, 3405, 0),\n    (3415, 3415, 0),\n    (3426, 3427, 0),\n    (3457, 3459, 0),\n    (3530, 3530, 0),\n    (3535, 3540, 0),\n    (3542, 3542, 0),\n    (3544, 3551, 0),\n    (3570, 3571, 0),\n    (3633, 3633, 0),\n    (3636, 3642, 0),\n    (3655, 3662, 0),\n    (3761, 3761, 0),\n    (3764, 3772, 0),\n    (3784, 3790, 0),\n    (3864, 3865, 0),\n    (3893, 3893, 0),\n    (3895, 3895, 0),\n    (3897, 3897, 0),\n    (3902, 3903, 0),\n    (3953, 3972, 0),\n    (3974, 3975, 0),\n    (3981, 3991, 0),\n    (3993, 4028, 0),\n    (4038, 4038, 0),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_emoji_codes.py": {
      "sha": "668eaff13635",
      "lines": 3610,
      "head": "EMOJI = {\n    \"1st_place_medal\": \"\ud83e\udd47\",\n    \"2nd_place_medal\": \"\ud83e\udd48\",\n    \"3rd_place_medal\": \"\ud83e\udd49\",\n    \"ab_button_(blood_type)\": \"\ud83c\udd8e\",\n    \"atm_sign\": \"\ud83c\udfe7\",\n    \"a_button_(blood_type)\": \"\ud83c\udd70\",\n    \"afghanistan\": \"\ud83c\udde6\ud83c\uddeb\",\n    \"albania\": \"\ud83c\udde6\ud83c\uddf1\",\n    \"algeria\": \"\ud83c\udde9\ud83c\uddff\",\n    \"american_samoa\": \"\ud83c\udde6\ud83c\uddf8\",\n    \"andorra\": \"\ud83c\udde6\ud83c\udde9\",\n    \"angola\": \"\ud83c\udde6\ud83c\uddf4\",\n    \"anguilla\": \"\ud83c\udde6\ud83c\uddee\",\n    \"antarctica\": \"\ud83c\udde6\ud83c\uddf6\",\n    \"antigua_&_barbuda\": \"\ud83c\udde6\ud83c\uddec\",\n    \"aquarius\": \"\u2652\",\n    \"argentina\": \"\ud83c\udde6\ud83c\uddf7\",\n    \"aries\": \"\u2648\",\n    \"armenia\": \"\ud83c\udde6\ud83c\uddf2\",\n    \"aruba\": \"\ud83c\udde6\ud83c\uddfc\",\n    \"ascension_island\": \"\ud83c\udde6\ud83c\udde8\",\n    \"australia\": \"\ud83c\udde6\ud83c\uddfa\",\n    \"austria\": \"\ud83c\udde6\ud83c\uddf9\",\n    \"azerbaijan\": \"\ud83c\udde6\ud83c\uddff\",\n    \"back_arrow\": \"\ud83d\udd19\",\n    \"b_button_(blood_type)\": \"\ud83c\udd71\",\n    \"bahamas\": \"\ud83c\udde7\ud83c\uddf8\",\n    \"bahrain\": \"\ud83c\udde7\ud83c\udded\",\n    \"bangladesh\": \"\ud83c\udde7\ud83c\udde9\",\n    \"barbados\": \"\ud83c\udde7\ud83c\udde7\",\n    \"belarus\": \"\ud83c\udde7\ud83c\uddfe\",\n    \"belgium\": \"\ud83c\udde7\ud83c\uddea\",\n    \"belize\": \"\ud83c\udde7\ud83c\uddff\",\n    \"benin\": \"\ud83c\udde7\ud83c\uddef\",\n    \"bermuda\": \"\ud83c\udde7\ud83c\uddf2\",\n    \"bhutan\": \"\ud83c\udde7\ud83c\uddf9\",\n    \"bolivia\": \"\ud83c\udde7\ud83c\uddf4\",\n    \"bosnia_&_herzegovina\": \"\ud83c\udde7\ud83c\udde6\",\n    \"botswana\": \"\ud83c\udde7\ud83c\uddfc\",\n    \"bouvet_island\": \"\ud83c\udde7\ud83c\uddfb\",\n    \"brazil\": \"\ud83c\udde7\ud83c\uddf7\",\n    \"british_indian_ocean_territory\": \"\ud83c\uddee\ud83c\uddf4\",\n    \"british_virgin_islands\": \"\ud83c\uddfb\ud83c\uddec\",\n    \"brunei\": \"\ud83c\udde7\ud83c\uddf3\",\n    \"bulgaria\": \"\ud83c\udde7\ud83c\uddec\",\n    \"burkina_faso\": \"\ud83c\udde7\ud83c\uddeb\",\n    \"burundi\": \"\ud83c\udde7\ud83c\uddee\",\n    \"cl_button\": \"\ud83c\udd91\",\n    \"cool_button\": \"\ud83c\udd92\",\n    \"cambodia\": \"\ud83c\uddf0\ud83c\udded\",\n    \"cameroon\": \"\ud83c\udde8\ud83c\uddf2\",\n    \"canada\": \"\ud83c\udde8\ud83c\udde6\",\n    \"canary_islands\": \"\ud83c\uddee\ud83c\udde8\",\n    \"cancer\": \"\u264b\",\n    \"cape_verde\": \"\ud83c\udde8\ud83c\uddfb\",\n    \"capricorn\": \"\u2651\",\n    \"caribbean_netherlands\": \"\ud83c\udde7\ud83c\uddf6\",\n    \"cayman_islands\": \"\ud83c\uddf0\ud83c\uddfe\",\n    \"central_african_republic\": \"\ud83c\udde8\ud83c\uddeb\",\n    \"ceuta_&_melilla\": \"\ud83c\uddea\ud83c\udde6\",\n    \"chad\": \"\ud83c\uddf9\ud83c\udde9\",\n    \"chile\": \"\ud83c\udde8\ud83c\uddf1\",\n    \"china\": \"\ud83c\udde8\ud83c\uddf3\",\n    \"christmas_island\": \"\ud83c\udde8\ud83c\uddfd\",\n    \"christmas_tree\": \"\ud83c\udf84\",\n    \"clipperton_island\": \"\ud83c\udde8\ud83c\uddf5\",\n    \"cocos_(keeling)_islands\": \"\ud83c\udde8\ud83c\udde8\",\n    \"colombia\": \"\ud83c\udde8\ud83c\uddf4\",\n    \"comoros\": \"\ud83c\uddf0\ud83c\uddf2\",\n    \"congo_-_brazzaville\": \"\ud83c\udde8\ud83c\uddec\",\n    \"congo_-_kinshasa\": \"\ud83c\udde8\ud83c\udde9\",\n    \"cook_islands\": \"\ud83c\udde8\ud83c\uddf0\",\n    \"costa_rica\": \"\ud83c\udde8\ud83c\uddf7\",\n    \"croatia\": \"\ud83c\udded\ud83c\uddf7\",\n    \"cuba\": \"\ud83c\udde8\ud83c\uddfa\",\n    \"cura\u00e7ao\": \"\ud83c\udde8\ud83c\uddfc\",\n    \"cyprus\": \"\ud83c\udde8\ud83c\uddfe\",\n    \"czechia\": \"\ud83c\udde8\ud83c\uddff\",\n    \"c\u00f4te_d\u2019ivoire\": \"\ud83c\udde8\ud83c\uddee\",\n    \"denmark\": \"\ud83c\udde9\ud83c\uddf0\",\n    \"diego_garcia\": \"\ud83c\udde9\ud83c\uddec\",\n    \"djibouti\": \"\ud83c\udde9\ud83c\uddef\",\n    \"dominica\": \"\ud83c\udde9\ud83c\uddf2\",\n    \"dominican_republic\": \"\ud83c\udde9\ud83c\uddf4\",\n    \"end_arrow\": \"\ud83d\udd1a\",\n    \"ecuador\": \"\ud83c\uddea\ud83c\udde8\",\n    \"egypt\": \"\ud83c\uddea\ud83c\uddec\",\n    \"el_salvador\": \"\ud83c\uddf8\ud83c\uddfb\",\n    \"england\": \"\ud83c\udff4\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f\",\n    \"equatorial_guinea\": \"\ud83c\uddec\ud83c\uddf6\",\n    \"eritrea\": \"\ud83c\uddea\ud83c\uddf7\",\n    \"estonia\": \"\ud83c\uddea\ud83c\uddea\",\n    \"ethiopia\": \"\ud83c\uddea\ud83c\uddf9\",\n    \"european_union\": \"\ud83c\uddea\ud83c\uddfa\",\n    \"free_button\": \"\ud83c\udd93\",\n    \"falkland_islands\": \"\ud83c\uddeb\ud83c\uddf0\",\n    \"faroe_islands\": \"\ud83c\uddeb\ud83c\uddf4\",\n    \"fiji\": \"\ud83c\uddeb\ud83c\uddef\",\n    \"finland\": \"\ud83c\uddeb\ud83c\uddee\",\n    \"france\": \"\ud83c\uddeb\ud83c\uddf7\",\n    \"french_guiana\": \"\ud83c\uddec\ud83c\uddeb\",\n    \"french_polynesia\": \"\ud83c\uddf5\ud83c\uddeb\",\n    \"french_southern_territories\": \"\ud83c\uddf9\ud83c\uddeb\",\n    \"gabon\": \"\ud83c\uddec\ud83c\udde6\",\n    \"gambia\": \"\ud83c\uddec\ud83c\uddf2\",\n    \"gemini\": \"\u264a\",\n    \"georgia\": \"\ud83c\uddec\ud83c\uddea\",\n    \"germany\": \"\ud83c\udde9\ud83c\uddea\",\n    \"ghana\": \"\ud83c\uddec\ud83c\udded\",\n    \"gibraltar\": \"\ud83c\uddec\ud83c\uddee\",\n    \"greece\": \"\ud83c\uddec\ud83c\uddf7\",\n    \"greenland\": \"\ud83c\uddec\ud83c\uddf1\",\n    \"grenada\": \"\ud83c\uddec\ud83c\udde9\",\n    \"guadeloupe\": \"\ud83c\uddec\ud83c\uddf5\",\n    \"guam\": \"\ud83c\uddec\ud83c\uddfa\",\n    \"guatemala\": \"\ud83c\uddec\ud83c\uddf9\",\n    \"guernsey\": \"\ud83c\uddec\ud83c\uddec\",\n    \"guinea\": \"\ud83c\uddec\ud83c\uddf3\",\n    \"guinea-bissau\": \"\ud83c\uddec\ud83c\uddfc\",\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_emoji_replace.py": {
      "sha": "24b63b5fc802",
      "lines": 32,
      "head": "from typing import Callable, Match, Optional\nimport re\n\nfrom ._emoji_codes import EMOJI\n\n\n_ReStringMatch = Match[str]  # regex match object\n_ReSubCallable = Callable[[_ReStringMatch], str]  # Callable invoked by re.sub\n_EmojiSubMethod = Callable[[_ReSubCallable, str], str]  # Sub method of a compiled re\n\n\ndef _emoji_replace(\n    text: str,\n    default_variant: Optional[str] = None,\n    _emoji_sub: _EmojiSubMethod = re.compile(r\"(:(\\S*?)(?:(?:\\-)(emoji|text))?:)\").sub,\n) -> str:\n    \"\"\"Replace emoji code in text.\"\"\"\n    get_emoji = EMOJI.__getitem__\n    variants = {\"text\": \"\\uFE0E\", \"emoji\": \"\\uFE0F\"}\n    get_variant = variants.get\n    default_variant_code = variants.get(default_variant, \"\") if default_variant else \"\"\n\n    def do_replace(match: Match[str]) -> str:\n        emoji_code, emoji_name, variant = match.groups()\n        try:\n            return get_emoji(emoji_name.lower()) + get_variant(\n                variant, default_variant_code\n            )\n        except KeyError:\n            return emoji_code\n\n    return _emoji_sub(do_replace, text)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_export_format.py": {
      "sha": "a2785fa046dd",
      "lines": 76,
      "head": "CONSOLE_HTML_FORMAT = \"\"\"\\\n<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n{stylesheet}\nbody {{\n    color: {foreground};\n    background-color: {background};\n}}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\">{code}</code></pre>\n</body>\n</html>\n\"\"\"\n\nCONSOLE_SVG_FORMAT = \"\"\"\\\n<svg class=\"rich-terminal\" viewBox=\"0 0 {width} {height}\" xmlns=\"http://www.w3.org/2000/svg\">\n    <!-- Generated with Rich https://www.textualize.io -->\n    <style>\n\n    @font-face {{\n        font-family: \"Fira Code\";\n        src: local(\"FiraCode-Regular\"),\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Regular.woff2\") format(\"woff2\"),\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Regular.woff\") format(\"woff\");\n        font-style: normal;\n        font-weight: 400;\n    }}\n    @font-face {{\n        font-family: \"Fira Code\";\n        src: local(\"FiraCode-Bold\"),\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Bold.woff2\") format(\"woff2\"),\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Bold.woff\") format(\"woff\");\n        font-style: bold;\n        font-weight: 700;\n    }}\n\n    .{unique_id}-matrix {{\n        font-family: Fira Code, monospace;\n        font-size: {char_height}px;\n        line-height: {line_height}px;\n        font-variant-east-asian: full-width;\n    }}\n\n    .{unique_id}-title {{\n        font-size: 18px;\n        font-weight: bold;\n        font-family: arial;\n    }}\n\n    {styles}\n    </style>\n\n    <defs>\n    <clipPath id=\"{unique_id}-clip-terminal\">\n      <rect x=\"0\" y=\"0\" width=\"{terminal_width}\" height=\"{terminal_height}\" />\n    </clipPath>\n    {lines}\n    </defs>\n\n    {chrome}\n    <g transform=\"translate({terminal_x}, {terminal_y})\" clip-path=\"url(#{unique_id}-clip-terminal)\">\n    {backgrounds}\n    <g class=\"{unique_id}-matrix\">\n    {matrix}\n    </g>\n    </g>\n</svg>\n\"\"\"\n\n_SVG_FONT_FAMILY = \"Rich Fira Code\"\n_SVG_CLASSES_PREFIX = \"rich-svg\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_extension.py": {
      "sha": "5b52136df195",
      "lines": 10,
      "head": "from typing import Any\n\n\ndef load_ipython_extension(ip: Any) -> None:  # pragma: no cover\n    # prevent circular import\n    from pip._vendor.rich.pretty import install\n    from pip._vendor.rich.traceback import install as tr_install\n\n    install()\n    tr_install()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_fileno.py": {
      "sha": "5519860d4817",
      "lines": 24,
      "head": "from __future__ import annotations\n\nfrom typing import IO, Callable\n\n\ndef get_fileno(file_like: IO[str]) -> int | None:\n    \"\"\"Get fileno() from a file, accounting for poorly implemented file-like objects.\n\n    Args:\n        file_like (IO): A file-like object.\n\n    Returns:\n        int | None: The result of fileno if available, or None if operation failed.\n    \"\"\"\n    fileno: Callable[[], int] | None = getattr(file_like, \"fileno\", None)\n    if fileno is not None:\n        try:\n            return fileno()\n        except Exception:\n            # `fileno` is documented as potentially raising a OSError\n            # Alas, from the issues, there are so many poorly implemented file-like objects,\n            # that `fileno()` can raise just about anything.\n            return None\n    return None\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_inspect.py": {
      "sha": "74ef73cc4c71",
      "lines": 268,
      "head": "import inspect\nfrom inspect import cleandoc, getdoc, getfile, isclass, ismodule, signature\nfrom typing import Any, Collection, Iterable, Optional, Tuple, Type, Union\n\nfrom .console import Group, RenderableType\nfrom .control import escape_control_codes\nfrom .highlighter import ReprHighlighter\nfrom .jupyter import JupyterMixin\nfrom .panel import Panel\nfrom .pretty import Pretty\nfrom .table import Table\nfrom .text import Text, TextType\n\n\ndef _first_paragraph(doc: str) -> str:\n    \"\"\"Get the first paragraph from a docstring.\"\"\"\n    paragraph, _, _ = doc.partition(\"\\n\\n\")\n    return paragraph\n\n\nclass Inspect(JupyterMixin):\n    \"\"\"A renderable to inspect any Python Object.\n\n    Args:\n        obj (Any): An object to inspect.\n        title (str, optional): Title to display over inspect result, or None use type. Defaults to None.\n        help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.\n        methods (bool, optional): Enable inspection of callables. Defaults to False.\n        docs (bool, optional): Also render doc strings. Defaults to True.\n        private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.\n        dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.\n        sort (bool, optional): Sort attributes alphabetically. Defaults to True.\n        all (bool, optional): Show all attributes. Defaults to False.\n        value (bool, optional): Pretty print value of object. Defaults to True.\n    \"\"\"\n\n    def __init__(\n        self,\n        obj: Any,\n        *,\n        title: Optional[TextType] = None,\n        help: bool = False,\n        methods: bool = False,\n        docs: bool = True,\n        private: bool = False,\n        dunder: bool = False,\n        sort: bool = True,\n        all: bool = True,\n        value: bool = True,\n    ) -> None:\n        self.highlighter = ReprHighlighter()\n        self.obj = obj\n        self.title = title or self._make_title(obj)\n        if all:\n            methods = private = dunder = True\n        self.help = help\n        self.methods = methods\n        self.docs = docs or help\n        self.private = private or dunder\n        self.dunder = dunder\n        self.sort = sort\n        self.value = value\n\n    def _make_title(self, obj: Any) -> Text:\n        \"\"\"Make a default title.\"\"\"\n        title_str = (\n            str(obj)\n            if (isclass(obj) or callable(obj) or ismodule(obj))\n            else str(type(obj))\n        )\n        title_text = self.highlighter(title_str)\n        return title_text\n\n    def __rich__(self) -> Panel:\n        return Panel.fit(\n            Group(*self._render()),\n            title=self.title,\n            border_style=\"scope.border\",\n            padding=(0, 1),\n        )\n\n    def _get_signature(self, name: str, obj: Any) -> Optional[Text]:\n        \"\"\"Get a signature for a callable.\"\"\"\n        try:\n            _signature = str(signature(obj)) + \":\"\n        except ValueError:\n            _signature = \"(...)\"\n        except TypeError:\n            return None\n\n        source_filename: Optional[str] = None\n        try:\n            source_filename = getfile(obj)\n        except (OSError, TypeError):\n            # OSError is raised if obj has no source file, e.g. when defined in REPL.\n            pass\n\n        callable_name = Text(name, style=\"inspect.callable\")\n        if source_filename:\n            callable_name.stylize(f\"link file://{source_filename}\")\n        signature_text = self.highlighter(_signature)\n\n        qualname = name or getattr(obj, \"__qualname__\", name)\n\n        # If obj is a module, there may be classes (which are callable) to display\n        if inspect.isclass(obj):\n            prefix = \"class\"\n        elif inspect.iscoroutinefunction(obj):\n            prefix = \"async def\"\n        else:\n            prefix = \"def\"\n\n        qual_signature = Text.assemble(\n            (f\"{prefix} \", f\"inspect.{prefix.replace(' ', '_')}\"),\n            (qualname, \"inspect.callable\"),\n            signature_text,\n        )\n\n        return qual_signature\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_log_render.py": {
      "sha": "e28c1f61c554",
      "lines": 94,
      "head": "from datetime import datetime\nfrom typing import Iterable, List, Optional, TYPE_CHECKING, Union, Callable\n\n\nfrom .text import Text, TextType\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleRenderable, RenderableType\n    from .table import Table\n\nFormatTimeCallable = Callable[[datetime], Text]\n\n\nclass LogRender:\n    def __init__(\n        self,\n        show_time: bool = True,\n        show_level: bool = False,\n        show_path: bool = True,\n        time_format: Union[str, FormatTimeCallable] = \"[%x %X]\",\n        omit_repeated_times: bool = True,\n        level_width: Optional[int] = 8,\n    ) -> None:\n        self.show_time = show_time\n        self.show_level = show_level\n        self.show_path = show_path\n        self.time_format = time_format\n        self.omit_repeated_times = omit_repeated_times\n        self.level_width = level_width\n        self._last_time: Optional[Text] = None\n\n    def __call__(\n        self,\n        console: \"Console\",\n        renderables: Iterable[\"ConsoleRenderable\"],\n        log_time: Optional[datetime] = None,\n        time_format: Optional[Union[str, FormatTimeCallable]] = None,\n        level: TextType = \"\",\n        path: Optional[str] = None,\n        line_no: Optional[int] = None,\n        link_path: Optional[str] = None,\n    ) -> \"Table\":\n        from .containers import Renderables\n        from .table import Table\n\n        output = Table.grid(padding=(0, 1))\n        output.expand = True\n        if self.show_time:\n            output.add_column(style=\"log.time\")\n        if self.show_level:\n            output.add_column(style=\"log.level\", width=self.level_width)\n        output.add_column(ratio=1, style=\"log.message\", overflow=\"fold\")\n        if self.show_path and path:\n            output.add_column(style=\"log.path\")\n        row: List[\"RenderableType\"] = []\n        if self.show_time:\n            log_time = log_time or console.get_datetime()\n            time_format = time_format or self.time_format\n            if callable(time_format):\n                log_time_display = time_format(log_time)\n            else:\n                log_time_display = Text(log_time.strftime(time_format))\n            if log_time_display == self._last_time and self.omit_repeated_times:\n                row.append(Text(\" \" * len(log_time_display)))\n            else:\n                row.append(log_time_display)\n                self._last_time = log_time_display\n        if self.show_level:\n            row.append(level)\n\n        row.append(Renderables(renderables))\n        if self.show_path and path:\n            path_text = Text()\n            path_text.append(\n                path, style=f\"link file://{link_path}\" if link_path else \"\"\n            )\n            if line_no:\n                path_text.append(\":\")\n                path_text.append(\n                    f\"{line_no}\",\n                    style=f\"link file://{link_path}#{line_no}\" if link_path else \"\",\n                )\n            row.append(path_text)\n\n        output.add_row(*row)\n        return output\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from pip._vendor.rich.console import Console\n\n    c = Console()\n    c.print(\"[on blue]Hello\", justify=\"right\")\n    c.log(\"[on blue]hello\", justify=\"right\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_loop.py": {
      "sha": "64c1a76eb241",
      "lines": 43,
      "head": "from typing import Iterable, Tuple, TypeVar\n\nT = TypeVar(\"T\")\n\n\ndef loop_first(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for first value.\"\"\"\n    iter_values = iter(values)\n    try:\n        value = next(iter_values)\n    except StopIteration:\n        return\n    yield True, value\n    for value in iter_values:\n        yield False, value\n\n\ndef loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    for value in iter_values:\n        yield False, previous_value\n        previous_value = value\n    yield True, previous_value\n\n\ndef loop_first_last(values: Iterable[T]) -> Iterable[Tuple[bool, bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for first and last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    first = True\n    for value in iter_values:\n        yield first, False, previous_value\n        first = False\n        previous_value = value\n    yield first, True, previous_value\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_null_file.py": {
      "sha": "1a51c1437012",
      "lines": 69,
      "head": "from types import TracebackType\nfrom typing import IO, Iterable, Iterator, List, Optional, Type\n\n\nclass NullFile(IO[str]):\n    def close(self) -> None:\n        pass\n\n    def isatty(self) -> bool:\n        return False\n\n    def read(self, __n: int = 1) -> str:\n        return \"\"\n\n    def readable(self) -> bool:\n        return False\n\n    def readline(self, __limit: int = 1) -> str:\n        return \"\"\n\n    def readlines(self, __hint: int = 1) -> List[str]:\n        return []\n\n    def seek(self, __offset: int, __whence: int = 1) -> int:\n        return 0\n\n    def seekable(self) -> bool:\n        return False\n\n    def tell(self) -> int:\n        return 0\n\n    def truncate(self, __size: Optional[int] = 1) -> int:\n        return 0\n\n    def writable(self) -> bool:\n        return False\n\n    def writelines(self, __lines: Iterable[str]) -> None:\n        pass\n\n    def __next__(self) -> str:\n        return \"\"\n\n    def __iter__(self) -> Iterator[str]:\n        return iter([\"\"])\n\n    def __enter__(self) -> IO[str]:\n        return self\n\n    def __exit__(\n        self,\n        __t: Optional[Type[BaseException]],\n        __value: Optional[BaseException],\n        __traceback: Optional[TracebackType],\n    ) -> None:\n        pass\n\n    def write(self, text: str) -> int:\n        return 0\n\n    def flush(self) -> None:\n        pass\n\n    def fileno(self) -> int:\n        return -1\n\n\nNULL_FILE = NullFile()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_palettes.py": {
      "sha": "ee198b57907e",
      "lines": 309,
      "head": "from .palette import Palette\n\n\n# Taken from https://en.wikipedia.org/wiki/ANSI_escape_code (Windows 10 column)\nWINDOWS_PALETTE = Palette(\n    [\n        (12, 12, 12),\n        (197, 15, 31),\n        (19, 161, 14),\n        (193, 156, 0),\n        (0, 55, 218),\n        (136, 23, 152),\n        (58, 150, 221),\n        (204, 204, 204),\n        (118, 118, 118),\n        (231, 72, 86),\n        (22, 198, 12),\n        (249, 241, 165),\n        (59, 120, 255),\n        (180, 0, 158),\n        (97, 214, 214),\n        (242, 242, 242),\n    ]\n)\n\n# # The standard ansi colors (including bright variants)\nSTANDARD_PALETTE = Palette(\n    [\n        (0, 0, 0),\n        (170, 0, 0),\n        (0, 170, 0),\n        (170, 85, 0),\n        (0, 0, 170),\n        (170, 0, 170),\n        (0, 170, 170),\n        (170, 170, 170),\n        (85, 85, 85),\n        (255, 85, 85),\n        (85, 255, 85),\n        (255, 255, 85),\n        (85, 85, 255),\n        (255, 85, 255),\n        (85, 255, 255),\n        (255, 255, 255),\n    ]\n)\n\n\n# The 256 color palette\nEIGHT_BIT_PALETTE = Palette(\n    [\n        (0, 0, 0),\n        (128, 0, 0),\n        (0, 128, 0),\n        (128, 128, 0),\n        (0, 0, 128),\n        (128, 0, 128),\n        (0, 128, 128),\n        (192, 192, 192),\n        (128, 128, 128),\n        (255, 0, 0),\n        (0, 255, 0),\n        (255, 255, 0),\n        (0, 0, 255),\n        (255, 0, 255),\n        (0, 255, 255),\n        (255, 255, 255),\n        (0, 0, 0),\n        (0, 0, 95),\n        (0, 0, 135),\n        (0, 0, 175),\n        (0, 0, 215),\n        (0, 0, 255),\n        (0, 95, 0),\n        (0, 95, 95),\n        (0, 95, 135),\n        (0, 95, 175),\n        (0, 95, 215),\n        (0, 95, 255),\n        (0, 135, 0),\n        (0, 135, 95),\n        (0, 135, 135),\n        (0, 135, 175),\n        (0, 135, 215),\n        (0, 135, 255),\n        (0, 175, 0),\n        (0, 175, 95),\n        (0, 175, 135),\n        (0, 175, 175),\n        (0, 175, 215),\n        (0, 175, 255),\n        (0, 215, 0),\n        (0, 215, 95),\n        (0, 215, 135),\n        (0, 215, 175),\n        (0, 215, 215),\n        (0, 215, 255),\n        (0, 255, 0),\n        (0, 255, 95),\n        (0, 255, 135),\n        (0, 255, 175),\n        (0, 255, 215),\n        (0, 255, 255),\n        (95, 0, 0),\n        (95, 0, 95),\n        (95, 0, 135),\n        (95, 0, 175),\n        (95, 0, 215),\n        (95, 0, 255),\n        (95, 95, 0),\n        (95, 95, 95),\n        (95, 95, 135),\n        (95, 95, 175),\n        (95, 95, 215),\n        (95, 95, 255),\n        (95, 135, 0),\n        (95, 135, 95),\n        (95, 135, 135),\n        (95, 135, 175),\n        (95, 135, 215),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_pick.py": {
      "sha": "72a297844fdb",
      "lines": 17,
      "head": "from typing import Optional\n\n\ndef pick_bool(*values: Optional[bool]) -> bool:\n    \"\"\"Pick the first non-none bool or return the last value.\n\n    Args:\n        *values (bool): Any number of boolean or None values.\n\n    Returns:\n        bool: First non-none boolean.\n    \"\"\"\n    assert values, \"1 or more values required\"\n    for value in values:\n        if value is not None:\n            return value\n    return bool(value)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_ratio.py": {
      "sha": "ecc088bfe541",
      "lines": 159,
      "head": "import sys\nfrom fractions import Fraction\nfrom math import ceil\nfrom typing import cast, List, Optional, Sequence\n\nif sys.version_info >= (3, 8):\n    from typing import Protocol\nelse:\n    from pip._vendor.typing_extensions import Protocol  # pragma: no cover\n\n\nclass Edge(Protocol):\n    \"\"\"Any object that defines an edge (such as Layout).\"\"\"\n\n    size: Optional[int] = None\n    ratio: int = 1\n    minimum_size: int = 1\n\n\ndef ratio_resolve(total: int, edges: Sequence[Edge]) -> List[int]:\n    \"\"\"Divide total space to satisfy size, ratio, and minimum_size, constraints.\n\n    The returned list of integers should add up to total in most cases, unless it is\n    impossible to satisfy all the constraints. For instance, if there are two edges\n    with a minimum size of 20 each and `total` is 30 then the returned list will be\n    greater than total. In practice, this would mean that a Layout object would\n    clip the rows that would overflow the screen height.\n\n    Args:\n        total (int): Total number of characters.\n        edges (List[Edge]): Edges within total space.\n\n    Returns:\n        List[int]: Number of characters for each edge.\n    \"\"\"\n    # Size of edge or None for yet to be determined\n    sizes = [(edge.size or None) for edge in edges]\n\n    _Fraction = Fraction\n\n    # While any edges haven't been calculated\n    while None in sizes:\n        # Get flexible edges and index to map these back on to sizes list\n        flexible_edges = [\n            (index, edge)\n            for index, (size, edge) in enumerate(zip(sizes, edges))\n            if size is None\n        ]\n        # Remaining space in total\n        remaining = total - sum(size or 0 for size in sizes)\n        if remaining <= 0:\n            # No room for flexible edges\n            return [\n                ((edge.minimum_size or 1) if size is None else size)\n                for size, edge in zip(sizes, edges)\n            ]\n        # Calculate number of characters in a ratio portion\n        portion = _Fraction(\n            remaining, sum((edge.ratio or 1) for _, edge in flexible_edges)\n        )\n\n        # If any edges will be less than their minimum, replace size with the minimum\n        for index, edge in flexible_edges:\n            if portion * edge.ratio <= edge.minimum_size:\n                sizes[index] = edge.minimum_size\n                # New fixed size will invalidate calculations, so we need to repeat the process\n                break\n        else:\n            # Distribute flexible space and compensate for rounding error\n            # Since edge sizes can only be integers we need to add the remainder\n            # to the following line\n            remainder = _Fraction(0)\n            for index, edge in flexible_edges:\n                size, remainder = divmod(portion * edge.ratio + remainder, 1)\n                sizes[index] = size\n            break\n    # Sizes now contains integers only\n    return cast(List[int], sizes)\n\n\ndef ratio_reduce(\n    total: int, ratios: List[int], maximums: List[int], values: List[int]\n) -> List[int]:\n    \"\"\"Divide an integer total in to parts based on ratios.\n\n    Args:\n        total (int): The total to divide.\n        ratios (List[int]): A list of integer ratios.\n        maximums (List[int]): List of maximums values for each slot.\n        values (List[int]): List of values\n\n    Returns:\n        List[int]: A list of integers guaranteed to sum to total.\n    \"\"\"\n    ratios = [ratio if _max else 0 for ratio, _max in zip(ratios, maximums)]\n    total_ratio = sum(ratios)\n    if not total_ratio:\n        return values[:]\n    total_remaining = total\n    result: List[int] = []\n    append = result.append\n    for ratio, maximum, value in zip(ratios, maximums, values):\n        if ratio and total_ratio > 0:\n            distributed = min(maximum, round(ratio * total_remaining / total_ratio))\n            append(value - distributed)\n            total_remaining -= distributed\n            total_ratio -= ratio\n        else:\n            append(value)\n    return result\n\n\ndef ratio_distribute(\n    total: int, ratios: List[int], minimums: Optional[List[int]] = None\n) -> List[int]:\n    \"\"\"Distribute an integer total in to parts based on ratios.\n\n    Args:\n        total (int): The total to divide.\n        ratios (List[int]): A list of integer ratios.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_spinners.py": {
      "sha": "7dc392ff666a",
      "lines": 482,
      "head": "\"\"\"\nSpinners are from:\n* cli-spinners:\n    MIT License\n    Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights to\n    use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n    the Software, and to permit persons to whom the Software is furnished to do so,\n    subject to the following conditions:\n    The above copyright notice and this permission notice shall be included\n    in all copies or substantial portions of the Software.\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\n    INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR\n    PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE\n    FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\n    ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n    IN THE SOFTWARE.\n\"\"\"\n\nSPINNERS = {\n    \"dots\": {\n        \"interval\": 80,\n        \"frames\": \"\u280b\u2819\u2839\u2838\u283c\u2834\u2826\u2827\u2807\u280f\",\n    },\n    \"dots2\": {\"interval\": 80, \"frames\": \"\u28fe\u28fd\u28fb\u28bf\u287f\u28df\u28ef\u28f7\"},\n    \"dots3\": {\n        \"interval\": 80,\n        \"frames\": \"\u280b\u2819\u281a\u281e\u2816\u2826\u2834\u2832\u2833\u2813\",\n    },\n    \"dots4\": {\n        \"interval\": 80,\n        \"frames\": \"\u2804\u2806\u2807\u280b\u2819\u2838\u2830\u2820\u2830\u2838\u2819\u280b\u2807\u2806\",\n    },\n    \"dots5\": {\n        \"interval\": 80,\n        \"frames\": \"\u280b\u2819\u281a\u2812\u2802\u2802\u2812\u2832\u2834\u2826\u2816\u2812\u2810\u2810\u2812\u2813\u280b\",\n    },\n    \"dots6\": {\n        \"interval\": 80,\n        \"frames\": \"\u2801\u2809\u2819\u281a\u2812\u2802\u2802\u2812\u2832\u2834\u2824\u2804\u2804\u2824\u2834\u2832\u2812\u2802\u2802\u2812\u281a\u2819\u2809\u2801\",\n    },\n    \"dots7\": {\n        \"interval\": 80,\n        \"frames\": \"\u2808\u2809\u280b\u2813\u2812\u2810\u2810\u2812\u2816\u2826\u2824\u2820\u2820\u2824\u2826\u2816\u2812\u2810\u2810\u2812\u2813\u280b\u2809\u2808\",\n    },\n    \"dots8\": {\n        \"interval\": 80,\n        \"frames\": \"\u2801\u2801\u2809\u2819\u281a\u2812\u2802\u2802\u2812\u2832\u2834\u2824\u2804\u2804\u2824\u2820\u2820\u2824\u2826\u2816\u2812\u2810\u2810\u2812\u2813\u280b\u2809\u2808\u2808\",\n    },\n    \"dots9\": {\"interval\": 80, \"frames\": \"\u28b9\u28ba\u28bc\u28f8\u28c7\u2867\u2857\u284f\"},\n    \"dots10\": {\"interval\": 80, \"frames\": \"\u2884\u2882\u2881\u2841\u2848\u2850\u2860\"},\n    \"dots11\": {\"interval\": 100, \"frames\": \"\u2801\u2802\u2804\u2840\u2880\u2820\u2810\u2808\"},\n    \"dots12\": {\n        \"interval\": 80,\n        \"frames\": [\n            \"\u2880\u2800\",\n            \"\u2840\u2800\",\n            \"\u2804\u2800\",\n            \"\u2882\u2800\",\n            \"\u2842\u2800\",\n            \"\u2805\u2800\",\n            \"\u2883\u2800\",\n            \"\u2843\u2800\",\n            \"\u280d\u2800\",\n            \"\u288b\u2800\",\n            \"\u284b\u2800\",\n            \"\u280d\u2801\",\n            \"\u288b\u2801\",\n            \"\u284b\u2801\",\n            \"\u280d\u2809\",\n            \"\u280b\u2809\",\n            \"\u280b\u2809\",\n            \"\u2809\u2819\",\n            \"\u2809\u2819\",\n            \"\u2809\u2829\",\n            \"\u2808\u2899\",\n            \"\u2808\u2859\",\n            \"\u2888\u2829\",\n            \"\u2840\u2899\",\n            \"\u2804\u2859\",\n            \"\u2882\u2829\",\n            \"\u2842\u2898\",\n            \"\u2805\u2858\",\n            \"\u2883\u2828\",\n            \"\u2843\u2890\",\n            \"\u280d\u2850\",\n            \"\u288b\u2820\",\n            \"\u284b\u2880\",\n            \"\u280d\u2841\",\n            \"\u288b\u2801\",\n            \"\u284b\u2801\",\n            \"\u280d\u2809\",\n            \"\u280b\u2809\",\n            \"\u280b\u2809\",\n            \"\u2809\u2819\",\n            \"\u2809\u2819\",\n            \"\u2809\u2829\",\n            \"\u2808\u2899\",\n            \"\u2808\u2859\",\n            \"\u2808\u2829\",\n            \"\u2800\u2899\",\n            \"\u2800\u2859\",\n            \"\u2800\u2829\",\n            \"\u2800\u2898\",\n            \"\u2800\u2858\",\n            \"\u2800\u2828\",\n            \"\u2800\u2890\",\n            \"\u2800\u2850\",\n            \"\u2800\u2820\",\n            \"\u2800\u2880\",\n            \"\u2800\u2840\",\n        ],\n    },\n    \"dots8Bit\": {\n        \"interval\": 80,\n        \"frames\": \"\u2800\u2801\u2802\u2803\u2804\u2805\u2806\u2807\u2840\u2841\u2842\u2843\u2844\u2845\u2846\u2847\u2808\u2809\u280a\u280b\u280c\u280d\u280e\u280f\u2848\u2849\u284a\u284b\u284c\u284d\u284e\u284f\u2810\u2811\u2812\u2813\u2814\u2815\u2816\u2817\u2850\u2851\u2852\u2853\u2854\u2855\u2856\u2857\u2818\u2819\u281a\u281b\u281c\u281d\u281e\u281f\u2858\u2859\"\n        \"\u285a\u285b\u285c\u285d\u285e\u285f\u2820\u2821\u2822\u2823\u2824\u2825\u2826\u2827\u2860\u2861\u2862\u2863\u2864\u2865\u2866\u2867\u2828\u2829\u282a\u282b\u282c\u282d\u282e\u282f\u2868\u2869\u286a\u286b\u286c\u286d\u286e\u286f\u2830\u2831\u2832\u2833\u2834\u2835\u2836\u2837\u2870\u2871\u2872\u2873\u2874\u2875\u2876\u2877\u2838\u2839\u283a\u283b\"\n        \"\u283c\u283d\u283e\u283f\u2878\u2879\u287a\u287b\u287c\u287d\u287e\u287f\u2880\u2881\u2882\u2883\u2884\u2885\u2886\u2887\u28c0\u28c1\u28c2\u28c3\u28c4\u28c5\u28c6\u28c7\u2888\u2889\u288a\u288b\u288c\u288d\u288e\u288f\u28c8\u28c9\u28ca\u28cb\u28cc\u28cd\u28ce\u28cf\u2890\u2891\u2892\u2893\u2894\u2895\u2896\u2897\u28d0\u28d1\u28d2\u28d3\u28d4\u28d5\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_stack.py": {
      "sha": "3a77a4cd0cda",
      "lines": 16,
      "head": "from typing import List, TypeVar\n\nT = TypeVar(\"T\")\n\n\nclass Stack(List[T]):\n    \"\"\"A small shim over builtin list.\"\"\"\n\n    @property\n    def top(self) -> T:\n        \"\"\"Get top of stack.\"\"\"\n        return self[-1]\n\n    def push(self, item: T) -> None:\n        \"\"\"Push an item on to the stack (append in stack nomenclature).\"\"\"\n        self.append(item)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_timer.py": {
      "sha": "b93f8ddd7bc4",
      "lines": 19,
      "head": "\"\"\"\nTimer context manager, only used in debug.\n\n\"\"\"\n\nfrom time import time\n\nimport contextlib\nfrom typing import Generator\n\n\n@contextlib.contextmanager\ndef timer(subject: str = \"time\") -> Generator[None, None, None]:\n    \"\"\"print the elapsed time. (only used in debugging)\"\"\"\n    start = time()\n    yield\n    elapsed = time() - start\n    elapsed_ms = elapsed * 1000\n    print(f\"{subject} elapsed {elapsed_ms:.1f}ms\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_win32_console.py": {
      "sha": "2cbc9f90a5ee",
      "lines": 661,
      "head": "\"\"\"Light wrapper around the Win32 Console API - this module should only be imported on Windows\n\nThe API that this module wraps is documented at https://docs.microsoft.com/en-us/windows/console/console-functions\n\"\"\"\n\nimport ctypes\nimport sys\nfrom typing import Any\n\nwindll: Any = None\nif sys.platform == \"win32\":\n    windll = ctypes.LibraryLoader(ctypes.WinDLL)\nelse:\n    raise ImportError(f\"{__name__} can only be imported on Windows\")\n\nimport time\nfrom ctypes import Structure, byref, wintypes\nfrom typing import IO, NamedTuple, Type, cast\n\nfrom pip._vendor.rich.color import ColorSystem\nfrom pip._vendor.rich.style import Style\n\nSTDOUT = -11\nENABLE_VIRTUAL_TERMINAL_PROCESSING = 4\n\nCOORD = wintypes._COORD\n\n\nclass LegacyWindowsError(Exception):\n    pass\n\n\nclass WindowsCoordinates(NamedTuple):\n    \"\"\"Coordinates in the Windows Console API are (y, x), not (x, y).\n    This class is intended to prevent that confusion.\n    Rows and columns are indexed from 0.\n    This class can be used in place of wintypes._COORD in arguments and argtypes.\n    \"\"\"\n\n    row: int\n    col: int\n\n    @classmethod\n    def from_param(cls, value: \"WindowsCoordinates\") -> COORD:\n        \"\"\"Converts a WindowsCoordinates into a wintypes _COORD structure.\n        This classmethod is internally called by ctypes to perform the conversion.\n\n        Args:\n            value (WindowsCoordinates): The input coordinates to convert.\n\n        Returns:\n            wintypes._COORD: The converted coordinates struct.\n        \"\"\"\n        return COORD(value.col, value.row)\n\n\nclass CONSOLE_SCREEN_BUFFER_INFO(Structure):\n    _fields_ = [\n        (\"dwSize\", COORD),\n        (\"dwCursorPosition\", COORD),\n        (\"wAttributes\", wintypes.WORD),\n        (\"srWindow\", wintypes.SMALL_RECT),\n        (\"dwMaximumWindowSize\", COORD),\n    ]\n\n\nclass CONSOLE_CURSOR_INFO(ctypes.Structure):\n    _fields_ = [(\"dwSize\", wintypes.DWORD), (\"bVisible\", wintypes.BOOL)]\n\n\n_GetStdHandle = windll.kernel32.GetStdHandle\n_GetStdHandle.argtypes = [\n    wintypes.DWORD,\n]\n_GetStdHandle.restype = wintypes.HANDLE\n\n\ndef GetStdHandle(handle: int = STDOUT) -> wintypes.HANDLE:\n    \"\"\"Retrieves a handle to the specified standard device (standard input, standard output, or standard error).\n\n    Args:\n        handle (int): Integer identifier for the handle. Defaults to -11 (stdout).\n\n    Returns:\n        wintypes.HANDLE: The handle\n    \"\"\"\n    return cast(wintypes.HANDLE, _GetStdHandle(handle))\n\n\n_GetConsoleMode = windll.kernel32.GetConsoleMode\n_GetConsoleMode.argtypes = [wintypes.HANDLE, wintypes.LPDWORD]\n_GetConsoleMode.restype = wintypes.BOOL\n\n\ndef GetConsoleMode(std_handle: wintypes.HANDLE) -> int:\n    \"\"\"Retrieves the current input mode of a console's input buffer\n    or the current output mode of a console screen buffer.\n\n    Args:\n        std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.\n\n    Raises:\n        LegacyWindowsError: If any error occurs while calling the Windows console API.\n\n    Returns:\n        int: Value representing the current console mode as documented at\n            https://docs.microsoft.com/en-us/windows/console/getconsolemode#parameters\n    \"\"\"\n\n    console_mode = wintypes.DWORD()\n    success = bool(_GetConsoleMode(std_handle, console_mode))\n    if not success:\n        raise LegacyWindowsError(\"Unable to get legacy Windows Console Mode\")\n    return console_mode.value\n\n\n_FillConsoleOutputCharacterW = windll.kernel32.FillConsoleOutputCharacterW\n_FillConsoleOutputCharacterW.argtypes = [\n    wintypes.HANDLE,\n    ctypes.c_char,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_windows.py": {
      "sha": "e312d9bfd14f",
      "lines": 71,
      "head": "import sys\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass WindowsConsoleFeatures:\n    \"\"\"Windows features available.\"\"\"\n\n    vt: bool = False\n    \"\"\"The console supports VT codes.\"\"\"\n    truecolor: bool = False\n    \"\"\"The console supports truecolor.\"\"\"\n\n\ntry:\n    import ctypes\n    from ctypes import LibraryLoader\n\n    if sys.platform == \"win32\":\n        windll = LibraryLoader(ctypes.WinDLL)\n    else:\n        windll = None\n        raise ImportError(\"Not windows\")\n\n    from pip._vendor.rich._win32_console import (\n        ENABLE_VIRTUAL_TERMINAL_PROCESSING,\n        GetConsoleMode,\n        GetStdHandle,\n        LegacyWindowsError,\n    )\n\nexcept (AttributeError, ImportError, ValueError):\n    # Fallback if we can't load the Windows DLL\n    def get_windows_console_features() -> WindowsConsoleFeatures:\n        features = WindowsConsoleFeatures()\n        return features\n\nelse:\n\n    def get_windows_console_features() -> WindowsConsoleFeatures:\n        \"\"\"Get windows console features.\n\n        Returns:\n            WindowsConsoleFeatures: An instance of WindowsConsoleFeatures.\n        \"\"\"\n        handle = GetStdHandle()\n        try:\n            console_mode = GetConsoleMode(handle)\n            success = True\n        except LegacyWindowsError:\n            console_mode = 0\n            success = False\n        vt = bool(success and console_mode & ENABLE_VIRTUAL_TERMINAL_PROCESSING)\n        truecolor = False\n        if vt:\n            win_version = sys.getwindowsversion()\n            truecolor = win_version.major > 10 or (\n                win_version.major == 10 and win_version.build >= 15063\n            )\n        features = WindowsConsoleFeatures(vt=vt, truecolor=truecolor)\n        return features\n\n\nif __name__ == \"__main__\":\n    import platform\n\n    features = get_windows_console_features()\n    from pip._vendor.rich import print\n\n    print(f'platform=\"{platform.system()}\"')\n    print(repr(features))\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_windows_renderer.py": {
      "sha": "f736af40e625",
      "lines": 56,
      "head": "from typing import Iterable, Sequence, Tuple, cast\n\nfrom pip._vendor.rich._win32_console import LegacyWindowsTerm, WindowsCoordinates\nfrom pip._vendor.rich.segment import ControlCode, ControlType, Segment\n\n\ndef legacy_windows_render(buffer: Iterable[Segment], term: LegacyWindowsTerm) -> None:\n    \"\"\"Makes appropriate Windows Console API calls based on the segments in the buffer.\n\n    Args:\n        buffer (Iterable[Segment]): Iterable of Segments to convert to Win32 API calls.\n        term (LegacyWindowsTerm): Used to call the Windows Console API.\n    \"\"\"\n    for text, style, control in buffer:\n        if not control:\n            if style:\n                term.write_styled(text, style)\n            else:\n                term.write_text(text)\n        else:\n            control_codes: Sequence[ControlCode] = control\n            for control_code in control_codes:\n                control_type = control_code[0]\n                if control_type == ControlType.CURSOR_MOVE_TO:\n                    _, x, y = cast(Tuple[ControlType, int, int], control_code)\n                    term.move_cursor_to(WindowsCoordinates(row=y - 1, col=x - 1))\n                elif control_type == ControlType.CARRIAGE_RETURN:\n                    term.write_text(\"\\r\")\n                elif control_type == ControlType.HOME:\n                    term.move_cursor_to(WindowsCoordinates(0, 0))\n                elif control_type == ControlType.CURSOR_UP:\n                    term.move_cursor_up()\n                elif control_type == ControlType.CURSOR_DOWN:\n                    term.move_cursor_down()\n                elif control_type == ControlType.CURSOR_FORWARD:\n                    term.move_cursor_forward()\n                elif control_type == ControlType.CURSOR_BACKWARD:\n                    term.move_cursor_backward()\n                elif control_type == ControlType.CURSOR_MOVE_TO_COLUMN:\n                    _, column = cast(Tuple[ControlType, int], control_code)\n                    term.move_cursor_to_column(column - 1)\n                elif control_type == ControlType.HIDE_CURSOR:\n                    term.hide_cursor()\n                elif control_type == ControlType.SHOW_CURSOR:\n                    term.show_cursor()\n                elif control_type == ControlType.ERASE_IN_LINE:\n                    _, mode = cast(Tuple[ControlType, int], control_code)\n                    if mode == 0:\n                        term.erase_end_of_line()\n                    elif mode == 1:\n                        term.erase_start_of_line()\n                    elif mode == 2:\n                        term.erase_line()\n                elif control_type == ControlType.SET_WINDOW_TITLE:\n                    _, title = cast(Tuple[ControlType, str], control_code)\n                    term.set_title(title)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\_wrap.py": {
      "sha": "3d22539ae35a",
      "lines": 93,
      "head": "from __future__ import annotations\n\nimport re\nfrom typing import Iterable\n\nfrom ._loop import loop_last\nfrom .cells import cell_len, chop_cells\n\nre_word = re.compile(r\"\\s*\\S+\\s*\")\n\n\ndef words(text: str) -> Iterable[tuple[int, int, str]]:\n    \"\"\"Yields each word from the text as a tuple\n    containing (start_index, end_index, word). A \"word\" in this context may\n    include the actual word and any whitespace to the right.\n    \"\"\"\n    position = 0\n    word_match = re_word.match(text, position)\n    while word_match is not None:\n        start, end = word_match.span()\n        word = word_match.group(0)\n        yield start, end, word\n        word_match = re_word.match(text, end)\n\n\ndef divide_line(text: str, width: int, fold: bool = True) -> list[int]:\n    \"\"\"Given a string of text, and a width (measured in cells), return a list\n    of cell offsets which the string should be split at in order for it to fit\n    within the given width.\n\n    Args:\n        text: The text to examine.\n        width: The available cell width.\n        fold: If True, words longer than `width` will be folded onto a new line.\n\n    Returns:\n        A list of indices to break the line at.\n    \"\"\"\n    break_positions: list[int] = []  # offsets to insert the breaks at\n    append = break_positions.append\n    cell_offset = 0\n    _cell_len = cell_len\n\n    for start, _end, word in words(text):\n        word_length = _cell_len(word.rstrip())\n        remaining_space = width - cell_offset\n        word_fits_remaining_space = remaining_space >= word_length\n\n        if word_fits_remaining_space:\n            # Simplest case - the word fits within the remaining width for this line.\n            cell_offset += _cell_len(word)\n        else:\n            # Not enough space remaining for this word on the current line.\n            if word_length > width:\n                # The word doesn't fit on any line, so we can't simply\n                # place it on the next line...\n                if fold:\n                    # Fold the word across multiple lines.\n                    folded_word = chop_cells(word, width=width)\n                    for last, line in loop_last(folded_word):\n                        if start:\n                            append(start)\n                        if last:\n                            cell_offset = _cell_len(line)\n                        else:\n                            start += len(line)\n                else:\n                    # Folding isn't allowed, so crop the word.\n                    if start:\n                        append(start)\n                    cell_offset = _cell_len(word)\n            elif cell_offset and start:\n                # The word doesn't fit within the remaining space on the current\n                # line, but it *can* fit on to the next (empty) line.\n                append(start)\n                cell_offset = _cell_len(word)\n\n    return break_positions\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from .console import Console\n\n    console = Console(width=10)\n    console.print(\"12345 abcdefghijklmnopqrstuvwyxzABCDEFGHIJKLMNOPQRSTUVWXYZ 12345\")\n    print(chop_cells(\"abcdefghijklmnopqrstuvwxyz\", 10))\n\n    console = Console(width=20)\n    console.rule()\n    console.print(\"Textual\u306fPython\u306e\u9ad8\u901f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u958b\u767a\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3067\u3059\")\n\n    console.rule()\n    console.print(\"\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f1670\u4e07\u8272\u3092\u4f7f\u7528\u3067\u304d\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\__init__.py": {
      "sha": "d6b97fece023",
      "lines": 177,
      "head": "\"\"\"Rich text and beautiful formatting in the terminal.\"\"\"\n\nimport os\nfrom typing import IO, TYPE_CHECKING, Any, Callable, Optional, Union\n\nfrom ._extension import load_ipython_extension  # noqa: F401\n\n__all__ = [\"get_console\", \"reconfigure\", \"print\", \"inspect\", \"print_json\"]\n\nif TYPE_CHECKING:\n    from .console import Console\n\n# Global console used by alternative print\n_console: Optional[\"Console\"] = None\n\ntry:\n    _IMPORT_CWD = os.path.abspath(os.getcwd())\nexcept FileNotFoundError:\n    # Can happen if the cwd has been deleted\n    _IMPORT_CWD = \"\"\n\n\ndef get_console() -> \"Console\":\n    \"\"\"Get a global :class:`~rich.console.Console` instance. This function is used when Rich requires a Console,\n    and hasn't been explicitly given one.\n\n    Returns:\n        Console: A console instance.\n    \"\"\"\n    global _console\n    if _console is None:\n        from .console import Console\n\n        _console = Console()\n\n    return _console\n\n\ndef reconfigure(*args: Any, **kwargs: Any) -> None:\n    \"\"\"Reconfigures the global console by replacing it with another.\n\n    Args:\n        *args (Any): Positional arguments for the replacement :class:`~rich.console.Console`.\n        **kwargs (Any): Keyword arguments for the replacement :class:`~rich.console.Console`.\n    \"\"\"\n    from pip._vendor.rich.console import Console\n\n    new_console = Console(*args, **kwargs)\n    _console = get_console()\n    _console.__dict__ = new_console.__dict__\n\n\ndef print(\n    *objects: Any,\n    sep: str = \" \",\n    end: str = \"\\n\",\n    file: Optional[IO[str]] = None,\n    flush: bool = False,\n) -> None:\n    r\"\"\"Print object(s) supplied via positional arguments.\n    This function has an identical signature to the built-in print.\n    For more advanced features, see the :class:`~rich.console.Console` class.\n\n    Args:\n        sep (str, optional): Separator between printed objects. Defaults to \" \".\n        end (str, optional): Character to write at end of output. Defaults to \"\\\\n\".\n        file (IO[str], optional): File to write to, or None for stdout. Defaults to None.\n        flush (bool, optional): Has no effect as Rich always flushes output. Defaults to False.\n\n    \"\"\"\n    from .console import Console\n\n    write_console = get_console() if file is None else Console(file=file)\n    return write_console.print(*objects, sep=sep, end=end)\n\n\ndef print_json(\n    json: Optional[str] = None,\n    *,\n    data: Any = None,\n    indent: Union[None, int, str] = 2,\n    highlight: bool = True,\n    skip_keys: bool = False,\n    ensure_ascii: bool = False,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    default: Optional[Callable[[Any], Any]] = None,\n    sort_keys: bool = False,\n) -> None:\n    \"\"\"Pretty prints JSON. Output will be valid JSON.\n\n    Args:\n        json (str): A string containing JSON.\n        data (Any): If json is not supplied, then encode this data.\n        indent (int, optional): Number of spaces to indent. Defaults to 2.\n        highlight (bool, optional): Enable highlighting of output: Defaults to True.\n        skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.\n        ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.\n        check_circular (bool, optional): Check for circular references. Defaults to True.\n        allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.\n        default (Callable, optional): A callable that converts values that can not be encoded\n            in to something that can be JSON encoded. Defaults to None.\n        sort_keys (bool, optional): Sort dictionary keys. Defaults to False.\n    \"\"\"\n\n    get_console().print_json(\n        json,\n        data=data,\n        indent=indent,\n        highlight=highlight,\n        skip_keys=skip_keys,\n        ensure_ascii=ensure_ascii,\n        check_circular=check_circular,\n        allow_nan=allow_nan,\n        default=default,\n        sort_keys=sort_keys,\n    )\n\n\ndef inspect(\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\rich\\__main__.py": {
      "sha": "537e7ddc00cb",
      "lines": 273,
      "head": "import colorsys\nimport io\nfrom time import process_time\n\nfrom pip._vendor.rich import box\nfrom pip._vendor.rich.color import Color\nfrom pip._vendor.rich.console import Console, ConsoleOptions, Group, RenderableType, RenderResult\nfrom pip._vendor.rich.markdown import Markdown\nfrom pip._vendor.rich.measure import Measurement\nfrom pip._vendor.rich.pretty import Pretty\nfrom pip._vendor.rich.segment import Segment\nfrom pip._vendor.rich.style import Style\nfrom pip._vendor.rich.syntax import Syntax\nfrom pip._vendor.rich.table import Table\nfrom pip._vendor.rich.text import Text\n\n\nclass ColorBox:\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        for y in range(0, 5):\n            for x in range(options.max_width):\n                h = x / options.max_width\n                l = 0.1 + ((y / 5) * 0.7)\n                r1, g1, b1 = colorsys.hls_to_rgb(h, l, 1.0)\n                r2, g2, b2 = colorsys.hls_to_rgb(h, l + 0.7 / 10, 1.0)\n                bgcolor = Color.from_rgb(r1 * 255, g1 * 255, b1 * 255)\n                color = Color.from_rgb(r2 * 255, g2 * 255, b2 * 255)\n                yield Segment(\"\u2584\", Style(color=color, bgcolor=bgcolor))\n            yield Segment.line()\n\n    def __rich_measure__(\n        self, console: \"Console\", options: ConsoleOptions\n    ) -> Measurement:\n        return Measurement(1, options.max_width)\n\n\ndef make_test_card() -> Table:\n    \"\"\"Get a renderable that demonstrates a number of features.\"\"\"\n    table = Table.grid(padding=1, pad_edge=True)\n    table.title = \"Rich features\"\n    table.add_column(\"Feature\", no_wrap=True, justify=\"center\", style=\"bold red\")\n    table.add_column(\"Demonstration\")\n\n    color_table = Table(\n        box=None,\n        expand=False,\n        show_header=False,\n        show_edge=False,\n        pad_edge=False,\n    )\n    color_table.add_row(\n        (\n            \"\u2713 [bold green]4-bit color[/]\\n\"\n            \"\u2713 [bold blue]8-bit color[/]\\n\"\n            \"\u2713 [bold magenta]Truecolor (16.7 million)[/]\\n\"\n            \"\u2713 [bold yellow]Dumb terminals[/]\\n\"\n            \"\u2713 [bold cyan]Automatic color conversion\"\n        ),\n        ColorBox(),\n    )\n\n    table.add_row(\"Colors\", color_table)\n\n    table.add_row(\n        \"Styles\",\n        \"All ansi styles: [bold]bold[/], [dim]dim[/], [italic]italic[/italic], [underline]underline[/], [strike]strikethrough[/], [reverse]reverse[/], and even [blink]blink[/].\",\n    )\n\n    lorem = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Quisque in metus sed sapien ultricies pretium a at justo. Maecenas luctus velit et auctor maximus.\"\n    lorem_table = Table.grid(padding=1, collapse_padding=True)\n    lorem_table.pad_edge = False\n    lorem_table.add_row(\n        Text(lorem, justify=\"left\", style=\"green\"),\n        Text(lorem, justify=\"center\", style=\"yellow\"),\n        Text(lorem, justify=\"right\", style=\"blue\"),\n        Text(lorem, justify=\"full\", style=\"red\"),\n    )\n    table.add_row(\n        \"Text\",\n        Group(\n            Text.from_markup(\n                \"\"\"Word wrap text. Justify [green]left[/], [yellow]center[/], [blue]right[/] or [red]full[/].\\n\"\"\"\n            ),\n            lorem_table,\n        ),\n    )\n\n    def comparison(renderable1: RenderableType, renderable2: RenderableType) -> Table:\n        table = Table(show_header=False, pad_edge=False, box=None, expand=True)\n        table.add_column(\"1\", ratio=1)\n        table.add_column(\"2\", ratio=1)\n        table.add_row(renderable1, renderable2)\n        return table\n\n    table.add_row(\n        \"Asian\\nlanguage\\nsupport\",\n        \":flag_for_china:  \u8be5\u5e93\u652f\u6301\u4e2d\u6587\uff0c\u65e5\u6587\u548c\u97e9\u6587\u6587\u672c\uff01\\n:flag_for_japan:  \u30e9\u30a4\u30d6\u30e9\u30ea\u306f\u4e2d\u56fd\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u97d3\u56fd\u8a9e\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\\n:flag_for_south_korea:  \uc774 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub294 \uc911\uad6d\uc5b4, \uc77c\ubcf8\uc5b4 \ubc0f \ud55c\uad6d\uc5b4 \ud14d\uc2a4\ud2b8\ub97c \uc9c0\uc6d0\ud569\ub2c8\ub2e4\",\n    )\n\n    markup_example = (\n        \"[bold magenta]Rich[/] supports a simple [i]bbcode[/i]-like [b]markup[/b] for [yellow]color[/], [underline]style[/], and emoji! \"\n        \":+1: :apple: :ant: :bear: :baguette_bread: :bus: \"\n    )\n    table.add_row(\"Markup\", markup_example)\n\n    example_table = Table(\n        show_edge=False,\n        show_header=True,\n        expand=False,\n        row_styles=[\"none\", \"dim\"],\n        box=box.SIMPLE,\n    )\n    example_table.add_column(\"[green]Date\", style=\"green\", no_wrap=True)\n    example_table.add_column(\"[blue]Title\", style=\"blue\")\n    example_table.add_column(\n        \"[cyan]Production Budget\",\n        style=\"cyan\",\n        justify=\"right\",\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\_parser.py": {
      "sha": "72b8e73319af",
      "lines": 770,
      "head": "# SPDX-License-Identifier: MIT\n# SPDX-FileCopyrightText: 2021 Taneli Hukkinen\n# Licensed to PSF under a Contributor Agreement.\n\nfrom __future__ import annotations\n\nfrom collections.abc import Iterable\nimport string\nimport sys\nfrom types import MappingProxyType\nfrom typing import IO, Any, Final, NamedTuple\nimport warnings\n\nfrom ._re import (\n    RE_DATETIME,\n    RE_LOCALTIME,\n    RE_NUMBER,\n    match_to_datetime,\n    match_to_localtime,\n    match_to_number,\n)\nfrom ._types import Key, ParseFloat, Pos\n\n# Inline tables/arrays are implemented using recursion. Pathologically\n# nested documents cause pure Python to raise RecursionError (which is OK),\n# but mypyc binary wheels will crash unrecoverably (not OK). According to\n# mypyc docs this will be fixed in the future:\n# https://mypyc.readthedocs.io/en/latest/differences_from_python.html#stack-overflows\n# Before mypyc's fix is in, recursion needs to be limited by this library.\n# Choosing `sys.getrecursionlimit()` as maximum inline table/array nesting\n# level, as it allows more nesting than pure Python, but still seems a far\n# lower number than where mypyc binaries crash.\nMAX_INLINE_NESTING: Final = sys.getrecursionlimit()\n\nASCII_CTRL: Final = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))\n\n# Neither of these sets include quotation mark or backslash. They are\n# currently handled as separate cases in the parser functions.\nILLEGAL_BASIC_STR_CHARS: Final = ASCII_CTRL - frozenset(\"\\t\")\nILLEGAL_MULTILINE_BASIC_STR_CHARS: Final = ASCII_CTRL - frozenset(\"\\t\\n\")\n\nILLEGAL_LITERAL_STR_CHARS: Final = ILLEGAL_BASIC_STR_CHARS\nILLEGAL_MULTILINE_LITERAL_STR_CHARS: Final = ILLEGAL_MULTILINE_BASIC_STR_CHARS\n\nILLEGAL_COMMENT_CHARS: Final = ILLEGAL_BASIC_STR_CHARS\n\nTOML_WS: Final = frozenset(\" \\t\")\nTOML_WS_AND_NEWLINE: Final = TOML_WS | frozenset(\"\\n\")\nBARE_KEY_CHARS: Final = frozenset(string.ascii_letters + string.digits + \"-_\")\nKEY_INITIAL_CHARS: Final = BARE_KEY_CHARS | frozenset(\"\\\"'\")\nHEXDIGIT_CHARS: Final = frozenset(string.hexdigits)\n\nBASIC_STR_ESCAPE_REPLACEMENTS: Final = MappingProxyType(\n    {\n        \"\\\\b\": \"\\u0008\",  # backspace\n        \"\\\\t\": \"\\u0009\",  # tab\n        \"\\\\n\": \"\\u000A\",  # linefeed\n        \"\\\\f\": \"\\u000C\",  # form feed\n        \"\\\\r\": \"\\u000D\",  # carriage return\n        '\\\\\"': \"\\u0022\",  # quote\n        \"\\\\\\\\\": \"\\u005C\",  # backslash\n    }\n)\n\n\nclass DEPRECATED_DEFAULT:\n    \"\"\"Sentinel to be used as default arg during deprecation\n    period of TOMLDecodeError's free-form arguments.\"\"\"\n\n\nclass TOMLDecodeError(ValueError):\n    \"\"\"An error raised if a document is not valid TOML.\n\n    Adds the following attributes to ValueError:\n    msg: The unformatted error message\n    doc: The TOML document being parsed\n    pos: The index of doc where parsing failed\n    lineno: The line corresponding to pos\n    colno: The column corresponding to pos\n    \"\"\"\n\n    def __init__(\n        self,\n        msg: str | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,\n        doc: str | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,\n        pos: Pos | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,\n        *args: Any,\n    ):\n        if (\n            args\n            or not isinstance(msg, str)\n            or not isinstance(doc, str)\n            or not isinstance(pos, int)\n        ):\n            warnings.warn(\n                \"Free-form arguments for TOMLDecodeError are deprecated. \"\n                \"Please set 'msg' (str), 'doc' (str) and 'pos' (int) arguments only.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            if pos is not DEPRECATED_DEFAULT:\n                args = pos, *args\n            if doc is not DEPRECATED_DEFAULT:\n                args = doc, *args\n            if msg is not DEPRECATED_DEFAULT:\n                args = msg, *args\n            ValueError.__init__(self, *args)\n            return\n\n        lineno = doc.count(\"\\n\", 0, pos) + 1\n        if lineno == 1:\n            colno = pos + 1\n        else:\n            colno = pos - doc.rindex(\"\\n\", 0, pos)\n\n        if pos >= len(doc):\n            coord_repr = \"end of document\"\n        else:\n            coord_repr = f\"line {lineno}, column {colno}\"\n        errmsg = f\"{msg} (at {coord_repr})\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\_re.py": {
      "sha": "10f4a1237635",
      "lines": 112,
      "head": "# SPDX-License-Identifier: MIT\n# SPDX-FileCopyrightText: 2021 Taneli Hukkinen\n# Licensed to PSF under a Contributor Agreement.\n\nfrom __future__ import annotations\n\nfrom datetime import date, datetime, time, timedelta, timezone, tzinfo\nfrom functools import lru_cache\nimport re\nfrom typing import Any, Final\n\nfrom ._types import ParseFloat\n\n# E.g.\n# - 00:32:00.999999\n# - 00:32:00\n_TIME_RE_STR: Final = (\n    r\"([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])(?:\\.([0-9]{1,6})[0-9]*)?\"\n)\n\nRE_NUMBER: Final = re.compile(\n    r\"\"\"\n0\n(?:\n    x[0-9A-Fa-f](?:_?[0-9A-Fa-f])*   # hex\n    |\n    b[01](?:_?[01])*                 # bin\n    |\n    o[0-7](?:_?[0-7])*               # oct\n)\n|\n[+-]?(?:0|[1-9](?:_?[0-9])*)         # dec, integer part\n(?P<floatpart>\n    (?:\\.[0-9](?:_?[0-9])*)?         # optional fractional part\n    (?:[eE][+-]?[0-9](?:_?[0-9])*)?  # optional exponent part\n)\n\"\"\",\n    flags=re.VERBOSE,\n)\nRE_LOCALTIME: Final = re.compile(_TIME_RE_STR)\nRE_DATETIME: Final = re.compile(\n    rf\"\"\"\n([0-9]{{4}})-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])  # date, e.g. 1988-10-27\n(?:\n    [Tt ]\n    {_TIME_RE_STR}\n    (?:([Zz])|([+-])([01][0-9]|2[0-3]):([0-5][0-9]))?  # optional time offset\n)?\n\"\"\",\n    flags=re.VERBOSE,\n)\n\n\ndef match_to_datetime(match: re.Match) -> datetime | date:\n    \"\"\"Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.\n\n    Raises ValueError if the match does not correspond to a valid date\n    or datetime.\n    \"\"\"\n    (\n        year_str,\n        month_str,\n        day_str,\n        hour_str,\n        minute_str,\n        sec_str,\n        micros_str,\n        zulu_time,\n        offset_sign_str,\n        offset_hour_str,\n        offset_minute_str,\n    ) = match.groups()\n    year, month, day = int(year_str), int(month_str), int(day_str)\n    if hour_str is None:\n        return date(year, month, day)\n    hour, minute, sec = int(hour_str), int(minute_str), int(sec_str)\n    micros = int(micros_str.ljust(6, \"0\")) if micros_str else 0\n    if offset_sign_str:\n        tz: tzinfo | None = cached_tz(\n            offset_hour_str, offset_minute_str, offset_sign_str\n        )\n    elif zulu_time:\n        tz = timezone.utc\n    else:  # local date-time\n        tz = None\n    return datetime(year, month, day, hour, minute, sec, micros, tzinfo=tz)\n\n\n# No need to limit cache size. This is only ever called on input\n# that matched RE_DATETIME, so there is an implicit bound of\n# 24 (hours) * 60 (minutes) * 2 (offset direction) = 2880.\n@lru_cache(maxsize=None)\ndef cached_tz(hour_str: str, minute_str: str, sign_str: str) -> timezone:\n    sign = 1 if sign_str == \"+\" else -1\n    return timezone(\n        timedelta(\n            hours=sign * int(hour_str),\n            minutes=sign * int(minute_str),\n        )\n    )\n\n\ndef match_to_localtime(match: re.Match) -> time:\n    hour_str, minute_str, sec_str, micros_str = match.groups()\n    micros = int(micros_str.ljust(6, \"0\")) if micros_str else 0\n    return time(int(hour_str), int(minute_str), int(sec_str), micros)\n\n\ndef match_to_number(match: re.Match, parse_float: ParseFloat) -> Any:\n    if match.group(\"floatpart\"):\n        return parse_float(match.group())\n    return int(match.group(), 0)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\_types.py": {
      "sha": "6dc6337d888e",
      "lines": 10,
      "head": "# SPDX-License-Identifier: MIT\n# SPDX-FileCopyrightText: 2021 Taneli Hukkinen\n# Licensed to PSF under a Contributor Agreement.\n\nfrom typing import Any, Callable, Tuple\n\n# Type annotations\nParseFloat = Callable[[str], Any]\nKey = Tuple[str, ...]\nPos = int\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli\\__init__.py": {
      "sha": "112a4884adb8",
      "lines": 8,
      "head": "# SPDX-License-Identifier: MIT\n# SPDX-FileCopyrightText: 2021 Taneli Hukkinen\n# Licensed to PSF under a Contributor Agreement.\n\n__all__ = (\"loads\", \"load\", \"TOMLDecodeError\")\n__version__ = \"2.2.1\"  # DO NOT EDIT THIS LINE MANUALLY. LET bump2version UTILITY DO IT\n\nfrom ._parser import TOMLDecodeError, load, loads\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli_w\\_writer.py": {
      "sha": "fc6fe651470a",
      "lines": 229,
      "head": "from __future__ import annotations\n\nfrom collections.abc import Mapping\nfrom datetime import date, datetime, time\nfrom types import MappingProxyType\n\nTYPE_CHECKING = False\nif TYPE_CHECKING:\n    from collections.abc import Generator\n    from decimal import Decimal\n    from typing import IO, Any, Final\n\nASCII_CTRL = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))\nILLEGAL_BASIC_STR_CHARS = frozenset('\"\\\\') | ASCII_CTRL - frozenset(\"\\t\")\nBARE_KEY_CHARS = frozenset(\n    \"abcdefghijklmnopqrstuvwxyz\" \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" \"0123456789\" \"-_\"\n)\nARRAY_TYPES = (list, tuple)\nMAX_LINE_LENGTH = 100\n\nCOMPACT_ESCAPES = MappingProxyType(\n    {\n        \"\\u0008\": \"\\\\b\",  # backspace\n        \"\\u000A\": \"\\\\n\",  # linefeed\n        \"\\u000C\": \"\\\\f\",  # form feed\n        \"\\u000D\": \"\\\\r\",  # carriage return\n        \"\\u0022\": '\\\\\"',  # quote\n        \"\\u005C\": \"\\\\\\\\\",  # backslash\n    }\n)\n\n\nclass Context:\n    def __init__(self, allow_multiline: bool, indent: int):\n        if indent < 0:\n            raise ValueError(\"Indent width must be non-negative\")\n        self.allow_multiline: Final = allow_multiline\n        # cache rendered inline tables (mapping from object id to rendered inline table)\n        self.inline_table_cache: Final[dict[int, str]] = {}\n        self.indent_str: Final = \" \" * indent\n\n\ndef dump(\n    obj: Mapping[str, Any],\n    fp: IO[bytes],\n    /,\n    *,\n    multiline_strings: bool = False,\n    indent: int = 4,\n) -> None:\n    ctx = Context(multiline_strings, indent)\n    for chunk in gen_table_chunks(obj, ctx, name=\"\"):\n        fp.write(chunk.encode())\n\n\ndef dumps(\n    obj: Mapping[str, Any], /, *, multiline_strings: bool = False, indent: int = 4\n) -> str:\n    ctx = Context(multiline_strings, indent)\n    return \"\".join(gen_table_chunks(obj, ctx, name=\"\"))\n\n\ndef gen_table_chunks(\n    table: Mapping[str, Any],\n    ctx: Context,\n    *,\n    name: str,\n    inside_aot: bool = False,\n) -> Generator[str, None, None]:\n    yielded = False\n    literals = []\n    tables: list[tuple[str, Any, bool]] = []  # => [(key, value, inside_aot)]\n    for k, v in table.items():\n        if isinstance(v, Mapping):\n            tables.append((k, v, False))\n        elif is_aot(v) and not all(is_suitable_inline_table(t, ctx) for t in v):\n            tables.extend((k, t, True) for t in v)\n        else:\n            literals.append((k, v))\n\n    if inside_aot or name and (literals or not tables):\n        yielded = True\n        yield f\"[[{name}]]\\n\" if inside_aot else f\"[{name}]\\n\"\n\n    if literals:\n        yielded = True\n        for k, v in literals:\n            yield f\"{format_key_part(k)} = {format_literal(v, ctx)}\\n\"\n\n    for k, v, in_aot in tables:\n        if yielded:\n            yield \"\\n\"\n        else:\n            yielded = True\n        key_part = format_key_part(k)\n        display_name = f\"{name}.{key_part}\" if name else key_part\n        yield from gen_table_chunks(v, ctx, name=display_name, inside_aot=in_aot)\n\n\ndef format_literal(obj: object, ctx: Context, *, nest_level: int = 0) -> str:\n    if isinstance(obj, bool):\n        return \"true\" if obj else \"false\"\n    if isinstance(obj, (int, float, date, datetime)):\n        return str(obj)\n    if isinstance(obj, time):\n        if obj.tzinfo:\n            raise ValueError(\"TOML does not support offset times\")\n        return str(obj)\n    if isinstance(obj, str):\n        return format_string(obj, allow_multiline=ctx.allow_multiline)\n    if isinstance(obj, ARRAY_TYPES):\n        return format_inline_array(obj, ctx, nest_level)\n    if isinstance(obj, Mapping):\n        return format_inline_table(obj, ctx)\n\n    # Lazy import to improve module import time\n    from decimal import Decimal\n\n    if isinstance(obj, Decimal):\n        return format_decimal(obj)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\tomli_w\\__init__.py": {
      "sha": "88afc4ec0f37",
      "lines": 4,
      "head": "__all__ = (\"dumps\", \"dump\")\n__version__ = \"1.2.0\"  # DO NOT EDIT THIS LINE MANUALLY. LET bump2version UTILITY DO IT\n\nfrom pip._vendor.tomli_w._writer import dump, dumps\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_api.py": {
      "sha": "ae8e9b5c0108",
      "lines": 333,
      "head": "import os\nimport platform\nimport socket\nimport ssl\nimport sys\nimport typing\n\nimport _ssl\n\nfrom ._ssl_constants import (\n    _original_SSLContext,\n    _original_super_SSLContext,\n    _truststore_SSLContext_dunder_class,\n    _truststore_SSLContext_super_class,\n)\n\nif platform.system() == \"Windows\":\n    from ._windows import _configure_context, _verify_peercerts_impl\nelif platform.system() == \"Darwin\":\n    from ._macos import _configure_context, _verify_peercerts_impl\nelse:\n    from ._openssl import _configure_context, _verify_peercerts_impl\n\nif typing.TYPE_CHECKING:\n    from pip._vendor.typing_extensions import Buffer\n\n# From typeshed/stdlib/ssl.pyi\n_StrOrBytesPath: typing.TypeAlias = str | bytes | os.PathLike[str] | os.PathLike[bytes]\n_PasswordType: typing.TypeAlias = str | bytes | typing.Callable[[], str | bytes]\n\n\ndef inject_into_ssl() -> None:\n    \"\"\"Injects the :class:`truststore.SSLContext` into the ``ssl``\n    module by replacing :class:`ssl.SSLContext`.\n    \"\"\"\n    setattr(ssl, \"SSLContext\", SSLContext)\n    # urllib3 holds on to its own reference of ssl.SSLContext\n    # so we need to replace that reference too.\n    try:\n        import pip._vendor.urllib3.util.ssl_ as urllib3_ssl\n\n        setattr(urllib3_ssl, \"SSLContext\", SSLContext)\n    except ImportError:\n        pass\n\n    # requests starting with 2.32.0 added a preloaded SSL context to improve concurrent performance;\n    # this unfortunately leads to a RecursionError, which can be avoided by patching the preloaded SSL context with\n    # the truststore patched instance\n    # also see https://github.com/psf/requests/pull/6667\n    try:\n        from pip._vendor.requests import adapters as requests_adapters\n\n        preloaded_context = getattr(requests_adapters, \"_preloaded_ssl_context\", None)\n        if preloaded_context is not None:\n            setattr(\n                requests_adapters,\n                \"_preloaded_ssl_context\",\n                SSLContext(ssl.PROTOCOL_TLS_CLIENT),\n            )\n    except ImportError:\n        pass\n\n\ndef extract_from_ssl() -> None:\n    \"\"\"Restores the :class:`ssl.SSLContext` class to its original state\"\"\"\n    setattr(ssl, \"SSLContext\", _original_SSLContext)\n    try:\n        import pip._vendor.urllib3.util.ssl_ as urllib3_ssl\n\n        urllib3_ssl.SSLContext = _original_SSLContext  # type: ignore[assignment]\n    except ImportError:\n        pass\n\n\nclass SSLContext(_truststore_SSLContext_super_class):  # type: ignore[misc]\n    \"\"\"SSLContext API that uses system certificates on all platforms\"\"\"\n\n    @property  # type: ignore[misc]\n    def __class__(self) -> type:\n        # Dirty hack to get around isinstance() checks\n        # for ssl.SSLContext instances in aiohttp/trustme\n        # when using non-CPython implementations.\n        return _truststore_SSLContext_dunder_class or SSLContext\n\n    def __init__(self, protocol: int = None) -> None:  # type: ignore[assignment]\n        self._ctx = _original_SSLContext(protocol)\n\n        class TruststoreSSLObject(ssl.SSLObject):\n            # This object exists because wrap_bio() doesn't\n            # immediately do the handshake so we need to do\n            # certificate verifications after SSLObject.do_handshake()\n\n            def do_handshake(self) -> None:\n                ret = super().do_handshake()\n                _verify_peercerts(self, server_hostname=self.server_hostname)\n                return ret\n\n        self._ctx.sslobject_class = TruststoreSSLObject\n\n    def wrap_socket(\n        self,\n        sock: socket.socket,\n        server_side: bool = False,\n        do_handshake_on_connect: bool = True,\n        suppress_ragged_eofs: bool = True,\n        server_hostname: str | None = None,\n        session: ssl.SSLSession | None = None,\n    ) -> ssl.SSLSocket:\n        # Use a context manager here because the\n        # inner SSLContext holds on to our state\n        # but also does the actual handshake.\n        with _configure_context(self._ctx):\n            ssl_sock = self._ctx.wrap_socket(\n                sock,\n                server_side=server_side,\n                server_hostname=server_hostname,\n                do_handshake_on_connect=do_handshake_on_connect,\n                suppress_ragged_eofs=suppress_ragged_eofs,\n                session=session,\n            )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_macos.py": {
      "sha": "dc5d177bcea3",
      "lines": 571,
      "head": "import contextlib\nimport ctypes\nimport platform\nimport ssl\nimport typing\nfrom ctypes import (\n    CDLL,\n    POINTER,\n    c_bool,\n    c_char_p,\n    c_int32,\n    c_long,\n    c_uint32,\n    c_ulong,\n    c_void_p,\n)\nfrom ctypes.util import find_library\n\nfrom ._ssl_constants import _set_ssl_context_verify_mode\n\n_mac_version = platform.mac_ver()[0]\n_mac_version_info = tuple(map(int, _mac_version.split(\".\")))\nif _mac_version_info < (10, 8):\n    raise ImportError(\n        f\"Only OS X 10.8 and newer are supported, not {_mac_version_info[0]}.{_mac_version_info[1]}\"\n    )\n\n_is_macos_version_10_14_or_later = _mac_version_info >= (10, 14)\n\n\ndef _load_cdll(name: str, macos10_16_path: str) -> CDLL:\n    \"\"\"Loads a CDLL by name, falling back to known path on 10.16+\"\"\"\n    try:\n        # Big Sur is technically 11 but we use 10.16 due to the Big Sur\n        # beta being labeled as 10.16.\n        path: str | None\n        if _mac_version_info >= (10, 16):\n            path = macos10_16_path\n        else:\n            path = find_library(name)\n        if not path:\n            raise OSError  # Caught and reraised as 'ImportError'\n        return CDLL(path, use_errno=True)\n    except OSError:\n        raise ImportError(f\"The library {name} failed to load\") from None\n\n\nSecurity = _load_cdll(\n    \"Security\", \"/System/Library/Frameworks/Security.framework/Security\"\n)\nCoreFoundation = _load_cdll(\n    \"CoreFoundation\",\n    \"/System/Library/Frameworks/CoreFoundation.framework/CoreFoundation\",\n)\n\nBoolean = c_bool\nCFIndex = c_long\nCFStringEncoding = c_uint32\nCFData = c_void_p\nCFString = c_void_p\nCFArray = c_void_p\nCFMutableArray = c_void_p\nCFError = c_void_p\nCFType = c_void_p\nCFTypeID = c_ulong\nCFTypeRef = POINTER(CFType)\nCFAllocatorRef = c_void_p\n\nOSStatus = c_int32\n\nCFErrorRef = POINTER(CFError)\nCFDataRef = POINTER(CFData)\nCFStringRef = POINTER(CFString)\nCFArrayRef = POINTER(CFArray)\nCFMutableArrayRef = POINTER(CFMutableArray)\nCFArrayCallBacks = c_void_p\nCFOptionFlags = c_uint32\n\nSecCertificateRef = POINTER(c_void_p)\nSecPolicyRef = POINTER(c_void_p)\nSecTrustRef = POINTER(c_void_p)\nSecTrustResultType = c_uint32\nSecTrustOptionFlags = c_uint32\n\ntry:\n    Security.SecCertificateCreateWithData.argtypes = [CFAllocatorRef, CFDataRef]\n    Security.SecCertificateCreateWithData.restype = SecCertificateRef\n\n    Security.SecCertificateCopyData.argtypes = [SecCertificateRef]\n    Security.SecCertificateCopyData.restype = CFDataRef\n\n    Security.SecCopyErrorMessageString.argtypes = [OSStatus, c_void_p]\n    Security.SecCopyErrorMessageString.restype = CFStringRef\n\n    Security.SecTrustSetAnchorCertificates.argtypes = [SecTrustRef, CFArrayRef]\n    Security.SecTrustSetAnchorCertificates.restype = OSStatus\n\n    Security.SecTrustSetAnchorCertificatesOnly.argtypes = [SecTrustRef, Boolean]\n    Security.SecTrustSetAnchorCertificatesOnly.restype = OSStatus\n\n    Security.SecPolicyCreateRevocation.argtypes = [CFOptionFlags]\n    Security.SecPolicyCreateRevocation.restype = SecPolicyRef\n\n    Security.SecPolicyCreateSSL.argtypes = [Boolean, CFStringRef]\n    Security.SecPolicyCreateSSL.restype = SecPolicyRef\n\n    Security.SecTrustCreateWithCertificates.argtypes = [\n        CFTypeRef,\n        CFTypeRef,\n        POINTER(SecTrustRef),\n    ]\n    Security.SecTrustCreateWithCertificates.restype = OSStatus\n\n    Security.SecTrustGetTrustResult.argtypes = [\n        SecTrustRef,\n        POINTER(SecTrustResultType),\n    ]\n    Security.SecTrustGetTrustResult.restype = OSStatus\n\n    Security.SecTrustEvaluate.argtypes = [\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_openssl.py": {
      "sha": "180fc796b1f3",
      "lines": 66,
      "head": "import contextlib\nimport os\nimport re\nimport ssl\nimport typing\n\n# candidates based on https://github.com/tiran/certifi-system-store by Christian Heimes\n_CA_FILE_CANDIDATES = [\n    # Alpine, Arch, Fedora 34+, OpenWRT, RHEL 9+, BSD\n    \"/etc/ssl/cert.pem\",\n    # Fedora <= 34, RHEL <= 9, CentOS <= 9\n    \"/etc/pki/tls/cert.pem\",\n    # Debian, Ubuntu (requires ca-certificates)\n    \"/etc/ssl/certs/ca-certificates.crt\",\n    # SUSE\n    \"/etc/ssl/ca-bundle.pem\",\n]\n\n_HASHED_CERT_FILENAME_RE = re.compile(r\"^[0-9a-fA-F]{8}\\.[0-9]$\")\n\n\n@contextlib.contextmanager\ndef _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]:\n    # First, check whether the default locations from OpenSSL\n    # seem like they will give us a usable set of CA certs.\n    # ssl.get_default_verify_paths already takes care of:\n    # - getting cafile from either the SSL_CERT_FILE env var\n    #   or the path configured when OpenSSL was compiled,\n    #   and verifying that that path exists\n    # - getting capath from either the SSL_CERT_DIR env var\n    #   or the path configured when OpenSSL was compiled,\n    #   and verifying that that path exists\n    # In addition we'll check whether capath appears to contain certs.\n    defaults = ssl.get_default_verify_paths()\n    if defaults.cafile or (defaults.capath and _capath_contains_certs(defaults.capath)):\n        ctx.set_default_verify_paths()\n    else:\n        # cafile from OpenSSL doesn't exist\n        # and capath from OpenSSL doesn't contain certs.\n        # Let's search other common locations instead.\n        for cafile in _CA_FILE_CANDIDATES:\n            if os.path.isfile(cafile):\n                ctx.load_verify_locations(cafile=cafile)\n                break\n\n    yield\n\n\ndef _capath_contains_certs(capath: str) -> bool:\n    \"\"\"Check whether capath exists and contains certs in the expected format.\"\"\"\n    if not os.path.isdir(capath):\n        return False\n    for name in os.listdir(capath):\n        if _HASHED_CERT_FILENAME_RE.match(name):\n            return True\n    return False\n\n\ndef _verify_peercerts_impl(\n    ssl_context: ssl.SSLContext,\n    cert_chain: list[bytes],\n    server_hostname: str | None = None,\n) -> None:\n    # This is a no-op because we've enabled SSLContext's built-in\n    # verification via verify_mode=CERT_REQUIRED, and don't need to repeat it.\n    pass\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_ssl_constants.py": {
      "sha": "339dae582f9b",
      "lines": 31,
      "head": "import ssl\nimport sys\nimport typing\n\n# Hold on to the original class so we can create it consistently\n# even if we inject our own SSLContext into the ssl module.\n_original_SSLContext = ssl.SSLContext\n_original_super_SSLContext = super(_original_SSLContext, _original_SSLContext)\n\n# CPython is known to be good, but non-CPython implementations\n# may implement SSLContext differently so to be safe we don't\n# subclass the SSLContext.\n\n# This is returned by truststore.SSLContext.__class__()\n_truststore_SSLContext_dunder_class: typing.Optional[type]\n\n# This value is the superclass of truststore.SSLContext.\n_truststore_SSLContext_super_class: type\n\nif sys.implementation.name == \"cpython\":\n    _truststore_SSLContext_super_class = _original_SSLContext\n    _truststore_SSLContext_dunder_class = None\nelse:\n    _truststore_SSLContext_super_class = object\n    _truststore_SSLContext_dunder_class = _original_SSLContext\n\n\ndef _set_ssl_context_verify_mode(\n    ssl_context: ssl.SSLContext, verify_mode: ssl.VerifyMode\n) -> None:\n    _original_super_SSLContext.verify_mode.__set__(ssl_context, verify_mode)  # type: ignore[attr-defined]\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\_windows.py": {
      "sha": "34b0022e88ed",
      "lines": 567,
      "head": "import contextlib\nimport ssl\nimport typing\nfrom ctypes import WinDLL  # type: ignore\nfrom ctypes import WinError  # type: ignore\nfrom ctypes import (\n    POINTER,\n    Structure,\n    c_char_p,\n    c_ulong,\n    c_void_p,\n    c_wchar_p,\n    cast,\n    create_unicode_buffer,\n    pointer,\n    sizeof,\n)\nfrom ctypes.wintypes import (\n    BOOL,\n    DWORD,\n    HANDLE,\n    LONG,\n    LPCSTR,\n    LPCVOID,\n    LPCWSTR,\n    LPFILETIME,\n    LPSTR,\n    LPWSTR,\n)\nfrom typing import TYPE_CHECKING, Any\n\nfrom ._ssl_constants import _set_ssl_context_verify_mode\n\nHCERTCHAINENGINE = HANDLE\nHCERTSTORE = HANDLE\nHCRYPTPROV_LEGACY = HANDLE\n\n\nclass CERT_CONTEXT(Structure):\n    _fields_ = (\n        (\"dwCertEncodingType\", DWORD),\n        (\"pbCertEncoded\", c_void_p),\n        (\"cbCertEncoded\", DWORD),\n        (\"pCertInfo\", c_void_p),\n        (\"hCertStore\", HCERTSTORE),\n    )\n\n\nPCERT_CONTEXT = POINTER(CERT_CONTEXT)\nPCCERT_CONTEXT = POINTER(PCERT_CONTEXT)\n\n\nclass CERT_ENHKEY_USAGE(Structure):\n    _fields_ = (\n        (\"cUsageIdentifier\", DWORD),\n        (\"rgpszUsageIdentifier\", POINTER(LPSTR)),\n    )\n\n\nPCERT_ENHKEY_USAGE = POINTER(CERT_ENHKEY_USAGE)\n\n\nclass CERT_USAGE_MATCH(Structure):\n    _fields_ = (\n        (\"dwType\", DWORD),\n        (\"Usage\", CERT_ENHKEY_USAGE),\n    )\n\n\nclass CERT_CHAIN_PARA(Structure):\n    _fields_ = (\n        (\"cbSize\", DWORD),\n        (\"RequestedUsage\", CERT_USAGE_MATCH),\n        (\"RequestedIssuancePolicy\", CERT_USAGE_MATCH),\n        (\"dwUrlRetrievalTimeout\", DWORD),\n        (\"fCheckRevocationFreshnessTime\", BOOL),\n        (\"dwRevocationFreshnessTime\", DWORD),\n        (\"pftCacheResync\", LPFILETIME),\n        (\"pStrongSignPara\", c_void_p),\n        (\"dwStrongSignFlags\", DWORD),\n    )\n\n\nif TYPE_CHECKING:\n    PCERT_CHAIN_PARA = pointer[CERT_CHAIN_PARA]  # type: ignore[misc]\nelse:\n    PCERT_CHAIN_PARA = POINTER(CERT_CHAIN_PARA)\n\n\nclass CERT_TRUST_STATUS(Structure):\n    _fields_ = (\n        (\"dwErrorStatus\", DWORD),\n        (\"dwInfoStatus\", DWORD),\n    )\n\n\nclass CERT_CHAIN_ELEMENT(Structure):\n    _fields_ = (\n        (\"cbSize\", DWORD),\n        (\"pCertContext\", PCERT_CONTEXT),\n        (\"TrustStatus\", CERT_TRUST_STATUS),\n        (\"pRevocationInfo\", c_void_p),\n        (\"pIssuanceUsage\", PCERT_ENHKEY_USAGE),\n        (\"pApplicationUsage\", PCERT_ENHKEY_USAGE),\n        (\"pwszExtendedErrorInfo\", LPCWSTR),\n    )\n\n\nPCERT_CHAIN_ELEMENT = POINTER(CERT_CHAIN_ELEMENT)\n\n\nclass CERT_SIMPLE_CHAIN(Structure):\n    _fields_ = (\n        (\"cbSize\", DWORD),\n        (\"TrustStatus\", CERT_TRUST_STATUS),\n        (\"cElement\", DWORD),\n        (\"rgpElement\", POINTER(PCERT_CHAIN_ELEMENT)),\n        (\"pTrustListInfo\", c_void_p),\n        (\"fHasRevocationFreshnessTime\", BOOL),\n        (\"dwRevocationFreshnessTime\", DWORD),\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\truststore\\__init__.py": {
      "sha": "fe1fd2b72b0b",
      "lines": 36,
      "head": "\"\"\"Verify certificates using native system trust stores\"\"\"\n\nimport sys as _sys\n\nif _sys.version_info < (3, 10):\n    raise ImportError(\"truststore requires Python 3.10 or later\")\n\n# Detect Python runtimes which don't implement SSLObject.get_unverified_chain() API\n# This API only became public in Python 3.13 but was available in CPython and PyPy since 3.10.\nif _sys.version_info < (3, 13) and _sys.implementation.name not in (\"cpython\", \"pypy\"):\n    try:\n        import ssl as _ssl\n    except ImportError:\n        raise ImportError(\"truststore requires the 'ssl' module\")\n    else:\n        _sslmem = _ssl.MemoryBIO()\n        _sslobj = _ssl.create_default_context().wrap_bio(\n            _sslmem,\n            _sslmem,\n        )\n        try:\n            while not hasattr(_sslobj, \"get_unverified_chain\"):\n                _sslobj = _sslobj._sslobj  # type: ignore[attr-defined]\n        except AttributeError:\n            raise ImportError(\n                \"truststore requires peer certificate chain APIs to be available\"\n            ) from None\n\n        del _ssl, _sslobj, _sslmem  # noqa: F821\n\nfrom ._api import SSLContext, extract_from_ssl, inject_into_ssl  # noqa: E402\n\ndel _api, _sys  # type: ignore[name-defined] # noqa: F821\n\n__all__ = [\"SSLContext\", \"inject_into_ssl\", \"extract_from_ssl\"]\n__version__ = \"0.10.1\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\connection.py": {
      "sha": "407f2d9812a7",
      "lines": 572,
      "head": "from __future__ import absolute_import\n\nimport datetime\nimport logging\nimport os\nimport re\nimport socket\nimport warnings\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\n\nfrom .packages import six\nfrom .packages.six.moves.http_client import HTTPConnection as _HTTPConnection\nfrom .packages.six.moves.http_client import HTTPException  # noqa: F401\nfrom .util.proxy import create_proxy_ssl_context\n\ntry:  # Compiled with SSL?\n    import ssl\n\n    BaseSSLError = ssl.SSLError\nexcept (ImportError, AttributeError):  # Platform-specific: No SSL.\n    ssl = None\n\n    class BaseSSLError(BaseException):\n        pass\n\n\ntry:\n    # Python 3: not a no-op, we're adding this to the namespace so it can be imported.\n    ConnectionError = ConnectionError\nexcept NameError:\n    # Python 2\n    class ConnectionError(Exception):\n        pass\n\n\ntry:  # Python 3:\n    # Not a no-op, we're adding this to the namespace so it can be imported.\n    BrokenPipeError = BrokenPipeError\nexcept NameError:  # Python 2:\n\n    class BrokenPipeError(Exception):\n        pass\n\n\nfrom ._collections import HTTPHeaderDict  # noqa (historical, removed in v2)\nfrom ._version import __version__\nfrom .exceptions import (\n    ConnectTimeoutError,\n    NewConnectionError,\n    SubjectAltNameWarning,\n    SystemTimeWarning,\n)\nfrom .util import SKIP_HEADER, SKIPPABLE_HEADERS, connection\nfrom .util.ssl_ import (\n    assert_fingerprint,\n    create_urllib3_context,\n    is_ipaddress,\n    resolve_cert_reqs,\n    resolve_ssl_version,\n    ssl_wrap_socket,\n)\nfrom .util.ssl_match_hostname import CertificateError, match_hostname\n\nlog = logging.getLogger(__name__)\n\nport_by_scheme = {\"http\": 80, \"https\": 443}\n\n# When it comes time to update this value as a part of regular maintenance\n# (ie test_recent_date is failing) update it to ~6 months before the current date.\nRECENT_DATE = datetime.date(2024, 1, 1)\n\n_CONTAINS_CONTROL_CHAR_RE = re.compile(r\"[^-!#$%&'*+.^_`|~0-9a-zA-Z]\")\n\n\nclass HTTPConnection(_HTTPConnection, object):\n    \"\"\"\n    Based on :class:`http.client.HTTPConnection` but provides an extra constructor\n    backwards-compatibility layer between older and newer Pythons.\n\n    Additional keyword parameters are used to configure attributes of the connection.\n    Accepted parameters include:\n\n    - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`\n    - ``source_address``: Set the source address for the current connection.\n    - ``socket_options``: Set specific options on the underlying socket. If not specified, then\n      defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling\n      Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.\n\n      For example, if you wish to enable TCP Keep Alive in addition to the defaults,\n      you might pass:\n\n      .. code-block:: python\n\n         HTTPConnection.default_socket_options + [\n             (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),\n         ]\n\n      Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).\n    \"\"\"\n\n    default_port = port_by_scheme[\"http\"]\n\n    #: Disable Nagle's algorithm by default.\n    #: ``[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]``\n    default_socket_options = [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]\n\n    #: Whether this connection verifies the host's certificate.\n    is_verified = False\n\n    #: Whether this proxy connection (if used) verifies the proxy host's\n    #: certificate.\n    proxy_is_verified = None\n\n    def __init__(self, *args, **kw):\n        if not six.PY2:\n            kw.pop(\"strict\", None)\n\n        # Pre-set source_address.\n        self.source_address = kw.get(\"source_address\")\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\connectionpool.py": {
      "sha": "2f56a8c8b4e2",
      "lines": 1140,
      "head": "from __future__ import absolute_import\n\nimport errno\nimport logging\nimport re\nimport socket\nimport sys\nimport warnings\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\n\nfrom ._collections import HTTPHeaderDict\nfrom .connection import (\n    BaseSSLError,\n    BrokenPipeError,\n    DummyConnection,\n    HTTPConnection,\n    HTTPException,\n    HTTPSConnection,\n    VerifiedHTTPSConnection,\n    port_by_scheme,\n)\nfrom .exceptions import (\n    ClosedPoolError,\n    EmptyPoolError,\n    HeaderParsingError,\n    HostChangedError,\n    InsecureRequestWarning,\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n    TimeoutError,\n)\nfrom .packages import six\nfrom .packages.six.moves import queue\nfrom .request import RequestMethods\nfrom .response import HTTPResponse\nfrom .util.connection import is_connection_dropped\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.queue import LifoQueue\nfrom .util.request import set_file_position\nfrom .util.response import assert_header_parsing\nfrom .util.retry import Retry\nfrom .util.ssl_match_hostname import CertificateError\nfrom .util.timeout import Timeout\nfrom .util.url import Url, _encode_target\nfrom .util.url import _normalize_host as normalize_host\nfrom .util.url import get_host, parse_url\n\ntry:  # Platform-specific: Python 3\n    import weakref\n\n    weakref_finalize = weakref.finalize\nexcept AttributeError:  # Platform-specific: Python 2\n    from .packages.backports.weakref_finalize import weakref_finalize\n\nxrange = six.moves.xrange\n\nlog = logging.getLogger(__name__)\n\n_Default = object()\n\n\n# Pool objects\nclass ConnectionPool(object):\n    \"\"\"\n    Base class for all connection pools, such as\n    :class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.\n\n    .. note::\n       ConnectionPool.urlopen() does not normalize or percent-encode target URIs\n       which is useful if your target server doesn't support percent-encoded\n       target URIs.\n    \"\"\"\n\n    scheme = None\n    QueueCls = LifoQueue\n\n    def __init__(self, host, port=None):\n        if not host:\n            raise LocationValueError(\"No host specified.\")\n\n        self.host = _normalize_host(host, scheme=self.scheme)\n        self._proxy_host = host.lower()\n        self.port = port\n\n    def __str__(self):\n        return \"%s(host=%r, port=%r)\" % (type(self).__name__, self.host, self.port)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n        # Return False to re-raise any potential exceptions\n        return False\n\n    def close(self):\n        \"\"\"\n        Close all pooled connections and disable the pool.\n        \"\"\"\n        pass\n\n\n# This is taken from http://hg.python.org/cpython/file/7aaba721ebc0/Lib/socket.py#l252\n_blocking_errnos = {errno.EAGAIN, errno.EWOULDBLOCK}\n\n\nclass HTTPConnectionPool(ConnectionPool, RequestMethods):\n    \"\"\"\n    Thread-safe connection pool for one host.\n\n    :param host:\n        Host used for this HTTP Connection (e.g. \"localhost\"), passed into\n        :class:`http.client.HTTPConnection`.\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\exceptions.py": {
      "sha": "ae0a47792b96",
      "lines": 323,
      "head": "from __future__ import absolute_import\n\nfrom .packages.six.moves.http_client import IncompleteRead as httplib_IncompleteRead\n\n# Base Exceptions\n\n\nclass HTTPError(Exception):\n    \"\"\"Base exception used by this module.\"\"\"\n\n    pass\n\n\nclass HTTPWarning(Warning):\n    \"\"\"Base warning used by this module.\"\"\"\n\n    pass\n\n\nclass PoolError(HTTPError):\n    \"\"\"Base exception for errors caused within a pool.\"\"\"\n\n    def __init__(self, pool, message):\n        self.pool = pool\n        HTTPError.__init__(self, \"%s: %s\" % (pool, message))\n\n    def __reduce__(self):\n        # For pickling purposes.\n        return self.__class__, (None, None)\n\n\nclass RequestError(PoolError):\n    \"\"\"Base exception for PoolErrors that have associated URLs.\"\"\"\n\n    def __init__(self, pool, url, message):\n        self.url = url\n        PoolError.__init__(self, pool, message)\n\n    def __reduce__(self):\n        # For pickling purposes.\n        return self.__class__, (None, self.url, None)\n\n\nclass SSLError(HTTPError):\n    \"\"\"Raised when SSL certificate fails in an HTTPS connection.\"\"\"\n\n    pass\n\n\nclass ProxyError(HTTPError):\n    \"\"\"Raised when the connection to a proxy fails.\"\"\"\n\n    def __init__(self, message, error, *args):\n        super(ProxyError, self).__init__(message, error, *args)\n        self.original_error = error\n\n\nclass DecodeError(HTTPError):\n    \"\"\"Raised when automatic decoding based on Content-Type fails.\"\"\"\n\n    pass\n\n\nclass ProtocolError(HTTPError):\n    \"\"\"Raised when something unexpected happens mid-request/response.\"\"\"\n\n    pass\n\n\n#: Renamed to ProtocolError but aliased for backwards compatibility.\nConnectionError = ProtocolError\n\n\n# Leaf Exceptions\n\n\nclass MaxRetryError(RequestError):\n    \"\"\"Raised when the maximum number of retries is exceeded.\n\n    :param pool: The connection pool\n    :type pool: :class:`~urllib3.connectionpool.HTTPConnectionPool`\n    :param string url: The requested Url\n    :param exceptions.Exception reason: The underlying error\n\n    \"\"\"\n\n    def __init__(self, pool, url, reason=None):\n        self.reason = reason\n\n        message = \"Max retries exceeded with url: %s (Caused by %r)\" % (url, reason)\n\n        RequestError.__init__(self, pool, url, message)\n\n\nclass HostChangedError(RequestError):\n    \"\"\"Raised when an existing pool gets a request for a foreign host.\"\"\"\n\n    def __init__(self, pool, url, retries=3):\n        message = \"Tried to open a foreign host with url: %s\" % url\n        RequestError.__init__(self, pool, url, message)\n        self.retries = retries\n\n\nclass TimeoutStateError(HTTPError):\n    \"\"\"Raised when passing an invalid state to a timeout\"\"\"\n\n    pass\n\n\nclass TimeoutError(HTTPError):\n    \"\"\"Raised when a socket timeout error occurs.\n\n    Catching this error will catch both :exc:`ReadTimeoutErrors\n    <ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.\n    \"\"\"\n\n    pass\n\n\nclass ReadTimeoutError(TimeoutError, RequestError):\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\fields.py": {
      "sha": "dfa65a499039",
      "lines": 274,
      "head": "from __future__ import absolute_import\n\nimport email.utils\nimport mimetypes\nimport re\n\nfrom .packages import six\n\n\ndef guess_content_type(filename, default=\"application/octet-stream\"):\n    \"\"\"\n    Guess the \"Content-Type\" of a file.\n\n    :param filename:\n        The filename to guess the \"Content-Type\" of using :mod:`mimetypes`.\n    :param default:\n        If no \"Content-Type\" can be guessed, default to `default`.\n    \"\"\"\n    if filename:\n        return mimetypes.guess_type(filename)[0] or default\n    return default\n\n\ndef format_header_param_rfc2231(name, value):\n    \"\"\"\n    Helper function to format and quote a single header parameter using the\n    strategy defined in RFC 2231.\n\n    Particularly useful for header parameters which might contain\n    non-ASCII values, like file names. This follows\n    `RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.\n\n    :param name:\n        The name of the parameter, a string expected to be ASCII only.\n    :param value:\n        The value of the parameter, provided as ``bytes`` or `str``.\n    :ret:\n        An RFC-2231-formatted unicode string.\n    \"\"\"\n    if isinstance(value, six.binary_type):\n        value = value.decode(\"utf-8\")\n\n    if not any(ch in value for ch in '\"\\\\\\r\\n'):\n        result = u'%s=\"%s\"' % (name, value)\n        try:\n            result.encode(\"ascii\")\n        except (UnicodeEncodeError, UnicodeDecodeError):\n            pass\n        else:\n            return result\n\n    if six.PY2:  # Python 2:\n        value = value.encode(\"utf-8\")\n\n    # encode_rfc2231 accepts an encoded string and returns an ascii-encoded\n    # string in Python 2 but accepts and returns unicode strings in Python 3\n    value = email.utils.encode_rfc2231(value, \"utf-8\")\n    value = \"%s*=%s\" % (name, value)\n\n    if six.PY2:  # Python 2:\n        value = value.decode(\"utf-8\")\n\n    return value\n\n\n_HTML5_REPLACEMENTS = {\n    u\"\\u0022\": u\"%22\",\n    # Replace \"\\\" with \"\\\\\".\n    u\"\\u005C\": u\"\\u005C\\u005C\",\n}\n\n# All control characters from 0x00 to 0x1F *except* 0x1B.\n_HTML5_REPLACEMENTS.update(\n    {\n        six.unichr(cc): u\"%{:02X}\".format(cc)\n        for cc in range(0x00, 0x1F + 1)\n        if cc not in (0x1B,)\n    }\n)\n\n\ndef _replace_multiple(value, needles_and_replacements):\n    def replacer(match):\n        return needles_and_replacements[match.group(0)]\n\n    pattern = re.compile(\n        r\"|\".join([re.escape(needle) for needle in needles_and_replacements.keys()])\n    )\n\n    result = pattern.sub(replacer, value)\n\n    return result\n\n\ndef format_header_param_html5(name, value):\n    \"\"\"\n    Helper function to format and quote a single header parameter using the\n    HTML5 strategy.\n\n    Particularly useful for header parameters which might contain\n    non-ASCII values, like file names. This follows the `HTML5 Working Draft\n    Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.\n\n    .. _HTML5 Working Draft Section 4.10.22.7:\n        https://w3c.github.io/html/sec-forms.html#multipart-form-data\n\n    :param name:\n        The name of the parameter, a string expected to be ASCII only.\n    :param value:\n        The value of the parameter, provided as ``bytes`` or `str``.\n    :ret:\n        A unicode string, stripped of troublesome characters.\n    \"\"\"\n    if isinstance(value, six.binary_type):\n        value = value.decode(\"utf-8\")\n\n    value = _replace_multiple(value, _HTML5_REPLACEMENTS)\n\n    return u'%s=\"%s\"' % (name, value)\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\filepost.py": {
      "sha": "5d0f199cd76d",
      "lines": 98,
      "head": "from __future__ import absolute_import\n\nimport binascii\nimport codecs\nimport os\nfrom io import BytesIO\n\nfrom .fields import RequestField\nfrom .packages import six\nfrom .packages.six import b\n\nwriter = codecs.lookup(\"utf-8\")[3]\n\n\ndef choose_boundary():\n    \"\"\"\n    Our embarrassingly-simple replacement for mimetools.choose_boundary.\n    \"\"\"\n    boundary = binascii.hexlify(os.urandom(16))\n    if not six.PY2:\n        boundary = boundary.decode(\"ascii\")\n    return boundary\n\n\ndef iter_field_objects(fields):\n    \"\"\"\n    Iterate over fields.\n\n    Supports list of (k, v) tuples and dicts, and lists of\n    :class:`~urllib3.fields.RequestField`.\n\n    \"\"\"\n    if isinstance(fields, dict):\n        i = six.iteritems(fields)\n    else:\n        i = iter(fields)\n\n    for field in i:\n        if isinstance(field, RequestField):\n            yield field\n        else:\n            yield RequestField.from_tuples(*field)\n\n\ndef iter_fields(fields):\n    \"\"\"\n    .. deprecated:: 1.6\n\n    Iterate over fields.\n\n    The addition of :class:`~urllib3.fields.RequestField` makes this function\n    obsolete. Instead, use :func:`iter_field_objects`, which returns\n    :class:`~urllib3.fields.RequestField` objects.\n\n    Supports list of (k, v) tuples and dicts.\n    \"\"\"\n    if isinstance(fields, dict):\n        return ((k, v) for k, v in six.iteritems(fields))\n\n    return ((k, v) for k, v in fields)\n\n\ndef encode_multipart_formdata(fields, boundary=None):\n    \"\"\"\n    Encode a dictionary of ``fields`` using the multipart/form-data MIME format.\n\n    :param fields:\n        Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).\n\n    :param boundary:\n        If not specified, then a random boundary will be generated using\n        :func:`urllib3.filepost.choose_boundary`.\n    \"\"\"\n    body = BytesIO()\n    if boundary is None:\n        boundary = choose_boundary()\n\n    for field in iter_field_objects(fields):\n        body.write(b(\"--%s\\r\\n\" % (boundary)))\n\n        writer(body).write(field.render_headers())\n        data = field.data\n\n        if isinstance(data, int):\n            data = str(data)  # Backwards compatibility\n\n        if isinstance(data, six.text_type):\n            writer(body).write(data)\n        else:\n            body.write(data)\n\n        body.write(b\"\\r\\n\")\n\n    body.write(b(\"--%s--\\r\\n\" % (boundary)))\n\n    content_type = str(\"multipart/form-data; boundary=%s\" % boundary)\n\n    return body.getvalue(), content_type\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\poolmanager.py": {
      "sha": "979ab46fb68c",
      "lines": 540,
      "head": "from __future__ import absolute_import\n\nimport collections\nimport functools\nimport logging\n\nfrom ._collections import HTTPHeaderDict, RecentlyUsedContainer\nfrom .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, port_by_scheme\nfrom .exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    ProxySchemeUnknown,\n    ProxySchemeUnsupported,\n    URLSchemeUnknown,\n)\nfrom .packages import six\nfrom .packages.six.moves.urllib.parse import urljoin\nfrom .request import RequestMethods\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.retry import Retry\nfrom .util.url import parse_url\n\n__all__ = [\"PoolManager\", \"ProxyManager\", \"proxy_from_url\"]\n\n\nlog = logging.getLogger(__name__)\n\nSSL_KEYWORDS = (\n    \"key_file\",\n    \"cert_file\",\n    \"cert_reqs\",\n    \"ca_certs\",\n    \"ssl_version\",\n    \"ca_cert_dir\",\n    \"ssl_context\",\n    \"key_password\",\n    \"server_hostname\",\n)\n\n# All known keyword arguments that could be provided to the pool manager, its\n# pools, or the underlying connections. This is used to construct a pool key.\n_key_fields = (\n    \"key_scheme\",  # str\n    \"key_host\",  # str\n    \"key_port\",  # int\n    \"key_timeout\",  # int or float or Timeout\n    \"key_retries\",  # int or Retry\n    \"key_strict\",  # bool\n    \"key_block\",  # bool\n    \"key_source_address\",  # str\n    \"key_key_file\",  # str\n    \"key_key_password\",  # str\n    \"key_cert_file\",  # str\n    \"key_cert_reqs\",  # str\n    \"key_ca_certs\",  # str\n    \"key_ssl_version\",  # str\n    \"key_ca_cert_dir\",  # str\n    \"key_ssl_context\",  # instance of ssl.SSLContext or urllib3.util.ssl_.SSLContext\n    \"key_maxsize\",  # int\n    \"key_headers\",  # dict\n    \"key__proxy\",  # parsed proxy url\n    \"key__proxy_headers\",  # dict\n    \"key__proxy_config\",  # class\n    \"key_socket_options\",  # list of (level (int), optname (int), value (int or str)) tuples\n    \"key__socks_options\",  # dict\n    \"key_assert_hostname\",  # bool or string\n    \"key_assert_fingerprint\",  # str\n    \"key_server_hostname\",  # str\n)\n\n#: The namedtuple class used to construct keys for the connection pool.\n#: All custom key schemes should include the fields in this key at a minimum.\nPoolKey = collections.namedtuple(\"PoolKey\", _key_fields)\n\n_proxy_config_fields = (\"ssl_context\", \"use_forwarding_for_https\")\nProxyConfig = collections.namedtuple(\"ProxyConfig\", _proxy_config_fields)\n\n\ndef _default_key_normalizer(key_class, request_context):\n    \"\"\"\n    Create a pool key out of a request context dictionary.\n\n    According to RFC 3986, both the scheme and host are case-insensitive.\n    Therefore, this function normalizes both before constructing the pool\n    key for an HTTPS request. If you wish to change this behaviour, provide\n    alternate callables to ``key_fn_by_scheme``.\n\n    :param key_class:\n        The class to use when constructing the key. This should be a namedtuple\n        with the ``scheme`` and ``host`` keys at a minimum.\n    :type  key_class: namedtuple\n    :param request_context:\n        A dictionary-like object that contain the context for a request.\n    :type  request_context: dict\n\n    :return: A namedtuple that can be used as a connection pool key.\n    :rtype:  PoolKey\n    \"\"\"\n    # Since we mutate the dictionary, make a copy first\n    context = request_context.copy()\n    context[\"scheme\"] = context[\"scheme\"].lower()\n    context[\"host\"] = context[\"host\"].lower()\n\n    # These are both dictionaries and need to be transformed into frozensets\n    for key in (\"headers\", \"_proxy_headers\", \"_socks_options\"):\n        if key in context and context[key] is not None:\n            context[key] = frozenset(context[key].items())\n\n    # The socket_options key may be a list and needs to be transformed into a\n    # tuple.\n    socket_opts = context.get(\"socket_options\")\n    if socket_opts is not None:\n        context[\"socket_options\"] = tuple(socket_opts)\n\n    # Map the kwargs to the names in the namedtuple - this is necessary since\n    # namedtuples can't have fields starting with '_'.\n    for key in list(context.keys()):\n        context[\"key_\" + key] = context.pop(key)\n\n    # Default to ``None`` for keys missing from the context\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\request.py": {
      "sha": "157989366f7b",
      "lines": 191,
      "head": "from __future__ import absolute_import\n\nimport sys\n\nfrom .filepost import encode_multipart_formdata\nfrom .packages import six\nfrom .packages.six.moves.urllib.parse import urlencode\n\n__all__ = [\"RequestMethods\"]\n\n\nclass RequestMethods(object):\n    \"\"\"\n    Convenience mixin for classes who implement a :meth:`urlopen` method, such\n    as :class:`urllib3.HTTPConnectionPool` and\n    :class:`urllib3.PoolManager`.\n\n    Provides behavior for making common types of HTTP request methods and\n    decides which type of request field encoding to use.\n\n    Specifically,\n\n    :meth:`.request_encode_url` is for sending requests whose fields are\n    encoded in the URL (such as GET, HEAD, DELETE).\n\n    :meth:`.request_encode_body` is for sending requests whose fields are\n    encoded in the *body* of the request using multipart or www-form-urlencoded\n    (such as for POST, PUT, PATCH).\n\n    :meth:`.request` is for making any kind of request, it will look up the\n    appropriate encoding format and use one of the above two methods to make\n    the request.\n\n    Initializer parameters:\n\n    :param headers:\n        Headers to include with all requests, unless other headers are given\n        explicitly.\n    \"\"\"\n\n    _encode_url_methods = {\"DELETE\", \"GET\", \"HEAD\", \"OPTIONS\"}\n\n    def __init__(self, headers=None):\n        self.headers = headers or {}\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        encode_multipart=True,\n        multipart_boundary=None,\n        **kw\n    ):  # Abstract\n        raise NotImplementedError(\n            \"Classes extending RequestMethods must implement \"\n            \"their own ``urlopen`` method.\"\n        )\n\n    def request(self, method, url, fields=None, headers=None, **urlopen_kw):\n        \"\"\"\n        Make a request using :meth:`urlopen` with the appropriate encoding of\n        ``fields`` based on the ``method`` used.\n\n        This is a convenience method that requires the least amount of manual\n        effort. It can be used in most situations, while still having the\n        option to drop down to more specific methods when necessary, such as\n        :meth:`request_encode_url`, :meth:`request_encode_body`,\n        or even the lowest level :meth:`urlopen`.\n        \"\"\"\n        method = method.upper()\n\n        urlopen_kw[\"request_url\"] = url\n\n        if method in self._encode_url_methods:\n            return self.request_encode_url(\n                method, url, fields=fields, headers=headers, **urlopen_kw\n            )\n        else:\n            return self.request_encode_body(\n                method, url, fields=fields, headers=headers, **urlopen_kw\n            )\n\n    def request_encode_url(self, method, url, fields=None, headers=None, **urlopen_kw):\n        \"\"\"\n        Make a request using :meth:`urlopen` with the ``fields`` encoded in\n        the url. This is useful for request methods like GET, HEAD, DELETE, etc.\n        \"\"\"\n        if headers is None:\n            headers = self.headers\n\n        extra_kw = {\"headers\": headers}\n        extra_kw.update(urlopen_kw)\n\n        if fields:\n            url += \"?\" + urlencode(fields)\n\n        return self.urlopen(method, url, **extra_kw)\n\n    def request_encode_body(\n        self,\n        method,\n        url,\n        fields=None,\n        headers=None,\n        encode_multipart=True,\n        multipart_boundary=None,\n        **urlopen_kw\n    ):\n        \"\"\"\n        Make a request using :meth:`urlopen` with the ``fields`` encoded in\n        the body. This is useful for request methods like POST, PUT, PATCH, etc.\n\n        When ``encode_multipart=True`` (default), then\n        :func:`urllib3.encode_multipart_formdata` is used to encode\n        the payload with the appropriate content type. Otherwise\n        :func:`urllib.parse.urlencode` is used with the\n        'application/x-www-form-urlencoded' content type.\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py": {
      "sha": "b29cb7de80c2",
      "lines": 879,
      "head": "from __future__ import absolute_import\n\nimport io\nimport logging\nimport sys\nimport warnings\nimport zlib\nfrom contextlib import contextmanager\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\n\nbrotli = None\n\nfrom . import util\nfrom ._collections import HTTPHeaderDict\nfrom .connection import BaseSSLError, HTTPException\nfrom .exceptions import (\n    BodyNotHttplibCompatible,\n    DecodeError,\n    HTTPError,\n    IncompleteRead,\n    InvalidChunkLength,\n    InvalidHeader,\n    ProtocolError,\n    ReadTimeoutError,\n    ResponseNotChunked,\n    SSLError,\n)\nfrom .packages import six\nfrom .util.response import is_fp_closed, is_response_to_head\n\nlog = logging.getLogger(__name__)\n\n\nclass DeflateDecoder(object):\n    def __init__(self):\n        self._first_try = True\n        self._data = b\"\"\n        self._obj = zlib.decompressobj()\n\n    def __getattr__(self, name):\n        return getattr(self._obj, name)\n\n    def decompress(self, data):\n        if not data:\n            return data\n\n        if not self._first_try:\n            return self._obj.decompress(data)\n\n        self._data += data\n        try:\n            decompressed = self._obj.decompress(data)\n            if decompressed:\n                self._first_try = False\n                self._data = None\n            return decompressed\n        except zlib.error:\n            self._first_try = False\n            self._obj = zlib.decompressobj(-zlib.MAX_WBITS)\n            try:\n                return self.decompress(self._data)\n            finally:\n                self._data = None\n\n\nclass GzipDecoderState(object):\n\n    FIRST_MEMBER = 0\n    OTHER_MEMBERS = 1\n    SWALLOW_DATA = 2\n\n\nclass GzipDecoder(object):\n    def __init__(self):\n        self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)\n        self._state = GzipDecoderState.FIRST_MEMBER\n\n    def __getattr__(self, name):\n        return getattr(self._obj, name)\n\n    def decompress(self, data):\n        ret = bytearray()\n        if self._state == GzipDecoderState.SWALLOW_DATA or not data:\n            return bytes(ret)\n        while True:\n            try:\n                ret += self._obj.decompress(data)\n            except zlib.error:\n                previous_state = self._state\n                # Ignore data after the first error\n                self._state = GzipDecoderState.SWALLOW_DATA\n                if previous_state == GzipDecoderState.OTHER_MEMBERS:\n                    # Allow trailing garbage acceptable in other gzip clients\n                    return bytes(ret)\n                raise\n            data = self._obj.unused_data\n            if not data:\n                return bytes(ret)\n            self._state = GzipDecoderState.OTHER_MEMBERS\n            self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)\n\n\nif brotli is not None:\n\n    class BrotliDecoder(object):\n        # Supports both 'brotlipy' and 'Brotli' packages\n        # since they share an import name. The top branches\n        # are for 'brotlipy' and bottom branches for 'Brotli'\n        def __init__(self):\n            self._obj = brotli.Decompressor()\n            if hasattr(self._obj, \"decompress\"):\n                self.decompress = self._obj.decompress\n            else:\n                self.decompress = self._obj.process\n\n        def flush(self):\n            if hasattr(self._obj, \"flush\"):\n                return self._obj.flush()\n            return b\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\_collections.py": {
      "sha": "ce4646fc0b14",
      "lines": 355,
      "head": "from __future__ import absolute_import\n\ntry:\n    from collections.abc import Mapping, MutableMapping\nexcept ImportError:\n    from collections import Mapping, MutableMapping\ntry:\n    from threading import RLock\nexcept ImportError:  # Platform-specific: No threads available\n\n    class RLock:\n        def __enter__(self):\n            pass\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            pass\n\n\nfrom collections import OrderedDict\n\nfrom .exceptions import InvalidHeader\nfrom .packages import six\nfrom .packages.six import iterkeys, itervalues\n\n__all__ = [\"RecentlyUsedContainer\", \"HTTPHeaderDict\"]\n\n\n_Null = object()\n\n\nclass RecentlyUsedContainer(MutableMapping):\n    \"\"\"\n    Provides a thread-safe dict-like container which maintains up to\n    ``maxsize`` keys while throwing away the least-recently-used keys beyond\n    ``maxsize``.\n\n    :param maxsize:\n        Maximum number of recent elements to retain.\n\n    :param dispose_func:\n        Every time an item is evicted from the container,\n        ``dispose_func(value)`` is called.  Callback which will get called\n    \"\"\"\n\n    ContainerCls = OrderedDict\n\n    def __init__(self, maxsize=10, dispose_func=None):\n        self._maxsize = maxsize\n        self.dispose_func = dispose_func\n\n        self._container = self.ContainerCls()\n        self.lock = RLock()\n\n    def __getitem__(self, key):\n        # Re-insert the item, moving it to the end of the eviction line.\n        with self.lock:\n            item = self._container.pop(key)\n            self._container[key] = item\n            return item\n\n    def __setitem__(self, key, value):\n        evicted_value = _Null\n        with self.lock:\n            # Possibly evict the existing value of 'key'\n            evicted_value = self._container.get(key, _Null)\n            self._container[key] = value\n\n            # If we didn't evict an existing value, we might have to evict the\n            # least recently used item from the beginning of the container.\n            if len(self._container) > self._maxsize:\n                _key, evicted_value = self._container.popitem(last=False)\n\n        if self.dispose_func and evicted_value is not _Null:\n            self.dispose_func(evicted_value)\n\n    def __delitem__(self, key):\n        with self.lock:\n            value = self._container.pop(key)\n\n        if self.dispose_func:\n            self.dispose_func(value)\n\n    def __len__(self):\n        with self.lock:\n            return len(self._container)\n\n    def __iter__(self):\n        raise NotImplementedError(\n            \"Iteration over this class is unlikely to be threadsafe.\"\n        )\n\n    def clear(self):\n        with self.lock:\n            # Copy pointers to all values, then wipe the mapping\n            values = list(itervalues(self._container))\n            self._container.clear()\n\n        if self.dispose_func:\n            for value in values:\n                self.dispose_func(value)\n\n    def keys(self):\n        with self.lock:\n            return list(iterkeys(self._container))\n\n\nclass HTTPHeaderDict(MutableMapping):\n    \"\"\"\n    :param headers:\n        An iterable of field-value pairs. Must not contain multiple field names\n        when compared case-insensitively.\n\n    :param kwargs:\n        Additional field-value pairs to pass in to ``dict.update``.\n\n    A ``dict`` like container for storing HTTP Headers.\n\n    Field names are stored and compared case-insensitively in compliance with\n    RFC 7230. Iteration provides the first case-sensitive key seen for each\n    case-insensitive pair.\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\_version.py": {
      "sha": "215fc0748a45",
      "lines": 2,
      "head": "# This file is protected via CODEOWNERS\n__version__ = \"1.26.20\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\__init__.py": {
      "sha": "cc9234ec06bd",
      "lines": 102,
      "head": "\"\"\"\nPython HTTP library with thread-safe connection pooling, file post support, user friendly, and more\n\"\"\"\nfrom __future__ import absolute_import\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nimport warnings\nfrom logging import NullHandler\n\nfrom . import exceptions\nfrom ._version import __version__\nfrom .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, connection_from_url\nfrom .filepost import encode_multipart_formdata\nfrom .poolmanager import PoolManager, ProxyManager, proxy_from_url\nfrom .response import HTTPResponse\nfrom .util.request import make_headers\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import get_host\n\n# === NOTE TO REPACKAGERS AND VENDORS ===\n# Please delete this block, this logic is only\n# for urllib3 being distributed via PyPI.\n# See: https://github.com/urllib3/urllib3/issues/2680\ntry:\n    import urllib3_secure_extra  # type: ignore # noqa: F401\nexcept ImportError:\n    pass\nelse:\n    warnings.warn(\n        \"'urllib3[secure]' extra is deprecated and will be removed \"\n        \"in a future release of urllib3 2.x. Read more in this issue: \"\n        \"https://github.com/urllib3/urllib3/issues/2680\",\n        category=DeprecationWarning,\n        stacklevel=2,\n    )\n\n__author__ = \"Andrey Petrov (andrey.petrov@shazow.net)\"\n__license__ = \"MIT\"\n__version__ = __version__\n\n__all__ = (\n    \"HTTPConnectionPool\",\n    \"HTTPSConnectionPool\",\n    \"PoolManager\",\n    \"ProxyManager\",\n    \"HTTPResponse\",\n    \"Retry\",\n    \"Timeout\",\n    \"add_stderr_logger\",\n    \"connection_from_url\",\n    \"disable_warnings\",\n    \"encode_multipart_formdata\",\n    \"get_host\",\n    \"make_headers\",\n    \"proxy_from_url\",\n)\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n\ndef add_stderr_logger(level=logging.DEBUG):\n    \"\"\"\n    Helper for quickly adding a StreamHandler to the logger. Useful for\n    debugging.\n\n    Returns the handler after adding it.\n    \"\"\"\n    # This method needs to be in this __init__.py to get the __name__ correct\n    # even if urllib3 is vendored within another package.\n    logger = logging.getLogger(__name__)\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)s %(message)s\"))\n    logger.addHandler(handler)\n    logger.setLevel(level)\n    logger.debug(\"Added a stderr logging handler to logger: %s\", __name__)\n    return handler\n\n\n# ... Clean up.\ndel NullHandler\n\n\n# All warning filters *must* be appended unless you're really certain that they\n# shouldn't be: otherwise, it's very hard for users to use most Python\n# mechanisms to silence them.\n# SecurityWarning's always go off by default.\nwarnings.simplefilter(\"always\", exceptions.SecurityWarning, append=True)\n# SubjectAltNameWarning's should go off once per host\nwarnings.simplefilter(\"default\", exceptions.SubjectAltNameWarning, append=True)\n# InsecurePlatformWarning's don't vary between requests, so we keep it default.\nwarnings.simplefilter(\"default\", exceptions.InsecurePlatformWarning, append=True)\n# SNIMissingWarnings should go off only once.\nwarnings.simplefilter(\"default\", exceptions.SNIMissingWarning, append=True)\n\n\ndef disable_warnings(category=exceptions.HTTPWarning):\n    \"\"\"\n    Helper for quickly disabling all urllib3 warnings.\n    \"\"\"\n    warnings.simplefilter(\"ignore\", category)\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\appengine.py": {
      "sha": "7ad51ea2742a",
      "lines": 314,
      "head": "\"\"\"\nThis module provides a pool manager that uses Google App Engine's\n`URLFetch Service <https://cloud.google.com/appengine/docs/python/urlfetch>`_.\n\nExample usage::\n\n    from pip._vendor.urllib3 import PoolManager\n    from pip._vendor.urllib3.contrib.appengine import AppEngineManager, is_appengine_sandbox\n\n    if is_appengine_sandbox():\n        # AppEngineManager uses AppEngine's URLFetch API behind the scenes\n        http = AppEngineManager()\n    else:\n        # PoolManager uses a socket-level API behind the scenes\n        http = PoolManager()\n\n    r = http.request('GET', 'https://google.com/')\n\nThere are `limitations <https://cloud.google.com/appengine/docs/python/\\\nurlfetch/#Python_Quotas_and_limits>`_ to the URLFetch service and it may not be\nthe best choice for your application. There are three options for using\nurllib3 on Google App Engine:\n\n1. You can use :class:`AppEngineManager` with URLFetch. URLFetch is\n   cost-effective in many circumstances as long as your usage is within the\n   limitations.\n2. You can use a normal :class:`~urllib3.PoolManager` by enabling sockets.\n   Sockets also have `limitations and restrictions\n   <https://cloud.google.com/appengine/docs/python/sockets/\\\n   #limitations-and-restrictions>`_ and have a lower free quota than URLFetch.\n   To use sockets, be sure to specify the following in your ``app.yaml``::\n\n        env_variables:\n            GAE_USE_SOCKETS_HTTPLIB : 'true'\n\n3. If you are using `App Engine Flexible\n<https://cloud.google.com/appengine/docs/flexible/>`_, you can use the standard\n:class:`PoolManager` without any configuration or special environment variables.\n\"\"\"\n\nfrom __future__ import absolute_import\n\nimport io\nimport logging\nimport warnings\n\nfrom ..exceptions import (\n    HTTPError,\n    HTTPWarning,\n    MaxRetryError,\n    ProtocolError,\n    SSLError,\n    TimeoutError,\n)\nfrom ..packages.six.moves.urllib.parse import urljoin\nfrom ..request import RequestMethods\nfrom ..response import HTTPResponse\nfrom ..util.retry import Retry\nfrom ..util.timeout import Timeout\nfrom . import _appengine_environ\n\ntry:\n    from google.appengine.api import urlfetch\nexcept ImportError:\n    urlfetch = None\n\n\nlog = logging.getLogger(__name__)\n\n\nclass AppEnginePlatformWarning(HTTPWarning):\n    pass\n\n\nclass AppEnginePlatformError(HTTPError):\n    pass\n\n\nclass AppEngineManager(RequestMethods):\n    \"\"\"\n    Connection manager for Google App Engine sandbox applications.\n\n    This manager uses the URLFetch service directly instead of using the\n    emulated httplib, and is subject to URLFetch limitations as described in\n    the App Engine documentation `here\n    <https://cloud.google.com/appengine/docs/python/urlfetch>`_.\n\n    Notably it will raise an :class:`AppEnginePlatformError` if:\n        * URLFetch is not available.\n        * If you attempt to use this on App Engine Flexible, as full socket\n          support is available.\n        * If a request size is more than 10 megabytes.\n        * If a response size is more than 32 megabytes.\n        * If you use an unsupported request method such as OPTIONS.\n\n    Beyond those cases, it will raise normal urllib3 errors.\n    \"\"\"\n\n    def __init__(\n        self,\n        headers=None,\n        retries=None,\n        validate_certificate=True,\n        urlfetch_retries=True,\n    ):\n        if not urlfetch:\n            raise AppEnginePlatformError(\n                \"URLFetch is not available in this environment.\"\n            )\n\n        warnings.warn(\n            \"urllib3 is using URLFetch on Google App Engine sandbox instead \"\n            \"of sockets. To use sockets directly instead of URLFetch see \"\n            \"https://urllib3.readthedocs.io/en/1.26.x/reference/urllib3.contrib.html.\",\n            AppEnginePlatformWarning,\n        )\n\n        RequestMethods.__init__(self, headers)\n        self.validate_certificate = validate_certificate\n        self.urlfetch_retries = urlfetch_retries\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\ntlmpool.py": {
      "sha": "40648662db69",
      "lines": 130,
      "head": "\"\"\"\nNTLM authenticating pool, contributed by erikcederstran\n\nIssue #10, see: http://code.google.com/p/urllib3/issues/detail?id=10\n\"\"\"\nfrom __future__ import absolute_import\n\nimport warnings\nfrom logging import getLogger\n\nfrom ntlm import ntlm\n\nfrom .. import HTTPSConnectionPool\nfrom ..packages.six.moves.http_client import HTTPSConnection\n\nwarnings.warn(\n    \"The 'urllib3.contrib.ntlmpool' module is deprecated and will be removed \"\n    \"in urllib3 v2.0 release, urllib3 is not able to support it properly due \"\n    \"to reasons listed in issue: https://github.com/urllib3/urllib3/issues/2282. \"\n    \"If you are a user of this module please comment in the mentioned issue.\",\n    DeprecationWarning,\n)\n\nlog = getLogger(__name__)\n\n\nclass NTLMConnectionPool(HTTPSConnectionPool):\n    \"\"\"\n    Implements an NTLM authentication version of an urllib3 connection pool\n    \"\"\"\n\n    scheme = \"https\"\n\n    def __init__(self, user, pw, authurl, *args, **kwargs):\n        \"\"\"\n        authurl is a random URL on the server that is protected by NTLM.\n        user is the Windows user, probably in the DOMAIN\\\\username format.\n        pw is the password for the user.\n        \"\"\"\n        super(NTLMConnectionPool, self).__init__(*args, **kwargs)\n        self.authurl = authurl\n        self.rawuser = user\n        user_parts = user.split(\"\\\\\", 1)\n        self.domain = user_parts[0].upper()\n        self.user = user_parts[1]\n        self.pw = pw\n\n    def _new_conn(self):\n        # Performs the NTLM handshake that secures the connection. The socket\n        # must be kept open while requests are performed.\n        self.num_connections += 1\n        log.debug(\n            \"Starting NTLM HTTPS connection no. %d: https://%s%s\",\n            self.num_connections,\n            self.host,\n            self.authurl,\n        )\n\n        headers = {\"Connection\": \"Keep-Alive\"}\n        req_header = \"Authorization\"\n        resp_header = \"www-authenticate\"\n\n        conn = HTTPSConnection(host=self.host, port=self.port)\n\n        # Send negotiation message\n        headers[req_header] = \"NTLM %s\" % ntlm.create_NTLM_NEGOTIATE_MESSAGE(\n            self.rawuser\n        )\n        log.debug(\"Request headers: %s\", headers)\n        conn.request(\"GET\", self.authurl, None, headers)\n        res = conn.getresponse()\n        reshdr = dict(res.headers)\n        log.debug(\"Response status: %s %s\", res.status, res.reason)\n        log.debug(\"Response headers: %s\", reshdr)\n        log.debug(\"Response data: %s [...]\", res.read(100))\n\n        # Remove the reference to the socket, so that it can not be closed by\n        # the response object (we want to keep the socket open)\n        res.fp = None\n\n        # Server should respond with a challenge message\n        auth_header_values = reshdr[resp_header].split(\", \")\n        auth_header_value = None\n        for s in auth_header_values:\n            if s[:5] == \"NTLM \":\n                auth_header_value = s[5:]\n        if auth_header_value is None:\n            raise Exception(\n                \"Unexpected %s response header: %s\" % (resp_header, reshdr[resp_header])\n            )\n\n        # Send authentication message\n        ServerChallenge, NegotiateFlags = ntlm.parse_NTLM_CHALLENGE_MESSAGE(\n            auth_header_value\n        )\n        auth_msg = ntlm.create_NTLM_AUTHENTICATE_MESSAGE(\n            ServerChallenge, self.user, self.domain, self.pw, NegotiateFlags\n        )\n        headers[req_header] = \"NTLM %s\" % auth_msg\n        log.debug(\"Request headers: %s\", headers)\n        conn.request(\"GET\", self.authurl, None, headers)\n        res = conn.getresponse()\n        log.debug(\"Response status: %s %s\", res.status, res.reason)\n        log.debug(\"Response headers: %s\", dict(res.headers))\n        log.debug(\"Response data: %s [...]\", res.read()[:100])\n        if res.status != 200:\n            if res.status == 401:\n                raise Exception(\"Server rejected request: wrong username or password\")\n            raise Exception(\"Wrong server response: %s %s\" % (res.status, res.reason))\n\n        res.fp = None\n        log.debug(\"Connection established\")\n        return conn\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\pyopenssl.py": {
      "sha": "f33c6754f3af",
      "lines": 518,
      "head": "\"\"\"\nTLS with SNI_-support for Python 2. Follow these instructions if you would\nlike to verify TLS certificates in Python 2. Note, the default libraries do\n*not* do certificate checking; you need to do additional work to validate\ncertificates yourself.\n\nThis needs the following packages installed:\n\n* `pyOpenSSL`_ (tested with 16.0.0)\n* `cryptography`_ (minimum 1.3.4, from pyopenssl)\n* `idna`_ (minimum 2.0, from cryptography)\n\nHowever, pyopenssl depends on cryptography, which depends on idna, so while we\nuse all three directly here we end up having relatively few packages required.\n\nYou can install them with the following command:\n\n.. code-block:: bash\n\n    $ python -m pip install pyopenssl cryptography idna\n\nTo activate certificate checking, call\n:func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code\nbefore you begin making HTTP requests. This can be done in a ``sitecustomize``\nmodule, or at any other time before your application begins using ``urllib3``,\nlike this:\n\n.. code-block:: python\n\n    try:\n        import pip._vendor.urllib3.contrib.pyopenssl as pyopenssl\n        pyopenssl.inject_into_urllib3()\n    except ImportError:\n        pass\n\nNow you can use :mod:`urllib3` as you normally would, and it will support SNI\nwhen the required modules are installed.\n\nActivating this module also has the positive side effect of disabling SSL/TLS\ncompression in Python 2 (see `CRIME attack`_).\n\n.. _sni: https://en.wikipedia.org/wiki/Server_Name_Indication\n.. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)\n.. _pyopenssl: https://www.pyopenssl.org\n.. _cryptography: https://cryptography.io\n.. _idna: https://github.com/kjd/idna\n\"\"\"\nfrom __future__ import absolute_import\n\nimport OpenSSL.crypto\nimport OpenSSL.SSL\nfrom cryptography import x509\nfrom cryptography.hazmat.backends.openssl import backend as openssl_backend\n\ntry:\n    from cryptography.x509 import UnsupportedExtension\nexcept ImportError:\n    # UnsupportedExtension is gone in cryptography >= 2.1.0\n    class UnsupportedExtension(Exception):\n        pass\n\n\nfrom io import BytesIO\nfrom socket import error as SocketError\nfrom socket import timeout\n\ntry:  # Platform-specific: Python 2\n    from socket import _fileobject\nexcept ImportError:  # Platform-specific: Python 3\n    _fileobject = None\n    from ..packages.backports.makefile import backport_makefile\n\nimport logging\nimport ssl\nimport sys\nimport warnings\n\nfrom .. import util\nfrom ..packages import six\nfrom ..util.ssl_ import PROTOCOL_TLS_CLIENT\n\nwarnings.warn(\n    \"'urllib3.contrib.pyopenssl' module is deprecated and will be removed \"\n    \"in a future release of urllib3 2.x. Read more in this issue: \"\n    \"https://github.com/urllib3/urllib3/issues/2680\",\n    category=DeprecationWarning,\n    stacklevel=2,\n)\n\n__all__ = [\"inject_into_urllib3\", \"extract_from_urllib3\"]\n\n# SNI always works.\nHAS_SNI = True\n\n# Map from urllib3 to PyOpenSSL compatible parameter-values.\n_openssl_versions = {\n    util.PROTOCOL_TLS: OpenSSL.SSL.SSLv23_METHOD,\n    PROTOCOL_TLS_CLIENT: OpenSSL.SSL.SSLv23_METHOD,\n    ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,\n}\n\nif hasattr(ssl, \"PROTOCOL_SSLv3\") and hasattr(OpenSSL.SSL, \"SSLv3_METHOD\"):\n    _openssl_versions[ssl.PROTOCOL_SSLv3] = OpenSSL.SSL.SSLv3_METHOD\n\nif hasattr(ssl, \"PROTOCOL_TLSv1_1\") and hasattr(OpenSSL.SSL, \"TLSv1_1_METHOD\"):\n    _openssl_versions[ssl.PROTOCOL_TLSv1_1] = OpenSSL.SSL.TLSv1_1_METHOD\n\nif hasattr(ssl, \"PROTOCOL_TLSv1_2\") and hasattr(OpenSSL.SSL, \"TLSv1_2_METHOD\"):\n    _openssl_versions[ssl.PROTOCOL_TLSv1_2] = OpenSSL.SSL.TLSv1_2_METHOD\n\n\n_stdlib_to_openssl_verify = {\n    ssl.CERT_NONE: OpenSSL.SSL.VERIFY_NONE,\n    ssl.CERT_OPTIONAL: OpenSSL.SSL.VERIFY_PEER,\n    ssl.CERT_REQUIRED: OpenSSL.SSL.VERIFY_PEER\n    + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,\n}\n_openssl_to_stdlib_verify = dict((v, k) for k, v in _stdlib_to_openssl_verify.items())\n\n# OpenSSL will only write 16K at a time\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\securetransport.py": {
      "sha": "ce2ae9334746",
      "lines": 920,
      "head": "\"\"\"\nSecureTranport support for urllib3 via ctypes.\n\nThis makes platform-native TLS available to urllib3 users on macOS without the\nuse of a compiler. This is an important feature because the Python Package\nIndex is moving to become a TLSv1.2-or-higher server, and the default OpenSSL\nthat ships with macOS is not capable of doing TLSv1.2. The only way to resolve\nthis is to give macOS users an alternative solution to the problem, and that\nsolution is to use SecureTransport.\n\nWe use ctypes here because this solution must not require a compiler. That's\nbecause pip is not allowed to require a compiler either.\n\nThis is not intended to be a seriously long-term solution to this problem.\nThe hope is that PEP 543 will eventually solve this issue for us, at which\npoint we can retire this contrib module. But in the short term, we need to\nsolve the impending tire fire that is Python on Mac without this kind of\ncontrib module. So...here we are.\n\nTo use this module, simply import and inject it::\n\n    import pip._vendor.urllib3.contrib.securetransport as securetransport\n    securetransport.inject_into_urllib3()\n\nHappy TLSing!\n\nThis code is a bastardised version of the code found in Will Bond's oscrypto\nlibrary. An enormous debt is owed to him for blazing this trail for us. For\nthat reason, this code should be considered to be covered both by urllib3's\nlicense and by oscrypto's:\n\n.. code-block::\n\n    Copyright (c) 2015-2016 Will Bond <will@wbond.net>\n\n    Permission is hereby granted, free of charge, to any person obtaining a\n    copy of this software and associated documentation files (the \"Software\"),\n    to deal in the Software without restriction, including without limitation\n    the rights to use, copy, modify, merge, publish, distribute, sublicense,\n    and/or sell copies of the Software, and to permit persons to whom the\n    Software is furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in\n    all copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n    DEALINGS IN THE SOFTWARE.\n\"\"\"\nfrom __future__ import absolute_import\n\nimport contextlib\nimport ctypes\nimport errno\nimport os.path\nimport shutil\nimport socket\nimport ssl\nimport struct\nimport threading\nimport weakref\n\nfrom .. import util\nfrom ..packages import six\nfrom ..util.ssl_ import PROTOCOL_TLS_CLIENT\nfrom ._securetransport.bindings import CoreFoundation, Security, SecurityConst\nfrom ._securetransport.low_level import (\n    _assert_no_error,\n    _build_tls_unknown_ca_alert,\n    _cert_array_from_pem,\n    _create_cfstring_array,\n    _load_client_cert_chain,\n    _temporary_keychain,\n)\n\ntry:  # Platform-specific: Python 2\n    from socket import _fileobject\nexcept ImportError:  # Platform-specific: Python 3\n    _fileobject = None\n    from ..packages.backports.makefile import backport_makefile\n\n__all__ = [\"inject_into_urllib3\", \"extract_from_urllib3\"]\n\n# SNI always works\nHAS_SNI = True\n\norig_util_HAS_SNI = util.HAS_SNI\norig_util_SSLContext = util.ssl_.SSLContext\n\n# This dictionary is used by the read callback to obtain a handle to the\n# calling wrapped socket. This is a pretty silly approach, but for now it'll\n# do. I feel like I should be able to smuggle a handle to the wrapped socket\n# directly in the SSLConnectionRef, but for now this approach will work I\n# guess.\n#\n# We need to lock around this structure for inserts, but we don't do it for\n# reads/writes in the callbacks. The reasoning here goes as follows:\n#\n#    1. It is not possible to call into the callbacks before the dictionary is\n#       populated, so once in the callback the id must be in the dictionary.\n#    2. The callbacks don't mutate the dictionary, they only read from it, and\n#       so cannot conflict with any of the insertions.\n#\n# This is good: if we had to lock in the callbacks we'd drastically slow down\n# the performance of this code.\n_connection_refs = weakref.WeakValueDictionary()\n_connection_ref_lock = threading.Lock()\n\n# Limit writes to 16kB. This is OpenSSL's limit, but we'll cargo-cult it over\n# for no better reason than we need *a* limit, and this one is right there.\nSSL_WRITE_BLOCKSIZE = 16384\n\n# This is our equivalent of util.ssl_.DEFAULT_CIPHERS, but expanded out to\n# individual cipher suites. We need to do this because this is how\n# SecureTransport wants them.\nCIPHER_SUITES = [\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\socks.py": {
      "sha": "3bde3fd1dc48",
      "lines": 216,
      "head": "# -*- coding: utf-8 -*-\n\"\"\"\nThis module contains provisional support for SOCKS proxies from within\nurllib3. This module supports SOCKS4, SOCKS4A (an extension of SOCKS4), and\nSOCKS5. To enable its functionality, either install PySocks or install this\nmodule with the ``socks`` extra.\n\nThe SOCKS implementation supports the full range of urllib3 features. It also\nsupports the following SOCKS features:\n\n- SOCKS4A (``proxy_url='socks4a://...``)\n- SOCKS4 (``proxy_url='socks4://...``)\n- SOCKS5 with remote DNS (``proxy_url='socks5h://...``)\n- SOCKS5 with local DNS (``proxy_url='socks5://...``)\n- Usernames and passwords for the SOCKS proxy\n\n.. note::\n   It is recommended to use ``socks5h://`` or ``socks4a://`` schemes in\n   your ``proxy_url`` to ensure that DNS resolution is done from the remote\n   server instead of client-side when connecting to a domain name.\n\nSOCKS4 supports IPv4 and domain names with the SOCKS4A extension. SOCKS5\nsupports IPv4, IPv6, and domain names.\n\nWhen connecting to a SOCKS4 proxy the ``username`` portion of the ``proxy_url``\nwill be sent as the ``userid`` section of the SOCKS request:\n\n.. code-block:: python\n\n    proxy_url=\"socks4a://<userid>@proxy-host\"\n\nWhen connecting to a SOCKS5 proxy the ``username`` and ``password`` portion\nof the ``proxy_url`` will be sent as the username/password to authenticate\nwith the proxy:\n\n.. code-block:: python\n\n    proxy_url=\"socks5h://<username>:<password>@proxy-host\"\n\n\"\"\"\nfrom __future__ import absolute_import\n\ntry:\n    import socks\nexcept ImportError:\n    import warnings\n\n    from ..exceptions import DependencyWarning\n\n    warnings.warn(\n        (\n            \"SOCKS support in urllib3 requires the installation of optional \"\n            \"dependencies: specifically, PySocks.  For more information, see \"\n            \"https://urllib3.readthedocs.io/en/1.26.x/contrib.html#socks-proxies\"\n        ),\n        DependencyWarning,\n    )\n    raise\n\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\n\nfrom ..connection import HTTPConnection, HTTPSConnection\nfrom ..connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom ..exceptions import ConnectTimeoutError, NewConnectionError\nfrom ..poolmanager import PoolManager\nfrom ..util.url import parse_url\n\ntry:\n    import ssl\nexcept ImportError:\n    ssl = None\n\n\nclass SOCKSConnection(HTTPConnection):\n    \"\"\"\n    A plain-text HTTP connection that connects via a SOCKS proxy.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        self._socks_options = kwargs.pop(\"_socks_options\")\n        super(SOCKSConnection, self).__init__(*args, **kwargs)\n\n    def _new_conn(self):\n        \"\"\"\n        Establish a new connection via the SOCKS proxy.\n        \"\"\"\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\"source_address\"] = self.source_address\n\n        if self.socket_options:\n            extra_kw[\"socket_options\"] = self.socket_options\n\n        try:\n            conn = socks.create_connection(\n                (self.host, self.port),\n                proxy_type=self._socks_options[\"socks_version\"],\n                proxy_addr=self._socks_options[\"proxy_host\"],\n                proxy_port=self._socks_options[\"proxy_port\"],\n                proxy_username=self._socks_options[\"username\"],\n                proxy_password=self._socks_options[\"password\"],\n                proxy_rdns=self._socks_options[\"rdns\"],\n                timeout=self.timeout,\n                **extra_kw\n            )\n\n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \"Connection to %s timed out. (connect timeout=%s)\"\n                % (self.host, self.timeout),\n            )\n\n        except socks.ProxyError as e:\n            # This is fragile as hell, but it seems to be the only way to raise\n            # useful errors here.\n            if e.socket_err:\n                error = e.socket_err\n                if isinstance(error, SocketTimeout):\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\_appengine_environ.py": {
      "sha": "c4cccec3d496",
      "lines": 36,
      "head": "\"\"\"\nThis module provides means to detect the App Engine environment.\n\"\"\"\n\nimport os\n\n\ndef is_appengine():\n    return is_local_appengine() or is_prod_appengine()\n\n\ndef is_appengine_sandbox():\n    \"\"\"Reports if the app is running in the first generation sandbox.\n\n    The second generation runtimes are technically still in a sandbox, but it\n    is much less restrictive, so generally you shouldn't need to check for it.\n    see https://cloud.google.com/appengine/docs/standard/runtimes\n    \"\"\"\n    return is_appengine() and os.environ[\"APPENGINE_RUNTIME\"] == \"python27\"\n\n\ndef is_local_appengine():\n    return \"APPENGINE_RUNTIME\" in os.environ and os.environ.get(\n        \"SERVER_SOFTWARE\", \"\"\n    ).startswith(\"Development/\")\n\n\ndef is_prod_appengine():\n    return \"APPENGINE_RUNTIME\" in os.environ and os.environ.get(\n        \"SERVER_SOFTWARE\", \"\"\n    ).startswith(\"Google App Engine/\")\n\n\ndef is_prod_appengine_mvms():\n    \"\"\"Deprecated.\"\"\"\n    return False\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\_securetransport\\bindings.py": {
      "sha": "5dc00f474814",
      "lines": 519,
      "head": "\"\"\"\nThis module uses ctypes to bind a whole bunch of functions and constants from\nSecureTransport. The goal here is to provide the low-level API to\nSecureTransport. These are essentially the C-level functions and constants, and\nthey're pretty gross to work with.\n\nThis code is a bastardised version of the code found in Will Bond's oscrypto\nlibrary. An enormous debt is owed to him for blazing this trail for us. For\nthat reason, this code should be considered to be covered both by urllib3's\nlicense and by oscrypto's:\n\n    Copyright (c) 2015-2016 Will Bond <will@wbond.net>\n\n    Permission is hereby granted, free of charge, to any person obtaining a\n    copy of this software and associated documentation files (the \"Software\"),\n    to deal in the Software without restriction, including without limitation\n    the rights to use, copy, modify, merge, publish, distribute, sublicense,\n    and/or sell copies of the Software, and to permit persons to whom the\n    Software is furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in\n    all copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n    DEALINGS IN THE SOFTWARE.\n\"\"\"\nfrom __future__ import absolute_import\n\nimport platform\nfrom ctypes import (\n    CDLL,\n    CFUNCTYPE,\n    POINTER,\n    c_bool,\n    c_byte,\n    c_char_p,\n    c_int32,\n    c_long,\n    c_size_t,\n    c_uint32,\n    c_ulong,\n    c_void_p,\n)\nfrom ctypes.util import find_library\n\nfrom ...packages.six import raise_from\n\nif platform.system() != \"Darwin\":\n    raise ImportError(\"Only macOS is supported\")\n\nversion = platform.mac_ver()[0]\nversion_info = tuple(map(int, version.split(\".\")))\nif version_info < (10, 8):\n    raise OSError(\n        \"Only OS X 10.8 and newer are supported, not %s.%s\"\n        % (version_info[0], version_info[1])\n    )\n\n\ndef load_cdll(name, macos10_16_path):\n    \"\"\"Loads a CDLL by name, falling back to known path on 10.16+\"\"\"\n    try:\n        # Big Sur is technically 11 but we use 10.16 due to the Big Sur\n        # beta being labeled as 10.16.\n        if version_info >= (10, 16):\n            path = macos10_16_path\n        else:\n            path = find_library(name)\n        if not path:\n            raise OSError  # Caught and reraised as 'ImportError'\n        return CDLL(path, use_errno=True)\n    except OSError:\n        raise_from(ImportError(\"The library %s failed to load\" % name), None)\n\n\nSecurity = load_cdll(\n    \"Security\", \"/System/Library/Frameworks/Security.framework/Security\"\n)\nCoreFoundation = load_cdll(\n    \"CoreFoundation\",\n    \"/System/Library/Frameworks/CoreFoundation.framework/CoreFoundation\",\n)\n\n\nBoolean = c_bool\nCFIndex = c_long\nCFStringEncoding = c_uint32\nCFData = c_void_p\nCFString = c_void_p\nCFArray = c_void_p\nCFMutableArray = c_void_p\nCFDictionary = c_void_p\nCFError = c_void_p\nCFType = c_void_p\nCFTypeID = c_ulong\n\nCFTypeRef = POINTER(CFType)\nCFAllocatorRef = c_void_p\n\nOSStatus = c_int32\n\nCFDataRef = POINTER(CFData)\nCFStringRef = POINTER(CFString)\nCFArrayRef = POINTER(CFArray)\nCFMutableArrayRef = POINTER(CFMutableArray)\nCFDictionaryRef = POINTER(CFDictionary)\nCFArrayCallBacks = c_void_p\nCFDictionaryKeyCallBacks = c_void_p\nCFDictionaryValueCallBacks = c_void_p\n\nSecCertificateRef = POINTER(c_void_p)\nSecExternalFormat = c_uint32\nSecExternalItemType = c_uint32\nSecIdentityRef = POINTER(c_void_p)\nSecItemImportExportFlags = c_uint32\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\_securetransport\\low_level.py": {
      "sha": "3e0a4a85c263",
      "lines": 397,
      "head": "\"\"\"\nLow-level helpers for the SecureTransport bindings.\n\nThese are Python functions that are not directly related to the high-level APIs\nbut are necessary to get them to work. They include a whole bunch of low-level\nCoreFoundation messing about and memory management. The concerns in this module\nare almost entirely about trying to avoid memory leaks and providing\nappropriate and useful assistance to the higher-level code.\n\"\"\"\nimport base64\nimport ctypes\nimport itertools\nimport os\nimport re\nimport ssl\nimport struct\nimport tempfile\n\nfrom .bindings import CFConst, CoreFoundation, Security\n\n# This regular expression is used to grab PEM data out of a PEM bundle.\n_PEM_CERTS_RE = re.compile(\n    b\"-----BEGIN CERTIFICATE-----\\n(.*?)\\n-----END CERTIFICATE-----\", re.DOTALL\n)\n\n\ndef _cf_data_from_bytes(bytestring):\n    \"\"\"\n    Given a bytestring, create a CFData object from it. This CFData object must\n    be CFReleased by the caller.\n    \"\"\"\n    return CoreFoundation.CFDataCreate(\n        CoreFoundation.kCFAllocatorDefault, bytestring, len(bytestring)\n    )\n\n\ndef _cf_dictionary_from_tuples(tuples):\n    \"\"\"\n    Given a list of Python tuples, create an associated CFDictionary.\n    \"\"\"\n    dictionary_size = len(tuples)\n\n    # We need to get the dictionary keys and values out in the same order.\n    keys = (t[0] for t in tuples)\n    values = (t[1] for t in tuples)\n    cf_keys = (CoreFoundation.CFTypeRef * dictionary_size)(*keys)\n    cf_values = (CoreFoundation.CFTypeRef * dictionary_size)(*values)\n\n    return CoreFoundation.CFDictionaryCreate(\n        CoreFoundation.kCFAllocatorDefault,\n        cf_keys,\n        cf_values,\n        dictionary_size,\n        CoreFoundation.kCFTypeDictionaryKeyCallBacks,\n        CoreFoundation.kCFTypeDictionaryValueCallBacks,\n    )\n\n\ndef _cfstr(py_bstr):\n    \"\"\"\n    Given a Python binary data, create a CFString.\n    The string must be CFReleased by the caller.\n    \"\"\"\n    c_str = ctypes.c_char_p(py_bstr)\n    cf_str = CoreFoundation.CFStringCreateWithCString(\n        CoreFoundation.kCFAllocatorDefault,\n        c_str,\n        CFConst.kCFStringEncodingUTF8,\n    )\n    return cf_str\n\n\ndef _create_cfstring_array(lst):\n    \"\"\"\n    Given a list of Python binary data, create an associated CFMutableArray.\n    The array must be CFReleased by the caller.\n\n    Raises an ssl.SSLError on failure.\n    \"\"\"\n    cf_arr = None\n    try:\n        cf_arr = CoreFoundation.CFArrayCreateMutable(\n            CoreFoundation.kCFAllocatorDefault,\n            0,\n            ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),\n        )\n        if not cf_arr:\n            raise MemoryError(\"Unable to allocate memory!\")\n        for item in lst:\n            cf_str = _cfstr(item)\n            if not cf_str:\n                raise MemoryError(\"Unable to allocate memory!\")\n            try:\n                CoreFoundation.CFArrayAppendValue(cf_arr, cf_str)\n            finally:\n                CoreFoundation.CFRelease(cf_str)\n    except BaseException as e:\n        if cf_arr:\n            CoreFoundation.CFRelease(cf_arr)\n        raise ssl.SSLError(\"Unable to allocate array: %s\" % (e,))\n    return cf_arr\n\n\ndef _cf_string_to_unicode(value):\n    \"\"\"\n    Creates a Unicode string from a CFString object. Used entirely for error\n    reporting.\n\n    Yes, it annoys me quite a lot that this function is this complex.\n    \"\"\"\n    value_as_void_p = ctypes.cast(value, ctypes.POINTER(ctypes.c_void_p))\n\n    string = CoreFoundation.CFStringGetCStringPtr(\n        value_as_void_p, CFConst.kCFStringEncodingUTF8\n    )\n    if string is None:\n        buffer = ctypes.create_string_buffer(1024)\n        result = CoreFoundation.CFStringGetCString(\n            value_as_void_p, buffer, 1024, CFConst.kCFStringEncodingUTF8\n        )\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\contrib\\_securetransport\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\six.py": {
      "sha": "cc785b461d93",
      "lines": 1076,
      "head": "# Copyright (c) 2010-2020 Benjamin Peterson\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\n\"\"\"Utilities for writing code that runs on Python 2 and 3\"\"\"\n\nfrom __future__ import absolute_import\n\nimport functools\nimport itertools\nimport operator\nimport sys\nimport types\n\n__author__ = \"Benjamin Peterson <benjamin@python.org>\"\n__version__ = \"1.16.0\"\n\n\n# Useful for very coarse version differentiation.\nPY2 = sys.version_info[0] == 2\nPY3 = sys.version_info[0] == 3\nPY34 = sys.version_info[0:2] >= (3, 4)\n\nif PY3:\n    string_types = (str,)\n    integer_types = (int,)\n    class_types = (type,)\n    text_type = str\n    binary_type = bytes\n\n    MAXSIZE = sys.maxsize\nelse:\n    string_types = (basestring,)\n    integer_types = (int, long)\n    class_types = (type, types.ClassType)\n    text_type = unicode\n    binary_type = str\n\n    if sys.platform.startswith(\"java\"):\n        # Jython always uses 32 bits.\n        MAXSIZE = int((1 << 31) - 1)\n    else:\n        # It's possible to have sizeof(long) != sizeof(Py_ssize_t).\n        class X(object):\n            def __len__(self):\n                return 1 << 31\n\n        try:\n            len(X())\n        except OverflowError:\n            # 32-bit\n            MAXSIZE = int((1 << 31) - 1)\n        else:\n            # 64-bit\n            MAXSIZE = int((1 << 63) - 1)\n        del X\n\nif PY34:\n    from importlib.util import spec_from_loader\nelse:\n    spec_from_loader = None\n\n\ndef _add_doc(func, doc):\n    \"\"\"Add documentation to a function.\"\"\"\n    func.__doc__ = doc\n\n\ndef _import_module(name):\n    \"\"\"Import module, returning the module after the last dot.\"\"\"\n    __import__(name)\n    return sys.modules[name]\n\n\nclass _LazyDescr(object):\n    def __init__(self, name):\n        self.name = name\n\n    def __get__(self, obj, tp):\n        result = self._resolve()\n        setattr(obj, self.name, result)  # Invokes __set__.\n        try:\n            # This is a bit ugly, but it avoids running this again by\n            # removing this descriptor.\n            delattr(obj.__class__, self.name)\n        except AttributeError:\n            pass\n        return result\n\n\nclass MovedModule(_LazyDescr):\n    def __init__(self, name, old, new=None):\n        super(MovedModule, self).__init__(name)\n        if PY3:\n            if new is None:\n                new = name\n            self.mod = new\n        else:\n            self.mod = old\n\n    def _resolve(self):\n        return _import_module(self.mod)\n\n    def __getattr__(self, attr):\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\backports\\makefile.py": {
      "sha": "df04cdfc4106",
      "lines": 51,
      "head": "# -*- coding: utf-8 -*-\n\"\"\"\nbackports.makefile\n~~~~~~~~~~~~~~~~~~\n\nBackports the Python 3 ``socket.makefile`` method for use with anything that\nwants to create a \"fake\" socket object.\n\"\"\"\nimport io\nfrom socket import SocketIO\n\n\ndef backport_makefile(\n    self, mode=\"r\", buffering=None, encoding=None, errors=None, newline=None\n):\n    \"\"\"\n    Backport of ``socket.makefile`` from Python 3.5.\n    \"\"\"\n    if not set(mode) <= {\"r\", \"w\", \"b\"}:\n        raise ValueError(\"invalid mode %r (only r, w, b allowed)\" % (mode,))\n    writing = \"w\" in mode\n    reading = \"r\" in mode or not writing\n    assert reading or writing\n    binary = \"b\" in mode\n    rawmode = \"\"\n    if reading:\n        rawmode += \"r\"\n    if writing:\n        rawmode += \"w\"\n    raw = SocketIO(self, rawmode)\n    self._makefile_refs += 1\n    if buffering is None:\n        buffering = -1\n    if buffering < 0:\n        buffering = io.DEFAULT_BUFFER_SIZE\n    if buffering == 0:\n        if not binary:\n            raise ValueError(\"unbuffered streams must be binary\")\n        return raw\n    if reading and writing:\n        buffer = io.BufferedRWPair(raw, raw, buffering)\n    elif reading:\n        buffer = io.BufferedReader(raw, buffering)\n    else:\n        assert writing\n        buffer = io.BufferedWriter(raw, buffering)\n    if binary:\n        return buffer\n    text = io.TextIOWrapper(buffer, encoding, errors, newline)\n    text.mode = mode\n    return text\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\backports\\weakref_finalize.py": {
      "sha": "d2ffb6de72f1",
      "lines": 155,
      "head": "# -*- coding: utf-8 -*-\n\"\"\"\nbackports.weakref_finalize\n~~~~~~~~~~~~~~~~~~\n\nBackports the Python 3 ``weakref.finalize`` method.\n\"\"\"\nfrom __future__ import absolute_import\n\nimport itertools\nimport sys\nfrom weakref import ref\n\n__all__ = [\"weakref_finalize\"]\n\n\nclass weakref_finalize(object):\n    \"\"\"Class for finalization of weakrefable objects\n    finalize(obj, func, *args, **kwargs) returns a callable finalizer\n    object which will be called when obj is garbage collected. The\n    first time the finalizer is called it evaluates func(*arg, **kwargs)\n    and returns the result. After this the finalizer is dead, and\n    calling it just returns None.\n    When the program exits any remaining finalizers for which the\n    atexit attribute is true will be run in reverse order of creation.\n    By default atexit is true.\n    \"\"\"\n\n    # Finalizer objects don't have any state of their own.  They are\n    # just used as keys to lookup _Info objects in the registry.  This\n    # ensures that they cannot be part of a ref-cycle.\n\n    __slots__ = ()\n    _registry = {}\n    _shutdown = False\n    _index_iter = itertools.count()\n    _dirty = False\n    _registered_with_atexit = False\n\n    class _Info(object):\n        __slots__ = (\"weakref\", \"func\", \"args\", \"kwargs\", \"atexit\", \"index\")\n\n    def __init__(self, obj, func, *args, **kwargs):\n        if not self._registered_with_atexit:\n            # We may register the exit function more than once because\n            # of a thread race, but that is harmless\n            import atexit\n\n            atexit.register(self._exitfunc)\n            weakref_finalize._registered_with_atexit = True\n        info = self._Info()\n        info.weakref = ref(obj, self)\n        info.func = func\n        info.args = args\n        info.kwargs = kwargs or None\n        info.atexit = True\n        info.index = next(self._index_iter)\n        self._registry[self] = info\n        weakref_finalize._dirty = True\n\n    def __call__(self, _=None):\n        \"\"\"If alive then mark as dead and return func(*args, **kwargs);\n        otherwise return None\"\"\"\n        info = self._registry.pop(self, None)\n        if info and not self._shutdown:\n            return info.func(*info.args, **(info.kwargs or {}))\n\n    def detach(self):\n        \"\"\"If alive then mark as dead and return (obj, func, args, kwargs);\n        otherwise return None\"\"\"\n        info = self._registry.get(self)\n        obj = info and info.weakref()\n        if obj is not None and self._registry.pop(self, None):\n            return (obj, info.func, info.args, info.kwargs or {})\n\n    def peek(self):\n        \"\"\"If alive then return (obj, func, args, kwargs);\n        otherwise return None\"\"\"\n        info = self._registry.get(self)\n        obj = info and info.weakref()\n        if obj is not None:\n            return (obj, info.func, info.args, info.kwargs or {})\n\n    @property\n    def alive(self):\n        \"\"\"Whether finalizer is alive\"\"\"\n        return self in self._registry\n\n    @property\n    def atexit(self):\n        \"\"\"Whether finalizer should be called at exit\"\"\"\n        info = self._registry.get(self)\n        return bool(info) and info.atexit\n\n    @atexit.setter\n    def atexit(self, value):\n        info = self._registry.get(self)\n        if info:\n            info.atexit = bool(value)\n\n    def __repr__(self):\n        info = self._registry.get(self)\n        obj = info and info.weakref()\n        if obj is None:\n            return \"<%s object at %#x; dead>\" % (type(self).__name__, id(self))\n        else:\n            return \"<%s object at %#x; for %r at %#x>\" % (\n                type(self).__name__,\n                id(self),\n                type(obj).__name__,\n                id(obj),\n            )\n\n    @classmethod\n    def _select_for_exit(cls):\n        # Return live finalizers marked for exit, oldest first\n        L = [(f, i) for (f, i) in cls._registry.items() if i.atexit]\n        L.sort(key=lambda item: item[1].index)\n        return [f for (f, i) in L]\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\packages\\backports\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\connection.py": {
      "sha": "4211cec45876",
      "lines": 149,
      "head": "from __future__ import absolute_import\n\nimport socket\n\nfrom ..contrib import _appengine_environ\nfrom ..exceptions import LocationParseError\nfrom ..packages import six\nfrom .wait import NoWayToWaitForSocketError, wait_for_read\n\n\ndef is_connection_dropped(conn):  # Platform-specific\n    \"\"\"\n    Returns True if the connection is dropped and should be closed.\n\n    :param conn:\n        :class:`http.client.HTTPConnection` object.\n\n    Note: For platforms like AppEngine, this will always return ``False`` to\n    let the platform handle connection recycling transparently for us.\n    \"\"\"\n    sock = getattr(conn, \"sock\", False)\n    if sock is False:  # Platform-specific: AppEngine\n        return False\n    if sock is None:  # Connection already closed (such as by httplib).\n        return True\n    try:\n        # Returns True if readable, which here means it's been dropped\n        return wait_for_read(sock, timeout=0.0)\n    except NoWayToWaitForSocketError:  # Platform-specific: AppEngine\n        return False\n\n\n# This function is copied from socket.py in the Python 2.7 standard\n# library test suite. Added to its signature is only `socket_options`.\n# One additional modification is that we avoid binding to IPv6 servers\n# discovered in DNS if the system doesn't have IPv6 functionality.\ndef create_connection(\n    address,\n    timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n    source_address=None,\n    socket_options=None,\n):\n    \"\"\"Connect to *address* and return the socket object.\n\n    Convenience function.  Connect to *address* (a 2-tuple ``(host,\n    port)``) and return the socket object.  Passing the optional\n    *timeout* parameter will set the timeout on the socket instance\n    before attempting to connect.  If no *timeout* is supplied, the\n    global default timeout setting returned by :func:`socket.getdefaulttimeout`\n    is used.  If *source_address* is set it must be a tuple of (host, port)\n    for the socket to bind as a source address before making the connection.\n    An host of '' or port 0 tells the OS to use the default.\n    \"\"\"\n\n    host, port = address\n    if host.startswith(\"[\"):\n        host = host.strip(\"[]\")\n    err = None\n\n    # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n    # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n    # The original create_connection function always returns all records.\n    family = allowed_gai_family()\n\n    try:\n        host.encode(\"idna\")\n    except UnicodeError:\n        return six.raise_from(\n            LocationParseError(u\"'%s', label empty or too long\" % host), None\n        )\n\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n        af, socktype, proto, canonname, sa = res\n        sock = None\n        try:\n            sock = socket.socket(af, socktype, proto)\n\n            # If provided, set socket level options before connecting.\n            _set_socket_options(sock, socket_options)\n\n            if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:\n                sock.settimeout(timeout)\n            if source_address:\n                sock.bind(source_address)\n            sock.connect(sa)\n            return sock\n\n        except socket.error as e:\n            err = e\n            if sock is not None:\n                sock.close()\n                sock = None\n\n    if err is not None:\n        raise err\n\n    raise socket.error(\"getaddrinfo returns an empty list\")\n\n\ndef _set_socket_options(sock, options):\n    if options is None:\n        return\n\n    for opt in options:\n        sock.setsockopt(*opt)\n\n\ndef allowed_gai_family():\n    \"\"\"This function is designed to work in the context of\n    getaddrinfo, where family=socket.AF_UNSPEC is the default and\n    will perform a DNS search for both IPv6 and IPv4 records.\"\"\"\n\n    family = socket.AF_INET\n    if HAS_IPV6:\n        family = socket.AF_UNSPEC\n    return family\n\n\ndef _has_ipv6(host):\n    \"\"\"Returns True if the system can bind an IPv6 address.\"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\proxy.py": {
      "sha": "86f816873904",
      "lines": 57,
      "head": "from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version\n\n\ndef connection_requires_http_tunnel(\n    proxy_url=None, proxy_config=None, destination_scheme=None\n):\n    \"\"\"\n    Returns True if the connection requires an HTTP CONNECT through the proxy.\n\n    :param URL proxy_url:\n        URL of the proxy.\n    :param ProxyConfig proxy_config:\n        Proxy configuration from poolmanager.py\n    :param str destination_scheme:\n        The scheme of the destination. (i.e https, http, etc)\n    \"\"\"\n    # If we're not using a proxy, no way to use a tunnel.\n    if proxy_url is None:\n        return False\n\n    # HTTP destinations never require tunneling, we always forward.\n    if destination_scheme == \"http\":\n        return False\n\n    # Support for forwarding with HTTPS proxies and HTTPS destinations.\n    if (\n        proxy_url.scheme == \"https\"\n        and proxy_config\n        and proxy_config.use_forwarding_for_https\n    ):\n        return False\n\n    # Otherwise always use a tunnel.\n    return True\n\n\ndef create_proxy_ssl_context(\n    ssl_version, cert_reqs, ca_certs=None, ca_cert_dir=None, ca_cert_data=None\n):\n    \"\"\"\n    Generates a default proxy ssl context if one hasn't been provided by the\n    user.\n    \"\"\"\n    ssl_context = create_urllib3_context(\n        ssl_version=resolve_ssl_version(ssl_version),\n        cert_reqs=resolve_cert_reqs(cert_reqs),\n    )\n\n    if (\n        not ca_certs\n        and not ca_cert_dir\n        and not ca_cert_data\n        and hasattr(ssl_context, \"load_default_certs\")\n    ):\n        ssl_context.load_default_certs()\n\n    return ssl_context\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\queue.py": {
      "sha": "f768307325c0",
      "lines": 22,
      "head": "import collections\n\nfrom ..packages import six\nfrom ..packages.six.moves import queue\n\nif six.PY2:\n    # Queue is imported for side effects on MS Windows. See issue #229.\n    import Queue as _unused_module_Queue  # noqa: F401\n\n\nclass LifoQueue(queue.Queue):\n    def _init(self, _):\n        self.queue = collections.deque()\n\n    def _qsize(self, len=len):\n        return len(self.queue)\n\n    def _put(self, item):\n        self.queue.append(item)\n\n    def _get(self):\n        return self.queue.pop()\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\request.py": {
      "sha": "db735e5c86ca",
      "lines": 137,
      "head": "from __future__ import absolute_import\n\nfrom base64 import b64encode\n\nfrom ..exceptions import UnrewindableBodyError\nfrom ..packages.six import b, integer_types\n\n# Pass as a value within ``headers`` to skip\n# emitting some HTTP headers that are added automatically.\n# The only headers that are supported are ``Accept-Encoding``,\n# ``Host``, and ``User-Agent``.\nSKIP_HEADER = \"@@@SKIP_HEADER@@@\"\nSKIPPABLE_HEADERS = frozenset([\"accept-encoding\", \"host\", \"user-agent\"])\n\nACCEPT_ENCODING = \"gzip,deflate\"\n\n_FAILEDTELL = object()\n\n\ndef make_headers(\n    keep_alive=None,\n    accept_encoding=None,\n    user_agent=None,\n    basic_auth=None,\n    proxy_basic_auth=None,\n    disable_cache=None,\n):\n    \"\"\"\n    Shortcuts for generating request headers.\n\n    :param keep_alive:\n        If ``True``, adds 'connection: keep-alive' header.\n\n    :param accept_encoding:\n        Can be a boolean, list, or string.\n        ``True`` translates to 'gzip,deflate'.\n        List will get joined by comma.\n        String will be used as provided.\n\n    :param user_agent:\n        String representing the user-agent you want, such as\n        \"python-urllib3/0.6\"\n\n    :param basic_auth:\n        Colon-separated username:password string for 'authorization: basic ...'\n        auth header.\n\n    :param proxy_basic_auth:\n        Colon-separated username:password string for 'proxy-authorization: basic ...'\n        auth header.\n\n    :param disable_cache:\n        If ``True``, adds 'cache-control: no-cache' header.\n\n    Example::\n\n        >>> make_headers(keep_alive=True, user_agent=\"Batman/1.0\")\n        {'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}\n        >>> make_headers(accept_encoding=True)\n        {'accept-encoding': 'gzip,deflate'}\n    \"\"\"\n    headers = {}\n    if accept_encoding:\n        if isinstance(accept_encoding, str):\n            pass\n        elif isinstance(accept_encoding, list):\n            accept_encoding = \",\".join(accept_encoding)\n        else:\n            accept_encoding = ACCEPT_ENCODING\n        headers[\"accept-encoding\"] = accept_encoding\n\n    if user_agent:\n        headers[\"user-agent\"] = user_agent\n\n    if keep_alive:\n        headers[\"connection\"] = \"keep-alive\"\n\n    if basic_auth:\n        headers[\"authorization\"] = \"Basic \" + b64encode(b(basic_auth)).decode(\"utf-8\")\n\n    if proxy_basic_auth:\n        headers[\"proxy-authorization\"] = \"Basic \" + b64encode(\n            b(proxy_basic_auth)\n        ).decode(\"utf-8\")\n\n    if disable_cache:\n        headers[\"cache-control\"] = \"no-cache\"\n\n    return headers\n\n\ndef set_file_position(body, pos):\n    \"\"\"\n    If a position is provided, move file to that point.\n    Otherwise, we'll attempt to record a position for future use.\n    \"\"\"\n    if pos is not None:\n        rewind_body(body, pos)\n    elif getattr(body, \"tell\", None) is not None:\n        try:\n            pos = body.tell()\n        except (IOError, OSError):\n            # This differentiates from None, allowing us to catch\n            # a failed `tell()` later when trying to rewind the body.\n            pos = _FAILEDTELL\n\n    return pos\n\n\ndef rewind_body(body, body_pos):\n    \"\"\"\n    Attempt to rewind body to a certain position.\n    Primarily used for request redirects and retries.\n\n    :param body:\n        File-like object that supports seek.\n\n    :param int pos:\n        Position to seek to in file.\n    \"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\response.py": {
      "sha": "a3b6dd229aa3",
      "lines": 107,
      "head": "from __future__ import absolute_import\n\nfrom email.errors import MultipartInvariantViolationDefect, StartBoundaryNotFoundDefect\n\nfrom ..exceptions import HeaderParsingError\nfrom ..packages.six.moves import http_client as httplib\n\n\ndef is_fp_closed(obj):\n    \"\"\"\n    Checks whether a given file-like object is closed.\n\n    :param obj:\n        The file-like object to check.\n    \"\"\"\n\n    try:\n        # Check `isclosed()` first, in case Python3 doesn't set `closed`.\n        # GH Issue #928\n        return obj.isclosed()\n    except AttributeError:\n        pass\n\n    try:\n        # Check via the official file-like-object way.\n        return obj.closed\n    except AttributeError:\n        pass\n\n    try:\n        # Check if the object is a container for another file-like object that\n        # gets released on exhaustion (e.g. HTTPResponse).\n        return obj.fp is None\n    except AttributeError:\n        pass\n\n    raise ValueError(\"Unable to determine whether fp is closed.\")\n\n\ndef assert_header_parsing(headers):\n    \"\"\"\n    Asserts whether all headers have been successfully parsed.\n    Extracts encountered errors from the result of parsing headers.\n\n    Only works on Python 3.\n\n    :param http.client.HTTPMessage headers: Headers to verify.\n\n    :raises urllib3.exceptions.HeaderParsingError:\n        If parsing errors are found.\n    \"\"\"\n\n    # This will fail silently if we pass in the wrong kind of parameter.\n    # To make debugging easier add an explicit check.\n    if not isinstance(headers, httplib.HTTPMessage):\n        raise TypeError(\"expected httplib.Message, got {0}.\".format(type(headers)))\n\n    defects = getattr(headers, \"defects\", None)\n    get_payload = getattr(headers, \"get_payload\", None)\n\n    unparsed_data = None\n    if get_payload:\n        # get_payload is actually email.message.Message.get_payload;\n        # we're only interested in the result if it's not a multipart message\n        if not headers.is_multipart():\n            payload = get_payload()\n\n            if isinstance(payload, (bytes, str)):\n                unparsed_data = payload\n    if defects:\n        # httplib is assuming a response body is available\n        # when parsing headers even when httplib only sends\n        # header data to parse_headers() This results in\n        # defects on multipart responses in particular.\n        # See: https://github.com/urllib3/urllib3/issues/800\n\n        # So we ignore the following defects:\n        # - StartBoundaryNotFoundDefect:\n        #     The claimed start boundary was never found.\n        # - MultipartInvariantViolationDefect:\n        #     A message claimed to be a multipart but no subparts were found.\n        defects = [\n            defect\n            for defect in defects\n            if not isinstance(\n                defect, (StartBoundaryNotFoundDefect, MultipartInvariantViolationDefect)\n            )\n        ]\n\n    if defects or unparsed_data:\n        raise HeaderParsingError(defects=defects, unparsed_data=unparsed_data)\n\n\ndef is_response_to_head(response):\n    \"\"\"\n    Checks whether the request of a response has been a HEAD-request.\n    Handles the quirks of AppEngine.\n\n    :param http.client.HTTPResponse response:\n        Response to check if the originating request\n        used 'HEAD' as a method.\n    \"\"\"\n    # FIXME: Can we do this somehow without accessing private httplib _method?\n    method = response._method\n    if isinstance(method, int):  # Platform-specific: Appengine\n        return method == 3\n    return method.upper() == \"HEAD\"\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\retry.py": {
      "sha": "edfffb8aeb67",
      "lines": 622,
      "head": "from __future__ import absolute_import\n\nimport email\nimport logging\nimport re\nimport time\nimport warnings\nfrom collections import namedtuple\nfrom itertools import takewhile\n\nfrom ..exceptions import (\n    ConnectTimeoutError,\n    InvalidHeader,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    ResponseError,\n)\nfrom ..packages import six\n\nlog = logging.getLogger(__name__)\n\n\n# Data structure for representing the metadata of requests that result in a retry.\nRequestHistory = namedtuple(\n    \"RequestHistory\", [\"method\", \"url\", \"error\", \"status\", \"redirect_location\"]\n)\n\n\n# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.\n_Default = object()\n\n\nclass _RetryMeta(type):\n    @property\n    def DEFAULT_METHOD_WHITELIST(cls):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_ALLOWED_METHODS\n\n    @DEFAULT_METHOD_WHITELIST.setter\n    def DEFAULT_METHOD_WHITELIST(cls, value):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_ALLOWED_METHODS = value\n\n    @property\n    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT\n\n    @DEFAULT_REDIRECT_HEADERS_BLACKLIST.setter\n    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls, value):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT = value\n\n    @property\n    def BACKOFF_MAX(cls):\n        warnings.warn(\n            \"Using 'Retry.BACKOFF_MAX' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_BACKOFF_MAX\n\n    @BACKOFF_MAX.setter\n    def BACKOFF_MAX(cls, value):\n        warnings.warn(\n            \"Using 'Retry.BACKOFF_MAX' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_BACKOFF_MAX = value\n\n\n@six.add_metaclass(_RetryMeta)\nclass Retry(object):\n    \"\"\"Retry configuration.\n\n    Each retry attempt will create a new Retry object with updated values, so\n    they can be safely reused.\n\n    Retries can be defined as a default for a pool::\n\n        retries = Retry(connect=5, read=2, redirect=5)\n        http = PoolManager(retries=retries)\n        response = http.request('GET', 'http://example.com/')\n\n    Or per-request (which overrides the default for the pool)::\n\n        response = http.request('GET', 'http://example.com/', retries=Retry(10))\n\n    Retries can be disabled by passing ``False``::\n\n        response = http.request('GET', 'http://example.com/', retries=False)\n\n    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless\n    retries are disabled, in which case the causing exception will be raised.\n\n    :param int total:\n        Total number of retries to allow. Takes precedence over other counts.\n\n        Set to ``None`` to remove this constraint and fall back on other\n        counts.\n\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\ssltransport.py": {
      "sha": "78d59e903fec",
      "lines": 221,
      "head": "import io\nimport socket\nimport ssl\n\nfrom ..exceptions import ProxySchemeUnsupported\nfrom ..packages import six\n\nSSL_BLOCKSIZE = 16384\n\n\nclass SSLTransport:\n    \"\"\"\n    The SSLTransport wraps an existing socket and establishes an SSL connection.\n\n    Contrary to Python's implementation of SSLSocket, it allows you to chain\n    multiple TLS connections together. It's particularly useful if you need to\n    implement TLS within TLS.\n\n    The class supports most of the socket API operations.\n    \"\"\"\n\n    @staticmethod\n    def _validate_ssl_context_for_tls_in_tls(ssl_context):\n        \"\"\"\n        Raises a ProxySchemeUnsupported if the provided ssl_context can't be used\n        for TLS in TLS.\n\n        The only requirement is that the ssl_context provides the 'wrap_bio'\n        methods.\n        \"\"\"\n\n        if not hasattr(ssl_context, \"wrap_bio\"):\n            if six.PY2:\n                raise ProxySchemeUnsupported(\n                    \"TLS in TLS requires SSLContext.wrap_bio() which isn't \"\n                    \"supported on Python 2\"\n                )\n            else:\n                raise ProxySchemeUnsupported(\n                    \"TLS in TLS requires SSLContext.wrap_bio() which isn't \"\n                    \"available on non-native SSLContext\"\n                )\n\n    def __init__(\n        self, socket, ssl_context, server_hostname=None, suppress_ragged_eofs=True\n    ):\n        \"\"\"\n        Create an SSLTransport around socket using the provided ssl_context.\n        \"\"\"\n        self.incoming = ssl.MemoryBIO()\n        self.outgoing = ssl.MemoryBIO()\n\n        self.suppress_ragged_eofs = suppress_ragged_eofs\n        self.socket = socket\n\n        self.sslobj = ssl_context.wrap_bio(\n            self.incoming, self.outgoing, server_hostname=server_hostname\n        )\n\n        # Perform initial handshake.\n        self._ssl_io_loop(self.sslobj.do_handshake)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *_):\n        self.close()\n\n    def fileno(self):\n        return self.socket.fileno()\n\n    def read(self, len=1024, buffer=None):\n        return self._wrap_ssl_read(len, buffer)\n\n    def recv(self, len=1024, flags=0):\n        if flags != 0:\n            raise ValueError(\"non-zero flags not allowed in calls to recv\")\n        return self._wrap_ssl_read(len)\n\n    def recv_into(self, buffer, nbytes=None, flags=0):\n        if flags != 0:\n            raise ValueError(\"non-zero flags not allowed in calls to recv_into\")\n        if buffer and (nbytes is None):\n            nbytes = len(buffer)\n        elif nbytes is None:\n            nbytes = 1024\n        return self.read(nbytes, buffer)\n\n    def sendall(self, data, flags=0):\n        if flags != 0:\n            raise ValueError(\"non-zero flags not allowed in calls to sendall\")\n        count = 0\n        with memoryview(data) as view, view.cast(\"B\") as byte_view:\n            amount = len(byte_view)\n            while count < amount:\n                v = self.send(byte_view[count:])\n                count += v\n\n    def send(self, data, flags=0):\n        if flags != 0:\n            raise ValueError(\"non-zero flags not allowed in calls to send\")\n        response = self._ssl_io_loop(self.sslobj.write, data)\n        return response\n\n    def makefile(\n        self, mode=\"r\", buffering=None, encoding=None, errors=None, newline=None\n    ):\n        \"\"\"\n        Python's httpclient uses makefile and buffered io when reading HTTP\n        messages and we need to support it.\n\n        This is unfortunately a copy and paste of socket.py makefile with small\n        changes to point to the socket directly.\n        \"\"\"\n        if not set(mode) <= {\"r\", \"w\", \"b\"}:\n            raise ValueError(\"invalid mode %r (only r, w, b allowed)\" % (mode,))\n\n        writing = \"w\" in mode\n        reading = \"r\" in mode or not writing\n        assert reading or writing\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\ssl_.py": {
      "sha": "7ca3e8530a9f",
      "lines": 504,
      "head": "from __future__ import absolute_import\n\nimport hashlib\nimport hmac\nimport os\nimport sys\nimport warnings\nfrom binascii import hexlify, unhexlify\n\nfrom ..exceptions import (\n    InsecurePlatformWarning,\n    ProxySchemeUnsupported,\n    SNIMissingWarning,\n    SSLError,\n)\nfrom ..packages import six\nfrom .url import BRACELESS_IPV6_ADDRZ_RE, IPV4_RE\n\nSSLContext = None\nSSLTransport = None\nHAS_SNI = False\nIS_PYOPENSSL = False\nIS_SECURETRANSPORT = False\nALPN_PROTOCOLS = [\"http/1.1\"]\n\n# Maps the length of a digest to a possible hash function producing this digest\nHASHFUNC_MAP = {\n    length: getattr(hashlib, algorithm, None)\n    for length, algorithm in ((32, \"md5\"), (40, \"sha1\"), (64, \"sha256\"))\n}\n\n\ndef _const_compare_digest_backport(a, b):\n    \"\"\"\n    Compare two digests of equal length in constant time.\n\n    The digests must be of type str/bytes.\n    Returns True if the digests match, and False otherwise.\n    \"\"\"\n    result = abs(len(a) - len(b))\n    for left, right in zip(bytearray(a), bytearray(b)):\n        result |= left ^ right\n    return result == 0\n\n\n_const_compare_digest = getattr(hmac, \"compare_digest\", _const_compare_digest_backport)\n\ntry:  # Test for SSL features\n    import ssl\n    from ssl import CERT_REQUIRED, wrap_socket\nexcept ImportError:\n    pass\n\ntry:\n    from ssl import HAS_SNI  # Has SNI?\nexcept ImportError:\n    pass\n\ntry:\n    from .ssltransport import SSLTransport\nexcept ImportError:\n    pass\n\n\ntry:  # Platform-specific: Python 3.6\n    from ssl import PROTOCOL_TLS\n\n    PROTOCOL_SSLv23 = PROTOCOL_TLS\nexcept ImportError:\n    try:\n        from ssl import PROTOCOL_SSLv23 as PROTOCOL_TLS\n\n        PROTOCOL_SSLv23 = PROTOCOL_TLS\n    except ImportError:\n        PROTOCOL_SSLv23 = PROTOCOL_TLS = 2\n\ntry:\n    from ssl import PROTOCOL_TLS_CLIENT\nexcept ImportError:\n    PROTOCOL_TLS_CLIENT = PROTOCOL_TLS\n\n\ntry:\n    from ssl import OP_NO_COMPRESSION, OP_NO_SSLv2, OP_NO_SSLv3\nexcept ImportError:\n    OP_NO_SSLv2, OP_NO_SSLv3 = 0x1000000, 0x2000000\n    OP_NO_COMPRESSION = 0x20000\n\n\ntry:  # OP_NO_TICKET was added in Python 3.6\n    from ssl import OP_NO_TICKET\nexcept ImportError:\n    OP_NO_TICKET = 0x4000\n\n\n# A secure default.\n# Sources for more information on TLS ciphers:\n#\n# - https://wiki.mozilla.org/Security/Server_Side_TLS\n# - https://www.ssllabs.com/projects/best-practices/index.html\n# - https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/\n#\n# The general intent is:\n# - prefer cipher suites that offer perfect forward secrecy (DHE/ECDHE),\n# - prefer ECDHE over DHE for better performance,\n# - prefer any AES-GCM and ChaCha20 over any AES-CBC for better performance and\n#   security,\n# - prefer AES-GCM over ChaCha20 because hardware-accelerated AES is common,\n# - disable NULL authentication, MD5 MACs, DSS, and other\n#   insecure ciphers for security reasons.\n# - NOTE: TLS 1.3 cipher suites are managed through a different interface\n#   not exposed by CPython (yet!) and are enabled by default if they're available.\nDEFAULT_CIPHERS = \":\".join(\n    [\n        \"ECDHE+AESGCM\",\n        \"ECDHE+CHACHA20\",\n        \"DHE+AESGCM\",\n        \"DHE+CHACHA20\",\n        \"ECDH+AESGCM\",\n        \"DH+AESGCM\",\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\ssl_match_hostname.py": {
      "sha": "e1f6ab140aa5",
      "lines": 159,
      "head": "\"\"\"The match_hostname() function from Python 3.3.3, essential when using SSL.\"\"\"\n\n# Note: This file is under the PSF license as the code comes from the python\n# stdlib.   http://docs.python.org/3/license.html\n\nimport re\nimport sys\n\n# ipaddress has been backported to 2.6+ in pypi.  If it is installed on the\n# system, use it to handle IPAddress ServerAltnames (this was added in\n# python-3.5) otherwise only do DNS matching.  This allows\n# util.ssl_match_hostname to continue to be used in Python 2.7.\ntry:\n    import ipaddress\nexcept ImportError:\n    ipaddress = None\n\n__version__ = \"3.5.0.1\"\n\n\nclass CertificateError(ValueError):\n    pass\n\n\ndef _dnsname_match(dn, hostname, max_wildcards=1):\n    \"\"\"Matching according to RFC 6125, section 6.4.3\n\n    http://tools.ietf.org/html/rfc6125#section-6.4.3\n    \"\"\"\n    pats = []\n    if not dn:\n        return False\n\n    # Ported from python3-syntax:\n    # leftmost, *remainder = dn.split(r'.')\n    parts = dn.split(r\".\")\n    leftmost = parts[0]\n    remainder = parts[1:]\n\n    wildcards = leftmost.count(\"*\")\n    if wildcards > max_wildcards:\n        # Issue #17980: avoid denials of service by refusing more\n        # than one wildcard per fragment.  A survey of established\n        # policy among SSL implementations showed it to be a\n        # reasonable choice.\n        raise CertificateError(\n            \"too many wildcards in certificate DNS name: \" + repr(dn)\n        )\n\n    # speed up common case w/o wildcards\n    if not wildcards:\n        return dn.lower() == hostname.lower()\n\n    # RFC 6125, section 6.4.3, subitem 1.\n    # The client SHOULD NOT attempt to match a presented identifier in which\n    # the wildcard character comprises a label other than the left-most label.\n    if leftmost == \"*\":\n        # When '*' is a fragment by itself, it matches a non-empty dotless\n        # fragment.\n        pats.append(\"[^.]+\")\n    elif leftmost.startswith(\"xn--\") or hostname.startswith(\"xn--\"):\n        # RFC 6125, section 6.4.3, subitem 3.\n        # The client SHOULD NOT attempt to match a presented identifier\n        # where the wildcard character is embedded within an A-label or\n        # U-label of an internationalized domain name.\n        pats.append(re.escape(leftmost))\n    else:\n        # Otherwise, '*' matches any dotless string, e.g. www*\n        pats.append(re.escape(leftmost).replace(r\"\\*\", \"[^.]*\"))\n\n    # add the remaining fragments, ignore any wildcards\n    for frag in remainder:\n        pats.append(re.escape(frag))\n\n    pat = re.compile(r\"\\A\" + r\"\\.\".join(pats) + r\"\\Z\", re.IGNORECASE)\n    return pat.match(hostname)\n\n\ndef _to_unicode(obj):\n    if isinstance(obj, str) and sys.version_info < (3,):\n        # ignored flake8 # F821 to support python 2.7 function\n        obj = unicode(obj, encoding=\"ascii\", errors=\"strict\")  # noqa: F821\n    return obj\n\n\ndef _ipaddress_match(ipname, host_ip):\n    \"\"\"Exact matching of IP addresses.\n\n    RFC 6125 explicitly doesn't define an algorithm for this\n    (section 1.7.2 - \"Out of Scope\").\n    \"\"\"\n    # OpenSSL may add a trailing newline to a subjectAltName's IP address\n    # Divergence from upstream: ipaddress can't handle byte str\n    ip = ipaddress.ip_address(_to_unicode(ipname).rstrip())\n    return ip == host_ip\n\n\ndef match_hostname(cert, hostname):\n    \"\"\"Verify that *cert* (in decoded format as returned by\n    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125\n    rules are followed, but IP addresses are not accepted for *hostname*.\n\n    CertificateError is raised on failure. On success, the function\n    returns nothing.\n    \"\"\"\n    if not cert:\n        raise ValueError(\n            \"empty or no certificate, match_hostname needs a \"\n            \"SSL socket or SSL context with either \"\n            \"CERT_OPTIONAL or CERT_REQUIRED\"\n        )\n    try:\n        # Divergence from upstream: ipaddress can't handle byte str\n        host_ip = ipaddress.ip_address(_to_unicode(hostname))\n    except (UnicodeError, ValueError):\n        # ValueError: Not an IP address (common case)\n        # UnicodeError: Divergence from upstream: Have to deal with ipaddress not taking\n        # byte strings.  addresses should be all ascii, so we consider it not\n        # an ipaddress in this case\n        host_ip = None\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\timeout.py": {
      "sha": "d7f1427c1b31",
      "lines": 271,
      "head": "from __future__ import absolute_import\n\nimport time\n\n# The default socket timeout, used by httplib to indicate that no timeout was; specified by the user\nfrom socket import _GLOBAL_DEFAULT_TIMEOUT, getdefaulttimeout\n\nfrom ..exceptions import TimeoutStateError\n\n# A sentinel value to indicate that no timeout was specified by the user in\n# urllib3\n_Default = object()\n\n\n# Use time.monotonic if available.\ncurrent_time = getattr(time, \"monotonic\", time.time)\n\n\nclass Timeout(object):\n    \"\"\"Timeout configuration.\n\n    Timeouts can be defined as a default for a pool:\n\n    .. code-block:: python\n\n       timeout = Timeout(connect=2.0, read=7.0)\n       http = PoolManager(timeout=timeout)\n       response = http.request('GET', 'http://example.com/')\n\n    Or per-request (which overrides the default for the pool):\n\n    .. code-block:: python\n\n       response = http.request('GET', 'http://example.com/', timeout=Timeout(10))\n\n    Timeouts can be disabled by setting all the parameters to ``None``:\n\n    .. code-block:: python\n\n       no_timeout = Timeout(connect=None, read=None)\n       response = http.request('GET', 'http://example.com/, timeout=no_timeout)\n\n\n    :param total:\n        This combines the connect and read timeouts into one; the read timeout\n        will be set to the time leftover from the connect attempt. In the\n        event that both a connect timeout and a total are specified, or a read\n        timeout and a total are specified, the shorter timeout will be applied.\n\n        Defaults to None.\n\n    :type total: int, float, or None\n\n    :param connect:\n        The maximum amount of time (in seconds) to wait for a connection\n        attempt to a server to succeed. Omitting the parameter will default the\n        connect timeout to the system default, probably `the global default\n        timeout in socket.py\n        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.\n        None will set an infinite timeout for connection attempts.\n\n    :type connect: int, float, or None\n\n    :param read:\n        The maximum amount of time (in seconds) to wait between consecutive\n        read operations for a response from the server. Omitting the parameter\n        will default the read timeout to the system default, probably `the\n        global default timeout in socket.py\n        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.\n        None will set an infinite timeout.\n\n    :type read: int, float, or None\n\n    .. note::\n\n        Many factors can affect the total amount of time for urllib3 to return\n        an HTTP response.\n\n        For example, Python's DNS resolver does not obey the timeout specified\n        on the socket. Other factors that can affect total request time include\n        high CPU load, high swap, the program running at a low priority level,\n        or other behaviors.\n\n        In addition, the read and total timeouts only measure the time between\n        read operations on the socket connecting the client and the server,\n        not the total amount of time for the request to return a complete\n        response. For most requests, the timeout is raised because the server\n        has not sent the first byte in the specified time. This is not always\n        the case; if a server streams one byte every fifteen seconds, a timeout\n        of 20 seconds will not trigger, even though the request will take\n        several minutes to complete.\n\n        If your goal is to cut off any request after a set amount of wall clock\n        time, consider having a second \"watcher\" thread to cut off a slow\n        request.\n    \"\"\"\n\n    #: A sentinel object representing the default timeout value\n    DEFAULT_TIMEOUT = _GLOBAL_DEFAULT_TIMEOUT\n\n    def __init__(self, total=None, connect=_Default, read=_Default):\n        self._connect = self._validate_timeout(connect, \"connect\")\n        self._read = self._validate_timeout(read, \"read\")\n        self.total = self._validate_timeout(total, \"total\")\n        self._start_connect = None\n\n    def __repr__(self):\n        return \"%s(connect=%r, read=%r, total=%r)\" % (\n            type(self).__name__,\n            self._connect,\n            self._read,\n            self.total,\n        )\n\n    # __str__ provided for backwards compatibility\n    __str__ = __repr__\n\n    @classmethod\n    def resolve_default_timeout(cls, timeout):\n        return getdefaulttimeout() if timeout is cls.DEFAULT_TIMEOUT else timeout\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\url.py": {
      "sha": "23d4363bf766",
      "lines": 435,
      "head": "from __future__ import absolute_import\n\nimport re\nfrom collections import namedtuple\n\nfrom ..exceptions import LocationParseError\nfrom ..packages import six\n\nurl_attrs = [\"scheme\", \"auth\", \"host\", \"port\", \"path\", \"query\", \"fragment\"]\n\n# We only want to normalize urls with an HTTP(S) scheme.\n# urllib3 infers URLs without a scheme (None) to be http.\nNORMALIZABLE_SCHEMES = (\"http\", \"https\", None)\n\n# Almost all of these patterns were derived from the\n# 'rfc3986' module: https://github.com/python-hyper/rfc3986\nPERCENT_RE = re.compile(r\"%[a-fA-F0-9]{2}\")\nSCHEME_RE = re.compile(r\"^(?:[a-zA-Z][a-zA-Z0-9+-]*:|/)\")\nURI_RE = re.compile(\n    r\"^(?:([a-zA-Z][a-zA-Z0-9+.-]*):)?\"\n    r\"(?://([^\\\\/?#]*))?\"\n    r\"([^?#]*)\"\n    r\"(?:\\?([^#]*))?\"\n    r\"(?:#(.*))?$\",\n    re.UNICODE | re.DOTALL,\n)\n\nIPV4_PAT = r\"(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\"\nHEX_PAT = \"[0-9A-Fa-f]{1,4}\"\nLS32_PAT = \"(?:{hex}:{hex}|{ipv4})\".format(hex=HEX_PAT, ipv4=IPV4_PAT)\n_subs = {\"hex\": HEX_PAT, \"ls32\": LS32_PAT}\n_variations = [\n    #                            6( h16 \":\" ) ls32\n    \"(?:%(hex)s:){6}%(ls32)s\",\n    #                       \"::\" 5( h16 \":\" ) ls32\n    \"::(?:%(hex)s:){5}%(ls32)s\",\n    # [               h16 ] \"::\" 4( h16 \":\" ) ls32\n    \"(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)s\",\n    # [ *1( h16 \":\" ) h16 ] \"::\" 3( h16 \":\" ) ls32\n    \"(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)s\",\n    # [ *2( h16 \":\" ) h16 ] \"::\" 2( h16 \":\" ) ls32\n    \"(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)s\",\n    # [ *3( h16 \":\" ) h16 ] \"::\"    h16 \":\"   ls32\n    \"(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)s\",\n    # [ *4( h16 \":\" ) h16 ] \"::\"              ls32\n    \"(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)s\",\n    # [ *5( h16 \":\" ) h16 ] \"::\"              h16\n    \"(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)s\",\n    # [ *6( h16 \":\" ) h16 ] \"::\"\n    \"(?:(?:%(hex)s:){0,6}%(hex)s)?::\",\n]\n\nUNRESERVED_PAT = r\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._\\-~\"\nIPV6_PAT = \"(?:\" + \"|\".join([x % _subs for x in _variations]) + \")\"\nZONE_ID_PAT = \"(?:%25|%)(?:[\" + UNRESERVED_PAT + \"]|%[a-fA-F0-9]{2})+\"\nIPV6_ADDRZ_PAT = r\"\\[\" + IPV6_PAT + r\"(?:\" + ZONE_ID_PAT + r\")?\\]\"\nREG_NAME_PAT = r\"(?:[^\\[\\]%:/?#]|%[a-fA-F0-9]{2})*\"\nTARGET_RE = re.compile(r\"^(/[^?#]*)(?:\\?([^#]*))?(?:#.*)?$\")\n\nIPV4_RE = re.compile(\"^\" + IPV4_PAT + \"$\")\nIPV6_RE = re.compile(\"^\" + IPV6_PAT + \"$\")\nIPV6_ADDRZ_RE = re.compile(\"^\" + IPV6_ADDRZ_PAT + \"$\")\nBRACELESS_IPV6_ADDRZ_RE = re.compile(\"^\" + IPV6_ADDRZ_PAT[2:-2] + \"$\")\nZONE_ID_RE = re.compile(\"(\" + ZONE_ID_PAT + r\")\\]$\")\n\n_HOST_PORT_PAT = (\"^(%s|%s|%s)(?::0*?(|0|[1-9][0-9]{0,4}))?$\") % (\n    REG_NAME_PAT,\n    IPV4_PAT,\n    IPV6_ADDRZ_PAT,\n)\n_HOST_PORT_RE = re.compile(_HOST_PORT_PAT, re.UNICODE | re.DOTALL)\n\nUNRESERVED_CHARS = set(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._-~\"\n)\nSUB_DELIM_CHARS = set(\"!$&'()*+,;=\")\nUSERINFO_CHARS = UNRESERVED_CHARS | SUB_DELIM_CHARS | {\":\"}\nPATH_CHARS = USERINFO_CHARS | {\"@\", \"/\"}\nQUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {\"?\"}\n\n\nclass Url(namedtuple(\"Url\", url_attrs)):\n    \"\"\"\n    Data structure for representing an HTTP URL. Used as a return value for\n    :func:`parse_url`. Both the scheme and host are normalized as they are\n    both case-insensitive according to RFC 3986.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __new__(\n        cls,\n        scheme=None,\n        auth=None,\n        host=None,\n        port=None,\n        path=None,\n        query=None,\n        fragment=None,\n    ):\n        if path and not path.startswith(\"/\"):\n            path = \"/\" + path\n        if scheme is not None:\n            scheme = scheme.lower()\n        return super(Url, cls).__new__(\n            cls, scheme, auth, host, port, path, query, fragment\n        )\n\n    @property\n    def hostname(self):\n        \"\"\"For backwards-compatibility with urlparse. We're nice like that.\"\"\"\n        return self.host\n\n    @property\n    def request_uri(self):\n        \"\"\"Absolute path including the query string.\"\"\"\n        uri = self.path or \"/\"\n\n        if self.query is not None:\n            uri += \"?\" + self.query\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\wait.py": {
      "sha": "7944d9bda2e8",
      "lines": 152,
      "head": "import errno\nimport select\nimport sys\nfrom functools import partial\n\ntry:\n    from time import monotonic\nexcept ImportError:\n    from time import time as monotonic\n\n__all__ = [\"NoWayToWaitForSocketError\", \"wait_for_read\", \"wait_for_write\"]\n\n\nclass NoWayToWaitForSocketError(Exception):\n    pass\n\n\n# How should we wait on sockets?\n#\n# There are two types of APIs you can use for waiting on sockets: the fancy\n# modern stateful APIs like epoll/kqueue, and the older stateless APIs like\n# select/poll. The stateful APIs are more efficient when you have a lots of\n# sockets to keep track of, because you can set them up once and then use them\n# lots of times. But we only ever want to wait on a single socket at a time\n# and don't want to keep track of state, so the stateless APIs are actually\n# more efficient. So we want to use select() or poll().\n#\n# Now, how do we choose between select() and poll()? On traditional Unixes,\n# select() has a strange calling convention that makes it slow, or fail\n# altogether, for high-numbered file descriptors. The point of poll() is to fix\n# that, so on Unixes, we prefer poll().\n#\n# On Windows, there is no poll() (or at least Python doesn't provide a wrapper\n# for it), but that's OK, because on Windows, select() doesn't have this\n# strange calling convention; plain select() works fine.\n#\n# So: on Windows we use select(), and everywhere else we use poll(). We also\n# fall back to select() in case poll() is somehow broken or missing.\n\nif sys.version_info >= (3, 5):\n    # Modern Python, that retries syscalls by default\n    def _retry_on_intr(fn, timeout):\n        return fn(timeout)\n\nelse:\n    # Old and broken Pythons.\n    def _retry_on_intr(fn, timeout):\n        if timeout is None:\n            deadline = float(\"inf\")\n        else:\n            deadline = monotonic() + timeout\n\n        while True:\n            try:\n                return fn(timeout)\n            # OSError for 3 <= pyver < 3.5, select.error for pyver <= 2.7\n            except (OSError, select.error) as e:\n                # 'e.args[0]' incantation works for both OSError and select.error\n                if e.args[0] != errno.EINTR:\n                    raise\n                else:\n                    timeout = deadline - monotonic()\n                    if timeout < 0:\n                        timeout = 0\n                    if timeout == float(\"inf\"):\n                        timeout = None\n                    continue\n\n\ndef select_wait_for_socket(sock, read=False, write=False, timeout=None):\n    if not read and not write:\n        raise RuntimeError(\"must specify at least one of read=True, write=True\")\n    rcheck = []\n    wcheck = []\n    if read:\n        rcheck.append(sock)\n    if write:\n        wcheck.append(sock)\n    # When doing a non-blocking connect, most systems signal success by\n    # marking the socket writable. Windows, though, signals success by marked\n    # it as \"exceptional\". We paper over the difference by checking the write\n    # sockets for both conditions. (The stdlib selectors module does the same\n    # thing.)\n    fn = partial(select.select, rcheck, wcheck, wcheck)\n    rready, wready, xready = _retry_on_intr(fn, timeout)\n    return bool(rready or wready or xready)\n\n\ndef poll_wait_for_socket(sock, read=False, write=False, timeout=None):\n    if not read and not write:\n        raise RuntimeError(\"must specify at least one of read=True, write=True\")\n    mask = 0\n    if read:\n        mask |= select.POLLIN\n    if write:\n        mask |= select.POLLOUT\n    poll_obj = select.poll()\n    poll_obj.register(sock, mask)\n\n    # For some reason, poll() takes timeout in milliseconds\n    def do_poll(t):\n        if t is not None:\n            t *= 1000\n        return poll_obj.poll(t)\n\n    return bool(_retry_on_intr(do_poll, timeout))\n\n\ndef null_wait_for_socket(*args, **kwargs):\n    raise NoWayToWaitForSocketError(\"no select-equivalent available\")\n\n\ndef _have_working_poll():\n    # Apparently some systems have a select.poll that fails as soon as you try\n    # to use it, either due to strange configuration or broken monkeypatching\n    # from libraries like eventlet/greenlet.\n    try:\n        poll_obj = select.poll()\n        _retry_on_intr(poll_obj.poll, 0)\n    except (AttributeError, OSError):\n"
    },
    ".venv\\Lib\\site-packages\\pip\\_vendor\\urllib3\\util\\__init__.py": {
      "sha": "896463bcd648",
      "lines": 49,
      "head": "from __future__ import absolute_import\n\n# For backwards compatibility, provide imports that used to be here.\nfrom .connection import is_connection_dropped\nfrom .request import SKIP_HEADER, SKIPPABLE_HEADERS, make_headers\nfrom .response import is_fp_closed\nfrom .retry import Retry\nfrom .ssl_ import (\n    ALPN_PROTOCOLS,\n    HAS_SNI,\n    IS_PYOPENSSL,\n    IS_SECURETRANSPORT,\n    PROTOCOL_TLS,\n    SSLContext,\n    assert_fingerprint,\n    resolve_cert_reqs,\n    resolve_ssl_version,\n    ssl_wrap_socket,\n)\nfrom .timeout import Timeout, current_time\nfrom .url import Url, get_host, parse_url, split_first\nfrom .wait import wait_for_read, wait_for_write\n\n__all__ = (\n    \"HAS_SNI\",\n    \"IS_PYOPENSSL\",\n    \"IS_SECURETRANSPORT\",\n    \"SSLContext\",\n    \"PROTOCOL_TLS\",\n    \"ALPN_PROTOCOLS\",\n    \"Retry\",\n    \"Timeout\",\n    \"Url\",\n    \"assert_fingerprint\",\n    \"current_time\",\n    \"is_connection_dropped\",\n    \"is_fp_closed\",\n    \"get_host\",\n    \"parse_url\",\n    \"make_headers\",\n    \"resolve_cert_reqs\",\n    \"resolve_ssl_version\",\n    \"split_first\",\n    \"ssl_wrap_socket\",\n    \"wait_for_read\",\n    \"wait_for_write\",\n    \"SKIP_HEADER\",\n    \"SKIPPABLE_HEADERS\",\n)\n"
    },
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\entry_points.txt": {
      "sha": "3830417b2050",
      "lines": 3,
      "head": "[console_scripts]\npip = pip._internal.cli.main:main\npip3 = pip._internal.cli.main:main\n"
    },
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\top_level.txt": {
      "sha": "d7a03141d5d6",
      "lines": 1,
      "head": "pip\n"
    },
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\licenses\\AUTHORS.txt": {
      "sha": "c7f85be7168f",
      "lines": 821,
      "head": "@Switch01\nA_Rog\nAakanksha Agrawal\nAbhinav Sagar\nABHYUDAY PRATAP SINGH\nabs51295\nAceGentile\nAdam Chainz\nAdam Tse\nAdam Turner\nAdam Wentz\nadmin\nAdolfo Ochagav\u00eda\nAdrien Morison\nAgus\nahayrapetyan\nAhilya\nAinsworthK\nAkash Srivastava\nAlan Yee\nAlbert Tugushev\nAlbert-Guan\nalbertg\nAlberto Sottile\nAleks Bunin\nAles Erjavec\nAlethea Flowers\nAlex Gaynor\nAlex Gr\u00f6nholm\nAlex Hedges\nAlex Loosley\nAlex Morega\nAlex Stachowiak\nAlexander Regueiro\nAlexander Shtyrov\nAlexandre Conrad\nAlexey Popravka\nAle\u0161 Erjavec\nAlli\nAmi Fischman\nAnanya Maiti\nAnatoly Techtonik\nAnders Kaseorg\nAndre Aguiar\nAndreas Lutro\nAndrei Geacar\nAndrew Gaul\nAndrew Shymanel\nAndrey Bienkowski\nAndrey Bulgakov\nAndr\u00e9s Delfino\nAndy Freeland\nAndy Kluger\nAni Hayrapetyan\nAniruddha Basak\nAnish Tambe\nAnrs Hu\nAnthony Sottile\nAntoine Musso\nAnton Ovchinnikov\nAnton Patrushev\nAnton Zelenov\nAntonio Alvarado Hernandez\nAntony Lee\nAntti Kaihola\nAnubhav Patel\nAnudit Nagar\nAnuj Godase\nAQNOUCH Mohammed\nAraHaan\narena\narenasys\nArindam Choudhury\nArmin Ronacher\nArnon Yaari\nArtem\nArun Babu Neelicattu\nAshley Manton\nAshwin Ramaswami\natse\nAtsushi Odagiri\nAvinash Karhana\nAvner Cohen\nAwit (Ah-Wit) Ghirmai\nBaptiste Mispelon\nBarney Gale\nbarneygale\nBartek Ogryczak\nBastian Venthur\nBen Bodenmiller\nBen Darnell\nBen Hoyt\nBen Mares\nBen Rosser\nBence Nagy\nBenjamin Peterson\nBenjamin VanEvery\nBenoit Pierre\nBerker Peksag\nBernard\nBernard Tyers\nBernardo B. Marques\nBernhard M. Wiedemann\nBertil Hatt\nBhavam Vidyarthi\nBlazej Michalik\nBogdan Opanchuk\nBorisZZZ\nBrad Erickson\nBradley Ayers\nBradley Reynolds\nBranch Vincent\nBrandon L. Reiss\nBrandt Bucher\nBrannon Dorsey\nBrett Randall\nBrett Rosen\nBrian Cristante\nBrian Rosner\nbriantracy\n"
    },
    ".venv\\Lib\\site-packages\\pip-25.1.1.dist-info\\licenses\\LICENSE.txt": {
      "sha": "d1816736d55c",
      "lines": 20,
      "head": "Copyright (c) 2008-present The pip developers (see AUTHORS.txt file)\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
    },
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\entry_points.txt": {
      "sha": "bc54f362a9ee",
      "lines": 2,
      "head": "[console_scripts]\ndotenv = dotenv.__main__:cli\n"
    },
    ".venv\\Lib\\site-packages\\python_dotenv-1.1.1.dist-info\\top_level.txt": {
      "sha": "796e6c80ed4f",
      "lines": 1,
      "head": "dotenv\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\exceptions.py": {
      "sha": "930a12ca5353",
      "lines": 894,
      "head": "\"\"\"Implements a number of Python exceptions which can be raised from within\na view to trigger a standard HTTP non-200 response.\n\nUsage Example\n-------------\n\n.. code-block:: python\n\n    from werkzeug.wrappers.request import Request\n    from werkzeug.exceptions import HTTPException, NotFound\n\n    def view(request):\n        raise NotFound()\n\n    @Request.application\n    def application(request):\n        try:\n            return view(request)\n        except HTTPException as e:\n            return e\n\nAs you can see from this example those exceptions are callable WSGI\napplications. However, they are not Werkzeug response objects. You\ncan get a response object by calling ``get_response()`` on a HTTP\nexception.\n\nKeep in mind that you may have to pass an environ (WSGI) or scope\n(ASGI) to ``get_response()`` because some errors fetch additional\ninformation relating to the request.\n\nIf you want to hook in a different exception page to say, a 404 status\ncode, you can add a second except for a specific subclass of an error:\n\n.. code-block:: python\n\n    @Request.application\n    def application(request):\n        try:\n            return view(request)\n        except NotFound as e:\n            return not_found(request)\n        except HTTPException as e:\n            return e\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\n\nfrom markupsafe import escape\nfrom markupsafe import Markup\n\nfrom ._internal import _get_environ\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .datastructures import WWWAuthenticate\n    from .sansio.response import Response\n    from .wrappers.request import Request as WSGIRequest\n    from .wrappers.response import Response as WSGIResponse\n\n\nclass HTTPException(Exception):\n    \"\"\"The base class for all HTTP exceptions. This exception can be called as a WSGI\n    application to render a default error page or you can catch the subclasses\n    of it independently and render nicer error messages.\n\n    .. versionchanged:: 2.1\n        Removed the ``wrap`` class method.\n    \"\"\"\n\n    code: int | None = None\n    description: str | None = None\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n    ) -> None:\n        super().__init__()\n        if description is not None:\n            self.description = description\n        self.response = response\n\n    @property\n    def name(self) -> str:\n        \"\"\"The status name.\"\"\"\n        from .http import HTTP_STATUS_CODES\n\n        return HTTP_STATUS_CODES.get(self.code, \"Unknown Error\")  # type: ignore\n\n    def get_description(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> str:\n        \"\"\"Get the description.\"\"\"\n        if self.description is None:\n            description = \"\"\n        else:\n            description = self.description\n\n        description = escape(description).replace(\"\\n\", Markup(\"<br>\"))\n        return f\"<p>{description}</p>\"\n\n    def get_body(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> str:\n        \"\"\"Get the HTML body.\"\"\"\n        return (\n            \"<!doctype html>\\n\"\n            \"<html lang=en>\\n\"\n            f\"<title>{self.code} {escape(self.name)}</title>\\n\"\n            f\"<h1>{escape(self.name)}</h1>\\n\"\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\formparser.py": {
      "sha": "ae2512608258",
      "lines": 430,
      "head": "from __future__ import annotations\n\nimport typing as t\nfrom io import BytesIO\nfrom urllib.parse import parse_qsl\n\nfrom ._internal import _plain_int\nfrom .datastructures import FileStorage\nfrom .datastructures import Headers\nfrom .datastructures import MultiDict\nfrom .exceptions import RequestEntityTooLarge\nfrom .http import parse_options_header\nfrom .sansio.multipart import Data\nfrom .sansio.multipart import Epilogue\nfrom .sansio.multipart import Field\nfrom .sansio.multipart import File\nfrom .sansio.multipart import MultipartDecoder\nfrom .sansio.multipart import NeedData\nfrom .wsgi import get_content_length\nfrom .wsgi import get_input_stream\n\n# there are some platforms where SpooledTemporaryFile is not available.\n# In that case we need to provide a fallback.\ntry:\n    from tempfile import SpooledTemporaryFile\nexcept ImportError:\n    from tempfile import TemporaryFile\n\n    SpooledTemporaryFile = None  # type: ignore\n\nif t.TYPE_CHECKING:\n    import typing as te\n\n    from _typeshed.wsgi import WSGIEnvironment\n\n    t_parse_result = tuple[\n        t.IO[bytes], MultiDict[str, str], MultiDict[str, FileStorage]\n    ]\n\n    class TStreamFactory(te.Protocol):\n        def __call__(\n            self,\n            total_content_length: int | None,\n            content_type: str | None,\n            filename: str | None,\n            content_length: int | None = None,\n        ) -> t.IO[bytes]: ...\n\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef default_stream_factory(\n    total_content_length: int | None,\n    content_type: str | None,\n    filename: str | None,\n    content_length: int | None = None,\n) -> t.IO[bytes]:\n    max_size = 1024 * 500\n\n    if SpooledTemporaryFile is not None:\n        return t.cast(t.IO[bytes], SpooledTemporaryFile(max_size=max_size, mode=\"rb+\"))\n    elif total_content_length is None or total_content_length > max_size:\n        return t.cast(t.IO[bytes], TemporaryFile(\"rb+\"))\n\n    return BytesIO()\n\n\ndef parse_form_data(\n    environ: WSGIEnvironment,\n    stream_factory: TStreamFactory | None = None,\n    max_form_memory_size: int | None = None,\n    max_content_length: int | None = None,\n    cls: type[MultiDict[str, t.Any]] | None = None,\n    silent: bool = True,\n    *,\n    max_form_parts: int | None = None,\n) -> t_parse_result:\n    \"\"\"Parse the form data in the environ and return it as tuple in the form\n    ``(stream, form, files)``.  You should only call this method if the\n    transport method is `POST`, `PUT`, or `PATCH`.\n\n    If the mimetype of the data transmitted is `multipart/form-data` the\n    files multidict will be filled with `FileStorage` objects.  If the\n    mimetype is unknown the input stream is wrapped and returned as first\n    argument, else the stream is empty.\n\n    This is a shortcut for the common usage of :class:`FormDataParser`.\n\n    :param environ: the WSGI environment to be used for parsing.\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    :param max_form_parts: The maximum number of multipart parts to be parsed. If this\n        is exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.\n    :return: A tuple in the form ``(stream, form, files)``.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``errors`` parameters were removed.\n\n    .. versionchanged:: 2.3\n        Added the ``max_form_parts`` parameter.\n\n    .. versionadded:: 0.5.1\n       Added the ``silent`` parameter.\n\n    .. versionadded:: 0.5\n       Added the ``max_form_memory_size``, ``max_content_length``, and ``cls``\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\http.py": {
      "sha": "1f4caa99abb6",
      "lines": 1405,
      "head": "from __future__ import annotations\n\nimport email.utils\nimport re\nimport typing as t\nimport warnings\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom enum import Enum\nfrom hashlib import sha1\nfrom time import mktime\nfrom time import struct_time\nfrom urllib.parse import quote\nfrom urllib.parse import unquote\nfrom urllib.request import parse_http_list as _parse_list_header\n\nfrom ._internal import _dt_as_utc\nfrom ._internal import _plain_int\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n_token_chars = frozenset(\n    \"!#$%&'*+-.0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz|~\"\n)\n_etag_re = re.compile(r'([Ww]/)?(?:\"(.*?)\"|(.*?))(?:\\s*,\\s*|$)')\n_entity_headers = frozenset(\n    [\n        \"allow\",\n        \"content-encoding\",\n        \"content-language\",\n        \"content-length\",\n        \"content-location\",\n        \"content-md5\",\n        \"content-range\",\n        \"content-type\",\n        \"expires\",\n        \"last-modified\",\n    ]\n)\n_hop_by_hop_headers = frozenset(\n    [\n        \"connection\",\n        \"keep-alive\",\n        \"proxy-authenticate\",\n        \"proxy-authorization\",\n        \"te\",\n        \"trailer\",\n        \"transfer-encoding\",\n        \"upgrade\",\n    ]\n)\nHTTP_STATUS_CODES = {\n    100: \"Continue\",\n    101: \"Switching Protocols\",\n    102: \"Processing\",\n    103: \"Early Hints\",  # see RFC 8297\n    200: \"OK\",\n    201: \"Created\",\n    202: \"Accepted\",\n    203: \"Non Authoritative Information\",\n    204: \"No Content\",\n    205: \"Reset Content\",\n    206: \"Partial Content\",\n    207: \"Multi Status\",\n    208: \"Already Reported\",  # see RFC 5842\n    226: \"IM Used\",  # see RFC 3229\n    300: \"Multiple Choices\",\n    301: \"Moved Permanently\",\n    302: \"Found\",\n    303: \"See Other\",\n    304: \"Not Modified\",\n    305: \"Use Proxy\",\n    306: \"Switch Proxy\",  # unused\n    307: \"Temporary Redirect\",\n    308: \"Permanent Redirect\",\n    400: \"Bad Request\",\n    401: \"Unauthorized\",\n    402: \"Payment Required\",  # unused\n    403: \"Forbidden\",\n    404: \"Not Found\",\n    405: \"Method Not Allowed\",\n    406: \"Not Acceptable\",\n    407: \"Proxy Authentication Required\",\n    408: \"Request Timeout\",\n    409: \"Conflict\",\n    410: \"Gone\",\n    411: \"Length Required\",\n    412: \"Precondition Failed\",\n    413: \"Request Entity Too Large\",\n    414: \"Request URI Too Long\",\n    415: \"Unsupported Media Type\",\n    416: \"Requested Range Not Satisfiable\",\n    417: \"Expectation Failed\",\n    418: \"I'm a teapot\",  # see RFC 2324\n    421: \"Misdirected Request\",  # see RFC 7540\n    422: \"Unprocessable Entity\",\n    423: \"Locked\",\n    424: \"Failed Dependency\",\n    425: \"Too Early\",  # see RFC 8470\n    426: \"Upgrade Required\",\n    428: \"Precondition Required\",  # see RFC 6585\n    429: \"Too Many Requests\",\n    431: \"Request Header Fields Too Large\",\n    449: \"Retry With\",  # proprietary MS extension\n    451: \"Unavailable For Legal Reasons\",\n    500: \"Internal Server Error\",\n    501: \"Not Implemented\",\n    502: \"Bad Gateway\",\n    503: \"Service Unavailable\",\n    504: \"Gateway Timeout\",\n    505: \"HTTP Version Not Supported\",\n    506: \"Variant Also Negotiates\",  # see RFC 2295\n    507: \"Insufficient Storage\",\n    508: \"Loop Detected\",  # see RFC 5842\n    510: \"Not Extended\",\n    511: \"Network Authentication Failed\",\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\local.py": {
      "sha": "8865d259e0ce",
      "lines": 653,
      "head": "from __future__ import annotations\n\nimport copy\nimport math\nimport operator\nimport typing as t\nfrom contextvars import ContextVar\nfrom functools import partial\nfrom functools import update_wrapper\nfrom operator import attrgetter\n\nfrom .wsgi import ClosingIterator\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\nT = t.TypeVar(\"T\")\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef release_local(local: Local | LocalStack[t.Any]) -> None:\n    \"\"\"Release the data for the current context in a :class:`Local` or\n    :class:`LocalStack` without using a :class:`LocalManager`.\n\n    This should not be needed for modern use cases, and may be removed\n    in the future.\n\n    .. versionadded:: 0.6.1\n    \"\"\"\n    local.__release_local__()\n\n\nclass Local:\n    \"\"\"Create a namespace of context-local data. This wraps a\n    :class:`ContextVar` containing a :class:`dict` value.\n\n    This may incur a performance penalty compared to using individual\n    context vars, as it has to copy data to avoid mutating the dict\n    between nested contexts.\n\n    :param context_var: The :class:`~contextvars.ContextVar` to use as\n        storage for this local. If not given, one will be created.\n        Context vars not created at the global scope may interfere with\n        garbage collection.\n\n    .. versionchanged:: 2.0\n        Uses ``ContextVar`` instead of a custom storage implementation.\n    \"\"\"\n\n    __slots__ = (\"__storage\",)\n\n    def __init__(self, context_var: ContextVar[dict[str, t.Any]] | None = None) -> None:\n        if context_var is None:\n            # A ContextVar not created at global scope interferes with\n            # Python's garbage collection. However, a local only makes\n            # sense defined at the global scope as well, in which case\n            # the GC issue doesn't seem relevant.\n            context_var = ContextVar(f\"werkzeug.Local<{id(self)}>.storage\")\n\n        object.__setattr__(self, \"_Local__storage\", context_var)\n\n    def __iter__(self) -> t.Iterator[tuple[str, t.Any]]:\n        return iter(self.__storage.get({}).items())\n\n    def __call__(\n        self, name: str, *, unbound_message: str | None = None\n    ) -> LocalProxy[t.Any]:\n        \"\"\"Create a :class:`LocalProxy` that access an attribute on this\n        local namespace.\n\n        :param name: Proxy this attribute.\n        :param unbound_message: The error message that the proxy will\n            show if the attribute isn't set.\n        \"\"\"\n        return LocalProxy(self, name, unbound_message=unbound_message)\n\n    def __release_local__(self) -> None:\n        self.__storage.set({})\n\n    def __getattr__(self, name: str) -> t.Any:\n        values = self.__storage.get({})\n\n        if name in values:\n            return values[name]\n\n        raise AttributeError(name)\n\n    def __setattr__(self, name: str, value: t.Any) -> None:\n        values = self.__storage.get({}).copy()\n        values[name] = value\n        self.__storage.set(values)\n\n    def __delattr__(self, name: str) -> None:\n        values = self.__storage.get({})\n\n        if name in values:\n            values = values.copy()\n            del values[name]\n            self.__storage.set(values)\n        else:\n            raise AttributeError(name)\n\n\nclass LocalStack(t.Generic[T]):\n    \"\"\"Create a stack of context-local data. This wraps a\n    :class:`ContextVar` containing a :class:`list` value.\n\n    This may incur a performance penalty compared to using individual\n    context vars, as it has to copy data to avoid mutating the list\n    between nested contexts.\n\n    :param context_var: The :class:`~contextvars.ContextVar` to use as\n        storage for this local. If not given, one will be created.\n        Context vars not created at the global scope may interfere with\n        garbage collection.\n\n    .. versionchanged:: 2.0\n        Uses ``ContextVar`` instead of a custom storage implementation.\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\security.py": {
      "sha": "8696a013babd",
      "lines": 166,
      "head": "from __future__ import annotations\n\nimport hashlib\nimport hmac\nimport os\nimport posixpath\nimport secrets\n\nSALT_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\nDEFAULT_PBKDF2_ITERATIONS = 1_000_000\n\n_os_alt_seps: list[str] = list(\n    sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"\n)\n\n\ndef gen_salt(length: int) -> str:\n    \"\"\"Generate a random string of SALT_CHARS with specified ``length``.\"\"\"\n    if length <= 0:\n        raise ValueError(\"Salt length must be at least 1.\")\n\n    return \"\".join(secrets.choice(SALT_CHARS) for _ in range(length))\n\n\ndef _hash_internal(method: str, salt: str, password: str) -> tuple[str, str]:\n    method, *args = method.split(\":\")\n    salt_bytes = salt.encode()\n    password_bytes = password.encode()\n\n    if method == \"scrypt\":\n        if not args:\n            n = 2**15\n            r = 8\n            p = 1\n        else:\n            try:\n                n, r, p = map(int, args)\n            except ValueError:\n                raise ValueError(\"'scrypt' takes 3 arguments.\") from None\n\n        maxmem = 132 * n * r * p  # ideally 128, but some extra seems needed\n        return (\n            hashlib.scrypt(\n                password_bytes, salt=salt_bytes, n=n, r=r, p=p, maxmem=maxmem\n            ).hex(),\n            f\"scrypt:{n}:{r}:{p}\",\n        )\n    elif method == \"pbkdf2\":\n        len_args = len(args)\n\n        if len_args == 0:\n            hash_name = \"sha256\"\n            iterations = DEFAULT_PBKDF2_ITERATIONS\n        elif len_args == 1:\n            hash_name = args[0]\n            iterations = DEFAULT_PBKDF2_ITERATIONS\n        elif len_args == 2:\n            hash_name = args[0]\n            iterations = int(args[1])\n        else:\n            raise ValueError(\"'pbkdf2' takes 2 arguments.\")\n\n        return (\n            hashlib.pbkdf2_hmac(\n                hash_name, password_bytes, salt_bytes, iterations\n            ).hex(),\n            f\"pbkdf2:{hash_name}:{iterations}\",\n        )\n    else:\n        raise ValueError(f\"Invalid hash method '{method}'.\")\n\n\ndef generate_password_hash(\n    password: str, method: str = \"scrypt\", salt_length: int = 16\n) -> str:\n    \"\"\"Securely hash a password for storage. A password can be compared to a stored hash\n    using :func:`check_password_hash`.\n\n    The following methods are supported:\n\n    -   ``scrypt``, the default. The parameters are ``n``, ``r``, and ``p``, the default\n        is ``scrypt:32768:8:1``. See :func:`hashlib.scrypt`.\n    -   ``pbkdf2``, less secure. The parameters are ``hash_method`` and ``iterations``,\n        the default is ``pbkdf2:sha256:600000``. See :func:`hashlib.pbkdf2_hmac`.\n\n    Default parameters may be updated to reflect current guidelines, and methods may be\n    deprecated and removed if they are no longer considered secure. To migrate old\n    hashes, you may generate a new hash when checking an old hash, or you may contact\n    users with a link to reset their password.\n\n    :param password: The plaintext password.\n    :param method: The key derivation function and parameters.\n    :param salt_length: The number of characters to generate for the salt.\n\n    .. versionchanged:: 3.1\n        The default iterations for pbkdf2 was increased to 1,000,000.\n\n    .. versionchanged:: 2.3\n        Scrypt support was added.\n\n    .. versionchanged:: 2.3\n        The default iterations for pbkdf2 was increased to 600,000.\n\n    .. versionchanged:: 2.3\n        All plain hashes are deprecated and will not be supported in Werkzeug 3.0.\n    \"\"\"\n    salt = gen_salt(salt_length)\n    h, actual_method = _hash_internal(method, salt, password)\n    return f\"{actual_method}${salt}${h}\"\n\n\ndef check_password_hash(pwhash: str, password: str) -> bool:\n    \"\"\"Securely check that the given stored password hash, previously generated using\n    :func:`generate_password_hash`, matches the given password.\n\n    Methods may be deprecated and removed if they are no longer considered secure. To\n    migrate old hashes, you may generate a new hash when checking an old hash, or you\n    may contact users with a link to reset their password.\n\n    :param pwhash: The hashed password.\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\serving.py": {
      "sha": "8704dd01632b",
      "lines": 1125,
      "head": "\"\"\"A WSGI and HTTP server for use **during development only**. This\nserver is convenient to use, but is not designed to be particularly\nstable, secure, or efficient. Use a dedicate WSGI server and HTTP\nserver when deploying to production.\n\nIt provides features like interactive debugging and code reloading. Use\n``run_simple`` to start the server. Put this in a ``run.py`` script:\n\n.. code-block:: python\n\n    from myapp import create_app\n    from werkzeug import run_simple\n\"\"\"\n\nfrom __future__ import annotations\n\nimport errno\nimport io\nimport os\nimport selectors\nimport socket\nimport socketserver\nimport sys\nimport typing as t\nfrom datetime import datetime as dt\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom http.server import BaseHTTPRequestHandler\nfrom http.server import HTTPServer\nfrom urllib.parse import unquote\nfrom urllib.parse import urlsplit\n\nfrom ._internal import _log\nfrom ._internal import _wsgi_encoding_dance\nfrom .exceptions import InternalServerError\nfrom .urls import uri_to_iri\n\ntry:\n    import ssl\n\n    connection_dropped_errors: tuple[type[Exception], ...] = (\n        ConnectionError,\n        socket.timeout,\n        ssl.SSLEOFError,\n    )\nexcept ImportError:\n\n    class _SslDummy:\n        def __getattr__(self, name: str) -> t.Any:\n            raise RuntimeError(  # noqa: B904\n                \"SSL is unavailable because this Python runtime was not\"\n                \" compiled with SSL/TLS support.\"\n            )\n\n    ssl = _SslDummy()  # type: ignore\n    connection_dropped_errors = (ConnectionError, socket.timeout)\n\n_log_add_style = True\n\nif os.name == \"nt\":\n    try:\n        __import__(\"colorama\")\n    except ImportError:\n        _log_add_style = False\n\ncan_fork = hasattr(os, \"fork\")\n\nif can_fork:\n    ForkingMixIn = socketserver.ForkingMixIn\nelse:\n\n    class ForkingMixIn:  # type: ignore\n        pass\n\n\ntry:\n    af_unix = socket.AF_UNIX\nexcept AttributeError:\n    af_unix = None  # type: ignore\n\nLISTEN_QUEUE = 128\n\n_TSSLContextArg = t.Optional[\n    t.Union[\"ssl.SSLContext\", tuple[str, t.Optional[str]], t.Literal[\"adhoc\"]]\n]\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n    from cryptography.hazmat.primitives.asymmetric.rsa import (\n        RSAPrivateKeyWithSerialization,\n    )\n    from cryptography.x509 import Certificate\n\n\nclass DechunkedInput(io.RawIOBase):\n    \"\"\"An input stream that handles Transfer-Encoding 'chunked'\"\"\"\n\n    def __init__(self, rfile: t.IO[bytes]) -> None:\n        self._rfile = rfile\n        self._done = False\n        self._len = 0\n\n    def readable(self) -> bool:\n        return True\n\n    def read_chunk_len(self) -> int:\n        try:\n            line = self._rfile.readline().decode(\"latin1\")\n            _len = int(line.strip(), 16)\n        except ValueError as e:\n            raise OSError(\"Invalid chunk header\") from e\n        if _len < 0:\n            raise OSError(\"Negative chunk length not allowed\")\n        return _len\n\n    def readinto(self, buf: bytearray) -> int:  # type: ignore\n        read = 0\n        while not self._done and read < len(buf):\n            if self._len == 0:\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\test.py": {
      "sha": "d231d6c88349",
      "lines": 1464,
      "head": "from __future__ import annotations\n\nimport dataclasses\nimport mimetypes\nimport sys\nimport typing as t\nfrom collections import defaultdict\nfrom datetime import datetime\nfrom io import BytesIO\nfrom itertools import chain\nfrom random import random\nfrom tempfile import TemporaryFile\nfrom time import time\nfrom urllib.parse import unquote\nfrom urllib.parse import urlsplit\nfrom urllib.parse import urlunsplit\n\nfrom ._internal import _get_environ\nfrom ._internal import _wsgi_decoding_dance\nfrom ._internal import _wsgi_encoding_dance\nfrom .datastructures import Authorization\nfrom .datastructures import CallbackDict\nfrom .datastructures import CombinedMultiDict\nfrom .datastructures import EnvironHeaders\nfrom .datastructures import FileMultiDict\nfrom .datastructures import Headers\nfrom .datastructures import MultiDict\nfrom .http import dump_cookie\nfrom .http import dump_options_header\nfrom .http import parse_cookie\nfrom .http import parse_date\nfrom .http import parse_options_header\nfrom .sansio.multipart import Data\nfrom .sansio.multipart import Epilogue\nfrom .sansio.multipart import Field\nfrom .sansio.multipart import File\nfrom .sansio.multipart import MultipartEncoder\nfrom .sansio.multipart import Preamble\nfrom .urls import _urlencode\nfrom .urls import iri_to_uri\nfrom .utils import cached_property\nfrom .utils import get_content_type\nfrom .wrappers.request import Request\nfrom .wrappers.response import Response\nfrom .wsgi import ClosingIterator\nfrom .wsgi import get_current_url\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\ndef stream_encode_multipart(\n    data: t.Mapping[str, t.Any],\n    use_tempfile: bool = True,\n    threshold: int = 1024 * 500,\n    boundary: str | None = None,\n) -> tuple[t.IO[bytes], int, str]:\n    \"\"\"Encode a dict of values (either strings or file descriptors or\n    :class:`FileStorage` objects.) into a multipart encoded string stored\n    in a file descriptor.\n\n    .. versionchanged:: 3.0\n        The ``charset`` parameter was removed.\n    \"\"\"\n    if boundary is None:\n        boundary = f\"---------------WerkzeugFormPart_{time()}{random()}\"\n\n    stream: t.IO[bytes] = BytesIO()\n    total_length = 0\n    on_disk = False\n    write_binary: t.Callable[[bytes], int]\n\n    if use_tempfile:\n\n        def write_binary(s: bytes) -> int:\n            nonlocal stream, total_length, on_disk\n\n            if on_disk:\n                return stream.write(s)\n            else:\n                length = len(s)\n\n                if length + total_length <= threshold:\n                    stream.write(s)\n                else:\n                    new_stream = t.cast(t.IO[bytes], TemporaryFile(\"wb+\"))\n                    new_stream.write(stream.getvalue())  # type: ignore\n                    new_stream.write(s)\n                    stream = new_stream\n                    on_disk = True\n\n                total_length += length\n                return length\n\n    else:\n        write_binary = stream.write\n\n    encoder = MultipartEncoder(boundary.encode())\n    write_binary(encoder.send_event(Preamble(data=b\"\")))\n    for key, value in _iter_data(data):\n        reader = getattr(value, \"read\", None)\n        if reader is not None:\n            filename = getattr(value, \"filename\", getattr(value, \"name\", None))\n            content_type = getattr(value, \"content_type\", None)\n            if content_type is None:\n                content_type = (\n                    filename\n                    and mimetypes.guess_type(filename)[0]\n                    or \"application/octet-stream\"\n                )\n            headers = value.headers\n            headers.update([(\"Content-Type\", content_type)])\n            if filename is None:\n                write_binary(encoder.send_event(Field(name=key, headers=headers)))\n            else:\n                write_binary(\n                    encoder.send_event(\n                        File(name=key, filename=filename, headers=headers)\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\testapp.py": {
      "sha": "69a8c76b708d",
      "lines": 194,
      "head": "\"\"\"A small application that can be used to test a WSGI server and check\nit for WSGI compliance.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport importlib.metadata\nimport os\nimport sys\nimport typing as t\nfrom textwrap import wrap\n\nfrom markupsafe import escape\n\nfrom .wrappers.request import Request\nfrom .wrappers.response import Response\n\nTEMPLATE = \"\"\"\\\n<!doctype html>\n<html lang=en>\n<title>WSGI Information</title>\n<style type=\"text/css\">\n  @import url(https://fonts.googleapis.com/css?family=Ubuntu);\n\n  body       { font-family: 'Lucida Grande', 'Lucida Sans Unicode', 'Geneva',\n               'Verdana', sans-serif; background-color: white; color: #000;\n               font-size: 15px; text-align: center; }\n  div.box    { text-align: left; width: 45em; margin: auto; padding: 50px 0;\n               background-color: white; }\n  h1, h2     { font-family: 'Ubuntu', 'Lucida Grande', 'Lucida Sans Unicode',\n               'Geneva', 'Verdana', sans-serif; font-weight: normal; }\n  h1         { margin: 0 0 30px 0; }\n  h2         { font-size: 1.4em; margin: 1em 0 0.5em 0; }\n  table      { width: 100%%; border-collapse: collapse; border: 1px solid #AFC5C9 }\n  table th   { background-color: #AFC1C4; color: white; font-size: 0.72em;\n               font-weight: normal; width: 18em; vertical-align: top;\n               padding: 0.5em 0 0.1em 0.5em; }\n  table td   { border: 1px solid #AFC5C9; padding: 0.1em 0 0.1em 0.5em; }\n  code       { font-family: 'Consolas', 'Monaco', 'Bitstream Vera Sans Mono',\n               monospace; font-size: 0.7em; }\n  ul li      { line-height: 1.5em; }\n  ul.path    { font-size: 0.7em; margin: 0 -30px; padding: 8px 30px;\n               list-style: none; background: #E8EFF0; }\n  ul.path li { line-height: 1.6em; }\n  li.virtual { color: #999; text-decoration: underline; }\n  li.exp     { background: white; }\n</style>\n<div class=\"box\">\n  <h1>WSGI Information</h1>\n  <p>\n    This page displays all available information about the WSGI server and\n    the underlying Python interpreter.\n  <h2 id=\"python-interpreter\">Python Interpreter</h2>\n  <table>\n    <tr>\n      <th>Python Version\n      <td>%(python_version)s\n    <tr>\n      <th>Platform\n      <td>%(platform)s [%(os)s]\n    <tr>\n      <th>API Version\n      <td>%(api_version)s\n    <tr>\n      <th>Byteorder\n      <td>%(byteorder)s\n    <tr>\n      <th>Werkzeug Version\n      <td>%(werkzeug_version)s\n  </table>\n  <h2 id=\"wsgi-environment\">WSGI Environment</h2>\n  <table>%(wsgi_env)s</table>\n  <h2 id=\"installed-eggs\">Installed Eggs</h2>\n  <p>\n    The following python packages were installed on the system as\n    Python eggs:\n  <ul>%(python_eggs)s</ul>\n  <h2 id=\"sys-path\">System Path</h2>\n  <p>\n    The following paths are the current contents of the load path.  The\n    following entries are looked up for Python packages.  Note that not\n    all items in this path are folders.  Gray and underlined items are\n    entries pointing to invalid resources or used by custom import hooks\n    such as the zip importer.\n  <p>\n    Items with a bright background were expanded for display from a relative\n    path.  If you encounter such paths in the output you might want to check\n    your setup as relative paths are usually problematic in multithreaded\n    environments.\n  <ul class=\"path\">%(sys_path)s</ul>\n</div>\n\"\"\"\n\n\ndef iter_sys_path() -> t.Iterator[tuple[str, bool, bool]]:\n    if os.name == \"posix\":\n\n        def strip(x: str) -> str:\n            prefix = os.path.expanduser(\"~\")\n            if x.startswith(prefix):\n                x = f\"~{x[len(prefix) :]}\"\n            return x\n\n    else:\n\n        def strip(x: str) -> str:\n            return x\n\n    cwd = os.path.abspath(os.getcwd())\n    for item in sys.path:\n        path = os.path.join(cwd, item or os.path.curdir)\n        yield strip(os.path.normpath(path)), not os.path.isdir(path), path != item\n\n\n@Request.application\ndef test_app(req: Request) -> Response:\n    \"\"\"Simple test application that dumps the environment.  You can use\n    it to check if Werkzeug is working properly:\n\n    .. sourcecode:: pycon\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\urls.py": {
      "sha": "9f5ec7c1dc22",
      "lines": 203,
      "head": "from __future__ import annotations\n\nimport codecs\nimport re\nimport typing as t\nimport urllib.parse\nfrom urllib.parse import quote\nfrom urllib.parse import unquote\nfrom urllib.parse import urlencode\nfrom urllib.parse import urlsplit\nfrom urllib.parse import urlunsplit\n\nfrom .datastructures import iter_multi_items\n\n\ndef _codec_error_url_quote(e: UnicodeError) -> tuple[str, int]:\n    \"\"\"Used in :func:`uri_to_iri` after unquoting to re-quote any\n    invalid bytes.\n    \"\"\"\n    # the docs state that UnicodeError does have these attributes,\n    # but mypy isn't picking them up\n    out = quote(e.object[e.start : e.end], safe=\"\")  # type: ignore\n    return out, e.end  # type: ignore\n\n\ncodecs.register_error(\"werkzeug.url_quote\", _codec_error_url_quote)\n\n\ndef _make_unquote_part(name: str, chars: str) -> t.Callable[[str], str]:\n    \"\"\"Create a function that unquotes all percent encoded characters except those\n    given. This allows working with unquoted characters if possible while not changing\n    the meaning of a given part of a URL.\n    \"\"\"\n    choices = \"|\".join(f\"{ord(c):02X}\" for c in sorted(chars))\n    pattern = re.compile(f\"((?:%(?:{choices}))+)\", re.I)\n\n    def _unquote_partial(value: str) -> str:\n        parts = iter(pattern.split(value))\n        out = []\n\n        for part in parts:\n            out.append(unquote(part, \"utf-8\", \"werkzeug.url_quote\"))\n            out.append(next(parts, \"\"))\n\n        return \"\".join(out)\n\n    _unquote_partial.__name__ = f\"_unquote_{name}\"\n    return _unquote_partial\n\n\n# characters that should remain quoted in URL parts\n# based on https://url.spec.whatwg.org/#percent-encoded-bytes\n# always keep all controls, space, and % quoted\n_always_unsafe = bytes((*range(0x21), 0x25, 0x7F)).decode()\n_unquote_fragment = _make_unquote_part(\"fragment\", _always_unsafe)\n_unquote_query = _make_unquote_part(\"query\", _always_unsafe + \"&=+#\")\n_unquote_path = _make_unquote_part(\"path\", _always_unsafe + \"/?#\")\n_unquote_user = _make_unquote_part(\"user\", _always_unsafe + \":@/?#\")\n\n\ndef uri_to_iri(uri: str) -> str:\n    \"\"\"Convert a URI to an IRI. All valid UTF-8 characters are unquoted,\n    leaving all reserved and invalid characters quoted. If the URL has\n    a domain, it is decoded from Punycode.\n\n    >>> uri_to_iri(\"http://xn--n3h.net/p%C3%A5th?q=%C3%A8ry%DF\")\n    'http://\\\\u2603.net/p\\\\xe5th?q=\\\\xe8ry%DF'\n\n    :param uri: The URI to convert.\n\n    .. versionchanged:: 3.0\n        Passing a tuple or bytes, and the ``charset`` and ``errors`` parameters,\n        are removed.\n\n    .. versionchanged:: 2.3\n        Which characters remain quoted is specific to each part of the URL.\n\n    .. versionchanged:: 0.15\n        All reserved and invalid characters remain quoted. Previously,\n        only some reserved characters were preserved, and invalid bytes\n        were replaced instead of left quoted.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    parts = urlsplit(uri)\n    path = _unquote_path(parts.path)\n    query = _unquote_query(parts.query)\n    fragment = _unquote_fragment(parts.fragment)\n\n    if parts.hostname:\n        netloc = _decode_idna(parts.hostname)\n    else:\n        netloc = \"\"\n\n    if \":\" in netloc:\n        netloc = f\"[{netloc}]\"\n\n    if parts.port:\n        netloc = f\"{netloc}:{parts.port}\"\n\n    if parts.username:\n        auth = _unquote_user(parts.username)\n\n        if parts.password:\n            password = _unquote_user(parts.password)\n            auth = f\"{auth}:{password}\"\n\n        netloc = f\"{auth}@{netloc}\"\n\n    return urlunsplit((parts.scheme, netloc, path, query, fragment))\n\n\ndef iri_to_uri(iri: str) -> str:\n    \"\"\"Convert an IRI to a URI. All non-ASCII and unsafe characters are\n    quoted. If the URL has a domain, it is encoded to Punycode.\n\n    >>> iri_to_uri('http://\\\\u2603.net/p\\\\xe5th?q=\\\\xe8ry%DF')\n    'http://xn--n3h.net/p%C3%A5th?q=%C3%A8ry%DF'\n\n    :param iri: The IRI to convert.\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\user_agent.py": {
      "sha": "b11f02727521",
      "lines": 47,
      "head": "from __future__ import annotations\n\n\nclass UserAgent:\n    \"\"\"Represents a parsed user agent header value.\n\n    The default implementation does no parsing, only the :attr:`string`\n    attribute is set. A subclass may parse the string to set the\n    common attributes or expose other information. Set\n    :attr:`werkzeug.wrappers.Request.user_agent_class` to use a\n    subclass.\n\n    :param string: The header value to parse.\n\n    .. versionadded:: 2.0\n        This replaces the previous ``useragents`` module, but does not\n        provide a built-in parser.\n    \"\"\"\n\n    platform: str | None = None\n    \"\"\"The OS name, if it could be parsed from the string.\"\"\"\n\n    browser: str | None = None\n    \"\"\"The browser name, if it could be parsed from the string.\"\"\"\n\n    version: str | None = None\n    \"\"\"The browser version, if it could be parsed from the string.\"\"\"\n\n    language: str | None = None\n    \"\"\"The browser language, if it could be parsed from the string.\"\"\"\n\n    def __init__(self, string: str) -> None:\n        self.string: str = string\n        \"\"\"The original header value.\"\"\"\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.browser}/{self.version}>\"\n\n    def __str__(self) -> str:\n        return self.string\n\n    def __bool__(self) -> bool:\n        return bool(self.browser)\n\n    def to_header(self) -> str:\n        \"\"\"Convert to a header value.\"\"\"\n        return self.string\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\utils.py": {
      "sha": "723875262c9e",
      "lines": 691,
      "head": "from __future__ import annotations\n\nimport io\nimport mimetypes\nimport os\nimport pkgutil\nimport re\nimport sys\nimport typing as t\nimport unicodedata\nfrom datetime import datetime\nfrom time import time\nfrom urllib.parse import quote\nfrom zlib import adler32\n\nfrom markupsafe import escape\n\nfrom ._internal import _DictAccessorProperty\nfrom ._internal import _missing\nfrom ._internal import _TAccessorValue\nfrom .datastructures import Headers\nfrom .exceptions import NotFound\nfrom .exceptions import RequestedRangeNotSatisfiable\nfrom .security import safe_join\nfrom .wsgi import wrap_file\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .wrappers.request import Request\n    from .wrappers.response import Response\n\n_T = t.TypeVar(\"_T\")\n\n_entity_re = re.compile(r\"&([^;]+);\")\n_filename_ascii_strip_re = re.compile(r\"[^A-Za-z0-9_.-]\")\n_windows_device_files = {\n    \"CON\",\n    \"PRN\",\n    \"AUX\",\n    \"NUL\",\n    *(f\"COM{i}\" for i in range(10)),\n    *(f\"LPT{i}\" for i in range(10)),\n}\n\n\nclass cached_property(property, t.Generic[_T]):\n    \"\"\"A :func:`property` that is only evaluated once. Subsequent access\n    returns the cached value. Setting the property sets the cached\n    value. Deleting the property clears the cached value, accessing it\n    again will evaluate it again.\n\n    .. code-block:: python\n\n        class Example:\n            @cached_property\n            def value(self):\n                # calculate something important here\n                return 42\n\n        e = Example()\n        e.value  # evaluates\n        e.value  # uses cache\n        e.value = 16  # sets cache\n        del e.value  # clears cache\n\n    If the class defines ``__slots__``, it must add ``_cache_{name}`` as\n    a slot. Alternatively, it can add ``__dict__``, but that's usually\n    not desirable.\n\n    .. versionchanged:: 2.1\n        Works with ``__slots__``.\n\n    .. versionchanged:: 2.0\n        ``del obj.name`` clears the cached value.\n    \"\"\"\n\n    def __init__(\n        self,\n        fget: t.Callable[[t.Any], _T],\n        name: str | None = None,\n        doc: str | None = None,\n    ) -> None:\n        super().__init__(fget, doc=doc)\n        self.__name__ = name or fget.__name__\n        self.slot_name = f\"_cache_{self.__name__}\"\n        self.__module__ = fget.__module__\n\n    def __set__(self, obj: object, value: _T) -> None:\n        if hasattr(obj, \"__dict__\"):\n            obj.__dict__[self.__name__] = value\n        else:\n            setattr(obj, self.slot_name, value)\n\n    def __get__(self, obj: object, type: type = None) -> _T:  # type: ignore\n        if obj is None:\n            return self  # type: ignore\n\n        obj_dict = getattr(obj, \"__dict__\", None)\n\n        if obj_dict is not None:\n            value: _T = obj_dict.get(self.__name__, _missing)\n        else:\n            value = getattr(obj, self.slot_name, _missing)  # type: ignore[arg-type]\n\n        if value is _missing:\n            value = self.fget(obj)  # type: ignore\n\n            if obj_dict is not None:\n                obj.__dict__[self.__name__] = value\n            else:\n                setattr(obj, self.slot_name, value)\n\n        return value\n\n    def __delete__(self, obj: object) -> None:\n        if hasattr(obj, \"__dict__\"):\n            del obj.__dict__[self.__name__]\n        else:\n            setattr(obj, self.slot_name, _missing)\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\wsgi.py": {
      "sha": "627a2b92d485",
      "lines": 595,
      "head": "from __future__ import annotations\n\nimport io\nimport typing as t\nfrom functools import partial\nfrom functools import update_wrapper\n\nfrom .exceptions import ClientDisconnected\nfrom .exceptions import RequestEntityTooLarge\nfrom .sansio import utils as _sansio_utils\nfrom .sansio.utils import host_is_trusted  # noqa: F401 # Imported as part of API\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\ndef responder(f: t.Callable[..., WSGIApplication]) -> WSGIApplication:\n    \"\"\"Marks a function as responder.  Decorate a function with it and it\n    will automatically call the return value as WSGI application.\n\n    Example::\n\n        @responder\n        def application(environ, start_response):\n            return Response('Hello World!')\n    \"\"\"\n    return update_wrapper(lambda *a: f(*a)(*a[-2:]), f)\n\n\ndef get_current_url(\n    environ: WSGIEnvironment,\n    root_only: bool = False,\n    strip_querystring: bool = False,\n    host_only: bool = False,\n    trusted_hosts: t.Iterable[str] | None = None,\n) -> str:\n    \"\"\"Recreate the URL for a request from the parts in a WSGI\n    environment.\n\n    The URL is an IRI, not a URI, so it may contain Unicode characters.\n    Use :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.\n\n    :param environ: The WSGI environment to get the URL parts from.\n    :param root_only: Only build the root path, don't include the\n        remaining path or query string.\n    :param strip_querystring: Don't include the query string.\n    :param host_only: Only build the scheme and host.\n    :param trusted_hosts: A list of trusted host names to validate the\n        host against.\n    \"\"\"\n    parts = {\n        \"scheme\": environ[\"wsgi.url_scheme\"],\n        \"host\": get_host(environ, trusted_hosts),\n    }\n\n    if not host_only:\n        parts[\"root_path\"] = environ.get(\"SCRIPT_NAME\", \"\")\n\n        if not root_only:\n            parts[\"path\"] = environ.get(\"PATH_INFO\", \"\")\n\n            if not strip_querystring:\n                parts[\"query_string\"] = environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\")\n\n    return _sansio_utils.get_current_url(**parts)\n\n\ndef _get_server(\n    environ: WSGIEnvironment,\n) -> tuple[str, int | None] | None:\n    name = environ.get(\"SERVER_NAME\")\n\n    if name is None:\n        return None\n\n    try:\n        port: int | None = int(environ.get(\"SERVER_PORT\", None))\n    except (TypeError, ValueError):\n        # unix socket\n        port = None\n\n    return name, port\n\n\ndef get_host(\n    environ: WSGIEnvironment, trusted_hosts: t.Iterable[str] | None = None\n) -> str:\n    \"\"\"Return the host for the given WSGI environment.\n\n    The ``Host`` header is preferred, then ``SERVER_NAME`` if it's not\n    set. The returned host will only contain the port if it is different\n    than the standard port for the protocol.\n\n    Optionally, verify that the host is trusted using\n    :func:`host_is_trusted` and raise a\n    :exc:`~werkzeug.exceptions.SecurityError` if it is not.\n\n    :param environ: A WSGI environment dict.\n    :param trusted_hosts: A list of trusted host names.\n\n    :return: Host, with port if necessary.\n    :raise ~werkzeug.exceptions.SecurityError: If the host is not\n        trusted.\n    \"\"\"\n    return _sansio_utils.get_host(\n        environ[\"wsgi.url_scheme\"],\n        environ.get(\"HTTP_HOST\"),\n        _get_server(environ),\n        trusted_hosts,\n    )\n\n\ndef get_content_length(environ: WSGIEnvironment) -> int | None:\n    \"\"\"Return the ``Content-Length`` header value as an int. If the header is not given\n    or the ``Transfer-Encoding`` header is ``chunked``, ``None`` is returned to indicate\n    a streaming request. If the value is not an integer, or negative, 0 is returned.\n\n    :param environ: The WSGI environ to get the content length from.\n\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\_internal.py": {
      "sha": "64082bef7916",
      "lines": 211,
      "head": "from __future__ import annotations\n\nimport logging\nimport re\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timezone\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .wrappers.request import Request\n\n_logger: logging.Logger | None = None\n\n\nclass _Missing:\n    def __repr__(self) -> str:\n        return \"no value\"\n\n    def __reduce__(self) -> str:\n        return \"_missing\"\n\n\n_missing = _Missing()\n\n\ndef _wsgi_decoding_dance(s: str) -> str:\n    return s.encode(\"latin1\").decode(errors=\"replace\")\n\n\ndef _wsgi_encoding_dance(s: str) -> str:\n    return s.encode().decode(\"latin1\")\n\n\ndef _get_environ(obj: WSGIEnvironment | Request) -> WSGIEnvironment:\n    env = getattr(obj, \"environ\", obj)\n    assert isinstance(\n        env, dict\n    ), f\"{type(obj).__name__!r} is not a WSGI environment (has to be a dict)\"\n    return env\n\n\ndef _has_level_handler(logger: logging.Logger) -> bool:\n    \"\"\"Check if there is a handler in the logging chain that will handle\n    the given logger's effective level.\n    \"\"\"\n    level = logger.getEffectiveLevel()\n    current = logger\n\n    while current:\n        if any(handler.level <= level for handler in current.handlers):\n            return True\n\n        if not current.propagate:\n            break\n\n        current = current.parent  # type: ignore\n\n    return False\n\n\nclass _ColorStreamHandler(logging.StreamHandler):  # type: ignore[type-arg]\n    \"\"\"On Windows, wrap stream with Colorama for ANSI style support.\"\"\"\n\n    def __init__(self) -> None:\n        try:\n            import colorama\n        except ImportError:\n            stream = None\n        else:\n            stream = colorama.AnsiToWin32(sys.stderr)\n\n        super().__init__(stream)\n\n\ndef _log(type: str, message: str, *args: t.Any, **kwargs: t.Any) -> None:\n    \"\"\"Log a message to the 'werkzeug' logger.\n\n    The logger is created the first time it is needed. If there is no\n    level set, it is set to :data:`logging.INFO`. If there is no handler\n    for the logger's effective level, a :class:`logging.StreamHandler`\n    is added.\n    \"\"\"\n    global _logger\n\n    if _logger is None:\n        _logger = logging.getLogger(\"werkzeug\")\n\n        if _logger.level == logging.NOTSET:\n            _logger.setLevel(logging.INFO)\n\n        if not _has_level_handler(_logger):\n            _logger.addHandler(_ColorStreamHandler())\n\n    getattr(_logger, type)(message.rstrip(), *args, **kwargs)\n\n\n@t.overload\ndef _dt_as_utc(dt: None) -> None: ...\n\n\n@t.overload\ndef _dt_as_utc(dt: datetime) -> datetime: ...\n\n\ndef _dt_as_utc(dt: datetime | None) -> datetime | None:\n    if dt is None:\n        return dt\n\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n    elif dt.tzinfo != timezone.utc:\n        return dt.astimezone(timezone.utc)\n\n    return dt\n\n\n_TAccessorValue = t.TypeVar(\"_TAccessorValue\")\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\_reloader.py": {
      "sha": "23425061bbc9",
      "lines": 471,
      "head": "from __future__ import annotations\n\nimport fnmatch\nimport os\nimport subprocess\nimport sys\nimport threading\nimport time\nimport typing as t\nfrom itertools import chain\nfrom pathlib import PurePath\n\nfrom ._internal import _log\n\n# The various system prefixes where imports are found. Base values are\n# different when running in a virtualenv. All reloaders will ignore the\n# base paths (usually the system installation). The stat reloader won't\n# scan the virtualenv paths, it will only include modules that are\n# already imported.\n_ignore_always = tuple({sys.base_prefix, sys.base_exec_prefix})\nprefix = {*_ignore_always, sys.prefix, sys.exec_prefix}\n\nif hasattr(sys, \"real_prefix\"):\n    # virtualenv < 20\n    prefix.add(sys.real_prefix)\n\n_stat_ignore_scan = tuple(prefix)\ndel prefix\n_ignore_common_dirs = {\n    \"__pycache__\",\n    \".git\",\n    \".hg\",\n    \".tox\",\n    \".nox\",\n    \".pytest_cache\",\n    \".mypy_cache\",\n}\n\n\ndef _iter_module_paths() -> t.Iterator[str]:\n    \"\"\"Find the filesystem paths associated with imported modules.\"\"\"\n    # List is in case the value is modified by the app while updating.\n    for module in list(sys.modules.values()):\n        name = getattr(module, \"__file__\", None)\n\n        if name is None or name.startswith(_ignore_always):\n            continue\n\n        while not os.path.isfile(name):\n            # Zip file, find the base file without the module path.\n            old = name\n            name = os.path.dirname(name)\n\n            if name == old:  # skip if it was all directories somehow\n                break\n        else:\n            yield name\n\n\ndef _remove_by_pattern(paths: set[str], exclude_patterns: set[str]) -> None:\n    for pattern in exclude_patterns:\n        paths.difference_update(fnmatch.filter(paths, pattern))\n\n\ndef _find_stat_paths(\n    extra_files: set[str], exclude_patterns: set[str]\n) -> t.Iterable[str]:\n    \"\"\"Find paths for the stat reloader to watch. Returns imported\n    module files, Python files under non-system paths. Extra files and\n    Python files under extra directories can also be scanned.\n\n    System paths have to be excluded for efficiency. Non-system paths,\n    such as a project root or ``sys.path.insert``, should be the paths\n    of interest to the user anyway.\n    \"\"\"\n    paths = set()\n\n    for path in chain(list(sys.path), extra_files):\n        path = os.path.abspath(path)\n\n        if os.path.isfile(path):\n            # zip file on sys.path, or extra file\n            paths.add(path)\n            continue\n\n        parent_has_py = {os.path.dirname(path): True}\n\n        for root, dirs, files in os.walk(path):\n            # Optimizations: ignore system prefixes, __pycache__ will\n            # have a py or pyc module at the import path, ignore some\n            # common known dirs such as version control and tool caches.\n            if (\n                root.startswith(_stat_ignore_scan)\n                or os.path.basename(root) in _ignore_common_dirs\n            ):\n                dirs.clear()\n                continue\n\n            has_py = False\n\n            for name in files:\n                if name.endswith((\".py\", \".pyc\")):\n                    has_py = True\n                    paths.add(os.path.join(root, name))\n\n            # Optimization: stop scanning a directory if neither it nor\n            # its parent contained Python files.\n            if not (has_py or parent_has_py[os.path.dirname(root)]):\n                dirs.clear()\n                continue\n\n            parent_has_py[root] = has_py\n\n    paths.update(_iter_module_paths())\n    _remove_by_pattern(paths, exclude_patterns)\n    return paths\n\n\ndef _find_watchdog_paths(\n    extra_files: set[str], exclude_patterns: set[str]\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\__init__.py": {
      "sha": "da9ab3c93e1f",
      "lines": 4,
      "head": "from .serving import run_simple as run_simple\nfrom .test import Client as Client\nfrom .wrappers import Request as Request\nfrom .wrappers import Response as Response\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\accept.py": {
      "sha": "501c3239be59",
      "lines": 350,
      "head": "from __future__ import annotations\n\nimport codecs\nimport collections.abc as cabc\nimport re\nimport typing as t\n\nfrom .structures import ImmutableList\n\n\nclass Accept(ImmutableList[tuple[str, float]]):\n    \"\"\"An :class:`Accept` object is just a list subclass for lists of\n    ``(value, quality)`` tuples.  It is automatically sorted by specificity\n    and quality.\n\n    All :class:`Accept` objects work similar to a list but provide extra\n    functionality for working with the data.  Containment checks are\n    normalized to the rules of that header:\n\n    >>> a = CharsetAccept([('ISO-8859-1', 1), ('utf-8', 0.7)])\n    >>> a.best\n    'ISO-8859-1'\n    >>> 'iso-8859-1' in a\n    True\n    >>> 'UTF8' in a\n    True\n    >>> 'utf7' in a\n    False\n\n    To get the quality for an item you can use normal item lookup:\n\n    >>> print a['utf-8']\n    0.7\n    >>> a['utf7']\n    0\n\n    .. versionchanged:: 0.5\n       :class:`Accept` objects are forced immutable now.\n\n    .. versionchanged:: 1.0.0\n       :class:`Accept` internal values are no longer ordered\n       alphabetically for equal quality tags. Instead the initial\n       order is preserved.\n\n    \"\"\"\n\n    def __init__(\n        self, values: Accept | cabc.Iterable[tuple[str, float]] | None = ()\n    ) -> None:\n        if values is None:\n            super().__init__()\n            self.provided = False\n        elif isinstance(values, Accept):\n            self.provided = values.provided\n            super().__init__(values)\n        else:\n            self.provided = True\n            values = sorted(\n                values, key=lambda x: (self._specificity(x[0]), x[1]), reverse=True\n            )\n            super().__init__(values)\n\n    def _specificity(self, value: str) -> tuple[bool, ...]:\n        \"\"\"Returns a tuple describing the value's specificity.\"\"\"\n        return (value != \"*\",)\n\n    def _value_matches(self, value: str, item: str) -> bool:\n        \"\"\"Check if a value matches a given accept item.\"\"\"\n        return item == \"*\" or item.lower() == value.lower()\n\n    @t.overload\n    def __getitem__(self, key: str) -> float: ...\n    @t.overload\n    def __getitem__(self, key: t.SupportsIndex) -> tuple[str, float]: ...\n    @t.overload\n    def __getitem__(self, key: slice) -> list[tuple[str, float]]: ...\n    def __getitem__(\n        self, key: str | t.SupportsIndex | slice\n    ) -> float | tuple[str, float] | list[tuple[str, float]]:\n        \"\"\"Besides index lookup (getting item n) you can also pass it a string\n        to get the quality for the item.  If the item is not in the list, the\n        returned quality is ``0``.\n        \"\"\"\n        if isinstance(key, str):\n            return self.quality(key)\n        return list.__getitem__(self, key)\n\n    def quality(self, key: str) -> float:\n        \"\"\"Returns the quality of the key.\n\n        .. versionadded:: 0.6\n           In previous versions you had to use the item-lookup syntax\n           (eg: ``obj[key]`` instead of ``obj.quality(key)``)\n        \"\"\"\n        for item, quality in self:\n            if self._value_matches(key, item):\n                return quality\n        return 0\n\n    def __contains__(self, value: str) -> bool:  # type: ignore[override]\n        for item, _quality in self:\n            if self._value_matches(value, item):\n                return True\n        return False\n\n    def __repr__(self) -> str:\n        pairs_str = \", \".join(f\"({x!r}, {y})\" for x, y in self)\n        return f\"{type(self).__name__}([{pairs_str}])\"\n\n    def index(self, key: str | tuple[str, float]) -> int:  # type: ignore[override]\n        \"\"\"Get the position of an entry or raise :exc:`ValueError`.\n\n        :param key: The key to be looked up.\n\n        .. versionchanged:: 0.5\n           This used to raise :exc:`IndexError`, which was inconsistent\n           with the list API.\n        \"\"\"\n        if isinstance(key, str):\n            for idx, (item, _quality) in enumerate(self):\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\auth.py": {
      "sha": "86901e5dd67f",
      "lines": 317,
      "head": "from __future__ import annotations\n\nimport base64\nimport binascii\nimport collections.abc as cabc\nimport typing as t\n\nfrom ..http import dump_header\nfrom ..http import parse_dict_header\nfrom ..http import quote_header_value\nfrom .structures import CallbackDict\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n\nclass Authorization:\n    \"\"\"Represents the parts of an ``Authorization`` request header.\n\n    :attr:`.Request.authorization` returns an instance if the header is set.\n\n    An instance can be used with the test :class:`.Client` request methods' ``auth``\n    parameter to send the header in test requests.\n\n    Depending on the auth scheme, either :attr:`parameters` or :attr:`token` will be\n    set. The ``Basic`` scheme's token is decoded into the ``username`` and ``password``\n    parameters.\n\n    For convenience, ``auth[\"key\"]`` and ``auth.key`` both access the key in the\n    :attr:`parameters` dict, along with ``auth.get(\"key\")`` and ``\"key\" in auth``.\n\n    .. versionchanged:: 2.3\n        The ``token`` parameter and attribute was added to support auth schemes that use\n        a token instead of parameters, such as ``Bearer``.\n\n    .. versionchanged:: 2.3\n        The object is no longer a ``dict``.\n\n    .. versionchanged:: 0.5\n        The object is an immutable dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        auth_type: str,\n        data: dict[str, str | None] | None = None,\n        token: str | None = None,\n    ) -> None:\n        self.type = auth_type\n        \"\"\"The authorization scheme, like ``basic``, ``digest``, or ``bearer``.\"\"\"\n\n        if data is None:\n            data = {}\n\n        self.parameters = data\n        \"\"\"A dict of parameters parsed from the header. Either this or :attr:`token`\n        will have a value for a given scheme.\n        \"\"\"\n\n        self.token = token\n        \"\"\"A token parsed from the header. Either this or :attr:`parameters` will have a\n        value for a given scheme.\n\n        .. versionadded:: 2.3\n        \"\"\"\n\n    def __getattr__(self, name: str) -> str | None:\n        return self.parameters.get(name)\n\n    def __getitem__(self, name: str) -> str | None:\n        return self.parameters.get(name)\n\n    def get(self, key: str, default: str | None = None) -> str | None:\n        return self.parameters.get(key, default)\n\n    def __contains__(self, key: str) -> bool:\n        return key in self.parameters\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, Authorization):\n            return NotImplemented\n\n        return (\n            other.type == self.type\n            and other.token == self.token\n            and other.parameters == self.parameters\n        )\n\n    @classmethod\n    def from_header(cls, value: str | None) -> te.Self | None:\n        \"\"\"Parse an ``Authorization`` header value and return an instance, or ``None``\n        if the value is empty.\n\n        :param value: The header value to parse.\n\n        .. versionadded:: 2.3\n        \"\"\"\n        if not value:\n            return None\n\n        scheme, _, rest = value.partition(\" \")\n        scheme = scheme.lower()\n        rest = rest.strip()\n\n        if scheme == \"basic\":\n            try:\n                username, _, password = base64.b64decode(rest).decode().partition(\":\")\n            except (binascii.Error, UnicodeError):\n                return None\n\n            return cls(scheme, {\"username\": username, \"password\": password})\n\n        if \"=\" in rest.rstrip(\"=\"):\n            # = that is not trailing, this is parameters.\n            return cls(scheme, parse_dict_header(rest), None)\n\n        # No = or only trailing =, this is a token.\n        return cls(scheme, None, rest)\n\n    def to_header(self) -> str:\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\cache_control.py": {
      "sha": "877db6857d6a",
      "lines": 273,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\nfrom inspect import cleandoc\n\nfrom .mixins import ImmutableDictMixin\nfrom .structures import CallbackDict\n\n\ndef cache_control_property(\n    key: str, empty: t.Any, type: type[t.Any] | None, *, doc: str | None = None\n) -> t.Any:\n    \"\"\"Return a new property object for a cache header. Useful if you\n    want to add support for a cache extension in a subclass.\n\n    :param key: The attribute name present in the parsed cache-control header dict.\n    :param empty: The value to use if the key is present without a value.\n    :param type: The type to convert the string value to instead of a string. If\n        conversion raises a ``ValueError``, the returned value is ``None``.\n    :param doc: The docstring for the property. If not given, it is generated\n        based on the other params.\n\n    .. versionchanged:: 3.1\n        Added the ``doc`` param.\n\n    .. versionchanged:: 2.0\n        Renamed from ``cache_property``.\n    \"\"\"\n    if doc is None:\n        parts = [f\"The ``{key}`` attribute.\"]\n\n        if type is bool:\n            parts.append(\"A ``bool``, either present or not.\")\n        else:\n            if type is None:\n                parts.append(\"A ``str``,\")\n            else:\n                parts.append(f\"A ``{type.__name__}``,\")\n\n            if empty is not None:\n                parts.append(f\"``{empty!r}`` if present with no value,\")\n\n            parts.append(\"or ``None`` if not present.\")\n\n        doc = \" \".join(parts)\n\n    return property(\n        lambda x: x._get_cache_value(key, empty, type),\n        lambda x, v: x._set_cache_value(key, v, type),\n        lambda x: x._del_cache_value(key),\n        doc=cleandoc(doc),\n    )\n\n\nclass _CacheControl(CallbackDict[str, t.Optional[str]]):\n    \"\"\"Subclass of a dict that stores values for a Cache-Control header.  It\n    has accessors for all the cache-control directives specified in RFC 2616.\n    The class does not differentiate between request and response directives.\n\n    Because the cache-control directives in the HTTP header use dashes the\n    python descriptors use underscores for that.\n\n    To get a header of the :class:`CacheControl` object again you can convert\n    the object into a string or call the :meth:`to_header` method.  If you plan\n    to subclass it and add your own items have a look at the sourcecode for\n    that class.\n\n    .. versionchanged:: 3.1\n        Dict values are always ``str | None``. Setting properties will\n        convert the value to a string. Setting a non-bool property to\n        ``False`` is equivalent to setting it to ``None``. Getting typed\n        properties will return ``None`` if conversion raises\n        ``ValueError``, rather than the string.\n\n    .. versionchanged:: 2.1\n        Setting int properties such as ``max_age`` will convert the\n        value to an int.\n\n    .. versionchanged:: 0.4\n       Setting ``no_cache`` or ``private`` to ``True`` will set the\n       implicit value ``\"*\"``.\n    \"\"\"\n\n    no_store: bool = cache_control_property(\"no-store\", None, bool)\n    max_age: int | None = cache_control_property(\"max-age\", None, int)\n    no_transform: bool = cache_control_property(\"no-transform\", None, bool)\n    stale_if_error: int | None = cache_control_property(\"stale-if-error\", None, int)\n\n    def __init__(\n        self,\n        values: cabc.Mapping[str, t.Any] | cabc.Iterable[tuple[str, t.Any]] | None = (),\n        on_update: cabc.Callable[[_CacheControl], None] | None = None,\n    ):\n        super().__init__(values, on_update)\n        self.provided = values is not None\n\n    def _get_cache_value(\n        self, key: str, empty: t.Any, type: type[t.Any] | None\n    ) -> t.Any:\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        if type is bool:\n            return key in self\n\n        if key not in self:\n            return None\n\n        if (value := self[key]) is None:\n            return empty\n\n        if type is not None:\n            try:\n                value = type(value)\n            except ValueError:\n                return None\n\n        return value\n\n    def _set_cache_value(\n        self, key: str, value: t.Any, type: type[t.Any] | None\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\csp.py": {
      "sha": "62ca66d35df5",
      "lines": 100,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\n\nfrom .structures import CallbackDict\n\n\ndef csp_property(key: str) -> t.Any:\n    \"\"\"Return a new property object for a content security policy header.\n    Useful if you want to add support for a csp extension in a\n    subclass.\n    \"\"\"\n    return property(\n        lambda x: x._get_value(key),\n        lambda x, v: x._set_value(key, v),\n        lambda x: x._del_value(key),\n        f\"accessor for {key!r}\",\n    )\n\n\nclass ContentSecurityPolicy(CallbackDict[str, str]):\n    \"\"\"Subclass of a dict that stores values for a Content Security Policy\n    header. It has accessors for all the level 3 policies.\n\n    Because the csp directives in the HTTP header use dashes the\n    python descriptors use underscores for that.\n\n    To get a header of the :class:`ContentSecuirtyPolicy` object again\n    you can convert the object into a string or call the\n    :meth:`to_header` method.  If you plan to subclass it and add your\n    own items have a look at the sourcecode for that class.\n\n    .. versionadded:: 1.0.0\n       Support for Content Security Policy headers was added.\n\n    \"\"\"\n\n    base_uri: str | None = csp_property(\"base-uri\")\n    child_src: str | None = csp_property(\"child-src\")\n    connect_src: str | None = csp_property(\"connect-src\")\n    default_src: str | None = csp_property(\"default-src\")\n    font_src: str | None = csp_property(\"font-src\")\n    form_action: str | None = csp_property(\"form-action\")\n    frame_ancestors: str | None = csp_property(\"frame-ancestors\")\n    frame_src: str | None = csp_property(\"frame-src\")\n    img_src: str | None = csp_property(\"img-src\")\n    manifest_src: str | None = csp_property(\"manifest-src\")\n    media_src: str | None = csp_property(\"media-src\")\n    navigate_to: str | None = csp_property(\"navigate-to\")\n    object_src: str | None = csp_property(\"object-src\")\n    prefetch_src: str | None = csp_property(\"prefetch-src\")\n    plugin_types: str | None = csp_property(\"plugin-types\")\n    report_to: str | None = csp_property(\"report-to\")\n    report_uri: str | None = csp_property(\"report-uri\")\n    sandbox: str | None = csp_property(\"sandbox\")\n    script_src: str | None = csp_property(\"script-src\")\n    script_src_attr: str | None = csp_property(\"script-src-attr\")\n    script_src_elem: str | None = csp_property(\"script-src-elem\")\n    style_src: str | None = csp_property(\"style-src\")\n    style_src_attr: str | None = csp_property(\"style-src-attr\")\n    style_src_elem: str | None = csp_property(\"style-src-elem\")\n    worker_src: str | None = csp_property(\"worker-src\")\n\n    def __init__(\n        self,\n        values: cabc.Mapping[str, str] | cabc.Iterable[tuple[str, str]] | None = (),\n        on_update: cabc.Callable[[ContentSecurityPolicy], None] | None = None,\n    ) -> None:\n        super().__init__(values, on_update)\n        self.provided = values is not None\n\n    def _get_value(self, key: str) -> str | None:\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        return self.get(key)\n\n    def _set_value(self, key: str, value: str | None) -> None:\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        if value is None:\n            self.pop(key, None)\n        else:\n            self[key] = value\n\n    def _del_value(self, key: str) -> None:\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        if key in self:\n            del self[key]\n\n    def to_header(self) -> str:\n        \"\"\"Convert the stored values into a cache control header.\"\"\"\n        from ..http import dump_csp_header\n\n        return dump_csp_header(self)\n\n    def __str__(self) -> str:\n        return self.to_header()\n\n    def __repr__(self) -> str:\n        kv_str = \" \".join(f\"{k}={v!r}\" for k, v in sorted(self.items()))\n        return f\"<{type(self).__name__} {kv_str}>\"\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\etag.py": {
      "sha": "ea4a8f1e76af",
      "lines": 106,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\n\n\nclass ETags(cabc.Collection[str]):\n    \"\"\"A set that can be used to check if one etag is present in a collection\n    of etags.\n    \"\"\"\n\n    def __init__(\n        self,\n        strong_etags: cabc.Iterable[str] | None = None,\n        weak_etags: cabc.Iterable[str] | None = None,\n        star_tag: bool = False,\n    ):\n        if not star_tag and strong_etags:\n            self._strong = frozenset(strong_etags)\n        else:\n            self._strong = frozenset()\n\n        self._weak = frozenset(weak_etags or ())\n        self.star_tag = star_tag\n\n    def as_set(self, include_weak: bool = False) -> set[str]:\n        \"\"\"Convert the `ETags` object into a python set.  Per default all the\n        weak etags are not part of this set.\"\"\"\n        rv = set(self._strong)\n        if include_weak:\n            rv.update(self._weak)\n        return rv\n\n    def is_weak(self, etag: str) -> bool:\n        \"\"\"Check if an etag is weak.\"\"\"\n        return etag in self._weak\n\n    def is_strong(self, etag: str) -> bool:\n        \"\"\"Check if an etag is strong.\"\"\"\n        return etag in self._strong\n\n    def contains_weak(self, etag: str) -> bool:\n        \"\"\"Check if an etag is part of the set including weak and strong tags.\"\"\"\n        return self.is_weak(etag) or self.contains(etag)\n\n    def contains(self, etag: str) -> bool:\n        \"\"\"Check if an etag is part of the set ignoring weak tags.\n        It is also possible to use the ``in`` operator.\n        \"\"\"\n        if self.star_tag:\n            return True\n        return self.is_strong(etag)\n\n    def contains_raw(self, etag: str) -> bool:\n        \"\"\"When passed a quoted tag it will check if this tag is part of the\n        set.  If the tag is weak it is checked against weak and strong tags,\n        otherwise strong only.\"\"\"\n        from ..http import unquote_etag\n\n        etag, weak = unquote_etag(etag)\n        if weak:\n            return self.contains_weak(etag)\n        return self.contains(etag)\n\n    def to_header(self) -> str:\n        \"\"\"Convert the etags set into a HTTP header string.\"\"\"\n        if self.star_tag:\n            return \"*\"\n        return \", \".join(\n            [f'\"{x}\"' for x in self._strong] + [f'W/\"{x}\"' for x in self._weak]\n        )\n\n    def __call__(\n        self,\n        etag: str | None = None,\n        data: bytes | None = None,\n        include_weak: bool = False,\n    ) -> bool:\n        if etag is None:\n            if data is None:\n                raise TypeError(\"'data' is required when 'etag' is not given.\")\n\n            from ..http import generate_etag\n\n            etag = generate_etag(data)\n        if include_weak:\n            if etag in self._weak:\n                return True\n        return etag in self._strong\n\n    def __bool__(self) -> bool:\n        return bool(self.star_tag or self._strong or self._weak)\n\n    def __str__(self) -> str:\n        return self.to_header()\n\n    def __len__(self) -> int:\n        return len(self._strong)\n\n    def __iter__(self) -> cabc.Iterator[str]:\n        return iter(self._strong)\n\n    def __contains__(self, etag: str) -> bool:  # type: ignore[override]\n        return self.contains(etag)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {str(self)!r}>\"\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\file_storage.py": {
      "sha": "915d3f0affe3",
      "lines": 209,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport mimetypes\nimport os\nimport typing as t\nfrom io import BytesIO\nfrom os import fsdecode\nfrom os import fspath\n\nfrom .._internal import _plain_int\nfrom .headers import Headers\nfrom .structures import MultiDict\n\n\nclass FileStorage:\n    \"\"\"The :class:`FileStorage` class is a thin wrapper over incoming files.\n    It is used by the request object to represent uploaded files.  All the\n    attributes of the wrapper stream are proxied by the file storage so\n    it's possible to do ``storage.read()`` instead of the long form\n    ``storage.stream.read()``.\n    \"\"\"\n\n    def __init__(\n        self,\n        stream: t.IO[bytes] | None = None,\n        filename: str | None = None,\n        name: str | None = None,\n        content_type: str | None = None,\n        content_length: int | None = None,\n        headers: Headers | None = None,\n    ):\n        self.name = name\n        self.stream = stream or BytesIO()\n\n        # If no filename is provided, attempt to get the filename from\n        # the stream object. Python names special streams like\n        # ``<stderr>`` with angular brackets, skip these streams.\n        if filename is None:\n            filename = getattr(stream, \"name\", None)\n\n            if filename is not None:\n                filename = fsdecode(filename)\n\n            if filename and filename[0] == \"<\" and filename[-1] == \">\":\n                filename = None\n        else:\n            filename = fsdecode(filename)\n\n        self.filename = filename\n\n        if headers is None:\n            headers = Headers()\n        self.headers = headers\n        if content_type is not None:\n            headers[\"Content-Type\"] = content_type\n        if content_length is not None:\n            headers[\"Content-Length\"] = str(content_length)\n\n    def _parse_content_type(self) -> None:\n        if not hasattr(self, \"_parsed_content_type\"):\n            self._parsed_content_type = http.parse_options_header(self.content_type)\n\n    @property\n    def content_type(self) -> str | None:\n        \"\"\"The content-type sent in the header.  Usually not available\"\"\"\n        return self.headers.get(\"content-type\")\n\n    @property\n    def content_length(self) -> int:\n        \"\"\"The content-length sent in the header.  Usually not available\"\"\"\n        if \"content-length\" in self.headers:\n            try:\n                return _plain_int(self.headers[\"content-length\"])\n            except ValueError:\n                pass\n\n        return 0\n\n    @property\n    def mimetype(self) -> str:\n        \"\"\"Like :attr:`content_type`, but without parameters (eg, without\n        charset, type etc.) and always lowercase.  For example if the content\n        type is ``text/HTML; charset=utf-8`` the mimetype would be\n        ``'text/html'``.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        self._parse_content_type()\n        return self._parsed_content_type[0].lower()\n\n    @property\n    def mimetype_params(self) -> dict[str, str]:\n        \"\"\"The mimetype parameters as dict.  For example if the content\n        type is ``text/html; charset=utf-8`` the params would be\n        ``{'charset': 'utf-8'}``.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        self._parse_content_type()\n        return self._parsed_content_type[1]\n\n    def save(\n        self, dst: str | os.PathLike[str] | t.IO[bytes], buffer_size: int = 16384\n    ) -> None:\n        \"\"\"Save the file to a destination path or file object.  If the\n        destination is a file object you have to close it yourself after the\n        call.  The buffer size is the number of bytes held in memory during\n        the copy process.  It defaults to 16KB.\n\n        For secure file saving also have a look at :func:`secure_filename`.\n\n        :param dst: a filename, :class:`os.PathLike`, or open file\n            object to write to.\n        :param buffer_size: Passed as the ``length`` parameter of\n            :func:`shutil.copyfileobj`.\n\n        .. versionchanged:: 1.0\n            Supports :mod:`pathlib`.\n        \"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\headers.py": {
      "sha": "e8180ae00e84",
      "lines": 662,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport re\nimport typing as t\n\nfrom .._internal import _missing\nfrom ..exceptions import BadRequestKeyError\nfrom .mixins import ImmutableHeadersMixin\nfrom .structures import iter_multi_items\nfrom .structures import MultiDict\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n    from _typeshed.wsgi import WSGIEnvironment\n\nT = t.TypeVar(\"T\")\n\n\nclass Headers:\n    \"\"\"An object that stores some headers. It has a dict-like interface,\n    but is ordered, can store the same key multiple times, and iterating\n    yields ``(key, value)`` pairs instead of only keys.\n\n    This data structure is useful if you want a nicer way to handle WSGI\n    headers which are stored as tuples in a list.\n\n    From Werkzeug 0.3 onwards, the :exc:`KeyError` raised by this class is\n    also a subclass of the :class:`~exceptions.BadRequest` HTTP exception\n    and will render a page for a ``400 BAD REQUEST`` if caught in a\n    catch-all for HTTP exceptions.\n\n    Headers is mostly compatible with the Python :class:`wsgiref.headers.Headers`\n    class, with the exception of `__getitem__`.  :mod:`wsgiref` will return\n    `None` for ``headers['missing']``, whereas :class:`Headers` will raise\n    a :class:`KeyError`.\n\n    To create a new ``Headers`` object, pass it a list, dict, or\n    other ``Headers`` object with default values. These values are\n    validated the same way values added later are.\n\n    :param defaults: The list of default values for the :class:`Headers`.\n\n    .. versionchanged:: 3.1\n        Implement ``|`` and ``|=`` operators.\n\n    .. versionchanged:: 2.1.0\n        Default values are validated the same as values added later.\n\n    .. versionchanged:: 0.9\n       This data structure now stores unicode values similar to how the\n       multi dicts do it.  The main difference is that bytes can be set as\n       well which will automatically be latin1 decoded.\n\n    .. versionchanged:: 0.9\n       The :meth:`linked` function was removed without replacement as it\n       was an API that does not support the changes to the encoding model.\n    \"\"\"\n\n    def __init__(\n        self,\n        defaults: (\n            Headers\n            | MultiDict[str, t.Any]\n            | cabc.Mapping[str, t.Any | list[t.Any] | tuple[t.Any, ...] | set[t.Any]]\n            | cabc.Iterable[tuple[str, t.Any]]\n            | None\n        ) = None,\n    ) -> None:\n        self._list: list[tuple[str, str]] = []\n\n        if defaults is not None:\n            self.extend(defaults)\n\n    @t.overload\n    def __getitem__(self, key: str) -> str: ...\n    @t.overload\n    def __getitem__(self, key: int) -> tuple[str, str]: ...\n    @t.overload\n    def __getitem__(self, key: slice) -> te.Self: ...\n    def __getitem__(self, key: str | int | slice) -> str | tuple[str, str] | te.Self:\n        if isinstance(key, str):\n            return self._get_key(key)\n\n        if isinstance(key, int):\n            return self._list[key]\n\n        return self.__class__(self._list[key])\n\n    def _get_key(self, key: str) -> str:\n        ikey = key.lower()\n\n        for k, v in self._list:\n            if k.lower() == ikey:\n                return v\n\n        raise BadRequestKeyError(key)\n\n    def __eq__(self, other: object) -> bool:\n        if other.__class__ is not self.__class__:\n            return NotImplemented\n\n        def lowered(item: tuple[str, ...]) -> tuple[str, ...]:\n            return item[0].lower(), *item[1:]\n\n        return set(map(lowered, other._list)) == set(map(lowered, self._list))  # type: ignore[attr-defined]\n\n    __hash__ = None  # type: ignore[assignment]\n\n    @t.overload\n    def get(self, key: str) -> str | None: ...\n    @t.overload\n    def get(self, key: str, default: str) -> str: ...\n    @t.overload\n    def get(self, key: str, default: T) -> str | T: ...\n    @t.overload\n    def get(self, key: str, type: cabc.Callable[[str], T]) -> T | None: ...\n    @t.overload\n    def get(self, key: str, default: T, type: cabc.Callable[[str], T]) -> T: ...\n    def get(  # type: ignore[misc]\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\mixins.py": {
      "sha": "eb0c86a52b01",
      "lines": 317,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\nfrom functools import update_wrapper\nfrom itertools import repeat\n\nfrom .._internal import _missing\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\nK = t.TypeVar(\"K\")\nV = t.TypeVar(\"V\")\nT = t.TypeVar(\"T\")\nF = t.TypeVar(\"F\", bound=cabc.Callable[..., t.Any])\n\n\ndef _immutable_error(self: t.Any) -> t.NoReturn:\n    raise TypeError(f\"{type(self).__name__!r} objects are immutable\")\n\n\nclass ImmutableListMixin:\n    \"\"\"Makes a :class:`list` immutable.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    _hash_cache: int | None = None\n\n    def __hash__(self) -> int:\n        if self._hash_cache is not None:\n            return self._hash_cache\n        rv = self._hash_cache = hash(tuple(self))  # type: ignore[arg-type]\n        return rv\n\n    def __reduce_ex__(self, protocol: t.SupportsIndex) -> t.Any:\n        return type(self), (list(self),)  # type: ignore[call-overload]\n\n    def __delitem__(self, key: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def __iadd__(self, other: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def __imul__(self, other: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def __setitem__(self, key: t.Any, value: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def append(self, item: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def remove(self, item: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def extend(self, iterable: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def insert(self, pos: t.Any, value: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def pop(self, index: t.Any = -1) -> t.NoReturn:\n        _immutable_error(self)\n\n    def reverse(self: t.Any) -> t.NoReturn:\n        _immutable_error(self)\n\n    def sort(self, key: t.Any = None, reverse: t.Any = False) -> t.NoReturn:\n        _immutable_error(self)\n\n\nclass ImmutableDictMixin(t.Generic[K, V]):\n    \"\"\"Makes a :class:`dict` immutable.\n\n    .. versionchanged:: 3.1\n        Disallow ``|=`` operator.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    _hash_cache: int | None = None\n\n    @classmethod\n    @t.overload\n    def fromkeys(\n        cls, keys: cabc.Iterable[K], value: None\n    ) -> ImmutableDictMixin[K, t.Any | None]: ...\n    @classmethod\n    @t.overload\n    def fromkeys(cls, keys: cabc.Iterable[K], value: V) -> ImmutableDictMixin[K, V]: ...\n    @classmethod\n    def fromkeys(\n        cls, keys: cabc.Iterable[K], value: V | None = None\n    ) -> ImmutableDictMixin[K, t.Any | None] | ImmutableDictMixin[K, V]:\n        instance = super().__new__(cls)\n        instance.__init__(zip(keys, repeat(value)))  # type: ignore[misc]\n        return instance\n\n    def __reduce_ex__(self, protocol: t.SupportsIndex) -> t.Any:\n        return type(self), (dict(self),)  # type: ignore[call-overload]\n\n    def _iter_hashitems(self) -> t.Iterable[t.Any]:\n        return self.items()  # type: ignore[attr-defined,no-any-return]\n\n    def __hash__(self) -> int:\n        if self._hash_cache is not None:\n            return self._hash_cache\n        rv = self._hash_cache = hash(frozenset(self._iter_hashitems()))\n        return rv\n\n    def setdefault(self, key: t.Any, default: t.Any = None) -> t.NoReturn:\n        _immutable_error(self)\n\n    def update(self, arg: t.Any, /, **kwargs: t.Any) -> t.NoReturn:\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\range.py": {
      "sha": "351bd6f6a387",
      "lines": 214,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\nfrom datetime import datetime\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\nT = t.TypeVar(\"T\")\n\n\nclass IfRange:\n    \"\"\"Very simple object that represents the `If-Range` header in parsed\n    form.  It will either have neither a etag or date or one of either but\n    never both.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    def __init__(self, etag: str | None = None, date: datetime | None = None):\n        #: The etag parsed and unquoted.  Ranges always operate on strong\n        #: etags so the weakness information is not necessary.\n        self.etag = etag\n        #: The date in parsed format or `None`.\n        self.date = date\n\n    def to_header(self) -> str:\n        \"\"\"Converts the object back into an HTTP header.\"\"\"\n        if self.date is not None:\n            return http.http_date(self.date)\n        if self.etag is not None:\n            return http.quote_etag(self.etag)\n        return \"\"\n\n    def __str__(self) -> str:\n        return self.to_header()\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {str(self)!r}>\"\n\n\nclass Range:\n    \"\"\"Represents a ``Range`` header. All methods only support only\n    bytes as the unit. Stores a list of ranges if given, but the methods\n    only work if only one range is provided.\n\n    :raise ValueError: If the ranges provided are invalid.\n\n    .. versionchanged:: 0.15\n        The ranges passed in are validated.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    def __init__(\n        self, units: str, ranges: cabc.Sequence[tuple[int, int | None]]\n    ) -> None:\n        #: The units of this range.  Usually \"bytes\".\n        self.units = units\n        #: A list of ``(begin, end)`` tuples for the range header provided.\n        #: The ranges are non-inclusive.\n        self.ranges = ranges\n\n        for start, end in ranges:\n            if start is None or (end is not None and (start < 0 or start >= end)):\n                raise ValueError(f\"{(start, end)} is not a valid range.\")\n\n    def range_for_length(self, length: int | None) -> tuple[int, int] | None:\n        \"\"\"If the range is for bytes, the length is not None and there is\n        exactly one range and it is satisfiable it returns a ``(start, stop)``\n        tuple, otherwise `None`.\n        \"\"\"\n        if self.units != \"bytes\" or length is None or len(self.ranges) != 1:\n            return None\n        start, end = self.ranges[0]\n        if end is None:\n            end = length\n            if start < 0:\n                start += length\n        if http.is_byte_range_valid(start, end, length):\n            return start, min(end, length)\n        return None\n\n    def make_content_range(self, length: int | None) -> ContentRange | None:\n        \"\"\"Creates a :class:`~werkzeug.datastructures.ContentRange` object\n        from the current range and given content length.\n        \"\"\"\n        rng = self.range_for_length(length)\n        if rng is not None:\n            return ContentRange(self.units, rng[0], rng[1], length)\n        return None\n\n    def to_header(self) -> str:\n        \"\"\"Converts the object back into an HTTP header.\"\"\"\n        ranges = []\n        for begin, end in self.ranges:\n            if end is None:\n                ranges.append(f\"{begin}-\" if begin >= 0 else str(begin))\n            else:\n                ranges.append(f\"{begin}-{end - 1}\")\n        return f\"{self.units}={','.join(ranges)}\"\n\n    def to_content_range_header(self, length: int | None) -> str | None:\n        \"\"\"Converts the object into `Content-Range` HTTP header,\n        based on given length\n        \"\"\"\n        range = self.range_for_length(length)\n        if range is not None:\n            return f\"{self.units} {range[0]}-{range[1] - 1}/{length}\"\n        return None\n\n    def __str__(self) -> str:\n        return self.to_header()\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {str(self)!r}>\"\n\n\nclass _CallbackProperty(t.Generic[T]):\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\structures.py": {
      "sha": "c4738536a499",
      "lines": 1239,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\nfrom copy import deepcopy\n\nfrom .. import exceptions\nfrom .._internal import _missing\nfrom .mixins import ImmutableDictMixin\nfrom .mixins import ImmutableListMixin\nfrom .mixins import ImmutableMultiDictMixin\nfrom .mixins import UpdateDictMixin\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\nK = t.TypeVar(\"K\")\nV = t.TypeVar(\"V\")\nT = t.TypeVar(\"T\")\n\n\ndef iter_multi_items(\n    mapping: (\n        MultiDict[K, V]\n        | cabc.Mapping[K, V | list[V] | tuple[V, ...] | set[V]]\n        | cabc.Iterable[tuple[K, V]]\n    ),\n) -> cabc.Iterator[tuple[K, V]]:\n    \"\"\"Iterates over the items of a mapping yielding keys and values\n    without dropping any from more complex structures.\n    \"\"\"\n    if isinstance(mapping, MultiDict):\n        yield from mapping.items(multi=True)\n    elif isinstance(mapping, cabc.Mapping):\n        for key, value in mapping.items():\n            if isinstance(value, (list, tuple, set)):\n                for v in value:\n                    yield key, v\n            else:\n                yield key, value\n    else:\n        yield from mapping\n\n\nclass ImmutableList(ImmutableListMixin, list[V]):  # type: ignore[misc]\n    \"\"\"An immutable :class:`list`.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    def __repr__(self) -> str:\n        return f\"{type(self).__name__}({list.__repr__(self)})\"\n\n\nclass TypeConversionDict(dict[K, V]):\n    \"\"\"Works like a regular dict but the :meth:`get` method can perform\n    type conversions.  :class:`MultiDict` and :class:`CombinedMultiDict`\n    are subclasses of this class and provide the same feature.\n\n    .. versionadded:: 0.5\n    \"\"\"\n\n    @t.overload  # type: ignore[override]\n    def get(self, key: K) -> V | None: ...\n    @t.overload\n    def get(self, key: K, default: V) -> V: ...\n    @t.overload\n    def get(self, key: K, default: T) -> V | T: ...\n    @t.overload\n    def get(self, key: str, type: cabc.Callable[[V], T]) -> T | None: ...\n    @t.overload\n    def get(self, key: str, default: T, type: cabc.Callable[[V], T]) -> T: ...\n    def get(  # type: ignore[misc]\n        self,\n        key: K,\n        default: V | T | None = None,\n        type: cabc.Callable[[V], T] | None = None,\n    ) -> V | T | None:\n        \"\"\"Return the default value if the requested data doesn't exist.\n        If `type` is provided and is a callable it should convert the value,\n        return it or raise a :exc:`ValueError` if that is not possible.  In\n        this case the function will return the default as if the value was not\n        found:\n\n        >>> d = TypeConversionDict(foo='42', bar='blub')\n        >>> d.get('foo', type=int)\n        42\n        >>> d.get('bar', -1, type=int)\n        -1\n\n        :param key: The key to be looked up.\n        :param default: The default value to be returned if the key can't\n                        be looked up.  If not further specified `None` is\n                        returned.\n        :param type: A callable that is used to cast the value in the\n                     :class:`MultiDict`.  If a :exc:`ValueError` or a\n                     :exc:`TypeError` is raised by this callable the default\n                     value is returned.\n\n        .. versionchanged:: 3.0.2\n           Returns the default value on :exc:`TypeError`, too.\n        \"\"\"\n        try:\n            rv = self[key]\n        except KeyError:\n            return default\n\n        if type is None:\n            return rv\n\n        try:\n            return type(rv)\n        except (ValueError, TypeError):\n            return default\n\n\nclass ImmutableTypeConversionDict(ImmutableDictMixin[K, V], TypeConversionDict[K, V]):  # type: ignore[misc]\n    \"\"\"Works like a :class:`TypeConversionDict` but does not support\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\datastructures\\__init__.py": {
      "sha": "ccefad0761d9",
      "lines": 64,
      "head": "from __future__ import annotations\n\nimport typing as t\n\nfrom .accept import Accept as Accept\nfrom .accept import CharsetAccept as CharsetAccept\nfrom .accept import LanguageAccept as LanguageAccept\nfrom .accept import MIMEAccept as MIMEAccept\nfrom .auth import Authorization as Authorization\nfrom .auth import WWWAuthenticate as WWWAuthenticate\nfrom .cache_control import RequestCacheControl as RequestCacheControl\nfrom .cache_control import ResponseCacheControl as ResponseCacheControl\nfrom .csp import ContentSecurityPolicy as ContentSecurityPolicy\nfrom .etag import ETags as ETags\nfrom .file_storage import FileMultiDict as FileMultiDict\nfrom .file_storage import FileStorage as FileStorage\nfrom .headers import EnvironHeaders as EnvironHeaders\nfrom .headers import Headers as Headers\nfrom .mixins import ImmutableDictMixin as ImmutableDictMixin\nfrom .mixins import ImmutableHeadersMixin as ImmutableHeadersMixin\nfrom .mixins import ImmutableListMixin as ImmutableListMixin\nfrom .mixins import ImmutableMultiDictMixin as ImmutableMultiDictMixin\nfrom .mixins import UpdateDictMixin as UpdateDictMixin\nfrom .range import ContentRange as ContentRange\nfrom .range import IfRange as IfRange\nfrom .range import Range as Range\nfrom .structures import CallbackDict as CallbackDict\nfrom .structures import CombinedMultiDict as CombinedMultiDict\nfrom .structures import HeaderSet as HeaderSet\nfrom .structures import ImmutableDict as ImmutableDict\nfrom .structures import ImmutableList as ImmutableList\nfrom .structures import ImmutableMultiDict as ImmutableMultiDict\nfrom .structures import ImmutableTypeConversionDict as ImmutableTypeConversionDict\nfrom .structures import iter_multi_items as iter_multi_items\nfrom .structures import MultiDict as MultiDict\nfrom .structures import TypeConversionDict as TypeConversionDict\n\n\ndef __getattr__(name: str) -> t.Any:\n    import warnings\n\n    if name == \"OrderedMultiDict\":\n        from .structures import _OrderedMultiDict\n\n        warnings.warn(\n            \"'OrderedMultiDict' is deprecated and will be removed in Werkzeug\"\n            \" 3.2. Use 'MultiDict' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _OrderedMultiDict\n\n    if name == \"ImmutableOrderedMultiDict\":\n        from .structures import _ImmutableOrderedMultiDict\n\n        warnings.warn(\n            \"'OrderedMultiDict' is deprecated and will be removed in Werkzeug\"\n            \" 3.2. Use 'ImmutableMultiDict' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _ImmutableOrderedMultiDict\n\n    raise AttributeError(name)\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\console.py": {
      "sha": "ab6af7a12dad",
      "lines": 219,
      "head": "from __future__ import annotations\n\nimport code\nimport sys\nimport typing as t\nfrom contextvars import ContextVar\nfrom types import CodeType\n\nfrom markupsafe import escape\n\nfrom .repr import debug_repr\nfrom .repr import dump\nfrom .repr import helper\n\n_stream: ContextVar[HTMLStringO] = ContextVar(\"werkzeug.debug.console.stream\")\n_ipy: ContextVar[_InteractiveConsole] = ContextVar(\"werkzeug.debug.console.ipy\")\n\n\nclass HTMLStringO:\n    \"\"\"A StringO version that HTML escapes on write.\"\"\"\n\n    def __init__(self) -> None:\n        self._buffer: list[str] = []\n\n    def isatty(self) -> bool:\n        return False\n\n    def close(self) -> None:\n        pass\n\n    def flush(self) -> None:\n        pass\n\n    def seek(self, n: int, mode: int = 0) -> None:\n        pass\n\n    def readline(self) -> str:\n        if len(self._buffer) == 0:\n            return \"\"\n        ret = self._buffer[0]\n        del self._buffer[0]\n        return ret\n\n    def reset(self) -> str:\n        val = \"\".join(self._buffer)\n        del self._buffer[:]\n        return val\n\n    def _write(self, x: str) -> None:\n        self._buffer.append(x)\n\n    def write(self, x: str) -> None:\n        self._write(escape(x))\n\n    def writelines(self, x: t.Iterable[str]) -> None:\n        self._write(escape(\"\".join(x)))\n\n\nclass ThreadedStream:\n    \"\"\"Thread-local wrapper for sys.stdout for the interactive console.\"\"\"\n\n    @staticmethod\n    def push() -> None:\n        if not isinstance(sys.stdout, ThreadedStream):\n            sys.stdout = t.cast(t.TextIO, ThreadedStream())\n\n        _stream.set(HTMLStringO())\n\n    @staticmethod\n    def fetch() -> str:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            return \"\"\n\n        return stream.reset()\n\n    @staticmethod\n    def displayhook(obj: object) -> None:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            return _displayhook(obj)  # type: ignore\n\n        # stream._write bypasses escaping as debug_repr is\n        # already generating HTML for us.\n        if obj is not None:\n            _ipy.get().locals[\"_\"] = obj\n            stream._write(debug_repr(obj))\n\n    def __setattr__(self, name: str, value: t.Any) -> None:\n        raise AttributeError(f\"read only attribute {name}\")\n\n    def __dir__(self) -> list[str]:\n        return dir(sys.__stdout__)\n\n    def __getattribute__(self, name: str) -> t.Any:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            stream = sys.__stdout__  # type: ignore[assignment]\n\n        return getattr(stream, name)\n\n    def __repr__(self) -> str:\n        return repr(sys.__stdout__)\n\n\n# add the threaded stream as display hook\n_displayhook = sys.displayhook\nsys.displayhook = ThreadedStream.displayhook\n\n\nclass _ConsoleLoader:\n    def __init__(self) -> None:\n        self._storage: dict[int, str] = {}\n\n    def register(self, code: CodeType, source: str) -> None:\n        self._storage[id(code)] = source\n        # register code objects of wrapped functions too.\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\repr.py": {
      "sha": "4b0d93d236e6",
      "lines": 282,
      "head": "\"\"\"Object representations for debugging purposes. Unlike the default\nrepr, these expose more information and produce HTML instead of ASCII.\n\nTogether with the CSS and JavaScript of the debugger this gives a\ncolorful and more compact output.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport codecs\nimport re\nimport sys\nimport typing as t\nfrom collections import deque\nfrom traceback import format_exception_only\n\nfrom markupsafe import escape\n\nmissing = object()\n_paragraph_re = re.compile(r\"(?:\\r\\n|\\r|\\n){2,}\")\nRegexType = type(_paragraph_re)\n\nHELP_HTML = \"\"\"\\\n<div class=box>\n  <h3>%(title)s</h3>\n  <pre class=help>%(text)s</pre>\n</div>\\\n\"\"\"\nOBJECT_DUMP_HTML = \"\"\"\\\n<div class=box>\n  <h3>%(title)s</h3>\n  %(repr)s\n  <table>%(items)s</table>\n</div>\\\n\"\"\"\n\n\ndef debug_repr(obj: object) -> str:\n    \"\"\"Creates a debug repr of an object as HTML string.\"\"\"\n    return DebugReprGenerator().repr(obj)\n\n\ndef dump(obj: object = missing) -> None:\n    \"\"\"Print the object details to stdout._write (for the interactive\n    console of the web debugger.\n    \"\"\"\n    gen = DebugReprGenerator()\n    if obj is missing:\n        rv = gen.dump_locals(sys._getframe(1).f_locals)\n    else:\n        rv = gen.dump_object(obj)\n    sys.stdout._write(rv)  # type: ignore\n\n\nclass _Helper:\n    \"\"\"Displays an HTML version of the normal help, for the interactive\n    debugger only because it requires a patched sys.stdout.\n    \"\"\"\n\n    def __repr__(self) -> str:\n        return \"Type help(object) for help about object.\"\n\n    def __call__(self, topic: t.Any | None = None) -> None:\n        if topic is None:\n            sys.stdout._write(f\"<span class=help>{self!r}</span>\")  # type: ignore\n            return\n        import pydoc\n\n        pydoc.help(topic)\n        rv = sys.stdout.reset()  # type: ignore\n        paragraphs = _paragraph_re.split(rv)\n        if len(paragraphs) > 1:\n            title = paragraphs[0]\n            text = \"\\n\\n\".join(paragraphs[1:])\n        else:\n            title = \"Help\"\n            text = paragraphs[0]\n        sys.stdout._write(HELP_HTML % {\"title\": title, \"text\": text})  # type: ignore\n\n\nhelper = _Helper()\n\n\ndef _add_subclass_info(inner: str, obj: object, base: type | tuple[type, ...]) -> str:\n    if isinstance(base, tuple):\n        for cls in base:\n            if type(obj) is cls:\n                return inner\n    elif type(obj) is base:\n        return inner\n    module = \"\"\n    if obj.__class__.__module__ not in (\"__builtin__\", \"exceptions\"):\n        module = f'<span class=\"module\">{obj.__class__.__module__}.</span>'\n    return f\"{module}{type(obj).__name__}({inner})\"\n\n\ndef _sequence_repr_maker(\n    left: str, right: str, base: type, limit: int = 8\n) -> t.Callable[[DebugReprGenerator, t.Iterable[t.Any], bool], str]:\n    def proxy(self: DebugReprGenerator, obj: t.Iterable[t.Any], recursive: bool) -> str:\n        if recursive:\n            return _add_subclass_info(f\"{left}...{right}\", obj, base)\n        buf = [left]\n        have_extended_section = False\n        for idx, item in enumerate(obj):\n            if idx:\n                buf.append(\", \")\n            if idx == limit:\n                buf.append('<span class=\"extended\">')\n                have_extended_section = True\n            buf.append(self.repr(item))\n        if have_extended_section:\n            buf.append(\"</span>\")\n        buf.append(right)\n        return _add_subclass_info(\"\".join(buf), obj, base)\n\n    return proxy\n\n\nclass DebugReprGenerator:\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\tbtools.py": {
      "sha": "184aa2f9bfa5",
      "lines": 450,
      "head": "from __future__ import annotations\n\nimport itertools\nimport linecache\nimport os\nimport re\nimport sys\nimport sysconfig\nimport traceback\nimport typing as t\n\nfrom markupsafe import escape\n\nfrom ..utils import cached_property\nfrom .console import Console\n\nHEADER = \"\"\"\\\n<!doctype html>\n<html lang=en>\n  <head>\n    <title>%(title)s // Werkzeug Debugger</title>\n    <link rel=\"stylesheet\" href=\"?__debugger__=yes&amp;cmd=resource&amp;f=style.css\">\n    <link rel=\"shortcut icon\"\n        href=\"?__debugger__=yes&amp;cmd=resource&amp;f=console.png\">\n    <script src=\"?__debugger__=yes&amp;cmd=resource&amp;f=debugger.js\"></script>\n    <script>\n      var CONSOLE_MODE = %(console)s,\n          EVALEX = %(evalex)s,\n          EVALEX_TRUSTED = %(evalex_trusted)s,\n          SECRET = \"%(secret)s\";\n    </script>\n  </head>\n  <body style=\"background-color: #fff\">\n    <div class=\"debugger\">\n\"\"\"\n\nFOOTER = \"\"\"\\\n      <div class=\"footer\">\n        Brought to you by <strong class=\"arthur\">DON'T PANIC</strong>, your\n        friendly Werkzeug powered traceback interpreter.\n      </div>\n    </div>\n\n    <div class=\"pin-prompt\">\n      <div class=\"inner\">\n        <h3>Console Locked</h3>\n        <p>\n          The console is locked and needs to be unlocked by entering the PIN.\n          You can find the PIN printed out on the standard output of your\n          shell that runs the server.\n        <form>\n          <p>PIN:\n            <input type=text name=pin size=14>\n            <input type=submit name=btn value=\"Confirm Pin\">\n        </form>\n      </div>\n    </div>\n  </body>\n</html>\n\"\"\"\n\nPAGE_HTML = (\n    HEADER\n    + \"\"\"\\\n<h1>%(exception_type)s</h1>\n<div class=\"detail\">\n  <p class=\"errormsg\">%(exception)s</p>\n</div>\n<h2 class=\"traceback\">Traceback <em>(most recent call last)</em></h2>\n%(summary)s\n<div class=\"plain\">\n    <p>\n      This is the Copy/Paste friendly version of the traceback.\n    </p>\n    <textarea cols=\"50\" rows=\"10\" name=\"code\" readonly>%(plaintext)s</textarea>\n</div>\n<div class=\"explanation\">\n  The debugger caught an exception in your WSGI application.  You can now\n  look at the traceback which led to the error.  <span class=\"nojavascript\">\n  If you enable JavaScript you can also use additional features such as code\n  execution (if the evalex feature is enabled), automatic pasting of the\n  exceptions and much more.</span>\n</div>\n\"\"\"\n    + FOOTER\n    + \"\"\"\n<!--\n\n%(plaintext_cs)s\n\n-->\n\"\"\"\n)\n\nCONSOLE_HTML = (\n    HEADER\n    + \"\"\"\\\n<h1>Interactive Console</h1>\n<div class=\"explanation\">\nIn this console you can execute Python expressions in the context of the\napplication.  The initial namespace was created by the debugger automatically.\n</div>\n<div class=\"console\"><div class=\"inner\">The Console requires JavaScript.</div></div>\n\"\"\"\n    + FOOTER\n)\n\nSUMMARY_HTML = \"\"\"\\\n<div class=\"%(classes)s\">\n  %(title)s\n  <ul>%(frames)s</ul>\n  %(description)s\n</div>\n\"\"\"\n\nFRAME_HTML = \"\"\"\\\n<div class=\"frame\" id=\"frame-%(id)d\">\n  <h4>File <cite class=\"filename\">\"%(filename)s\"</cite>,\n      line <em class=\"line\">%(lineno)s</em>,\n      in <code class=\"function\">%(function_name)s</code></h4>\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\__init__.py": {
      "sha": "c4614f12ee97",
      "lines": 565,
      "head": "from __future__ import annotations\n\nimport getpass\nimport hashlib\nimport json\nimport os\nimport pkgutil\nimport re\nimport sys\nimport time\nimport typing as t\nimport uuid\nfrom contextlib import ExitStack\nfrom io import BytesIO\nfrom itertools import chain\nfrom multiprocessing import Value\nfrom os.path import basename\nfrom os.path import join\nfrom zlib import adler32\n\nfrom .._internal import _log\nfrom ..exceptions import NotFound\nfrom ..exceptions import SecurityError\nfrom ..http import parse_cookie\nfrom ..sansio.utils import host_is_trusted\nfrom ..security import gen_salt\nfrom ..utils import send_file\nfrom ..wrappers.request import Request\nfrom ..wrappers.response import Response\nfrom .console import Console\nfrom .tbtools import DebugFrameSummary\nfrom .tbtools import DebugTraceback\nfrom .tbtools import render_console_html\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n# A week\nPIN_TIME = 60 * 60 * 24 * 7\n\n\ndef hash_pin(pin: str) -> str:\n    return hashlib.sha1(f\"{pin} added salt\".encode(\"utf-8\", \"replace\")).hexdigest()[:12]\n\n\n_machine_id: str | bytes | None = None\n\n\ndef get_machine_id() -> str | bytes | None:\n    global _machine_id\n\n    if _machine_id is not None:\n        return _machine_id\n\n    def _generate() -> str | bytes | None:\n        linux = b\"\"\n\n        # machine-id is stable across boots, boot_id is not.\n        for filename in \"/etc/machine-id\", \"/proc/sys/kernel/random/boot_id\":\n            try:\n                with open(filename, \"rb\") as f:\n                    value = f.readline().strip()\n            except OSError:\n                continue\n\n            if value:\n                linux += value\n                break\n\n        # Containers share the same machine id, add some cgroup\n        # information. This is used outside containers too but should be\n        # relatively stable across boots.\n        try:\n            with open(\"/proc/self/cgroup\", \"rb\") as f:\n                linux += f.readline().strip().rpartition(b\"/\")[2]\n        except OSError:\n            pass\n\n        if linux:\n            return linux\n\n        # On OS X, use ioreg to get the computer's serial number.\n        try:\n            # subprocess may not be available, e.g. Google App Engine\n            # https://github.com/pallets/werkzeug/issues/925\n            from subprocess import PIPE\n            from subprocess import Popen\n\n            dump = Popen(\n                [\"ioreg\", \"-c\", \"IOPlatformExpertDevice\", \"-d\", \"2\"], stdout=PIPE\n            ).communicate()[0]\n            match = re.search(b'\"serial-number\" = <([^>]+)', dump)\n\n            if match is not None:\n                return match.group(1)\n        except (OSError, ImportError):\n            pass\n\n        # On Windows, use winreg to get the machine guid.\n        if sys.platform == \"win32\":\n            import winreg\n\n            try:\n                with winreg.OpenKey(\n                    winreg.HKEY_LOCAL_MACHINE,\n                    \"SOFTWARE\\\\Microsoft\\\\Cryptography\",\n                    0,\n                    winreg.KEY_READ | winreg.KEY_WOW64_64KEY,\n                ) as rk:\n                    guid: str | bytes\n                    guid_type: int\n                    guid, guid_type = winreg.QueryValueEx(rk, \"MachineGuid\")\n\n                    if guid_type == winreg.REG_SZ:\n                        return guid.encode()\n\n                    return guid\n            except OSError:\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\debugger.js": {
      "sha": "17036785afff",
      "lines": 344,
      "head": "docReady(() => {\n  if (!EVALEX_TRUSTED) {\n    initPinBox();\n  }\n  // if we are in console mode, show the console.\n  if (CONSOLE_MODE && EVALEX) {\n    createInteractiveConsole();\n  }\n\n  const frames = document.querySelectorAll(\"div.traceback div.frame\");\n  if (EVALEX) {\n    addConsoleIconToFrames(frames);\n  }\n  addEventListenersToElements(document.querySelectorAll(\"div.detail\"), \"click\", () =>\n    document.querySelector(\"div.traceback\").scrollIntoView(false)\n  );\n  addToggleFrameTraceback(frames);\n  addToggleTraceTypesOnClick(document.querySelectorAll(\"h2.traceback\"));\n  addInfoPrompt(document.querySelectorAll(\"span.nojavascript\"));\n  wrapPlainTraceback();\n});\n\nfunction addToggleFrameTraceback(frames) {\n  frames.forEach((frame) => {\n    frame.addEventListener(\"click\", () => {\n      frame.getElementsByTagName(\"pre\")[0].parentElement.classList.toggle(\"expanded\");\n    });\n  })\n}\n\n\nfunction wrapPlainTraceback() {\n  const plainTraceback = document.querySelector(\"div.plain textarea\");\n  const wrapper = document.createElement(\"pre\");\n  const textNode = document.createTextNode(plainTraceback.textContent);\n  wrapper.appendChild(textNode);\n  plainTraceback.replaceWith(wrapper);\n}\n\nfunction makeDebugURL(args) {\n  const params = new URLSearchParams(args)\n  params.set(\"s\", SECRET)\n  return `?__debugger__=yes&${params}`\n}\n\nfunction initPinBox() {\n  document.querySelector(\".pin-prompt form\").addEventListener(\n    \"submit\",\n    function (event) {\n      event.preventDefault();\n      const btn = this.btn;\n      btn.disabled = true;\n\n      fetch(\n        makeDebugURL({cmd: \"pinauth\", pin: this.pin.value})\n      )\n        .then((res) => res.json())\n        .then(({auth, exhausted}) => {\n          if (auth) {\n            EVALEX_TRUSTED = true;\n            fadeOut(document.getElementsByClassName(\"pin-prompt\")[0]);\n          } else {\n            alert(\n              `Error: ${\n                exhausted\n                  ? \"too many attempts.  Restart server to retry.\"\n                  : \"incorrect pin\"\n              }`\n            );\n          }\n        })\n        .catch((err) => {\n          alert(\"Error: Could not verify PIN.  Network error?\");\n          console.error(err);\n        })\n        .finally(() => (btn.disabled = false));\n    },\n    false\n  );\n}\n\nfunction promptForPin() {\n  if (!EVALEX_TRUSTED) {\n    fetch(makeDebugURL({cmd: \"printpin\"}));\n    const pinPrompt = document.getElementsByClassName(\"pin-prompt\")[0];\n    fadeIn(pinPrompt);\n    document.querySelector('.pin-prompt input[name=\"pin\"]').focus();\n  }\n}\n\n/**\n * Helper function for shell initialization\n */\nfunction openShell(consoleNode, target, frameID) {\n  promptForPin();\n  if (consoleNode) {\n    slideToggle(consoleNode);\n    return consoleNode;\n  }\n  let historyPos = 0;\n  const history = [\"\"];\n  const consoleElement = createConsole();\n  const output = createConsoleOutput();\n  const form = createConsoleInputForm();\n  const command = createConsoleInput();\n\n  target.parentNode.appendChild(consoleElement);\n  consoleElement.append(output);\n  consoleElement.append(form);\n  form.append(command);\n  command.focus();\n  slideToggle(consoleElement);\n\n  form.addEventListener(\"submit\", (e) => {\n    handleConsoleSubmit(e, command, frameID).then((consoleOutput) => {\n      output.append(consoleOutput);\n      command.focus();\n      consoleElement.scrollTo(0, consoleElement.scrollHeight);\n      const old = history.pop();\n      history.push(command.value);\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\ICON_LICENSE.md": {
      "sha": "f040b2dbca14",
      "lines": 6,
      "head": "Silk icon set 1.3 by Mark James <mjames@gmail.com>\n\nhttp://www.famfamfam.com/lab/icons/silk/\n\nLicense: [CC-BY-2.5](https://creativecommons.org/licenses/by/2.5/)\nor [CC-BY-3.0](https://creativecommons.org/licenses/by/3.0/)\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\debug\\shared\\style.css": {
      "sha": "212ace82151a",
      "lines": 150,
      "head": "body, input  { font-family: sans-serif; color: #000; text-align: center;\n               margin: 1em; padding: 0; font-size: 15px; }\nh1, h2, h3   { font-weight: normal; }\n\ninput        { background-color: #fff; margin: 0; text-align: left;\n               outline: none !important; }\ninput[type=\"submit\"] { padding: 3px 6px; }\na            { color: #11557C; }\na:hover      { color: #177199; }\npre, code,\ntextarea     { font-family: monospace; font-size: 14px; }\n\ndiv.debugger { text-align: left; padding: 12px; margin: auto;\n               background-color: white; }\nh1           { font-size: 36px; margin: 0 0 0.3em 0; }\ndiv.detail { cursor: pointer; }\ndiv.detail p { margin: 0 0 8px 13px; font-size: 14px; white-space: pre-wrap;\n               font-family: monospace; }\ndiv.explanation { margin: 20px 13px; font-size: 15px; color: #555; }\ndiv.footer   { font-size: 13px; text-align: right; margin: 30px 0;\n               color: #86989B; }\n\nh2           { font-size: 16px; margin: 1.3em 0 0.0 0; padding: 9px;\n               background-color: #11557C; color: white; }\nh2 em, h3 em { font-style: normal; color: #A5D6D9; font-weight: normal; }\n\ndiv.traceback, div.plain { border: 1px solid #ddd; margin: 0 0 1em 0; padding: 10px; }\ndiv.plain p      { margin: 0; }\ndiv.plain textarea,\ndiv.plain pre { margin: 10px 0 0 0; padding: 4px;\n                background-color: #E8EFF0; border: 1px solid #D3E7E9; }\ndiv.plain textarea { width: 99%; height: 300px; }\ndiv.traceback h3 { font-size: 1em; margin: 0 0 0.8em 0; }\ndiv.traceback ul { list-style: none; margin: 0; padding: 0 0 0 1em; }\ndiv.traceback h4 { font-size: 13px; font-weight: normal; margin: 0.7em 0 0.1em 0; }\ndiv.traceback pre { margin: 0; padding: 5px 0 3px 15px;\n                    background-color: #E8EFF0; border: 1px solid #D3E7E9; }\ndiv.traceback .library .current { background: white; color: #555; }\ndiv.traceback .expanded .current { background: #E8EFF0; color: black; }\ndiv.traceback pre:hover { background-color: #DDECEE; color: black; cursor: pointer; }\ndiv.traceback div.source.expanded pre + pre { border-top: none; }\n\ndiv.traceback span.ws { display: none; }\ndiv.traceback pre.before, div.traceback pre.after { display: none; background: white; }\ndiv.traceback div.source.expanded pre.before,\ndiv.traceback div.source.expanded pre.after {\n    display: block;\n}\n\ndiv.traceback div.source.expanded span.ws {\n    display: inline;\n}\n\ndiv.traceback blockquote { margin: 1em 0 0 0; padding: 0; white-space: pre-line; }\ndiv.traceback img { float: right; padding: 2px; margin: -3px 2px 0 0; display: none; }\ndiv.traceback img:hover { background-color: #ddd; cursor: pointer;\n                          border-color: #BFDDE0; }\ndiv.traceback pre:hover img { display: block; }\ndiv.traceback cite.filename { font-style: normal; color: #3B666B; }\n\npre.console { border: 1px solid #ccc; background: white!important;\n              color: black; padding: 5px!important;\n              margin: 3px 0 0 0!important; cursor: default!important;\n              max-height: 400px; overflow: auto; }\npre.console form { color: #555; }\npre.console input { background-color: transparent; color: #555;\n                    width: 90%; font-family: monospace; font-size: 14px;\n                     border: none!important; }\n\nspan.string { color: #30799B; }\nspan.number { color: #9C1A1C; }\nspan.help   { color: #3A7734; }\nspan.object { color: #485F6E; }\nspan.extended { opacity: 0.5; }\nspan.extended:hover { opacity: 1; }\na.toggle { text-decoration: none; background-repeat: no-repeat;\n           background-position: center center;\n           background-image: url(?__debugger__=yes&cmd=resource&f=more.png); }\na.toggle:hover { background-color: #444; }\na.open { background-image: url(?__debugger__=yes&cmd=resource&f=less.png); }\n\npre.console div.traceback,\npre.console div.box { margin: 5px 10px; white-space: normal;\n                      border: 1px solid #11557C; padding: 10px;\n                      font-family: sans-serif;  }\npre.console div.box h3,\npre.console div.traceback h3 { margin: -10px -10px 10px -10px; padding: 5px;\n                               background: #11557C; color: white; }\n\npre.console div.traceback pre:hover { cursor: default; background: #E8EFF0; }\npre.console div.traceback pre.syntaxerror { background: inherit; border: none;\n                                            margin: 20px -10px -10px -10px;\n                                            padding: 10px; border-top: 1px solid #BFDDE0;\n                                            background: #E8EFF0; }\npre.console div.noframe-traceback pre.syntaxerror { margin-top: -10px; border: none; }\n\npre.console div.box pre.repr { padding: 0; margin: 0; background-color: white; border: none; }\npre.console div.box table { margin-top: 6px; }\npre.console div.box pre { border: none; }\npre.console div.box pre.help { background-color: white; }\npre.console div.box pre.help:hover { cursor: default; }\npre.console table tr { vertical-align: top; }\ndiv.console { border: 1px solid #ccc; padding: 4px; background-color: #fafafa; }\n\ndiv.traceback pre, div.console pre {\n    white-space: pre-wrap;       /* css-3 should we be so lucky... */\n    white-space: -moz-pre-wrap;  /* Mozilla, since 1999 */\n    white-space: -pre-wrap;      /* Opera 4-6 ?? */\n    white-space: -o-pre-wrap;    /* Opera 7 ?? */\n    word-wrap: break-word;       /* Internet Explorer 5.5+ */\n    _white-space: pre;           /* IE only hack to re-specify in\n                                 addition to word-wrap  */\n}\n\n\ndiv.pin-prompt {\n    position: absolute;\n    display: none;\n    top: 0;\n    bottom: 0;\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\dispatcher.py": {
      "sha": "0c1f688c0eee",
      "lines": 81,
      "head": "\"\"\"\nApplication Dispatcher\n======================\n\nThis middleware creates a single WSGI application that dispatches to\nmultiple other WSGI applications mounted at different URL paths.\n\nA common example is writing a Single Page Application, where you have a\nbackend API and a frontend written in JavaScript that does the routing\nin the browser rather than requesting different pages from the server.\nThe frontend is a single HTML and JS file that should be served for any\npath besides \"/api\".\n\nThis example dispatches to an API app under \"/api\", an admin app\nunder \"/admin\", and an app that serves frontend files for all other\nrequests::\n\n    app = DispatcherMiddleware(serve_frontend, {\n        '/api': api_app,\n        '/admin': admin_app,\n    })\n\nIn production, you might instead handle this at the HTTP server level,\nserving files or proxying to application servers based on location. The\nAPI and admin apps would each be deployed with a separate WSGI server,\nand the static files would be served directly by the HTTP server.\n\n.. autoclass:: DispatcherMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass DispatcherMiddleware:\n    \"\"\"Combine multiple applications as a single WSGI application.\n    Requests are dispatched to an application based on the path it is\n    mounted under.\n\n    :param app: The WSGI application to dispatch to if the request\n        doesn't match a mounted path.\n    :param mounts: Maps path prefixes to applications for dispatching.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        mounts: dict[str, WSGIApplication] | None = None,\n    ) -> None:\n        self.app = app\n        self.mounts = mounts or {}\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        script = environ.get(\"PATH_INFO\", \"\")\n        path_info = \"\"\n\n        while \"/\" in script:\n            if script in self.mounts:\n                app = self.mounts[script]\n                break\n\n            script, last_item = script.rsplit(\"/\", 1)\n            path_info = f\"/{last_item}{path_info}\"\n        else:\n            app = self.mounts.get(script, self.app)\n\n        original_script_name = environ.get(\"SCRIPT_NAME\", \"\")\n        environ[\"SCRIPT_NAME\"] = original_script_name + script\n        environ[\"PATH_INFO\"] = path_info\n        return app(environ, start_response)\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\http_proxy.py": {
      "sha": "7d839ca0fd19",
      "lines": 236,
      "head": "\"\"\"\nBasic HTTP Proxy\n================\n\n.. autoclass:: ProxyMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom http import client\nfrom urllib.parse import quote\nfrom urllib.parse import urlsplit\n\nfrom ..datastructures import EnvironHeaders\nfrom ..http import is_hop_by_hop_header\nfrom ..wsgi import get_input_stream\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProxyMiddleware:\n    \"\"\"Proxy requests under a path to an external server, routing other\n    requests to the app.\n\n    This middleware can only proxy HTTP requests, as HTTP is the only\n    protocol handled by the WSGI server. Other protocols, such as\n    WebSocket requests, cannot be proxied at this layer. This should\n    only be used for development, in production a real proxy server\n    should be used.\n\n    The middleware takes a dict mapping a path prefix to a dict\n    describing the host to be proxied to::\n\n        app = ProxyMiddleware(app, {\n            \"/static/\": {\n                \"target\": \"http://127.0.0.1:5001/\",\n            }\n        })\n\n    Each host has the following options:\n\n    ``target``:\n        The target URL to dispatch to. This is required.\n    ``remove_prefix``:\n        Whether to remove the prefix from the URL before dispatching it\n        to the target. The default is ``False``.\n    ``host``:\n        ``\"<auto>\"`` (default):\n            The host header is automatically rewritten to the URL of the\n            target.\n        ``None``:\n            The host header is unmodified from the client request.\n        Any other value:\n            The host header is overwritten with the value.\n    ``headers``:\n        A dictionary of headers to be sent with the request to the\n        target. The default is ``{}``.\n    ``ssl_context``:\n        A :class:`ssl.SSLContext` defining how to verify requests if the\n        target is HTTPS. The default is ``None``.\n\n    In the example above, everything under ``\"/static/\"`` is proxied to\n    the server on port 5001. The host header is rewritten to the target,\n    and the ``\"/static/\"`` prefix is removed from the URLs.\n\n    :param app: The WSGI application to wrap.\n    :param targets: Proxy target configurations. See description above.\n    :param chunk_size: Size of chunks to read from input stream and\n        write to target.\n    :param timeout: Seconds before an operation to a target fails.\n\n    .. versionadded:: 0.14\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        targets: t.Mapping[str, dict[str, t.Any]],\n        chunk_size: int = 2 << 13,\n        timeout: int = 10,\n    ) -> None:\n        def _set_defaults(opts: dict[str, t.Any]) -> dict[str, t.Any]:\n            opts.setdefault(\"remove_prefix\", False)\n            opts.setdefault(\"host\", \"<auto>\")\n            opts.setdefault(\"headers\", {})\n            opts.setdefault(\"ssl_context\", None)\n            return opts\n\n        self.app = app\n        self.targets = {\n            f\"/{k.strip('/')}/\": _set_defaults(v) for k, v in targets.items()\n        }\n        self.chunk_size = chunk_size\n        self.timeout = timeout\n\n    def proxy_to(\n        self, opts: dict[str, t.Any], path: str, prefix: str\n    ) -> WSGIApplication:\n        target = urlsplit(opts[\"target\"])\n        # socket can handle unicode host, but header must be ascii\n        host = target.hostname.encode(\"idna\").decode(\"ascii\")\n\n        def application(\n            environ: WSGIEnvironment, start_response: StartResponse\n        ) -> t.Iterable[bytes]:\n            headers = list(EnvironHeaders(environ).items())\n            headers[:] = [\n                (k, v)\n                for k, v in headers\n                if not is_hop_by_hop_header(k)\n                and k.lower() not in (\"content-length\", \"host\")\n            ]\n            headers.append((\"Connection\", \"close\"))\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\lint.py": {
      "sha": "946ad963ab1c",
      "lines": 439,
      "head": "\"\"\"\nWSGI Protocol Linter\n====================\n\nThis module provides a middleware that performs sanity checks on the\nbehavior of the WSGI server and application. It checks that the\n:pep:`3333` WSGI spec is properly implemented. It also warns on some\ncommon HTTP errors such as non-empty responses for 304 status codes.\n\n.. autoclass:: LintMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom types import TracebackType\nfrom urllib.parse import urlparse\nfrom warnings import warn\n\nfrom ..datastructures import Headers\nfrom ..http import is_entity_header\nfrom ..wsgi import FileWrapper\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass WSGIWarning(Warning):\n    \"\"\"Warning class for WSGI warnings.\"\"\"\n\n\nclass HTTPWarning(Warning):\n    \"\"\"Warning class for HTTP warnings.\"\"\"\n\n\ndef check_type(context: str, obj: object, need: type = str) -> None:\n    if type(obj) is not need:\n        warn(\n            f\"{context!r} requires {need.__name__!r}, got {type(obj).__name__!r}.\",\n            WSGIWarning,\n            stacklevel=3,\n        )\n\n\nclass InputStream:\n    def __init__(self, stream: t.IO[bytes]) -> None:\n        self._stream = stream\n\n    def read(self, *args: t.Any) -> bytes:\n        if len(args) == 0:\n            warn(\n                \"WSGI does not guarantee an EOF marker on the input stream, thus making\"\n                \" calls to 'wsgi.input.read()' unsafe. Conforming servers may never\"\n                \" return from this call.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        elif len(args) != 1:\n            warn(\n                \"Too many parameters passed to 'wsgi.input.read()'.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        return self._stream.read(*args)\n\n    def readline(self, *args: t.Any) -> bytes:\n        if len(args) == 0:\n            warn(\n                \"Calls to 'wsgi.input.readline()' without arguments are unsafe. Use\"\n                \" 'wsgi.input.read()' instead.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        elif len(args) == 1:\n            warn(\n                \"'wsgi.input.readline()' was called with a size hint. WSGI does not\"\n                \" support this, although it's available on all major servers.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        else:\n            raise TypeError(\"Too many arguments passed to 'wsgi.input.readline()'.\")\n        return self._stream.readline(*args)\n\n    def __iter__(self) -> t.Iterator[bytes]:\n        try:\n            return iter(self._stream)\n        except TypeError:\n            warn(\"'wsgi.input' is not iterable.\", WSGIWarning, stacklevel=2)\n            return iter(())\n\n    def close(self) -> None:\n        warn(\"The application closed the input stream!\", WSGIWarning, stacklevel=2)\n        self._stream.close()\n\n\nclass ErrorStream:\n    def __init__(self, stream: t.IO[str]) -> None:\n        self._stream = stream\n\n    def write(self, s: str) -> None:\n        check_type(\"wsgi.error.write()\", s, str)\n        self._stream.write(s)\n\n    def flush(self) -> None:\n        self._stream.flush()\n\n    def writelines(self, seq: t.Iterable[str]) -> None:\n        for line in seq:\n            self.write(line)\n\n    def close(self) -> None:\n        warn(\"The application closed the error stream!\", WSGIWarning, stacklevel=2)\n        self._stream.close()\n\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\profiler.py": {
      "sha": "2c66ebd1c414",
      "lines": 155,
      "head": "\"\"\"\nApplication Profiler\n====================\n\nThis module provides a middleware that profiles each request with the\n:mod:`cProfile` module. This can help identify bottlenecks in your code\nthat may be slowing down your application.\n\n.. autoclass:: ProfilerMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\nimport sys\nimport time\nimport typing as t\nfrom pstats import Stats\n\ntry:\n    from cProfile import Profile\nexcept ImportError:\n    from profile import Profile  # type: ignore\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProfilerMiddleware:\n    \"\"\"Wrap a WSGI application and profile the execution of each\n    request. Responses are buffered so that timings are more exact.\n\n    If ``stream`` is given, :class:`pstats.Stats` are written to it\n    after each request. If ``profile_dir`` is given, :mod:`cProfile`\n    data files are saved to that directory, one file per request.\n\n    The filename can be customized by passing ``filename_format``. If\n    it is a string, it will be formatted using :meth:`str.format` with\n    the following fields available:\n\n    -   ``{method}`` - The request method; GET, POST, etc.\n    -   ``{path}`` - The request path or 'root' should one not exist.\n    -   ``{elapsed}`` - The elapsed time of the request in milliseconds.\n    -   ``{time}`` - The time of the request.\n\n    If it is a callable, it will be called with the WSGI ``environ`` and\n    be expected to return a filename string. The ``environ`` dictionary\n    will also have the ``\"werkzeug.profiler\"`` key populated with a\n    dictionary containing the following fields (more may be added in the\n    future):\n    -   ``{elapsed}`` - The elapsed time of the request in milliseconds.\n    -   ``{time}`` - The time of the request.\n\n    :param app: The WSGI application to wrap.\n    :param stream: Write stats to this stream. Disable with ``None``.\n    :param sort_by: A tuple of columns to sort stats by. See\n        :meth:`pstats.Stats.sort_stats`.\n    :param restrictions: A tuple of restrictions to filter stats by. See\n        :meth:`pstats.Stats.print_stats`.\n    :param profile_dir: Save profile data files to this directory.\n    :param filename_format: Format string for profile data file names,\n        or a callable returning a name. See explanation above.\n\n    .. code-block:: python\n\n        from werkzeug.middleware.profiler import ProfilerMiddleware\n        app = ProfilerMiddleware(app)\n\n    .. versionchanged:: 3.0\n        Added the ``\"werkzeug.profiler\"`` key to the ``filename_format(environ)``\n        parameter with the  ``elapsed`` and ``time`` fields.\n\n    .. versionchanged:: 0.15\n        Stats are written even if ``profile_dir`` is given, and can be\n        disable by passing ``stream=None``.\n\n    .. versionadded:: 0.15\n        Added ``filename_format``.\n\n    .. versionadded:: 0.9\n        Added ``restrictions`` and ``profile_dir``.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        stream: t.IO[str] | None = sys.stdout,\n        sort_by: t.Iterable[str] = (\"time\", \"calls\"),\n        restrictions: t.Iterable[str | int | float] = (),\n        profile_dir: str | None = None,\n        filename_format: str = \"{method}.{path}.{elapsed:.0f}ms.{time:.0f}.prof\",\n    ) -> None:\n        self._app = app\n        self._stream = stream\n        self._sort_by = sort_by\n        self._restrictions = restrictions\n        self._profile_dir = profile_dir\n        self._filename_format = filename_format\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        response_body: list[bytes] = []\n\n        def catching_start_response(status, headers, exc_info=None):  # type: ignore\n            start_response(status, headers, exc_info)\n            return response_body.append\n\n        def runapp() -> None:\n            app_iter = self._app(\n                environ, t.cast(\"StartResponse\", catching_start_response)\n            )\n            response_body.extend(app_iter)\n\n            if hasattr(app_iter, \"close\"):\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\proxy_fix.py": {
      "sha": "c80632e438d9",
      "lines": 183,
      "head": "\"\"\"\nX-Forwarded-For Proxy Fix\n=========================\n\nThis module provides a middleware that adjusts the WSGI environ based on\n``X-Forwarded-`` headers that proxies in front of an application may\nset.\n\nWhen an application is running behind a proxy server, WSGI may see the\nrequest as coming from that server rather than the real client. Proxies\nset various headers to track where the request actually came from.\n\nThis middleware should only be used if the application is actually\nbehind such a proxy, and should be configured with the number of proxies\nthat are chained in front of it. Not all proxies set all the headers.\nSince incoming headers can be faked, you must set how many proxies are\nsetting each header so the middleware knows what to trust.\n\n.. autoclass:: ProxyFix\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\n\nfrom ..http import parse_list_header\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProxyFix:\n    \"\"\"Adjust the WSGI environ based on ``X-Forwarded-`` that proxies in\n    front of the application may set.\n\n    -   ``X-Forwarded-For`` sets ``REMOTE_ADDR``.\n    -   ``X-Forwarded-Proto`` sets ``wsgi.url_scheme``.\n    -   ``X-Forwarded-Host`` sets ``HTTP_HOST``, ``SERVER_NAME``, and\n        ``SERVER_PORT``.\n    -   ``X-Forwarded-Port`` sets ``HTTP_HOST`` and ``SERVER_PORT``.\n    -   ``X-Forwarded-Prefix`` sets ``SCRIPT_NAME``.\n\n    You must tell the middleware how many proxies set each header so it\n    knows what values to trust. It is a security issue to trust values\n    that came from the client rather than a proxy.\n\n    The original values of the headers are stored in the WSGI\n    environ as ``werkzeug.proxy_fix.orig``, a dict.\n\n    :param app: The WSGI application to wrap.\n    :param x_for: Number of values to trust for ``X-Forwarded-For``.\n    :param x_proto: Number of values to trust for ``X-Forwarded-Proto``.\n    :param x_host: Number of values to trust for ``X-Forwarded-Host``.\n    :param x_port: Number of values to trust for ``X-Forwarded-Port``.\n    :param x_prefix: Number of values to trust for\n        ``X-Forwarded-Prefix``.\n\n    .. code-block:: python\n\n        from werkzeug.middleware.proxy_fix import ProxyFix\n        # App is behind one proxy that sets the -For and -Host headers.\n        app = ProxyFix(app, x_for=1, x_host=1)\n\n    .. versionchanged:: 1.0\n        The ``num_proxies`` argument and attribute; the ``get_remote_addr`` method; and\n        the environ keys ``orig_remote_addr``, ``orig_wsgi_url_scheme``, and\n        ``orig_http_host`` were removed.\n\n    .. versionchanged:: 0.15\n        All headers support multiple values. Each header is configured with a separate\n        number of trusted proxies.\n\n    .. versionchanged:: 0.15\n        Original WSGI environ values are stored in the ``werkzeug.proxy_fix.orig`` dict.\n\n    .. versionchanged:: 0.15\n        Support ``X-Forwarded-Port`` and ``X-Forwarded-Prefix``.\n\n    .. versionchanged:: 0.15\n        ``X-Forwarded-Host`` and ``X-Forwarded-Port`` modify\n        ``SERVER_NAME`` and ``SERVER_PORT``.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        x_for: int = 1,\n        x_proto: int = 1,\n        x_host: int = 0,\n        x_port: int = 0,\n        x_prefix: int = 0,\n    ) -> None:\n        self.app = app\n        self.x_for = x_for\n        self.x_proto = x_proto\n        self.x_host = x_host\n        self.x_port = x_port\n        self.x_prefix = x_prefix\n\n    def _get_real_value(self, trusted: int, value: str | None) -> str | None:\n        \"\"\"Get the real value from a list header based on the configured\n        number of trusted proxies.\n\n        :param trusted: Number of values to trust in the header.\n        :param value: Comma separated list header value to parse.\n        :return: The real value, or ``None`` if there are fewer values\n            than the number of trusted proxies.\n\n        .. versionchanged:: 1.0\n            Renamed from ``_get_trusted_comma``.\n\n        .. versionadded:: 0.15\n        \"\"\"\n        if not (trusted and value):\n            return None\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\shared_data.py": {
      "sha": "a80b8557b241",
      "lines": 283,
      "head": "\"\"\"\nServe Shared Static Files\n=========================\n\n.. autoclass:: SharedDataMiddleware\n    :members: is_allowed\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport collections.abc as cabc\nimport importlib.util\nimport mimetypes\nimport os\nimport posixpath\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timezone\nfrom io import BytesIO\nfrom time import time\nfrom zlib import adler32\n\nfrom ..http import http_date\nfrom ..http import is_resource_modified\nfrom ..security import safe_join\nfrom ..utils import get_content_type\nfrom ..wsgi import get_path_info\nfrom ..wsgi import wrap_file\n\n_TOpener = t.Callable[[], tuple[t.IO[bytes], datetime, int]]\n_TLoader = t.Callable[[t.Optional[str]], tuple[t.Optional[str], t.Optional[_TOpener]]]\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass SharedDataMiddleware:\n    \"\"\"A WSGI middleware which provides static content for development\n    environments or simple server setups. Its usage is quite simple::\n\n        import os\n        from werkzeug.middleware.shared_data import SharedDataMiddleware\n\n        app = SharedDataMiddleware(app, {\n            '/shared': os.path.join(os.path.dirname(__file__), 'shared')\n        })\n\n    The contents of the folder ``./shared`` will now be available on\n    ``http://example.com/shared/``.  This is pretty useful during development\n    because a standalone media server is not required. Files can also be\n    mounted on the root folder and still continue to use the application because\n    the shared data middleware forwards all unhandled requests to the\n    application, even if the requests are below one of the shared folders.\n\n    If `pkg_resources` is available you can also tell the middleware to serve\n    files from package data::\n\n        app = SharedDataMiddleware(app, {\n            '/static': ('myapplication', 'static')\n        })\n\n    This will then serve the ``static`` folder in the `myapplication`\n    Python package.\n\n    The optional `disallow` parameter can be a list of :func:`~fnmatch.fnmatch`\n    rules for files that are not accessible from the web.  If `cache` is set to\n    `False` no caching headers are sent.\n\n    Currently the middleware does not support non-ASCII filenames. If the\n    encoding on the file system happens to match the encoding of the URI it may\n    work but this could also be by accident. We strongly suggest using ASCII\n    only file names for static files.\n\n    The middleware will guess the mimetype using the Python `mimetype`\n    module.  If it's unable to figure out the charset it will fall back\n    to `fallback_mimetype`.\n\n    :param app: the application to wrap.  If you don't want to wrap an\n                application you can pass it :exc:`NotFound`.\n    :param exports: a list or dict of exported files and folders.\n    :param disallow: a list of :func:`~fnmatch.fnmatch` rules.\n    :param cache: enable or disable caching headers.\n    :param cache_timeout: the cache timeout in seconds for the headers.\n    :param fallback_mimetype: The fallback mimetype for unknown files.\n\n    .. versionchanged:: 1.0\n        The default ``fallback_mimetype`` is\n        ``application/octet-stream``. If a filename looks like a text\n        mimetype, the ``utf-8`` charset is added to it.\n\n    .. versionadded:: 0.6\n        Added ``fallback_mimetype``.\n\n    .. versionchanged:: 0.5\n        Added ``cache_timeout``.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        exports: (\n            cabc.Mapping[str, str | tuple[str, str]]\n            | t.Iterable[tuple[str, str | tuple[str, str]]]\n        ),\n        disallow: None = None,\n        cache: bool = True,\n        cache_timeout: int = 60 * 60 * 12,\n        fallback_mimetype: str = \"application/octet-stream\",\n    ) -> None:\n        self.app = app\n        self.exports: list[tuple[str, _TLoader]] = []\n        self.cache = cache\n        self.cache_timeout = cache_timeout\n\n        if isinstance(exports, cabc.Mapping):\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\middleware\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\converters.py": {
      "sha": "71b3b0336595",
      "lines": 261,
      "head": "from __future__ import annotations\n\nimport re\nimport typing as t\nimport uuid\nfrom urllib.parse import quote\n\nif t.TYPE_CHECKING:\n    from .map import Map\n\n\nclass ValidationError(ValueError):\n    \"\"\"Validation error.  If a rule converter raises this exception the rule\n    does not match the current URL and the next URL is tried.\n    \"\"\"\n\n\nclass BaseConverter:\n    \"\"\"Base class for all converters.\n\n    .. versionchanged:: 2.3\n        ``part_isolating`` defaults to ``False`` if ``regex`` contains a ``/``.\n    \"\"\"\n\n    regex = \"[^/]+\"\n    weight = 100\n    part_isolating = True\n\n    def __init_subclass__(cls, **kwargs: t.Any) -> None:\n        super().__init_subclass__(**kwargs)\n\n        # If the converter isn't inheriting its regex, disable part_isolating by default\n        # if the regex contains a / character.\n        if \"regex\" in cls.__dict__ and \"part_isolating\" not in cls.__dict__:\n            cls.part_isolating = \"/\" not in cls.regex\n\n    def __init__(self, map: Map, *args: t.Any, **kwargs: t.Any) -> None:\n        self.map = map\n\n    def to_python(self, value: str) -> t.Any:\n        return value\n\n    def to_url(self, value: t.Any) -> str:\n        # safe = https://url.spec.whatwg.org/#url-path-segment-string\n        return quote(str(value), safe=\"!$&'()*+,/:;=@\")\n\n\nclass UnicodeConverter(BaseConverter):\n    \"\"\"This converter is the default converter and accepts any string but\n    only one path segment.  Thus the string can not include a slash.\n\n    This is the default validator.\n\n    Example::\n\n        Rule('/pages/<page>'),\n        Rule('/<string(length=2):lang_code>')\n\n    :param map: the :class:`Map`.\n    :param minlength: the minimum length of the string.  Must be greater\n                      or equal 1.\n    :param maxlength: the maximum length of the string.\n    :param length: the exact length of the string.\n    \"\"\"\n\n    def __init__(\n        self,\n        map: Map,\n        minlength: int = 1,\n        maxlength: int | None = None,\n        length: int | None = None,\n    ) -> None:\n        super().__init__(map)\n        if length is not None:\n            length_regex = f\"{{{int(length)}}}\"\n        else:\n            if maxlength is None:\n                maxlength_value = \"\"\n            else:\n                maxlength_value = str(int(maxlength))\n            length_regex = f\"{{{int(minlength)},{maxlength_value}}}\"\n        self.regex = f\"[^/]{length_regex}\"\n\n\nclass AnyConverter(BaseConverter):\n    \"\"\"Matches one of the items provided.  Items can either be Python\n    identifiers or strings::\n\n        Rule('/<any(about, help, imprint, class, \"foo,bar\"):page_name>')\n\n    :param map: the :class:`Map`.\n    :param items: this function accepts the possible items as positional\n                  arguments.\n\n    .. versionchanged:: 2.2\n        Value is validated when building a URL.\n    \"\"\"\n\n    def __init__(self, map: Map, *items: str) -> None:\n        super().__init__(map)\n        self.items = set(items)\n        self.regex = f\"(?:{'|'.join([re.escape(x) for x in items])})\"\n\n    def to_url(self, value: t.Any) -> str:\n        if value in self.items:\n            return str(value)\n\n        valid_values = \", \".join(f\"'{item}'\" for item in sorted(self.items))\n        raise ValueError(f\"'{value}' is not one of {valid_values}\")\n\n\nclass PathConverter(BaseConverter):\n    \"\"\"Like the default :class:`UnicodeConverter`, but it also matches\n    slashes.  This is useful for wikis and similar applications::\n\n        Rule('/<path:wikipage>')\n        Rule('/<path:wikipage>/edit')\n\n    :param map: the :class:`Map`.\n    \"\"\"\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\exceptions.py": {
      "sha": "3ac51bd906a9",
      "lines": 152,
      "head": "from __future__ import annotations\n\nimport difflib\nimport typing as t\n\nfrom ..exceptions import BadRequest\nfrom ..exceptions import HTTPException\nfrom ..utils import cached_property\nfrom ..utils import redirect\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from ..wrappers.request import Request\n    from ..wrappers.response import Response\n    from .map import MapAdapter\n    from .rules import Rule\n\n\nclass RoutingException(Exception):\n    \"\"\"Special exceptions that require the application to redirect, notifying\n    about missing urls, etc.\n\n    :internal:\n    \"\"\"\n\n\nclass RequestRedirect(HTTPException, RoutingException):\n    \"\"\"Raise if the map requests a redirect. This is for example the case if\n    `strict_slashes` are activated and an url that requires a trailing slash.\n\n    The attribute `new_url` contains the absolute destination url.\n    \"\"\"\n\n    code = 308\n\n    def __init__(self, new_url: str) -> None:\n        super().__init__(new_url)\n        self.new_url = new_url\n\n    def get_response(\n        self,\n        environ: WSGIEnvironment | Request | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> Response:\n        return redirect(self.new_url, self.code)\n\n\nclass RequestPath(RoutingException):\n    \"\"\"Internal exception.\"\"\"\n\n    __slots__ = (\"path_info\",)\n\n    def __init__(self, path_info: str) -> None:\n        super().__init__()\n        self.path_info = path_info\n\n\nclass RequestAliasRedirect(RoutingException):  # noqa: B903\n    \"\"\"This rule is an alias and wants to redirect to the canonical URL.\"\"\"\n\n    def __init__(self, matched_values: t.Mapping[str, t.Any], endpoint: t.Any) -> None:\n        super().__init__()\n        self.matched_values = matched_values\n        self.endpoint = endpoint\n\n\nclass BuildError(RoutingException, LookupError):\n    \"\"\"Raised if the build system cannot find a URL for an endpoint with the\n    values provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any],\n        method: str | None,\n        adapter: MapAdapter | None = None,\n    ) -> None:\n        super().__init__(endpoint, values, method)\n        self.endpoint = endpoint\n        self.values = values\n        self.method = method\n        self.adapter = adapter\n\n    @cached_property\n    def suggested(self) -> Rule | None:\n        return self.closest_rule(self.adapter)\n\n    def closest_rule(self, adapter: MapAdapter | None) -> Rule | None:\n        def _score_rule(rule: Rule) -> float:\n            return sum(\n                [\n                    0.98\n                    * difflib.SequenceMatcher(\n                        # endpoints can be any type, compare as strings\n                        None,\n                        str(rule.endpoint),\n                        str(self.endpoint),\n                    ).ratio(),\n                    0.01 * bool(set(self.values or ()).issubset(rule.arguments)),\n                    0.01 * bool(rule.methods and self.method in rule.methods),\n                ]\n            )\n\n        if adapter and adapter.map._rules:\n            return max(adapter.map._rules, key=_score_rule)\n\n        return None\n\n    def __str__(self) -> str:\n        message = [f\"Could not build url for endpoint {self.endpoint!r}\"]\n        if self.method:\n            message.append(f\" ({self.method!r})\")\n        if self.values:\n            message.append(f\" with values {sorted(self.values)!r}\")\n        message.append(\".\")\n        if self.suggested:\n            if self.endpoint == self.suggested.endpoint:\n                if (\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\map.py": {
      "sha": "53c2e5e10f12",
      "lines": 951,
      "head": "from __future__ import annotations\n\nimport typing as t\nimport warnings\nfrom pprint import pformat\nfrom threading import Lock\nfrom urllib.parse import quote\nfrom urllib.parse import urljoin\nfrom urllib.parse import urlunsplit\n\nfrom .._internal import _get_environ\nfrom .._internal import _wsgi_decoding_dance\nfrom ..datastructures import ImmutableDict\nfrom ..datastructures import MultiDict\nfrom ..exceptions import BadHost\nfrom ..exceptions import HTTPException\nfrom ..exceptions import MethodNotAllowed\nfrom ..exceptions import NotFound\nfrom ..urls import _urlencode\nfrom ..wsgi import get_host\nfrom .converters import DEFAULT_CONVERTERS\nfrom .exceptions import BuildError\nfrom .exceptions import NoMatch\nfrom .exceptions import RequestAliasRedirect\nfrom .exceptions import RequestPath\nfrom .exceptions import RequestRedirect\nfrom .exceptions import WebsocketMismatch\nfrom .matcher import StateMachineMatcher\nfrom .rules import _simple_rule_re\nfrom .rules import Rule\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from ..wrappers.request import Request\n    from .converters import BaseConverter\n    from .rules import RuleFactory\n\n\nclass Map:\n    \"\"\"The map class stores all the URL rules and some configuration\n    parameters.  Some of the configuration values are only stored on the\n    `Map` instance since those affect all rules, others are just defaults\n    and can be overridden for each rule.  Note that you have to specify all\n    arguments besides the `rules` as keyword arguments!\n\n    :param rules: sequence of url rules for this map.\n    :param default_subdomain: The default subdomain for rules without a\n                              subdomain defined.\n    :param strict_slashes: If a rule ends with a slash but the matched\n        URL does not, redirect to the URL with a trailing slash.\n    :param merge_slashes: Merge consecutive slashes when matching or\n        building URLs. Matches will redirect to the normalized URL.\n        Slashes in variable parts are not merged.\n    :param redirect_defaults: This will redirect to the default rule if it\n                              wasn't visited that way. This helps creating\n                              unique URLs.\n    :param converters: A dict of converters that adds additional converters\n                       to the list of converters. If you redefine one\n                       converter this will override the original one.\n    :param sort_parameters: If set to `True` the url parameters are sorted.\n                            See `url_encode` for more details.\n    :param sort_key: The sort key function for `url_encode`.\n    :param host_matching: if set to `True` it enables the host matching\n                          feature and disables the subdomain one.  If\n                          enabled the `host` parameter to rules is used\n                          instead of the `subdomain` one.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``encoding_errors`` parameters were removed.\n\n    .. versionchanged:: 1.0\n        If ``url_scheme`` is ``ws`` or ``wss``, only WebSocket rules will match.\n\n    .. versionchanged:: 1.0\n        The ``merge_slashes`` parameter was added.\n\n    .. versionchanged:: 0.7\n        The ``encoding_errors`` and ``host_matching`` parameters were added.\n\n    .. versionchanged:: 0.5\n        The ``sort_parameters`` and ``sort_key``  paramters were added.\n    \"\"\"\n\n    #: A dict of default converters to be used.\n    default_converters = ImmutableDict(DEFAULT_CONVERTERS)\n\n    #: The type of lock to use when updating.\n    #:\n    #: .. versionadded:: 1.0\n    lock_class = Lock\n\n    def __init__(\n        self,\n        rules: t.Iterable[RuleFactory] | None = None,\n        default_subdomain: str = \"\",\n        strict_slashes: bool = True,\n        merge_slashes: bool = True,\n        redirect_defaults: bool = True,\n        converters: t.Mapping[str, type[BaseConverter]] | None = None,\n        sort_parameters: bool = False,\n        sort_key: t.Callable[[t.Any], t.Any] | None = None,\n        host_matching: bool = False,\n    ) -> None:\n        self._matcher = StateMachineMatcher(merge_slashes)\n        self._rules_by_endpoint: dict[t.Any, list[Rule]] = {}\n        self._remap = True\n        self._remap_lock = self.lock_class()\n\n        self.default_subdomain = default_subdomain\n        self.strict_slashes = strict_slashes\n        self.redirect_defaults = redirect_defaults\n        self.host_matching = host_matching\n\n        self.converters = self.default_converters.copy()\n        if converters:\n            self.converters.update(converters)\n\n        self.sort_parameters = sort_parameters\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\matcher.py": {
      "sha": "1ce0efde0cae",
      "lines": 202,
      "head": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom dataclasses import field\n\nfrom .converters import ValidationError\nfrom .exceptions import NoMatch\nfrom .exceptions import RequestAliasRedirect\nfrom .exceptions import RequestPath\nfrom .rules import Rule\nfrom .rules import RulePart\n\n\nclass SlashRequired(Exception):\n    pass\n\n\n@dataclass\nclass State:\n    \"\"\"A representation of a rule state.\n\n    This includes the *rules* that correspond to the state and the\n    possible *static* and *dynamic* transitions to the next state.\n    \"\"\"\n\n    dynamic: list[tuple[RulePart, State]] = field(default_factory=list)\n    rules: list[Rule] = field(default_factory=list)\n    static: dict[str, State] = field(default_factory=dict)\n\n\nclass StateMachineMatcher:\n    def __init__(self, merge_slashes: bool) -> None:\n        self._root = State()\n        self.merge_slashes = merge_slashes\n\n    def add(self, rule: Rule) -> None:\n        state = self._root\n        for part in rule._parts:\n            if part.static:\n                state.static.setdefault(part.content, State())\n                state = state.static[part.content]\n            else:\n                for test_part, new_state in state.dynamic:\n                    if test_part == part:\n                        state = new_state\n                        break\n                else:\n                    new_state = State()\n                    state.dynamic.append((part, new_state))\n                    state = new_state\n        state.rules.append(rule)\n\n    def update(self) -> None:\n        # For every state the dynamic transitions should be sorted by\n        # the weight of the transition\n        state = self._root\n\n        def _update_state(state: State) -> None:\n            state.dynamic.sort(key=lambda entry: entry[0].weight)\n            for new_state in state.static.values():\n                _update_state(new_state)\n            for _, new_state in state.dynamic:\n                _update_state(new_state)\n\n        _update_state(state)\n\n    def match(\n        self, domain: str, path: str, method: str, websocket: bool\n    ) -> tuple[Rule, t.MutableMapping[str, t.Any]]:\n        # To match to a rule we need to start at the root state and\n        # try to follow the transitions until we find a match, or find\n        # there is no transition to follow.\n\n        have_match_for = set()\n        websocket_mismatch = False\n\n        def _match(\n            state: State, parts: list[str], values: list[str]\n        ) -> tuple[Rule, list[str]] | None:\n            # This function is meant to be called recursively, and will attempt\n            # to match the head part to the state's transitions.\n            nonlocal have_match_for, websocket_mismatch\n\n            # The base case is when all parts have been matched via\n            # transitions. Hence if there is a rule with methods &\n            # websocket that work return it and the dynamic values\n            # extracted.\n            if parts == []:\n                for rule in state.rules:\n                    if rule.methods is not None and method not in rule.methods:\n                        have_match_for.update(rule.methods)\n                    elif rule.websocket != websocket:\n                        websocket_mismatch = True\n                    else:\n                        return rule, values\n\n                # Test if there is a match with this path with a\n                # trailing slash, if so raise an exception to report\n                # that matching is possible with an additional slash\n                if \"\" in state.static:\n                    for rule in state.static[\"\"].rules:\n                        if websocket == rule.websocket and (\n                            rule.methods is None or method in rule.methods\n                        ):\n                            if rule.strict_slashes:\n                                raise SlashRequired()\n                            else:\n                                return rule, values\n                return None\n\n            part = parts[0]\n            # To match this part try the static transitions first\n            if part in state.static:\n                rv = _match(state.static[part], parts[1:], values)\n                if rv is not None:\n                    return rv\n            # No match via the static transitions, so try the dynamic\n            # ones.\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\rules.py": {
      "sha": "7787009b7e88",
      "lines": 928,
      "head": "from __future__ import annotations\n\nimport ast\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom string import Template\nfrom types import CodeType\nfrom urllib.parse import quote\n\nfrom ..datastructures import iter_multi_items\nfrom ..urls import _urlencode\nfrom .converters import ValidationError\n\nif t.TYPE_CHECKING:\n    from .converters import BaseConverter\n    from .map import Map\n\n\nclass Weighting(t.NamedTuple):\n    number_static_weights: int\n    static_weights: list[tuple[int, int]]\n    number_argument_weights: int\n    argument_weights: list[int]\n\n\n@dataclass\nclass RulePart:\n    \"\"\"A part of a rule.\n\n    Rules can be represented by parts as delimited by `/` with\n    instances of this class representing those parts. The *content* is\n    either the raw content if *static* or a regex string to match\n    against. The *weight* can be used to order parts when matching.\n\n    \"\"\"\n\n    content: str\n    final: bool\n    static: bool\n    suffixed: bool\n    weight: Weighting\n\n\n_part_re = re.compile(\n    r\"\"\"\n    (?:\n        (?P<slash>/)                                 # a slash\n      |\n        (?P<static>[^</]+)                           # static rule data\n      |\n        (?:\n          <\n            (?:\n              (?P<converter>[a-zA-Z_][a-zA-Z0-9_]*)   # converter name\n              (?:\\((?P<arguments>.*?)\\))?             # converter arguments\n              :                                       # variable delimiter\n            )?\n            (?P<variable>[a-zA-Z_][a-zA-Z0-9_]*)      # variable name\n           >\n        )\n    )\n    \"\"\",\n    re.VERBOSE,\n)\n\n_simple_rule_re = re.compile(r\"<([^>]+)>\")\n_converter_args_re = re.compile(\n    r\"\"\"\n    \\s*\n    ((?P<name>\\w+)\\s*=\\s*)?\n    (?P<value>\n        True|False|\n        \\d+.\\d+|\n        \\d+.|\n        \\d+|\n        [\\w\\d_.]+|\n        [urUR]?(?P<stringval>\"[^\"]*?\"|'[^']*')\n    )\\s*,\n    \"\"\",\n    re.VERBOSE,\n)\n\n\n_PYTHON_CONSTANTS = {\"None\": None, \"True\": True, \"False\": False}\n\n\ndef _find(value: str, target: str, pos: int) -> int:\n    \"\"\"Find the *target* in *value* after *pos*.\n\n    Returns the *value* length if *target* isn't found.\n    \"\"\"\n    try:\n        return value.index(target, pos)\n    except ValueError:\n        return len(value)\n\n\ndef _pythonize(value: str) -> None | bool | int | float | str:\n    if value in _PYTHON_CONSTANTS:\n        return _PYTHON_CONSTANTS[value]\n    for convert in int, float:\n        try:\n            return convert(value)\n        except ValueError:\n            pass\n    if value[:1] == value[-1:] and value[0] in \"\\\"'\":\n        value = value[1:-1]\n    return str(value)\n\n\ndef parse_converter_args(argstr: str) -> tuple[tuple[t.Any, ...], dict[str, t.Any]]:\n    argstr += \",\"\n    args = []\n    kwargs = {}\n    position = 0\n\n    for item in _converter_args_re.finditer(argstr):\n        if item.start() != position:\n            raise ValueError(\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\routing\\__init__.py": {
      "sha": "abfd2a588d17",
      "lines": 134,
      "head": "\"\"\"When it comes to combining multiple controller or view functions\n(however you want to call them) you need a dispatcher. A simple way\nwould be applying regular expression tests on the ``PATH_INFO`` and\ncalling registered callback functions that return the value then.\n\nThis module implements a much more powerful system than simple regular\nexpression matching because it can also convert values in the URLs and\nbuild URLs.\n\nHere a simple example that creates a URL map for an application with\ntwo subdomains (www and kb) and some URL rules:\n\n.. code-block:: python\n\n    m = Map([\n        # Static URLs\n        Rule('/', endpoint='static/index'),\n        Rule('/about', endpoint='static/about'),\n        Rule('/help', endpoint='static/help'),\n        # Knowledge Base\n        Subdomain('kb', [\n            Rule('/', endpoint='kb/index'),\n            Rule('/browse/', endpoint='kb/browse'),\n            Rule('/browse/<int:id>/', endpoint='kb/browse'),\n            Rule('/browse/<int:id>/<int:page>', endpoint='kb/browse')\n        ])\n    ], default_subdomain='www')\n\nIf the application doesn't use subdomains it's perfectly fine to not set\nthe default subdomain and not use the `Subdomain` rule factory. The\nendpoint in the rules can be anything, for example import paths or\nunique identifiers. The WSGI application can use those endpoints to get the\nhandler for that URL.  It doesn't have to be a string at all but it's\nrecommended.\n\nNow it's possible to create a URL adapter for one of the subdomains and\nbuild URLs:\n\n.. code-block:: python\n\n    c = m.bind('example.com')\n\n    c.build(\"kb/browse\", dict(id=42))\n    'http://kb.example.com/browse/42/'\n\n    c.build(\"kb/browse\", dict())\n    'http://kb.example.com/browse/'\n\n    c.build(\"kb/browse\", dict(id=42, page=3))\n    'http://kb.example.com/browse/42/3'\n\n    c.build(\"static/about\")\n    '/about'\n\n    c.build(\"static/index\", force_external=True)\n    'http://www.example.com/'\n\n    c = m.bind('example.com', subdomain='kb')\n\n    c.build(\"static/about\")\n    'http://www.example.com/about'\n\nThe first argument to bind is the server name *without* the subdomain.\nPer default it will assume that the script is mounted on the root, but\noften that's not the case so you can provide the real mount point as\nsecond argument:\n\n.. code-block:: python\n\n    c = m.bind('example.com', '/applications/example')\n\nThe third argument can be the subdomain, if not given the default\nsubdomain is used.  For more details about binding have a look at the\ndocumentation of the `MapAdapter`.\n\nAnd here is how you can match URLs:\n\n.. code-block:: python\n\n    c = m.bind('example.com')\n\n    c.match(\"/\")\n    ('static/index', {})\n\n    c.match(\"/about\")\n    ('static/about', {})\n\n    c = m.bind('example.com', '/', 'kb')\n\n    c.match(\"/\")\n    ('kb/index', {})\n\n    c.match(\"/browse/42/23\")\n    ('kb/browse', {'id': 42, 'page': 23})\n\nIf matching fails you get a ``NotFound`` exception, if the rule thinks\nit's a good idea to redirect (for example because the URL was defined\nto have a slash at the end but the request was missing that slash) it\nwill raise a ``RequestRedirect`` exception. Both are subclasses of\n``HTTPException`` so you can use those errors as responses in the\napplication.\n\nIf matching succeeded but the URL rule was incompatible to the given\nmethod (for example there were only rules for ``GET`` and ``HEAD`` but\nrouting tried to match a ``POST`` request) a ``MethodNotAllowed``\nexception is raised.\n\"\"\"\n\nfrom .converters import AnyConverter as AnyConverter\nfrom .converters import BaseConverter as BaseConverter\nfrom .converters import FloatConverter as FloatConverter\nfrom .converters import IntegerConverter as IntegerConverter\nfrom .converters import PathConverter as PathConverter\nfrom .converters import UnicodeConverter as UnicodeConverter\nfrom .converters import UUIDConverter as UUIDConverter\nfrom .converters import ValidationError as ValidationError\nfrom .exceptions import BuildError as BuildError\nfrom .exceptions import NoMatch as NoMatch\nfrom .exceptions import RequestAliasRedirect as RequestAliasRedirect\nfrom .exceptions import RequestPath as RequestPath\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\http.py": {
      "sha": "4d5d0a93d244",
      "lines": 170,
      "head": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom datetime import datetime\n\nfrom .._internal import _dt_as_utc\nfrom ..http import generate_etag\nfrom ..http import parse_date\nfrom ..http import parse_etags\nfrom ..http import parse_if_range_header\nfrom ..http import unquote_etag\n\n_etag_re = re.compile(r'([Ww]/)?(?:\"(.*?)\"|(.*?))(?:\\s*,\\s*|$)')\n\n\ndef is_resource_modified(\n    http_range: str | None = None,\n    http_if_range: str | None = None,\n    http_if_modified_since: str | None = None,\n    http_if_none_match: str | None = None,\n    http_if_match: str | None = None,\n    etag: str | None = None,\n    data: bytes | None = None,\n    last_modified: datetime | str | None = None,\n    ignore_if_range: bool = True,\n) -> bool:\n    \"\"\"Convenience method for conditional requests.\n    :param http_range: Range HTTP header\n    :param http_if_range: If-Range HTTP header\n    :param http_if_modified_since: If-Modified-Since HTTP header\n    :param http_if_none_match: If-None-Match HTTP header\n    :param http_if_match: If-Match HTTP header\n    :param etag: the etag for the response for comparison.\n    :param data: or alternatively the data of the response to automatically\n                 generate an etag using :func:`generate_etag`.\n    :param last_modified: an optional date of the last modification.\n    :param ignore_if_range: If `False`, `If-Range` header will be taken into\n                            account.\n    :return: `True` if the resource was modified, otherwise `False`.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if etag is None and data is not None:\n        etag = generate_etag(data)\n    elif data is not None:\n        raise TypeError(\"both data and etag given\")\n\n    unmodified = False\n    if isinstance(last_modified, str):\n        last_modified = parse_date(last_modified)\n\n    # HTTP doesn't use microsecond, remove it to avoid false positive\n    # comparisons. Mark naive datetimes as UTC.\n    if last_modified is not None:\n        last_modified = _dt_as_utc(last_modified.replace(microsecond=0))\n\n    if_range = None\n    if not ignore_if_range and http_range is not None:\n        # https://tools.ietf.org/html/rfc7233#section-3.2\n        # A server MUST ignore an If-Range header field received in a request\n        # that does not contain a Range header field.\n        if_range = parse_if_range_header(http_if_range)\n\n    if if_range is not None and if_range.date is not None:\n        modified_since: datetime | None = if_range.date\n    else:\n        modified_since = parse_date(http_if_modified_since)\n\n    if modified_since and last_modified and last_modified <= modified_since:\n        unmodified = True\n\n    if etag:\n        etag, _ = unquote_etag(etag)\n\n        if if_range is not None and if_range.etag is not None:\n            unmodified = parse_etags(if_range.etag).contains(etag)\n        else:\n            if_none_match = parse_etags(http_if_none_match)\n            if if_none_match:\n                # https://tools.ietf.org/html/rfc7232#section-3.2\n                # \"A recipient MUST use the weak comparison function when comparing\n                # entity-tags for If-None-Match\"\n                unmodified = if_none_match.contains_weak(etag)\n\n            # https://tools.ietf.org/html/rfc7232#section-3.1\n            # \"Origin server MUST use the strong comparison function when\n            # comparing entity-tags for If-Match\"\n            if_match = parse_etags(http_if_match)\n            if if_match:\n                unmodified = not if_match.is_strong(etag)\n\n    return not unmodified\n\n\n_cookie_re = re.compile(\n    r\"\"\"\n    ([^=;]*)\n    (?:\\s*=\\s*\n      (\n        \"(?:[^\\\\\"]|\\\\.)*\"\n      |\n        .*?\n      )\n    )?\n    \\s*;\\s*\n    \"\"\",\n    flags=re.ASCII | re.VERBOSE,\n)\n_cookie_unslash_re = re.compile(rb\"\\\\([0-3][0-7]{2}|.)\")\n\n\ndef _cookie_unslash_replace(m: t.Match[bytes]) -> bytes:\n    v = m.group(1)\n\n    if len(v) == 1:\n        return v\n\n    return int(v, 8).to_bytes(1, \"big\")\n\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\multipart.py": {
      "sha": "d786b767da9b",
      "lines": 323,
      "head": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom enum import auto\nfrom enum import Enum\n\nfrom ..datastructures import Headers\nfrom ..exceptions import RequestEntityTooLarge\nfrom ..http import parse_options_header\n\n\nclass Event:\n    pass\n\n\n@dataclass(frozen=True)\nclass Preamble(Event):\n    data: bytes\n\n\n@dataclass(frozen=True)\nclass Field(Event):\n    name: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass File(Event):\n    name: str\n    filename: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass Data(Event):\n    data: bytes\n    more_data: bool\n\n\n@dataclass(frozen=True)\nclass Epilogue(Event):\n    data: bytes\n\n\nclass NeedData(Event):\n    pass\n\n\nNEED_DATA = NeedData()\n\n\nclass State(Enum):\n    PREAMBLE = auto()\n    PART = auto()\n    DATA = auto()\n    DATA_START = auto()\n    EPILOGUE = auto()\n    COMPLETE = auto()\n\n\n# Multipart line breaks MUST be CRLF (\\r\\n) by RFC-7578, except that\n# many implementations break this and either use CR or LF alone.\nLINE_BREAK = b\"(?:\\r\\n|\\n|\\r)\"\nBLANK_LINE_RE = re.compile(b\"(?:\\r\\n\\r\\n|\\r\\r|\\n\\n)\", re.MULTILINE)\nLINE_BREAK_RE = re.compile(LINE_BREAK, re.MULTILINE)\n# Header values can be continued via a space or tab after the linebreak, as\n# per RFC2231\nHEADER_CONTINUATION_RE = re.compile(b\"%s[ \\t]\" % LINE_BREAK, re.MULTILINE)\n# This must be long enough to contain any line breaks plus any\n# additional boundary markers (--) such that they will be found in a\n# subsequent search\nSEARCH_EXTRA_LENGTH = 8\n\n\nclass MultipartDecoder:\n    \"\"\"Decodes a multipart message as bytes into Python events.\n\n    The part data is returned as available to allow the caller to save\n    the data from memory to disk, if desired.\n    \"\"\"\n\n    def __init__(\n        self,\n        boundary: bytes,\n        max_form_memory_size: int | None = None,\n        *,\n        max_parts: int | None = None,\n    ) -> None:\n        self.buffer = bytearray()\n        self.complete = False\n        self.max_form_memory_size = max_form_memory_size\n        self.max_parts = max_parts\n        self.state = State.PREAMBLE\n        self.boundary = boundary\n\n        # Note in the below \\h i.e. horizontal whitespace is used\n        # as [^\\S\\n\\r] as \\h isn't supported in python.\n\n        # The preamble must end with a boundary where the boundary is\n        # prefixed by a line break, RFC2046. Except that many\n        # implementations including Werkzeug's tests omit the line\n        # break prefix. In addition the first boundary could be the\n        # epilogue boundary (for empty form-data) hence the matching\n        # group to understand if it is an epilogue boundary.\n        self.preamble_re = re.compile(\n            rb\"%s?--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        # A boundary must include a line break prefix and suffix, and\n        # may include trailing whitespace. In addition the boundary\n        # could be the epilogue boundary hence the matching group to\n        # understand if it is an epilogue boundary.\n        self.boundary_re = re.compile(\n            rb\"%s--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\request.py": {
      "sha": "52582a188d43",
      "lines": 534,
      "head": "from __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\nfrom urllib.parse import parse_qsl\n\nfrom ..datastructures import Accept\nfrom ..datastructures import Authorization\nfrom ..datastructures import CharsetAccept\nfrom ..datastructures import ETags\nfrom ..datastructures import Headers\nfrom ..datastructures import HeaderSet\nfrom ..datastructures import IfRange\nfrom ..datastructures import ImmutableList\nfrom ..datastructures import ImmutableMultiDict\nfrom ..datastructures import LanguageAccept\nfrom ..datastructures import MIMEAccept\nfrom ..datastructures import MultiDict\nfrom ..datastructures import Range\nfrom ..datastructures import RequestCacheControl\nfrom ..http import parse_accept_header\nfrom ..http import parse_cache_control_header\nfrom ..http import parse_date\nfrom ..http import parse_etags\nfrom ..http import parse_if_range_header\nfrom ..http import parse_list_header\nfrom ..http import parse_options_header\nfrom ..http import parse_range_header\nfrom ..http import parse_set_header\nfrom ..user_agent import UserAgent\nfrom ..utils import cached_property\nfrom ..utils import header_property\nfrom .http import parse_cookie\nfrom .utils import get_content_length\nfrom .utils import get_current_url\nfrom .utils import get_host\n\n\nclass Request:\n    \"\"\"Represents the non-IO parts of a HTTP request, including the\n    method, URL info, and headers.\n\n    This class is not meant for general use. It should only be used when\n    implementing WSGI, ASGI, or another HTTP application spec. Werkzeug\n    provides a WSGI implementation at :cls:`werkzeug.wrappers.Request`.\n\n    :param method: The method the request was made with, such as\n        ``GET``.\n    :param scheme: The URL scheme of the protocol the request used, such\n        as ``https`` or ``wss``.\n    :param server: The address of the server. ``(host, port)``,\n        ``(path, None)`` for unix sockets, or ``None`` if not known.\n    :param root_path: The prefix that the application is mounted under.\n        This is prepended to generated URLs, but is not part of route\n        matching.\n    :param path: The path part of the URL after ``root_path``.\n    :param query_string: The part of the URL after the \"?\".\n    :param headers: The headers received with the request.\n    :param remote_addr: The address of the client sending the request.\n\n    .. versionchanged:: 3.0\n        The ``charset``, ``url_charset``, and ``encoding_errors`` attributes\n        were removed.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: the class to use for `args` and `form`.  The default is an\n    #: :class:`~werkzeug.datastructures.ImmutableMultiDict` which supports\n    #: multiple values per key. A :class:`~werkzeug.datastructures.ImmutableDict`\n    #: is faster but only remembers the last key. It is also\n    #: possible to use mutable structures, but this is not recommended.\n    #:\n    #: .. versionadded:: 0.6\n    parameter_storage_class: type[MultiDict[str, t.Any]] = ImmutableMultiDict\n\n    #: The type to be used for dict values from the incoming WSGI\n    #: environment. (For example for :attr:`cookies`.) By default an\n    #: :class:`~werkzeug.datastructures.ImmutableMultiDict` is used.\n    #:\n    #: .. versionchanged:: 1.0.0\n    #:     Changed to ``ImmutableMultiDict`` to support multiple values.\n    #:\n    #: .. versionadded:: 0.6\n    dict_storage_class: type[MultiDict[str, t.Any]] = ImmutableMultiDict\n\n    #: the type to be used for list values from the incoming WSGI environment.\n    #: By default an :class:`~werkzeug.datastructures.ImmutableList` is used\n    #: (for example for :attr:`access_list`).\n    #:\n    #: .. versionadded:: 0.6\n    list_storage_class: type[list[t.Any]] = ImmutableList\n\n    user_agent_class: type[UserAgent] = UserAgent\n    \"\"\"The class used and returned by the :attr:`user_agent` property to\n    parse the header. Defaults to\n    :class:`~werkzeug.user_agent.UserAgent`, which does no parsing. An\n    extension can provide a subclass that uses a parser to provide other\n    data.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: Valid host names when handling requests. By default all hosts are\n    #: trusted, which means that whatever the client says the host is\n    #: will be accepted.\n    #:\n    #: Because ``Host`` and ``X-Forwarded-Host`` headers can be set to\n    #: any value by a malicious client, it is recommended to either set\n    #: this property or implement similar validation in the proxy (if\n    #: the application is being run behind one).\n    #:\n    #: .. versionadded:: 0.9\n    trusted_hosts: list[str] | None = None\n\n    def __init__(\n        self,\n        method: str,\n        scheme: str,\n        server: tuple[str, int | None] | None,\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\response.py": {
      "sha": "c245eb88a2c9",
      "lines": 763,
      "head": "from __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom http import HTTPStatus\n\nfrom ..datastructures import CallbackDict\nfrom ..datastructures import ContentRange\nfrom ..datastructures import ContentSecurityPolicy\nfrom ..datastructures import Headers\nfrom ..datastructures import HeaderSet\nfrom ..datastructures import ResponseCacheControl\nfrom ..datastructures import WWWAuthenticate\nfrom ..http import COEP\nfrom ..http import COOP\nfrom ..http import dump_age\nfrom ..http import dump_cookie\nfrom ..http import dump_header\nfrom ..http import dump_options_header\nfrom ..http import http_date\nfrom ..http import HTTP_STATUS_CODES\nfrom ..http import parse_age\nfrom ..http import parse_cache_control_header\nfrom ..http import parse_content_range_header\nfrom ..http import parse_csp_header\nfrom ..http import parse_date\nfrom ..http import parse_options_header\nfrom ..http import parse_set_header\nfrom ..http import quote_etag\nfrom ..http import unquote_etag\nfrom ..utils import get_content_type\nfrom ..utils import header_property\n\nif t.TYPE_CHECKING:\n    from ..datastructures.cache_control import _CacheControl\n\n\ndef _set_property(name: str, doc: str | None = None) -> property:\n    def fget(self: Response) -> HeaderSet:\n        def on_update(header_set: HeaderSet) -> None:\n            if not header_set and name in self.headers:\n                del self.headers[name]\n            elif header_set:\n                self.headers[name] = header_set.to_header()\n\n        return parse_set_header(self.headers.get(name), on_update)\n\n    def fset(\n        self: Response,\n        value: None | (str | dict[str, str | int] | t.Iterable[str]),\n    ) -> None:\n        if not value:\n            del self.headers[name]\n        elif isinstance(value, str):\n            self.headers[name] = value\n        else:\n            self.headers[name] = dump_header(value)\n\n    return property(fget, fset, doc=doc)\n\n\nclass Response:\n    \"\"\"Represents the non-IO parts of an HTTP response, specifically the\n    status and headers but not the body.\n\n    This class is not meant for general use. It should only be used when\n    implementing WSGI, ASGI, or another HTTP application spec. Werkzeug\n    provides a WSGI implementation at :cls:`werkzeug.wrappers.Response`.\n\n    :param status: The status code for the response. Either an int, in\n        which case the default status message is added, or a string in\n        the form ``{code} {message}``, like ``404 Not Found``. Defaults\n        to 200.\n    :param headers: A :class:`~werkzeug.datastructures.Headers` object,\n        or a list of ``(key, value)`` tuples that will be converted to a\n        ``Headers`` object.\n    :param mimetype: The mime type (content type without charset or\n        other parameters) of the response. If the value starts with\n        ``text/`` (or matches some other special cases), the charset\n        will be added to create the ``content_type``.\n    :param content_type: The full content type of the response.\n        Overrides building the value from ``mimetype``.\n\n    .. versionchanged:: 3.0\n        The ``charset`` attribute was removed.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: the default status if none is provided.\n    default_status = 200\n\n    #: the default mimetype if none is provided.\n    default_mimetype: str | None = \"text/plain\"\n\n    #: Warn if a cookie header exceeds this size. The default, 4093, should be\n    #: safely `supported by most browsers <cookie_>`_. A cookie larger than\n    #: this size will still be sent, but it may be ignored or handled\n    #: incorrectly by some browsers. Set to 0 to disable this check.\n    #:\n    #: .. versionadded:: 0.13\n    #:\n    #: .. _`cookie`: http://browsercookielimits.squawky.net/\n    max_cookie_size = 4093\n\n    # A :class:`Headers` object representing the response headers.\n    headers: Headers\n\n    def __init__(\n        self,\n        status: int | str | HTTPStatus | None = None,\n        headers: t.Mapping[str, str | t.Iterable[str]]\n        | t.Iterable[tuple[str, str]]\n        | None = None,\n        mimetype: str | None = None,\n        content_type: str | None = None,\n    ) -> None:\n        if isinstance(headers, Headers):\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\utils.py": {
      "sha": "67a594e2c6d2",
      "lines": 167,
      "head": "from __future__ import annotations\n\nimport typing as t\nfrom urllib.parse import quote\n\nfrom .._internal import _plain_int\nfrom ..exceptions import SecurityError\nfrom ..urls import uri_to_iri\n\n\ndef host_is_trusted(hostname: str | None, trusted_list: t.Iterable[str]) -> bool:\n    \"\"\"Check if a host matches a list of trusted names.\n\n    :param hostname: The name to check.\n    :param trusted_list: A list of valid names to match. If a name\n        starts with a dot it will match all subdomains.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    if not hostname:\n        return False\n\n    try:\n        hostname = hostname.partition(\":\")[0].encode(\"idna\").decode(\"ascii\")\n    except UnicodeEncodeError:\n        return False\n\n    if isinstance(trusted_list, str):\n        trusted_list = [trusted_list]\n\n    for ref in trusted_list:\n        if ref.startswith(\".\"):\n            ref = ref[1:]\n            suffix_match = True\n        else:\n            suffix_match = False\n\n        try:\n            ref = ref.partition(\":\")[0].encode(\"idna\").decode(\"ascii\")\n        except UnicodeEncodeError:\n            return False\n\n        if ref == hostname or (suffix_match and hostname.endswith(f\".{ref}\")):\n            return True\n\n    return False\n\n\ndef get_host(\n    scheme: str,\n    host_header: str | None,\n    server: tuple[str, int | None] | None = None,\n    trusted_hosts: t.Iterable[str] | None = None,\n) -> str:\n    \"\"\"Return the host for the given parameters.\n\n    This first checks the ``host_header``. If it's not present, then\n    ``server`` is used. The host will only contain the port if it is\n    different than the standard port for the protocol.\n\n    Optionally, verify that the host is trusted using\n    :func:`host_is_trusted` and raise a\n    :exc:`~werkzeug.exceptions.SecurityError` if it is not.\n\n    :param scheme: The protocol the request used, like ``\"https\"``.\n    :param host_header: The ``Host`` header value.\n    :param server: Address of the server. ``(host, port)``, or\n        ``(path, None)`` for unix sockets.\n    :param trusted_hosts: A list of trusted host names.\n\n    :return: Host, with port if necessary.\n    :raise ~werkzeug.exceptions.SecurityError: If the host is not\n        trusted.\n\n    .. versionchanged:: 3.1.3\n        If ``SERVER_NAME`` is IPv6, it is wrapped in ``[]``.\n    \"\"\"\n    host = \"\"\n\n    if host_header is not None:\n        host = host_header\n    elif server is not None:\n        host = server[0]\n\n        # If SERVER_NAME is IPv6, wrap it in [] to match Host header.\n        # Check for : because domain or IPv4 can't have that.\n        if \":\" in host and host[0] != \"[\":\n            host = f\"[{host}]\"\n\n        if server[1] is not None:\n            host = f\"{host}:{server[1]}\"\n\n    if scheme in {\"http\", \"ws\"} and host.endswith(\":80\"):\n        host = host[:-3]\n    elif scheme in {\"https\", \"wss\"} and host.endswith(\":443\"):\n        host = host[:-4]\n\n    if trusted_hosts is not None:\n        if not host_is_trusted(host, trusted_hosts):\n            raise SecurityError(f\"Host {host!r} is not trusted.\")\n\n    return host\n\n\ndef get_current_url(\n    scheme: str,\n    host: str,\n    root_path: str | None = None,\n    path: str | None = None,\n    query_string: bytes | None = None,\n) -> str:\n    \"\"\"Recreate the URL for a request. If an optional part isn't\n    provided, it and subsequent parts are not included in the URL.\n\n    The URL is an IRI, not a URI, so it may contain Unicode characters.\n    Use :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.\n\n    :param scheme: The protocol the request used, like ``\"https\"``.\n    :param host: The host the request was made to. See :func:`get_host`.\n    :param root_path: Prefix that the application is mounted under. This\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\sansio\\__init__.py": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    ".venv\\Lib\\site-packages\\werkzeug\\wrappers\\request.py": {
      "sha": "8d7d358b0b44",
      "lines": 650,
      "head": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport functools\nimport json\nimport typing as t\nfrom io import BytesIO\n\nfrom .._internal import _wsgi_decoding_dance\nfrom ..datastructures import CombinedMultiDict\nfrom ..datastructures import EnvironHeaders\nfrom ..datastructures import FileStorage\nfrom ..datastructures import ImmutableMultiDict\nfrom ..datastructures import iter_multi_items\nfrom ..datastructures import MultiDict\nfrom ..exceptions import BadRequest\nfrom ..exceptions import UnsupportedMediaType\nfrom ..formparser import default_stream_factory\nfrom ..formparser import FormDataParser\nfrom ..sansio.request import Request as _SansIORequest\nfrom ..utils import cached_property\nfrom ..utils import environ_property\nfrom ..wsgi import _get_server\nfrom ..wsgi import get_input_stream\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass Request(_SansIORequest):\n    \"\"\"Represents an incoming WSGI HTTP request, with headers and body\n    taken from the WSGI environment. Has properties and methods for\n    using the functionality defined by various HTTP specs. The data in\n    requests object is read-only.\n\n    Text data is assumed to use UTF-8 encoding, which should be true for\n    the vast majority of modern clients. Using an encoding set by the\n    client is unsafe in Python due to extra encodings it provides, such\n    as ``zip``. To change the assumed encoding, subclass and replace\n    :attr:`charset`.\n\n    :param environ: The WSGI environ is generated by the WSGI server and\n        contains information about the server configuration and client\n        request.\n    :param populate_request: Add this request object to the WSGI environ\n        as ``environ['werkzeug.request']``. Can be useful when\n        debugging.\n    :param shallow: Makes reading from :attr:`stream` (and any method\n        that would read from it) raise a :exc:`RuntimeError`. Useful to\n        prevent consuming the form data in middleware, which would make\n        it unavailable to the final application.\n\n    .. versionchanged:: 3.0\n        The ``charset``, ``url_charset``, and ``encoding_errors`` parameters\n        were removed.\n\n    .. versionchanged:: 2.1\n        Old ``BaseRequest`` and mixin classes were removed.\n\n    .. versionchanged:: 2.1\n        Remove the ``disable_data_descriptor`` attribute.\n\n    .. versionchanged:: 2.0\n        Combine ``BaseRequest`` and mixins into a single ``Request``\n        class.\n\n    .. versionchanged:: 0.5\n        Read-only mode is enforced with immutable classes for all data.\n    \"\"\"\n\n    #: the maximum content length.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: parsing fails because more than the specified value is transmitted\n    #: a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: .. versionadded:: 0.5\n    max_content_length: int | None = None\n\n    #: the maximum form field size.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: data in memory for post data is longer than the specified value a\n    #: :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: .. versionchanged:: 3.1\n    #:     Defaults to 500kB instead of unlimited.\n    #:\n    #: .. versionadded:: 0.5\n    max_form_memory_size: int | None = 500_000\n\n    #: The maximum number of multipart parts to parse, passed to\n    #: :attr:`form_data_parser_class`. Parsing form data with more than this\n    #: many parts will raise :exc:`~.RequestEntityTooLarge`.\n    #:\n    #: .. versionadded:: 2.2.3\n    max_form_parts = 1000\n\n    #: The form data parser that should be used.  Can be replaced to customize\n    #: the form date parsing.\n    form_data_parser_class: type[FormDataParser] = FormDataParser\n\n    #: The WSGI environment containing HTTP headers and information from\n    #: the WSGI server.\n    environ: WSGIEnvironment\n\n    #: Set when creating the request object. If ``True``, reading from\n    #: the request body will cause a ``RuntimeException``. Useful to\n    #: prevent modifying the stream from middleware.\n    shallow: bool\n\n    def __init__(\n        self,\n        environ: WSGIEnvironment,\n        populate_request: bool = True,\n        shallow: bool = False,\n    ) -> None:\n        super().__init__(\n            method=environ.get(\"REQUEST_METHOD\", \"GET\"),\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\wrappers\\response.py": {
      "sha": "1a634ff75ef9",
      "lines": 831,
      "head": "from __future__ import annotations\n\nimport json\nimport typing as t\nfrom http import HTTPStatus\nfrom urllib.parse import urljoin\n\nfrom .._internal import _get_environ\nfrom ..datastructures import Headers\nfrom ..http import generate_etag\nfrom ..http import http_date\nfrom ..http import is_resource_modified\nfrom ..http import parse_etags\nfrom ..http import parse_range_header\nfrom ..http import remove_entity_headers\nfrom ..sansio.response import Response as _SansIOResponse\nfrom ..urls import iri_to_uri\nfrom ..utils import cached_property\nfrom ..wsgi import _RangeWrapper\nfrom ..wsgi import ClosingIterator\nfrom ..wsgi import get_current_url\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .request import Request\n\n\ndef _iter_encoded(iterable: t.Iterable[str | bytes]) -> t.Iterator[bytes]:\n    for item in iterable:\n        if isinstance(item, str):\n            yield item.encode()\n        else:\n            yield item\n\n\nclass Response(_SansIOResponse):\n    \"\"\"Represents an outgoing WSGI HTTP response with body, status, and\n    headers. Has properties and methods for using the functionality\n    defined by various HTTP specs.\n\n    The response body is flexible to support different use cases. The\n    simple form is passing bytes, or a string which will be encoded as\n    UTF-8. Passing an iterable of bytes or strings makes this a\n    streaming response. A generator is particularly useful for building\n    a CSV file in memory or using SSE (Server Sent Events). A file-like\n    object is also iterable, although the\n    :func:`~werkzeug.utils.send_file` helper should be used in that\n    case.\n\n    The response object is itself a WSGI application callable. When\n    called (:meth:`__call__`) with ``environ`` and ``start_response``,\n    it will pass its status and headers to ``start_response`` then\n    return its body as an iterable.\n\n    .. code-block:: python\n\n        from werkzeug.wrappers.response import Response\n\n        def index():\n            return Response(\"Hello, World!\")\n\n        def application(environ, start_response):\n            path = environ.get(\"PATH_INFO\") or \"/\"\n\n            if path == \"/\":\n                response = index()\n            else:\n                response = Response(\"Not Found\", status=404)\n\n            return response(environ, start_response)\n\n    :param response: The data for the body of the response. A string or\n        bytes, or tuple or list of strings or bytes, for a fixed-length\n        response, or any other iterable of strings or bytes for a\n        streaming response. Defaults to an empty body.\n    :param status: The status code for the response. Either an int, in\n        which case the default status message is added, or a string in\n        the form ``{code} {message}``, like ``404 Not Found``. Defaults\n        to 200.\n    :param headers: A :class:`~werkzeug.datastructures.Headers` object,\n        or a list of ``(key, value)`` tuples that will be converted to a\n        ``Headers`` object.\n    :param mimetype: The mime type (content type without charset or\n        other parameters) of the response. If the value starts with\n        ``text/`` (or matches some other special cases), the charset\n        will be added to create the ``content_type``.\n    :param content_type: The full content type of the response.\n        Overrides building the value from ``mimetype``.\n    :param direct_passthrough: Pass the response body directly through\n        as the WSGI iterable. This can be used when the body is a binary\n        file or other iterator of bytes, to skip some unnecessary\n        checks. Use :func:`~werkzeug.utils.send_file` instead of setting\n        this manually.\n\n    .. versionchanged:: 2.1\n        Old ``BaseResponse`` and mixin classes were removed.\n\n    .. versionchanged:: 2.0\n        Combine ``BaseResponse`` and mixins into a single ``Response``\n        class.\n\n    .. versionchanged:: 0.5\n        The ``direct_passthrough`` parameter was added.\n    \"\"\"\n\n    #: if set to `False` accessing properties on the response object will\n    #: not try to consume the response iterator and convert it into a list.\n    #:\n    #: .. versionadded:: 0.6.2\n    #:\n    #:    That attribute was previously called `implicit_seqence_conversion`.\n    #:    (Notice the typo).  If you did use this feature, you have to adapt\n    #:    your code to the name change.\n    implicit_sequence_conversion = True\n\n    #: If a redirect ``Location`` header is a relative URL, make it an\n    #: absolute URL, including scheme and domain.\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug\\wrappers\\__init__.py": {
      "sha": "b3358998476a",
      "lines": 3,
      "head": "from .request import Request as Request\nfrom .response import Response as Response\nfrom .response import ResponseStream as ResponseStream\n"
    },
    ".venv\\Lib\\site-packages\\werkzeug-3.1.3.dist-info\\LICENSE.txt": {
      "sha": "c4dbdbc12926",
      "lines": 28,
      "head": "Copyright 2007 Pallets\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n1.  Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n2.  Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\n3.  Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
    },
    ".venv\\Scripts\\activate_this.py": {
      "sha": "82c44d848a3f",
      "lines": 38,
      "head": "\"\"\"\nActivate virtualenv for current interpreter:\n\nimport runpy\nrunpy.run_path(this_file)\n\nThis can be used when you must use an existing Python interpreter, not the virtualenv bin/python.\n\"\"\"  # noqa: D415\n\nfrom __future__ import annotations\n\nimport os\nimport site\nimport sys\n\ntry:\n    abs_file = os.path.abspath(__file__)\nexcept NameError as exc:\n    msg = \"You must use import runpy; runpy.run_path(this_file)\"\n    raise AssertionError(msg) from exc\n\nbin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len('Scripts') - 1]  # strip away the bin part from the __file__, plus the path separator\n\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = '' or os.path.basename(base)\n\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in '..\\\\Lib\\\\site-packages'.split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if '' else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\n\nsys.real_prefix = sys.prefix\nsys.prefix = base\n"
    },
    "static\\css\\custom.css": {
      "sha": "12fd38b733d5",
      "lines": 408,
      "head": ".container {\n  max-width: 800px; }\n.header {\n  margin-top: 6rem;\n  text-align: center; }\n.value-prop {\n  margin-top: 1rem; }\n.value-props {\n  margin-top: 4rem;\n  margin-bottom: 4rem; }\n.docs-header {\n  text-transform: uppercase;\n  font-size: 1.3rem;\n  letter-spacing: .2rem;\n  color: #267326;\n  font-weight: 700; }\n.docs-section {\n  border-top: 1px solid #eee;\n  padding: 4rem 0;\n  margin-bottom: 0;}\n.value-img {\n  display: block;\n  text-align: center;\n  margin: 2.5rem auto 0; }\n.example-grid .column,\n.example-grid .columns {\n  background: #EEE;\n  text-align: center;\n  border-radius: 4px;\n  font-size: 1rem;\n  text-transform: uppercase;\n  height: 30px;\n  line-height: 30px;\n  margin-bottom: .75rem;\n  font-weight: 600;\n  letter-spacing: .1rem; }\n.docs-example .row,\n.docs-example.row,\n.docs-example form {\n  margin-bottom: 0; }\n.docs-example h1,\n.docs-example h2,\n.docs-example h3,\n.docs-example h4,\n.docs-example h5,\n.docs-example h6 {\n  margin-bottom: 1rem; }\n.heading-font-size {\n  font-size: 1.2rem;\n  color: #999;\n  letter-spacing: normal; }\n.code-example {\n  margin-top: 1.5rem;\n  margin-bottom: 0; }\n.code-example-body {\n  white-space: pre;\n  word-wrap: break-word }\n.example {\n  position: relative;\n  margin-top: 4rem; }\n.example-header {\n  font-weight: 600;\n  margin-top: 1.5rem;\n  margin-bottom: .5rem; }\n.example-description {\n  margin-bottom: 1.5rem; }\n.example-screenshot-wrapper {\n  display: block;\n  position: relative;\n  overflow: hidden;\n  border-radius: 6px;\n  border: 1px solid #eee;\n  height: 250px; }\n.example-screenshot {\n  width: 100%;\n  height: auto; }\n.example-screenshot.coming-soon {\n  width: auto;\n  position: absolute;\n  background: #eee;\n  top: 5px;\n  right: 5px;\n  bottom: 5px;\n  left: 5px; }\n.navbar {\n  display: block; }\n/* Navbar */\n  .navbar + .docs-section {\n    border-top-width: 0; }\n  .navbar,\n  .navbar-spacer {\n    display: block;\n    width: 100%;\n    height: 6.5rem;\n    background: #fff;\n    z-index: 99;\n    border-top: 1px solid #eee;\n    border-bottom: 1px solid #eee; }\n  .navbar-spacer {\n    display: none; }\n  .navbar > .container {\n    width: 100%; }\n  .navbar-list {\n    list-style: none;\n    margin-bottom: 0; }\n  .navbar-item {\n    position: relative;\n    float: left;\n    margin-bottom: 0; }\n  .navbar-link {\n    text-transform: uppercase;\n    font-size: 1.0rem;\n    font-weight: 600;\n    letter-spacing: .2rem;\n    margin-right: 35px;\n    text-decoration: none;\n    line-height: 6.5rem;\n    color: #222; }\n  .navbar-link.active {\n    color: #33C3F0; }\n"
    },
    "static\\css\\normalize.css": {
      "sha": "3f40e8a9fe8e",
      "lines": 427,
      "head": "/*! normalize.css v3.0.2 | MIT License | git.io/normalize */\n\n/**\n * 1. Set default font family to sans-serif.\n * 2. Prevent iOS text size adjust after orientation change, without disabling\n *    user zoom.\n */\n\nhtml {\n  font-family: sans-serif; /* 1 */\n  -ms-text-size-adjust: 100%; /* 2 */\n  -webkit-text-size-adjust: 100%; /* 2 */\n}\n\n/**\n * Remove default margin.\n */\n\nbody {\n  margin: 0;\n}\n\n/* HTML5 display definitions\n   ========================================================================== */\n\n/**\n * Correct `block` display not defined for any HTML5 element in IE 8/9.\n * Correct `block` display not defined for `details` or `summary` in IE 10/11\n * and Firefox.\n * Correct `block` display not defined for `main` in IE 11.\n */\n\narticle,\naside,\ndetails,\nfigcaption,\nfigure,\nfooter,\nheader,\nhgroup,\nmain,\nmenu,\nnav,\nsection,\nsummary {\n  display: block;\n}\n\n/**\n * 1. Correct `inline-block` display not defined in IE 8/9.\n * 2. Normalize vertical alignment of `progress` in Chrome, Firefox, and Opera.\n */\n\naudio,\ncanvas,\nprogress,\nvideo {\n  display: inline-block; /* 1 */\n  vertical-align: baseline; /* 2 */\n}\n\n/**\n * Prevent modern browsers from displaying `audio` without controls.\n * Remove excess height in iOS 5 devices.\n */\n\naudio:not([controls]) {\n  display: none;\n  height: 0;\n}\n\n/**\n * Address `[hidden]` styling not present in IE 8/9/10.\n * Hide the `template` element in IE 8/9/11, Safari, and Firefox < 22.\n */\n\n[hidden],\ntemplate {\n  display: none;\n}\n\n/* Links\n   ========================================================================== */\n\n/**\n * Remove the gray background color from active links in IE 10.\n */\n\na {\n  background-color: transparent;\n}\n\n/**\n * Improve readability when focused and also mouse hovered in all browsers.\n */\n\na:active,\na:hover {\n  outline: 0;\n}\n\n/* Text-level semantics\n   ========================================================================== */\n\n/**\n * Address styling not present in IE 8/9/10/11, Safari, and Chrome.\n */\n\nabbr[title] {\n  border-bottom: 1px dotted;\n}\n\n/**\n * Address style set to `bolder` in Firefox 4+, Safari, and Chrome.\n */\n\nb,\nstrong {\n  font-weight: bold;\n}\n"
    },
    "static\\css\\skeleton.css": {
      "sha": "0bfd7933feba",
      "lines": 423,
      "head": "/*\n* Skeleton V2.0.4\n* Copyright 2014, Dave Gamache\n* www.getskeleton.com\n* Free to use under the MIT license.\n* http://www.opensource.org/licenses/mit-license.php\n* 12/29/2014\n*/\n\n\n/* Table of contents\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\n- Grid\n- Base Styles\n- Typography\n- Links\n- Buttons\n- Forms\n- Lists\n- Code\n- Tables\n- Spacing\n- Utilities\n- Clearing\n- Media Queries\n*/\n\n\n/* Grid\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013 */\n.container {\n  position: relative;\n  width: 100%;\n  max-width: 960px;\n  margin: 0 auto;\n  padding: 0 20px;\n  box-sizing: border-box; }\n.column,\n.columns {\n  width: 100%;\n  float: left;\n  box-sizing: border-box; }\n\n/* For devices larger than 400px */\n@media (min-width: 400px) {\n  .container {\n    width: 85%;\n    padding: 0; }\n}\n\n/* For devices larger than 550px */\n@media (min-width: 550px) {\n  .container {\n    width: 80%; }\n  .column,\n  .columns {\n    margin-left: 4%; }\n  .column:first-child,\n  .columns:first-child {\n    margin-left: 0; }\n\n  .one.column,\n  .one.columns                    { width: 4.66666666667%; }\n  .two.columns                    { width: 13.3333333333%; }\n  .three.columns                  { width: 22%;            }\n  .four.columns                   { width: 30.6666666667%; }\n  .five.columns                   { width: 39.3333333333%; }\n  .six.columns                    { width: 48%;            }\n  .seven.columns                  { width: 56.6666666667%; }\n  .eight.columns                  { width: 65.3333333333%; }\n  .nine.columns                   { width: 74.0%;          }\n  .ten.columns                    { width: 82.6666666667%; }\n  .eleven.columns                 { width: 91.3333333333%; }\n  .twelve.columns                 { width: 100%; margin-left: 0; }\n\n  .one-third.column               { width: 30.6666666667%; }\n  .two-thirds.column              { width: 65.3333333333%; }\n\n  .one-half.column                { width: 48%; }\n\n  /* Offsets */\n  .offset-by-one.column,\n  .offset-by-one.columns          { margin-left: 8.66666666667%; }\n  .offset-by-two.column,\n  .offset-by-two.columns          { margin-left: 17.3333333333%; }\n  .offset-by-three.column,\n  .offset-by-three.columns        { margin-left: 26%;            }\n  .offset-by-four.column,\n  .offset-by-four.columns         { margin-left: 34.6666666667%; }\n  .offset-by-five.column,\n  .offset-by-five.columns         { margin-left: 43.3333333333%; }\n  .offset-by-six.column,\n  .offset-by-six.columns          { margin-left: 52%;            }\n  .offset-by-seven.column,\n  .offset-by-seven.columns        { margin-left: 60.6666666667%; }\n  .offset-by-eight.column,\n  .offset-by-eight.columns        { margin-left: 69.3333333333%; }\n  .offset-by-nine.column,\n  .offset-by-nine.columns         { margin-left: 78.0%;          }\n  .offset-by-ten.column,\n  .offset-by-ten.columns          { margin-left: 86.6666666667%; }\n  .offset-by-eleven.column,\n  .offset-by-eleven.columns       { margin-left: 95.3333333333%; }\n\n  .offset-by-one-third.column,\n  .offset-by-one-third.columns    { margin-left: 34.6666666667%; }\n  .offset-by-two-thirds.column,\n  .offset-by-two-thirds.columns   { margin-left: 69.3333333333%; }\n\n  .offset-by-one-half.column,\n  .offset-by-one-half.columns     { margin-left: 52%; }\n\n}\n\n\n/* Base Styles\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013 */\n/* NOTE\nhtml is set to 62.5% so that all the REM measurements throughout Skeleton\nare based on 10px sizing. So basically 1.5rem = 15px :) */\n"
    },
    "static\\js\\jquery.min.js": {
      "sha": "d911f2621278",
      "lines": 1,
      "head": "// jQuery placeholder \u2014 replace with your original if needed"
    },
    "static\\js\\site.js": {
      "sha": "f8243b4a6963",
      "lines": 1,
      "head": "// site.js placeholder \u2014 original copied if present in your zip"
    },
    "templates\\base.html": {
      "sha": "f17f3b575cb2",
      "lines": 94,
      "head": "<!doctype html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"utf-8\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n  <title>{{ title or config.SITE_TITLE }}</title>\n  <meta name=\"description\" content=\"Tawrid Knowledge Base\" />\n\n  <!-- CSS: keep your original pipeline -->\n  <link rel=\"icon\" href=\"{{ url_for('static', filename='images/default-logo.png') }}\">\n  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/normalize.css') }}\">\n  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/skeleton.css') }}\">\n  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/custom.css') }}\">\n</head>\n<body>\n\n  <!-- ===== HEADER (.thePad) from your original index.html ===== -->\n  <div class=\"thePad\" style=\"position: sticky; top: 0; z-index: 1000;background:#fff; \">\n    <div class=\"row\" style=\"border: solid 1px black; \">\n      <div class=\"twelve columns\" style=\"background-color: white;\">\n        <div class=\"six columns\">\n         <span>\n            <img class=\"kb-header-logo\" src=\"{{ url_for('static', filename='images/default-logo.png') }}\" alt=\"Tawrid Logo\" onclick=\"window.scrollTo({ top: 0, behavior: 'smooth' }); return false;\">\n          </span>\n        </div>\n        <div class=\"six columns\">\n          <nav class=\"navbar\">\n            <ul class=\"navbar-list\" style=\"float:right;\">\n              <li class=\"navbar-item\">\n                <a class=\"navbar-link\" href=\"#selectPlaylist\">VideoTutorials</a>\n              </li>\n              <li class=\"navbar-item\">\n                <a class=\"navbar-link\" href=\"#tabMenu\">User Manuals</a>\n              </li>\n            </ul>\n          </nav>\n        </div>\n      </div>\n    </div>\n  </div>\n\n  <!-- ===== PAGE CONTENT GOES HERE ===== -->\n  {% block content %}{% endblock %}\n\n  <!-- ===== FOOTER (.thePad) from your original index.html ===== -->\n  <div class=\"thePad\">\n    <div class=\"row\">\n      <div class=\"twelve columns\" style=\"bottom: 0; border: solid 1px black;\">\n        <center>\n          <em>Source code \u00a9 by Tawrid Company. All rights reserved.</em>\n        </center>\n      </div>\n    </div>\n  </div>\n\n  <!-- JS: keep your originals -->\n  <script src=\"{{ url_for('static', filename='js/jquery.min.js') }}\"></script>\n  <script src=\"{{ url_for('static', filename='js/site.js') }}\"></script>\n\n<script>\n  // Add tabindex so we can focus containers (helps screen readers too)\n  (function ensureTabTargets(){\n    [\"selectPlaylist\",\"tabMenu\"].forEach(id=>{\n      var el = document.getElementById(id);\n      if (el && !el.hasAttribute(\"tabindex\")) el.setAttribute(\"tabindex\",\"-1\");\n    });\n  })();\n\n  // Reusable flash helper\n  function kbFlash(id, durMs=1200){\n    var el = document.getElementById(id);\n    if(!el) return;\n    // focus without scrolling (in case we already are there)\n    el.focus({ preventScroll: true });\n    // restart animation every click\n    el.classList.remove(\"kb-flash\");\n    void el.offsetWidth; // reflow trick to restart CSS animation\n    el.classList.add(\"kb-flash\");\n    setTimeout(function(){ el.classList.remove(\"kb-flash\"); }, durMs);\n  }\n\n  // Hook all header nav links that point to in-page anchors\n  document.querySelectorAll('.navbar a[href^=\"#\"]').forEach(function(a){\n    a.addEventListener('click', function(){\n      var id = this.getAttribute('href').slice(1);\n      // Delay flash to after the browser does the anchor jump (if any)\n      requestAnimationFrame(function(){ kbFlash(id); });\n    });\n  });\n</script>\n\n</body>\n</html>\n"
    },
    "templates\\index.html": {
      "sha": "932492006c81",
      "lines": 291,
      "head": "{% extends \"base.html\" %}\n{% block content %}\n\n<!-- ===== ROW #1: Video player (9 cols) + Playlist (3 cols) ===== -->\n<div class=\"row\" style=\"margin-top: 20px;\">\n  <div class=\"twelve columns\">\n\n    <!-- Video player -->\n    <div class=\"seven columns\" style = \"margin-left : 130px; height : 450px;\">\n      <iframe id=\"VideoPlayer\" class=\"responsive-iframe\"\n              src=\"{{ default_video_url or '' }}\"\n              frameborder=\"0\" allowfullscreen=\"\"></iframe>\n    </div>\n\n    <!-- Playlist -->\n    <div class=\"three columns\">\n      <div class=\"scroll_container custom-scrollbar\" style=\"height: 350px;\">\n        <!-- ONE dynamic list container -->\n        <div id=\"playListItems\" class=\"playListItems\"></div>\n      </div>\n\n      <!-- Switch Playlist (dropdown + button inline) -->\n      <div id=\"selectPlaylist\" style=\"margin-top: 20px; height: 100px;\">\n        <select id=\"thePlayListItems\">\n          <option value=\"01_supplier\" selected>Supplier</option>\n          <option value=\"02_buyer\">Buyer</option>\n          <option value=\"03_funder\">Funder</option>\n        </select>\n        <button class=\"button-primary\" onclick=\"switchPlaylist()\">Switch Playlist</button>\n\n        <div>\n          <center><p id=\"tagLines\">Listing Supplier Playlist</p></center>\n        </div>\n      </div>\n    </div>\n\n  </div>\n</div>\n\n\n<!-- ===== ROW #2: HowTo Docs \u2013 tabs generated from /api/pdfs folders ===== -->\n<div class=\"row\" style=\"margin-top: 10px;\">\n  <div class=\"ten columns\" style=\"margin-left: 70px;\">\n\n    <!-- Tabs (built dynamically) -->\n    <span id=\"tabMenu\" class=\"nav-menu\"></span>\n\n    <!-- Single docs block that repopulates when tab changes -->\n    <div id=\"docs\" class=\"appBlock\">\n      <legend class=\"docs-header\" id=\"docs-legend\"></legend>\n      <h6 id=\"docs-blurb\"></h6>\n\n      <table class=\"docList\">\n        <colgroup>\n          <col width=\"32.6%\">\n          <col width=\"67.4%\">\n        </colgroup>\n        <thead>\n          <tr>\n            <th>Document Name</th>\n            <th>Purpose</th>\n          </tr>\n        </thead>\n        <tbody id=\"doc-tbody\"></tbody>\n      </table>\n    </div>\n\n  </div>\n</div>\n\n<!-- ===== PAGE SCRIPT (videos + docs) ===== -->\n<script>\n  /* -------------------- CONFIG FROM SERVER -------------------- */\n  const CATEGORIES = {{ categories | tojson }};   // videos use this (Supplier/Buyer/Funder)\n  const DEFAULT_CODE = \"01_supplier\";\n\n  // Data stores\n  let KB_VIDEOS = {};     // /api/videos\n  let KB_PDFS  = {};      // /api/pdfs  -> { \"<folder>\": [{name, viewer}, ...], ... }\n  let DESCRIPTIONS = {};  // reserved for future per-video descriptions\n\n  /* -------------------- HELPERS -------------------- */\n  function titleFromFilename(name) {\n    const noExt = name.replace(/\\.[^/.]+$/, \"\");\n    return noExt.replace(/[_-]+/g, \" \").trim();\n  }\n  function prettyLabelFromFolder(code) {\n    // 01_supplier -> Supplier, 02_buyer -> Buyer, 03_funder -> Funder, otherwise Title Case\n    const cleaned = code.replace(/^\\d+[_-]*/, \"\");\n    return cleaned.replace(/[_-]+/g, \" \").replace(/\\b\\w/g, c => c.toUpperCase());\n  }\n\n  /* -------------------- VIDEO PLAYLIST (unchanged) -------------------- */\n  function makeListItem(code, fileObj, idx, isActive) {\n    const id = `${code}__${idx}`;\n    const div = document.createElement(\"div\");\n    div.className = `row listItem ${isActive ? \"playlist-active\" : \"playlist-item\"}`;\n    if (idx === 0) div.style.marginTop = \"5px\";\n    div.id = id;\n\n    div.dataset.url  = fileObj.url;\n    div.dataset.code = code;\n    div.dataset.name = fileObj.name;\n    div.setAttribute(\"onclick\", `changeVideo('${id}')`);\n\n    const b = document.createElement(\"b\");\n    b.className = \"listTitle\";\n    b.textContent = titleFromFilename(fileObj.name);\n\n    const fs = document.createElement(\"fieldset\");\n    const key = `${code}|${fileObj.name}`;\n    fs.textContent = DESCRIPTIONS[code]?.[fileObj.name]\n      || DESCRIPTIONS[key]\n      || \"Video description coming soon.\";\n\n    div.appendChild(b);\n    div.appendChild(fs);\n    return div;\n  }\n\n"
    },
    "templates\\view.html": {
      "sha": "e16c7650dc0e",
      "lines": 10,
      "head": "\n{% extends \"base.html\" %}\n{% block content %}\n  <h5>{{ file_name }}</h5>\n  {% if mime.startswith(\"application/pdf\") %}\n    <embed src=\"{{ file_url }}\" type=\"application/pdf\" width=\"100%\" height=\"800px\"/>\n  {% else %}\n    <p><a href=\"{{ file_url }}\">Download / Open</a></p>\n  {% endif %}\n{% endblock %}\n"
    },
    "uploads\\pdf\\01_supplier\\ReportGeneration_Cortex.html": {
      "sha": "76d2693be9e3",
      "lines": 10,
      "head": "<html>\n   <head>\n\t<title>\n         SymexUserManual\n    </title>\t\n   </head>\n<body>\n<embed src=\"ReportGeneration_Cortex.pdf\" width=\"100%\" height=\"100%\" />\n</body>\n</html>"
    },
    "uploads\\pdf\\01_supplier\\Restart_CORTEX_CC_services.html": {
      "sha": "fd1f948a36ac",
      "lines": 10,
      "head": "<html>\n   <head>\n\t<title>\n         SymexUserManual\n    </title>\t\n   </head>\n<body>\n<embed src=\"Restart_CORTEX_CC_services.pdf\" width=\"100%\" height=\"100%\" />\n</body>\n</html>"
    },
    "uploads\\pdf\\02_buyer\\Issuance_Fawri_Card_manual.html": {
      "sha": "bc65fc895362",
      "lines": 10,
      "head": "<html>\n   <head>\n\t<title>\n         SymexUserManual\n    </title>\t\n   </head>\n<body>\n<embed src=\"Issuance_Fawri_Card_manual.pdf\" width=\"100%\" height=\"100%\" />\n</body>\n</html>"
    },
    "uploads\\pdf\\02_buyer\\New Text Document.txt": {
      "sha": "da39a3ee5e6b",
      "lines": 0,
      "head": ""
    },
    "uploads\\pdf\\02_buyer\\SymexUserManual.html": {
      "sha": "710e53b59a3f",
      "lines": 10,
      "head": "<html>\n   <head>\n\t<title>\n         SymexUserManual\n    </title>\t\n   </head>\n<body>\n<embed src=\"SymexUserManual.pdf\" width=\"100%\" height=\"100%\" />\n</body>\n</html>"
    },
    "uploads\\pdf\\03_funder\\Cashier_System_Guide.html": {
      "sha": "0e6024fc8920",
      "lines": 10,
      "head": "<html>\n   <head>\n\t<title>\n         CashierUserManual\n    </title>\t\n   </head>\n<body>\n<embed src=\"Cashier_System_Guide.pdf\" width=\"100%\" height=\"100%\" />\n</body>\n</html>"
    }
  }
}